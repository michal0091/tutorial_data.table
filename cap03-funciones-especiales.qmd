# Funciones Especiales y An√°lisis Temporal

::: {.callout-tip icon="false"}
## En este cap√≠tulo dominar√°s
- **Funciones de ventana**: `shift()`, `frollmean()`, `frollapply()`
- **Funciones condicionales r√°pidas**: `fifelse()`, `fcase()`, `between()`
- **An√°lisis temporal avanzado** con series de tiempo
- **Funciones de agregaci√≥n especiales**: `frank()`, `rleid()`, `uniqueN()`
- **Operaciones con strings** optimizadas para data.table
- **An√°lisis de supervivencia** y detecci√≥n de patrones
:::

```{r}
#| label: setup-cap03-funciones-especiales
#| include: false

library(data.table)
library(ggplot2)
library(lubridate)
library(knitr)
library(DT)

# Configuraci√≥n
options(datatable.print.nrows = 8)
options(datatable.print.class = TRUE)

# Datasets para funciones especiales
set.seed(2024)

# Dataset financiero para an√°lisis temporal
precios_diarios <- data.table(
  fecha = rep(seq(as.Date("2024-01-01"), as.Date("2024-06-30"), by = "day"), 4),
  ticker = rep(c("AAPL", "GOOGL", "MSFT", "NVDA"), each = 182),
  precio_apertura = round(c(
    cumsum(rnorm(182, 0.2, 2)) + 180,   # AAPL
    cumsum(rnorm(182, 0.1, 10)) + 2800, # GOOGL
    cumsum(rnorm(182, 0.3, 3)) + 370,   # MSFT
    cumsum(rnorm(182, 1.0, 15)) + 600   # NVDA tendencia alcista
  ), 2),
  volumen = round(runif(728, 500000, 20000000), 0)
)

# Calcular precios derivados
precios_diarios[, `:=`(
  precio_cierre = precio_apertura + rnorm(.N, 0, 2),
  precio_max = precio_apertura + abs(rnorm(.N, 2, 1)),
  precio_min = precio_apertura - abs(rnorm(.N, 1, 0.5))
)]

# Asegurar l√≥gica de precios
precios_diarios[, `:=`(
  precio_cierre = pmax(precio_min, pmin(precio_max, precio_cierre)),
  precio_max = pmax(precio_apertura, precio_cierre, precio_max),
  precio_min = pmin(precio_apertura, precio_cierre, precio_min)
)]

# Dataset de clientes para an√°lisis de supervivencia
clientes_retencion <- data.table(
  cliente_id = 1:1000,
  fecha_registro = sample(seq(as.Date("2023-01-01"), as.Date("2024-01-01"), by = "day"), 1000, replace = TRUE),
  plan = sample(c("B√°sico", "Premium", "Empresarial"), 1000, replace = TRUE, prob = c(0.6, 0.3, 0.1)),
  edad = sample(18:75, 1000, replace = TRUE),
  pais = sample(c("Espa√±a", "M√©xico", "Argentina", "Colombia", "Chile"), 1000, replace = TRUE),
  ingresos_mensuales = round(exp(rnorm(1000, 8.5, 1)), 0),
  activo = sample(c(TRUE, FALSE), 1000, replace = TRUE, prob = c(0.75, 0.25)),
  fecha_ultima_actividad = NA
)

# Simular fechas de √∫ltima actividad para clientes activos
clientes_retencion[activo == TRUE, 
                   fecha_ultima_actividad := sample(seq(as.Date("2024-01-01"), as.Date("2024-06-30"), by = "day"), 
                                                   sum(activo), replace = TRUE)]

# Dataset de transacciones para an√°lisis de patrones
transacciones_comportamiento <- data.table(
  transaccion_id = 1:5000,
  cliente_id = sample(1:1000, 5000, replace = TRUE),
  fecha_transaccion = sample(seq(as.POSIXct("2024-01-01 00:00:00"), 
                                as.POSIXct("2024-06-30 23:59:59"), by = "hour"), 5000, replace = TRUE),
  categoria = sample(c("Alimentaci√≥n", "Transporte", "Entretenimiento", "Salud", "Educaci√≥n"), 
                    5000, replace = TRUE),
  monto = round(exp(rnorm(5000, 4, 1.2)), 2),
  metodo_pago = sample(c("Tarjeta", "Efectivo", "Digital"), 5000, replace = TRUE, prob = c(0.5, 0.3, 0.2)),
  comercio_id = sample(1:200, 5000, replace = TRUE)
)

# Dataset de sensores para an√°lisis de series temporales
sensores_temperatura <- data.table(
  timestamp = rep(seq(as.POSIXct("2024-06-01 00:00:00"), 
                     as.POSIXct("2024-06-07 23:59:59"), by = "15 min"), 3),
  sensor_id = rep(c("TEMP_A", "TEMP_B", "TEMP_C"), each = 672),
  temperatura = c(
    20 + 5*sin(seq(0, 14*pi, length.out = 672)) + rnorm(672, 0, 1),  # Patr√≥n senoidal para TEMP_A
    22 + 3*cos(seq(0, 14*pi, length.out = 672)) + rnorm(672, 0, 0.8), # Patr√≥n cosenoidal para TEMP_B
    cumsum(rnorm(672, 0, 0.5)) + 21 + rnorm(672, 0, 0.3)            # Random walk para TEMP_C
  ),
  ubicacion = rep(c("Almac√©n_A", "Almac√©n_B", "Almac√©n_C"), each = 672)
)

# Limpiar valores extremos
sensores_temperatura[temperatura < 5 | temperatura > 40, temperatura := NA]
```

## Funciones de Ventana (Window Functions)

Las funciones de ventana permiten realizar c√°lculos sobre un conjunto de filas relacionadas con la fila actual, sin colapsar el resultado como lo har√≠an las funciones de agregaci√≥n.

### 1. **`shift()`: Valores Anteriores y Posteriores**

```{r}
#| label: shift-basico
#| echo: true

# Calcular cambios diarios en precios
precios_con_lag <- precios_diarios[order(ticker, fecha)][,
  `:=`(
    precio_anterior = shift(precio_cierre, 1),          # t-1
    precio_siguiente = shift(precio_cierre, -1),        # t+1
    precio_3_dias_antes = shift(precio_cierre, 3),      # t-3
    volumen_anterior = shift(volumen, 1)
  ), by = ticker]

# Calcular m√©tricas de cambio
precios_con_lag[, `:=`(
  cambio_diario = precio_cierre - precio_anterior,
  cambio_pct = round((precio_cierre - precio_anterior) / precio_anterior * 100, 2),
  volatilidad_3d = round(abs(precio_cierre - precio_3_dias_antes) / precio_3_dias_antes * 100, 2),
  cambio_volumen = volumen - volumen_anterior
)]

print("An√°lisis de cambios diarios:")
print(head(precios_con_lag[!is.na(precio_anterior), 
                          .(ticker, fecha, precio_cierre, cambio_diario, cambio_pct, volatilidad_3d)], 10))
```

### 2. **`frollmean()` y Medias M√≥viles**

```{r}
#| label: frollmean-avanzado
#| echo: true

# M√∫ltiples medias m√≥viles para an√°lisis t√©cnico
precios_ma <- precios_diarios[order(ticker, fecha)][,
  `:=`(
    ma_5 = frollmean(precio_cierre, 5),           # Media m√≥vil 5 d√≠as
    ma_20 = frollmean(precio_cierre, 20),         # Media m√≥vil 20 d√≠as
    ma_50 = frollmean(precio_cierre, 50),         # Media m√≥vil 50 d√≠as
    volume_ma_10 = frollmean(volumen, 10),        # Media m√≥vil volumen 10 d√≠as
    volatilidad_20 = frollapply(precio_cierre, 20, sd, na.rm = TRUE)  # Volatilidad 20 d√≠as
  ), by = ticker]

# Se√±ales t√©cnicas basadas en cruces de medias m√≥viles
precios_ma[!is.na(ma_50), `:=`(
  se√±al_alcista = ma_5 > ma_20 & ma_20 > ma_50,
  se√±al_bajista = ma_5 < ma_20 & ma_20 < ma_50,
  precio_sobre_ma20 = precio_cierre > ma_20,
  volumen_alto = volumen > volume_ma_10 * 1.5
)]

# Resumen de se√±ales por ticker
se√±ales_resumen <- precios_ma[!is.na(se√±al_alcista), .(
  dias_analizados = .N,
  se√±ales_alcistas = sum(se√±al_alcista, na.rm = TRUE),
  se√±ales_bajistas = sum(se√±al_bajista, na.rm = TRUE),
  dias_sobre_ma20 = sum(precio_sobre_ma20, na.rm = TRUE),
  volatilidad_promedio = round(mean(volatilidad_20, na.rm = TRUE), 2)
), by = ticker]

print("Resumen de se√±ales t√©cnicas:")
print(se√±ales_resumen)
```

### 3. **`frollapply()`: Funciones Personalizadas**

```{r}
#| label: frollapply-personalizado
#| echo: true

# Funciones personalizadas para an√°lisis de ventana
precios_estadisticas <- precios_diarios[order(ticker, fecha)][,
  `:=`(
    rango_10d = frollapply(precio_cierre, 10, function(x) max(x) - min(x)),
    percentil_75_20d = frollapply(precio_cierre, 20, function(x) quantile(x, 0.75, na.rm = TRUE)),
    coef_variacion_15d = frollapply(precio_cierre, 15, function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)),
    precio_z_score_30d = frollapply(precio_cierre, 30, function(x) {
      if(length(x) < 30) return(NA)
      (tail(x, 1) - mean(x)) / sd(x)
    }),
    tendencia_5d = frollapply(precio_cierre, 5, function(x) {
      if(length(x) < 5) return(NA)
      lm_result <- lm(x ~ seq_along(x))
      coef(lm_result)[2]  # Pendiente
    })
  ), by = ticker]

# An√°lisis de distribuciones y outliers
analisis_outliers <- precios_estadisticas[!is.na(precio_z_score_30d), .(
  ticker,
  fecha,
  precio_cierre,
  z_score = round(precio_z_score_30d, 2),
  coef_var = round(coef_variacion_15d, 3),
  tendencia = round(tendencia_5d, 4),
  outlier_extremo = abs(precio_z_score_30d) > 2
)][outlier_extremo == TRUE][order(-abs(z_score))]

print("Precios con comportamiento outlier (|z-score| > 2):")
print(head(analisis_outliers, 10))
```

## Funciones Condicionales Optimizadas

### 1. **`fifelse()`: Condicionales R√°pidas**

```{r}
#| label: fifelse-optimizado
#| echo: true

# Comparaci√≥n de rendimiento: fifelse vs ifelse
clientes_clasificacion <- copy(clientes_retencion)

# fifelse para clasificaciones m√∫ltiples y anidadas
clientes_clasificacion[, `:=`(
  segmento_edad = fifelse(
    edad < 25, "Joven",
    fifelse(edad < 45, "Adulto", "Senior")
  ),
  categoria_ingresos = fifelse(
    ingresos_mensuales < 2000, "Bajos",
    fifelse(ingresos_mensuales < 5000, "Medios", "Altos")
  ),
  tipo_cliente = fifelse(
    plan == "Empresarial", "Corporativo",
    fifelse(activo & ingresos_mensuales > 3000, "Premium_Activo", "Est√°ndar")
  )
)]

# An√°lisis de segmentos
segmentos_analisis <- clientes_clasificacion[, .(
  clientes = .N,
  ingresos_promedio = round(mean(ingresos_mensuales), 0),
  tasa_actividad = round(mean(activo) * 100, 1),
  planes_premium = sum(plan %in% c("Premium", "Empresarial"))
), by = .(segmento_edad, categoria_ingresos, tipo_cliente)]

print("An√°lisis de segmentos de clientes:")
print(segmentos_analisis[order(-clientes)])
```

### 2. **`fcase()`: M√∫ltiples Condiciones Elegantes**

```{r}
#| label: fcase-multiples-condiciones
#| echo: true

# Sistema de scoring complejo con fcase
clientes_clasificacion[, score_retencion := fcase(
  # Casos de alto valor
  plan == "Empresarial" & activo & ingresos_mensuales > 5000, 95,
  plan == "Premium" & activo & ingresos_mensuales > 3000, 85,
  plan == "B√°sico" & activo & ingresos_mensuales > 4000, 80,
  
  # Casos de riesgo medio
  !activo & ingresos_mensuales > 3000 & !is.na(fecha_ultima_actividad), 60,
  activo & ingresos_mensuales < 2000, 55,
  
  # Casos de alto riesgo
  !activo & is.na(fecha_ultima_actividad), 20,
  !activo & ingresos_mensuales < 2000, 15,
  
  # Caso por defecto
  default = 50
)]

# Estrategia de retenci√≥n basada en score
clientes_clasificacion[, estrategia_retencion := fcase(
  score_retencion >= 90, "Mantener_Premium",
  score_retencion >= 70, "Fidelizar_Activo", 
  score_retencion >= 50, "Reactivar_Moderado",
  score_retencion >= 30, "Reactivar_Intensivo",
  default = "Evaluar_Cancelaci√≥n"
)]

# Resumen estrat√©gico
resumen_estrategia <- clientes_clasificacion[, .(
  clientes = .N,
  score_promedio = round(mean(score_retencion), 1),
  ingresos_totales = sum(ingresos_mensuales),
  valor_cliente_promedio = round(mean(ingresos_mensuales), 0)
), by = estrategia_retencion][order(-score_promedio)]

print("Estrategias de retenci√≥n por score:")
print(resumen_estrategia)
```

### 3. **`between()`: Rangos Eficientes**

```{r}
#| label: between-rangos
#| echo: true

# Usar between para clasificaciones por rangos
transacciones_analisis <- copy(transacciones_comportamiento)

transacciones_analisis[, `:=`(
  # Clasificaci√≥n por monto usando between
  categoria_monto = fcase(
    between(monto, 0, 20), "Micro",
    between(monto, 20.01, 100), "Peque√±a", 
    between(monto, 100.01, 500), "Mediana",
    between(monto, 500.01, 2000), "Grande",
    monto > 2000, "Muy Grande",
    default = "Sin Clasificar"
  ),
  
  # Clasificaci√≥n temporal
  hora = hour(fecha_transaccion),
  franja_horaria = fcase(
    between(hour(fecha_transaccion), 6, 11), "Ma√±ana",
    between(hour(fecha_transaccion), 12, 17), "Tarde", 
    between(hour(fecha_transaccion), 18, 22), "Noche",
    default = "Madrugada"
  ),
  
  # D√≠a de la semana
  dia_semana = wday(fecha_transaccion, label = TRUE),
  es_fin_semana = wday(fecha_transaccion) %in% c(1, 7)
)]

# An√°lisis de patrones de comportamiento
patrones_comportamiento <- transacciones_analisis[, .(
  transacciones = .N,
  monto_promedio = round(mean(monto), 2),
  monto_mediana = round(median(monto), 2),
  monto_total = round(sum(monto), 2)
), by = .(categoria_monto, franja_horaria, es_fin_semana)][
  order(-transacciones)
]

print("Patrones de comportamiento transaccional:")
print(head(patrones_comportamiento, 12))
```

## Funciones de Agregaci√≥n Especiales

### 1. **`frank()`: Rankings y Percentiles**

```{r}
#| label: frank-rankings
#| echo: true

# Rankings complejos con frank()
rankings_clientes <- clientes_clasificacion[, `:=`(
  # Ranking por ingresos (descendente)
  rank_ingresos = frank(-ingresos_mensuales),
  rank_ingresos_pct = frank(-ingresos_mensuales / .N * 100),
  
  # Ranking por score de retenci√≥n
  rank_retencion = frank(-score_retencion),
  
  # Ranking dentro de cada plan
  rank_en_plan = frank(.SD[,-ingresos_mensuales, by = plan]),
  rank_en_pais = frank(.SD[,-ingresos_mensuales, by = pais])
)]

# Top performers por categor√≠a
top_performers <- rankings_clientes[rank_ingresos <= 50, .(
  cliente_id, plan, pais, ingresos_mensuales, score_retencion,
  rank_global = rank_ingresos,
  rank_en_plan, rank_en_pais,
  percentil_ingresos = round(100 - rank_ingresos_pct, 1)
)][order(rank_global)]

print("Top 10 clientes por ingresos:")
print(head(top_performers, 10))
```

### 2. **`rleid()`: Identificaci√≥n de Runs**

```{r}
#| label: rleid-runs
#| echo: true

# Identificar secuencias de comportamiento con rleid()
sensores_runs <- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(
  # Clasificar temperatura en rangos
  temp_categoria = fcase(
    temperatura < 18, "Baja",
    between(temperatura, 18, 22), "Normal",
    between(temperatura, 22, 26), "Alta",
    temperatura > 26, "Muy Alta",
    default = "Sin Datos"
  )
)][, `:=`(
  # Identificar runs (secuencias consecutivas)
  run_id = rleid(temp_categoria),
  # Tambi√©n podemos identificar runs de tendencia
  tendencia = fcase(
    temperatura > shift(temperatura, 1), "Subida",
    temperatura < shift(temperatura, 1), "Bajada", 
    default = "Estable"
  )
), by = sensor_id][, `:=`(
  run_tendencia = rleid(tendencia)
), by = sensor_id]

# An√°lisis de runs de temperatura
analisis_runs <- sensores_runs[!is.na(temperatura), .(
  duracion_run = .N,
  temp_promedio = round(mean(temperatura, na.rm = TRUE), 1),
  temp_min = round(min(temperatura, na.rm = TRUE), 1),
  temp_max = round(max(temperatura, na.rm = TRUE), 1),
  inicio_run = min(timestamp),
  fin_run = max(timestamp)
), by = .(sensor_id, temp_categoria, run_id)][
  duracion_run >= 4  # Solo runs de al menos 4 mediciones (1 hora)
][order(sensor_id, -duracion_run)]

print("Runs de temperatura m√°s largos:")
print(head(analisis_runs, 12))
```

### 3. **`uniqueN()`: Conteos de √önicos Eficientes**

```{r}
#| label: uniqueN-eficiente
#| echo: true

# An√°lisis de diversidad con uniqueN()
diversidad_transacciones <- transacciones_analisis[, .(
  # Diversidad b√°sica
  transacciones_totales = .N,
  categorias_usadas = uniqueN(categoria),
  comercios_visitados = uniqueN(comercio_id),
  metodos_pago_usados = uniqueN(metodo_pago),
  
  # M√©tricas de comportamiento
  dias_activos = uniqueN(as.Date(fecha_transaccion)),
  horas_activas = uniqueN(hour(fecha_transaccion)),
  monto_promedio = round(mean(monto), 2),
  
  # Diversidad temporal
  meses_activos = uniqueN(month(fecha_transaccion)),
  dias_semana_activos = uniqueN(wday(fecha_transaccion))
), by = cliente_id]

# Calcular √≠ndices de diversidad
diversidad_transacciones[, `:=`(
  indice_diversidad_categoria = round(categorias_usadas / 5 * 100, 1),  # 5 categor√≠as posibles
  indice_diversidad_temporal = round(horas_activas / 24 * 100, 1),      # 24 horas posibles
  indice_actividad = round(dias_activos / 180 * 100, 1),                # ~180 d√≠as en periodo
  score_engagement = round((categorias_usadas * 10) + (dias_activos * 2) + (comercios_visitados * 3), 0)
)]

# Clasificar clientes por engagement
diversidad_transacciones[, categoria_engagement := fcase(
  score_engagement > 200, "Muy Alto",
  score_engagement > 100, "Alto",
  score_engagement > 50, "Medio", 
  score_engagement > 20, "Bajo",
  default = "Muy Bajo"
)]

# Resumen por categor√≠a de engagement
resumen_engagement <- diversidad_transacciones[, .(
  clientes = .N,
  transacciones_promedio = round(mean(transacciones_totales), 1),
  diversidad_categoria_promedio = round(mean(indice_diversidad_categoria), 1),
  score_promedio = round(mean(score_engagement), 0)
), by = categoria_engagement][order(-score_promedio)]

print("An√°lisis de engagement de clientes:")
print(resumen_engagement)
```

## An√°lisis Temporal Avanzado

### 1. **Detecci√≥n de Anomal√≠as Temporales**

```{r}
#| label: anomalias-temporales
#| echo: true

# Sistema de detecci√≥n de anomal√≠as para sensores
anomalias_sensores <- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(
  # Medias m√≥viles para diferentes ventanas
  temp_ma_short = frollmean(temperatura, 4, na.rm = TRUE),    # 1 hora
  temp_ma_long = frollmean(temperatura, 24, na.rm = TRUE),    # 6 horas
  temp_sd_window = frollapply(temperatura, 12, sd, na.rm = TRUE), # Desviaci√≥n m√≥vil
  
  # Cambios absolutos
  cambio_temp = abs(temperatura - shift(temperatura, 1)),
  cambio_temp_2 = abs(temperatura - shift(temperatura, 2))
), by = sensor_id][, `:=`(
  # Detecci√≥n de anomal√≠as
  anomalia_spike = cambio_temp > 3,  # Cambio s√∫bito > 3 grados
  anomalia_drift = !is.na(temp_ma_long) & abs(temperatura - temp_ma_long) > 5, # Desviaci√≥n > 5 grados de media larga
  anomalia_variabilidad = !is.na(temp_sd_window) & temp_sd_window > 2 # Alta variabilidad
  
 
)]

# Score compuesto de anomal√≠a
anomalias_sensores[, score_anomalia := (as.numeric(anomalia_spike) * 3) + 
                  (as.numeric(anomalia_drift) * 2) + 
                  (as.numeric(anomalia_variabilidad) * 1)]


# Resumen de anomal√≠as por sensor
resumen_anomalias <- anomalias_sensores[!is.na(temperatura), .(
  lecturas_totales = .N,
  anomalias_spike = sum(anomalia_spike, na.rm = TRUE),
  anomalias_drift = sum(anomalia_drift, na.rm = TRUE),
  anomalias_variabilidad = sum(anomalia_variabilidad, na.rm = TRUE),
  score_promedio = round(mean(score_anomalia, na.rm = TRUE), 2),
  temp_min = round(min(temperatura, na.rm = TRUE), 1),
  temp_max = round(max(temperatura, na.rm = TRUE), 1)
), by = .(sensor_id, ubicacion)]

print("Resumen de anomal√≠as por sensor:")
print(resumen_anomalias)

# Top anomal√≠as individuales
top_anomalias <- anomalias_sensores[score_anomalia >= 2, .(
  sensor_id, timestamp, temperatura, temp_ma_long, 
  cambio_temp, score_anomalia
)][order(-score_anomalia)]

if(nrow(top_anomalias) > 0) {
  print("\nTop anomal√≠as detectadas:")
  print(head(top_anomalias, 8))
} else {
  cat("\nNo se detectaron anomal√≠as significativas (score >= 2)\n")
}
```

### 2. **An√°lisis de Ciclos y Estacionalidad**

```{r}
#| label: ciclos-estacionalidad
#| echo: true

# An√°lisis de patrones c√≠clicos en datos de sensores
patrones_ciclicos <- sensores_temperatura[!is.na(temperatura)][, `:=`(
  hora = hour(timestamp),
  dia = as.numeric(as.Date(timestamp) - min(as.Date(timestamp))) + 1,
  minuto_del_dia = hour(timestamp) * 60 + minute(timestamp)
)][, .(
  temperatura_promedio = round(mean(temperatura), 1),
  temperatura_sd = round(sd(temperatura), 2),
  lecturas = .N
), by = .(sensor_id, hora)]

# Identificar patrones horarios
patrones_resumen <- patrones_ciclicos[, .(
  hora_mas_fria = hora[which.min(temperatura_promedio)],
  temp_mas_fria = min(temperatura_promedio),
  hora_mas_calida = hora[which.max(temperatura_promedio)],
  temp_mas_calida = max(temperatura_promedio),
  amplitud_termica = round(max(temperatura_promedio) - min(temperatura_promedio), 1),
  variabilidad_promedio = round(mean(temperatura_sd), 2)
), by = sensor_id]

print("Patrones t√©rmicos diarios por sensor:")
print(patrones_resumen)
```

## Ejercicios Pr√°cticos

::: {.callout-note icon="false"}
## üèãÔ∏è Ejercicio 11: Sistema de Alertas de Anomal√≠as

Usando los datasets de sensores y transacciones:

1. **Implementa** un sistema de detecci√≥n de anomal√≠as multicapa
2. **Usa `frollapply()`** para ventanas personalizadas de detecci√≥n
3. **Clasifica anomal√≠as** con `fcase()` por severidad
4. **Genera alertas** autom√°ticas con `rleid()` para secuencias an√≥malas

:::

::: {.callout-tip collapse="true"}
## üí° Soluci√≥n del Ejercicio 11

```{r}
#| label: solucion-ejercicio-11
#| echo: true

# Sistema completo de detecci√≥n de anomal√≠as multicapa
# CAPA 1: Anomal√≠as estad√≠sticas
sistema_anomalias <- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(
  # Ventanas de referencia
  temp_ma_1h = frollmean(temperatura, 4, na.rm = TRUE),
  temp_ma_6h = frollmean(temperatura, 24, na.rm = TRUE), 
  temp_ma_24h = frollmean(temperatura, 96, na.rm = TRUE),
  
  # Medidas de variabilidad
  temp_sd_1h = frollapply(temperatura, 4, sd, na.rm = TRUE),
  temp_sd_6h = frollapply(temperatura, 24, sd, na.rm = TRUE),
  
  # Percentiles m√≥viles
  temp_p25_6h = frollapply(temperatura, 24, function(x) quantile(x, 0.25, na.rm = TRUE)),
  temp_p75_6h = frollapply(temperatura, 24, function(x) quantile(x, 0.75, na.rm = TRUE)),
  
  # Cambios temporales
  cambio_15min = abs(temperatura - shift(temperatura, 1)),
  cambio_1h = abs(temperatura - shift(temperatura, 4)),
  tendencia_1h = frollapply(temperatura, 4, function(x) {
    if(length(x) < 4) return(0)
    lm(x ~ seq_along(x))$coefficients[2]
  })
), by = sensor_id][, `:=`(
  # CAPA 2: Detecci√≥n de anomal√≠as espec√≠ficas
  anomalia_spike = cambio_15min > 5,  # Cambio s√∫bito > 5¬∞C
  anomalia_drift = !is.na(temp_ma_6h) & abs(temperatura - temp_ma_6h) > 4, # Drift > 4¬∞C
  anomalia_variabilidad = !is.na(temp_sd_1h) & temp_sd_1h > 3, # Alta variabilidad
  anomalia_outlier = !is.na(temp_p25_6h) & !is.na(temp_p75_6h) & 
                    (temperatura < (temp_p25_6h - 1.5*(temp_p75_6h - temp_p25_6h)) |
                     temperatura > (temp_p75_6h + 1.5*(temp_p75_6h - temp_p25_6h))),
  anomalia_tendencia = !is.na(tendencia_1h) & abs(tendencia_1h) > 1, # Tendencia > 1¬∞C/15min
  anomalia_frozen = !is.na(temp_sd_1h) & temp_sd_1h < 0.1 & !is.na(temperatura)  # Sensor "congelado"
)]

# CAPA 3: Clasificaci√≥n por severidad con fcase()
sistema_anomalias[, `:=`(
  # Score compuesto
  score_anomalia = (as.numeric(anomalia_spike) * 5) + 
                  (as.numeric(anomalia_drift) * 3) +
                  (as.numeric(anomalia_variabilidad) * 2) +
                  (as.numeric(anomalia_outlier) * 2) +
                  (as.numeric(anomalia_tendencia) * 4) +
                  (as.numeric(anomalia_frozen) * 6)
)][, severidad := fcase(
  score_anomalia >= 10, "CR√çTICA",
  score_anomalia >= 6, "ALTA", 
  score_anomalia >= 3, "MEDIA",
  score_anomalia >= 1, "BAJA",
  default = "NORMAL"
)]

# CAPA 4: Detecci√≥n de secuencias an√≥malas con rleid()
sistema_anomalias[, `:=`(
  es_anomalo = severidad != "NORMAL",
  secuencia_id = rleid(severidad != "NORMAL")
), by = sensor_id]

# An√°lisis de secuencias an√≥malas
secuencias_anomalas <- sistema_anomalias[es_anomalo == TRUE, .(
  duracion_minutos = .N * 15,  # 15 min por medici√≥n
  severidad_maxima = severidad[which.max(score_anomalia)],
  score_maximo = max(score_anomalia),
  score_promedio = round(mean(score_anomalia), 1),
  temp_min = round(min(temperatura, na.rm = TRUE), 1),
  temp_max = round(max(temperatura, na.rm = TRUE), 1),
  inicio = min(timestamp),
  fin = max(timestamp),
  tipos_anomalia = paste(unique(c(
    if(any(anomalia_spike)) "SPIKE",
    if(any(anomalia_drift)) "DRIFT", 
    if(any(anomalia_variabilidad)) "VARIABILIDAD",
    if(any(anomalia_outlier)) "OUTLIER",
    if(any(anomalia_tendencia)) "TENDENCIA",
    if(any(anomalia_frozen)) "FROZEN"
  )), collapse = ", ")
), by = .(sensor_id, secuencia_id)][
  duracion_minutos >= 30  # Solo secuencias de al menos 30 minutos
][order(-score_maximo)]

# SISTEMA DE ALERTAS AUTOM√ÅTICAS
cat("üö® SISTEMA DE ALERTAS DE ANOMAL√çAS üö®\n\n")

# Alertas activas por sensor
alertas_activas <- sistema_anomalias[es_anomalo == TRUE, .N, by = .(sensor_id, severidad)][order(sensor_id, severidad)]

if(nrow(alertas_activas) > 0) {
  cat("ALERTAS ACTIVAS POR SENSOR:\n")
  print(alertas_activas)
} else {
  cat("‚úÖ No hay alertas activas en este momento.\n")
}

# Top secuencias cr√≠ticas
if(nrow(secuencias_anomalas) > 0) {
  cat("\nüî• TOP SECUENCIAS AN√ìMALAS:\n")
  print(head(secuencias_anomalas[, .(sensor_id, severidad_maxima, duracion_minutos, 
                                    score_maximo, tipos_anomalia, inicio)], 8))
} else {
  cat("\n‚úÖ No se detectaron secuencias an√≥malas significativas.\n")
}

# Resumen estad√≠stico
resumen_sistema <- sistema_anomalias[!is.na(temperatura), .(
  lecturas_totales = .N,
  anomalias_detectadas = sum(es_anomalo),
  pct_anomalias = round(mean(es_anomalo) * 100, 2),
  score_promedio = round(mean(score_anomalia), 2)
), by = sensor_id]

cat("\nüìä RESUMEN DEL SISTEMA:\n")
print(resumen_sistema)

# # Crear tabla interactiva de secuencias cr√≠ticas (comentado para PDF)
# if(nrow(secuencias_anomalas) > 0) {
#   DT::datatable(
#     secuencias_anomalas[1:min(20, nrow(secuencias_anomalas))],
#     caption = "Secuencias An√≥malas Detectadas - Sistema Multicapa",
#     options = list(pageLength = 10, scrollX = TRUE)
#   ) %>%
#     DT::formatStyle(
#       "severidad_maxima",
#       backgroundColor = DT::styleEqual(
#         c("CR√çTICA", "ALTA", "MEDIA", "BAJA"),
#         c("red", "orange", "yellow", "lightblue")
#       )
#     )
# }
```
:::

::: {.callout-note icon="false"}
## üèãÔ∏è Ejercicio 12: An√°lisis de Supervivencia de Clientes

1. **Calcula m√©tricas temporales** con `shift()` y funciones de ventana
2. **Identifica patrones de churn** usando `rleid()` para secuencias de inactividad
3. **Clasifica riesgo de abandono** con `fcase()` m√∫ltiples criterios
4. **Genera score predictivo** combinando m√∫ltiples se√±ales

:::

::: {.callout-tip collapse="true"}
## üí° Soluci√≥n del Ejercicio 12

```{r}
#| label: solucion-ejercicio-12
#| echo: true

# An√°lisis de supervivencia y predicci√≥n de churn
# 1. Preparar datos temporales con m√©tricas de ventana
analisis_supervivencia <- clientes_retencion[, `:=`(
  dias_desde_registro = as.numeric(as.Date("2024-06-30") - fecha_registro),
  dias_desde_ultima_actividad = fifelse(
    is.na(fecha_ultima_actividad), 
    as.numeric(as.Date("2024-06-30") - fecha_registro),
    as.numeric(as.Date("2024-06-30") - fecha_ultima_actividad)
  )
)]

# Combinar con datos transaccionales para an√°lisis de comportamiento
comportamiento_clientes <- transacciones_comportamiento[, .(
  transacciones_totales = .N,
  gasto_total = sum(monto),
  gasto_promedio = round(mean(monto), 2),
  dias_activos = uniqueN(as.Date(fecha_transaccion)),
  categorias_usadas = uniqueN(categoria),
  ultima_transaccion = max(as.Date(fecha_transaccion)),
  primera_transaccion = min(as.Date(fecha_transaccion))
), by = cliente_id]

# Join con datos de clientes
supervivencia_completa <- analisis_supervivencia[
  comportamiento_clientes, on = .(cliente_id), nomatch = NULL
][, `:=`(
  dias_desde_primera_trans = as.numeric(as.Date("2024-06-30") - primera_transaccion),
  dias_desde_ultima_trans = as.numeric(as.Date("2024-06-30") - ultima_transaccion),
  frecuencia_transaccional = round(transacciones_totales / dias_activos, 2)
)]

# 2. Identificar patrones de declive con funciones de ventana
# Simular datos de actividad mensual para an√°lisis temporal
actividad_mensual <- supervivencia_completa[, .(
  cliente_id, activo, ingresos_mensuales, gasto_total, transacciones_totales
)][, .(
  cliente_id, 
  mes = rep(1:6, .N),
  actividad_simulada = as.numeric(activo) * exp(-abs(rnorm(.N * 6, 0, 0.3))),
  gasto_simulado = rep(gasto_total / 6, 6) * exp(rnorm(.N * 6, 0, 0.4))
), by = cliente_id][order(cliente_id, mes)]

# Aplicar funciones de ventana para detectar tendencias
actividad_tendencias <- actividad_mensual[, `:=`(
  actividad_ma3 = frollmean(actividad_simulada, 3),
  gasto_ma3 = frollmean(gasto_simulado, 3),
  actividad_anterior = shift(actividad_simulada, 1),
  gasto_anterior = shift(gasto_simulado, 1),
  tendencia_actividad = actividad_simulada - shift(actividad_simulada, 1),
  secuencia_declive = rleid(actividad_simulada < shift(actividad_simulada, 1))
), by = cliente_id]

# 3. An√°lisis de riesgo de churn con m√∫ltiples criterios
modelo_churn <- supervivencia_completa[, `:=`(
  # Se√±ales de riesgo temporal
  riesgo_inactividad = fcase(
    dias_desde_ultima_trans > 90, "ALTO",
    dias_desde_ultima_trans > 60, "MEDIO",
    dias_desde_ultima_trans > 30, "BAJO",
    default = "M√çNIMO"
  ),
  
  # Se√±ales de comportamiento
  riesgo_engagement = fcase(
    frecuencia_transaccional < 0.1 & categorias_usadas <= 2, "ALTO",
    frecuencia_transaccional < 0.3 & categorias_usadas <= 3, "MEDIO", 
    frecuencia_transaccional < 0.5, "BAJO",
    default = "M√çNIMO"
  ),
  
  # Se√±ales econ√≥micas
  riesgo_economico = fcase(
    gasto_promedio < ingresos_mensuales * 0.01, "ALTO",  # Gasta <1% de ingresos
    gasto_promedio < ingresos_mensuales * 0.03, "MEDIO", # Gasta <3% de ingresos
    gasto_promedio < ingresos_mensuales * 0.05, "BAJO",  # Gasta <5% de ingresos
    default = "M√çNIMO"
  ),
  
  # Se√±al de valor del cliente
  valor_cliente = round((gasto_total / dias_activos) * (ingresos_mensuales / 1000), 0)
)][, `:=`(
  # Score compuesto de riesgo de churn
  score_churn = (
    (riesgo_inactividad == "ALTO") * 40 + (riesgo_inactividad == "MEDIO") * 25 + (riesgo_inactividad == "BAJO") * 10 +
    (riesgo_engagement == "ALTO") * 30 + (riesgo_engagement == "MEDIO") * 20 + (riesgo_engagement == "BAJO") * 10 +
    (riesgo_economico == "ALTO") * 20 + (riesgo_economico == "MEDIO") * 12 + (riesgo_economico == "BAJO") * 5 +
    ifelse(!activo, 25, 0)  # Penalizaci√≥n por inactividad actual
  )
)][, `:=`(
  # 4. Clasificaci√≥n final y estrategia
  clasificacion_churn = fcase(
    score_churn >= 80, "CHURN_INMEDIATO",
    score_churn >= 60, "ALTO_RIESGO", 
    score_churn >= 40, "RIESGO_MODERADO",
    score_churn >= 20, "BAJO_RIESGO",
    default = "SALUDABLE"
  ),
  
  estrategia_retencion = fcase(
    score_churn >= 80, "Contacto_Inmediato + Oferta_Especial",
    score_churn >= 60, "Programa_Reactivaci√≥n + Descuentos",
    score_churn >= 40, "Comunicaci√≥n_Personalizada", 
    score_churn >= 20, "Monitoreo_Activo",
    default = "Mantenimiento_Rutinario"
  )
)]

# An√°lisis de resultados
cat("üìà AN√ÅLISIS DE SUPERVIVENCIA DE CLIENTES üìà\n\n")

# Distribuci√≥n por clasificaci√≥n
distribucion_churn <- modelo_churn[, .N, by = clasificacion_churn][order(-N)]
cat("DISTRIBUCI√ìN POR RIESGO DE CHURN:\n")
print(distribucion_churn)

# Estad√≠sticas por grupo de riesgo
stats_por_riesgo <- modelo_churn[, .(
  clientes = .N,
  score_promedio = round(mean(score_churn), 1),
  ingresos_promedio = round(mean(ingresos_mensuales), 0),
  valor_cliente_promedio = round(mean(valor_cliente), 0),
  dias_inactividad_promedio = round(mean(dias_desde_ultima_trans), 0),
  tasa_actividad_actual = round(mean(activo) * 100, 1)
), by = clasificacion_churn][order(-score_promedio)]

cat("\nüìä ESTAD√çSTICAS POR GRUPO DE RIESGO:\n")
print(stats_por_riesgo)

# Clientes cr√≠ticos que requieren atenci√≥n inmediata
clientes_criticos <- modelo_churn[clasificacion_churn %in% c("CHURN_INMEDIATO", "ALTO_RIESGO"), .(
  cliente_id, plan, pais, ingresos_mensuales, valor_cliente, 
  score_churn, clasificacion_churn, estrategia_retencion,
  dias_inactividad = dias_desde_ultima_trans
)][order(-score_churn)]

cat("\nüö® CLIENTES QUE REQUIEREN ATENCI√ìN INMEDIATA:\n")
print(head(clientes_criticos, 10))

# ROI potencial de estrategias de retenci√≥n
roi_estrategias <- modelo_churn[, .(
  clientes_objetivo = .N,
  valor_total_riesgo = sum(valor_cliente),
  valor_promedio_cliente = round(mean(valor_cliente), 0),
  inversion_retencion_estimada = .N * fcase(
    unique(clasificacion_churn) == "CHURN_INMEDIATO", 200,
    unique(clasificacion_churn) == "ALTO_RIESGO", 100,
    unique(clasificacion_churn) == "RIESGO_MODERADO", 50,
    default = 20
  ),
  roi_potencial = round((sum(valor_cliente) * 0.7) / (.N * fcase(
    unique(clasificacion_churn) == "CHURN_INMEDIATO", 200,
    unique(clasificacion_churn) == "ALTO_RIESGO", 100, 
    unique(clasificacion_churn) == "RIESGO_MODERADO", 50,
    default = 20
  )), 1)
), by = .(clasificacion_churn, estrategia_retencion)][order(-roi_potencial)]

cat("\nüí∞ AN√ÅLISIS DE ROI DE ESTRATEGIAS:\n")
print(roi_estrategias)
```
:::

---

::: {.callout-important}
## üéØ Puntos Clave de Este Cap√≠tulo

1. **Funciones de ventana** (`shift`, `frollmean`, `frollapply`) permiten an√°lisis temporal sofisticado sin colapsar datos
2. **Funciones condicionales** (`fifelse`, `fcase`, `between`) optimizan clasificaciones complejas
3. **Funciones de agregaci√≥n especiales** (`frank`, `rleid`, `uniqueN`) revelan patrones ocultos en los datos
4. **An√°lisis temporal** combina m√∫ltiples t√©cnicas para detecci√≥n de anomal√≠as y predicci√≥n
5. **Performance**: Estas funciones est√°n altamente optimizadas y son significativamente m√°s r√°pidas que alternativas de R base
6. **Casos de uso reales**: Finanzas, IoT, an√°lisis de comportamiento - las aplicaciones son ilimitadas
:::

Las funciones especiales de `data.table` te dan superpoderes para an√°lisis complejos. En el pr√≥ximo cap√≠tulo exploraremos las t√©cnicas de reshape que complementan perfectamente estas funciones para transformaciones de datos avanzadas.

