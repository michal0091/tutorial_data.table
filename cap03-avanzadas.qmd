# Técnicas Avanzadas y Funciones Especiales {#sec-avanzadas}

::: {.callout-tip icon="false"}
## En este capítulo dominarás
- **Símbolos especiales avanzados**: `.SD`, `.SDcols`, `.I`, `.GRP` 
- **Non-equi joins**: Uniones basadas en rangos e inequidades
- **Rolling joins**: La joya de la corona para análisis temporal
- **Reshape de datos**: `melt()` y `dcast()` para transformaciones
- **Funciones de ventana** y análisis de series temporales
:::

```{r}
#| label: setup-cap03
#| include: false

library(data.table)
library(ggplot2)
library(lubridate)
library(knitr)
library(DT)

# Configuración
options(datatable.print.nrows = 8)
options(datatable.print.class = TRUE)

# Datasets para ejemplos avanzados
set.seed(2024)

# Dataset financiero para rolling joins
precios_acciones <- data.table(
  fecha = seq(as.Date("2024-01-01"), as.Date("2024-12-31"), by = "day"),
  accion = rep(c("AAPL", "GOOGL", "MSFT", "TSLA"), each = 92),
  precio = round(c(
    rnorm(92, 150, 10),  # AAPL
    rnorm(92, 2800, 200), # GOOGL  
    rnorm(92, 350, 25),   # MSFT
    rnorm(92, 200, 30)    # TSLA
  ), 2)
)[precio > 0]  # Asegurar precios positivos

# Dataset de transacciones para rolling joins
transacciones_fecha <- data.table(
  trans_id = 1:1000,
  accion = sample(c("AAPL", "GOOGL", "MSFT", "TSLA"), 1000, replace = TRUE),
  fecha_transaccion = sample(seq(as.Date("2024-01-01"), as.Date("2024-12-31"), by = "day"), 1000, replace = TRUE),
  cantidad = sample(1:100, 1000, replace = TRUE),
  tipo = sample(c("Compra", "Venta"), 1000, replace = TRUE)
)

# Dataset de pacientes para non-equi joins
pacientes <- data.table(
  paciente_id = 1:20,
  edad = sample(20:80, 20, replace = TRUE),
  glucosa = round(runif(20, 70, 250), 1),
  presion_sistolica = sample(90:180, 20, replace = TRUE),
  peso = round(rnorm(20, 70, 15), 1)
)[peso > 40]

# Rangos médicos para clasificación
rangos_glucosa <- data.table(
  min_glucosa = c(0, 100, 126),
  max_glucosa = c(99, 125, 300),
  categoria = c("Normal", "Prediabetes", "Diabetes")
)

# Dataset para reshape
ventas_wide <- data.table(
  producto = c("Laptop", "Mouse", "Teclado", "Monitor"),
  Q1_2023 = c(150, 300, 250, 100),
  Q2_2023 = c(180, 280, 270, 120),
  Q3_2023 = c(200, 320, 290, 110),
  Q4_2023 = c(220, 350, 310, 130),
  Q1_2024 = c(190, 330, 280, 140)
)

# Dataset de sensores para análisis temporal
sensores <- data.table(
  timestamp = seq(as.POSIXct("2024-01-01 00:00:00"), 
                 as.POSIXct("2024-01-07 23:59:59"), 
                 by = "5 min"),
  sensor_id = rep(c("S001", "S002", "S003"), length.out = 2016),
  temperatura = round(rnorm(2016, 20, 5), 1),
  humedad = round(runif(2016, 30, 90), 1)
)
```

## Los Símbolos Especiales: Poder Avanzado

### 1. **`.SD`: El Subset de Datos**

`.SD` es un `data.table` que contiene el **Subset of Data** para el grupo actual, excluyendo las columnas de agrupación:

```{r}
#| label: SD-basico
#| echo: true

# Ver qué contiene .SD en cada grupo
precios_muestra <- precios_acciones[1:20]
precios_muestra[, {
  cat("Acción:", .BY[[1]], "- Filas en .SD:", nrow(.SD), "\n")
  list(filas = nrow(.SD))
}, by = accion]
```

#### **Aplicar funciones a múltiples columnas**

```{r}
#| label: SD-lapply
#| echo: true

# Estadísticas completas por paciente grupo de edad
pacientes[, edad_grupo := cut(edad, breaks = c(0, 30, 50, 100), 
                              labels = c("Joven", "Adulto", "Senior"))]

stats_por_grupo <- pacientes[, lapply(.SD, function(x) {
  if(is.numeric(x)) {
    list(media = round(mean(x, na.rm = TRUE), 1),
         mediana = round(median(x, na.rm = TRUE), 1),
         sd = round(sd(x, na.rm = TRUE), 1))
  } else {
    list(media = NA, mediana = NA, sd = NA)
  }
}), by = edad_grupo, .SDcols = c("glucosa", "presion_sistolica", "peso")]

print(stats_por_grupo)
```

### 2. **`.SDcols`: Control Granular de Columnas**

`.SDcols` especifica exactamente qué columnas incluir en `.SD`:

```{r}
#| label: SDcols-avanzado
#| echo: true

# Múltiples formas de especificar .SDcols
medidas_vitales <- c("glucosa", "presion_sistolica", "peso")

# 1. Por nombres exactos
resultado1 <- pacientes[, lapply(.SD, mean), by = edad_grupo, .SDcols = medidas_vitales]

# 2. Por patrones
resultado2 <- pacientes[, lapply(.SD, max), by = edad_grupo, .SDcols = patterns("glucosa|peso")]

# 3. Por función (columnas numéricas)
resultado3 <- pacientes[, lapply(.SD, min), by = edad_grupo, .SDcols = is.numeric]

print("Por patrones:")
print(resultado2)
```

### 3. **`.I`: Índices de Fila**

`.I` contiene los números de fila del grupo actual:

```{r}
#| label: I-avanzado
#| echo: true

# Encontrar los índices de los 2 precios más altos por acción
indices_top2 <- precios_acciones[fecha <= as.Date("2024-01-31"), 
                                .I[order(-precio)[1:2]], 
                                by = accion]

print(indices_top2)

# Usar esos índices para extraer las filas completas
top_precios <- precios_acciones[indices_top2$V1]
print(top_precios[order(accion, -precio)])
```

### 4. **`.GRP`: Identificador de Grupo**

```{r}
#| label: GRP-ejemplo
#| echo: true

# Crear identificador único para cada combinación de grupo
pacientes[, `:=`(
  grupo_id = .GRP,
  grupo_nombre = paste0("Grupo_", .GRP)
), by = .(edad_grupo)]

print(pacientes[, .(paciente_id, edad_grupo, grupo_id, grupo_nombre)][order(grupo_id)])
```

## Non-Equi Joins: Más Allá de la Igualdad

Los non-equi joins permiten unir tablas basándose en rangos, inequidades, y condiciones complejas:

### 1. **Join por Rangos**

```{r}
#| label: non-equi-rangos
#| echo: true

# Clasificar pacientes según rangos de glucosa
pacientes_clasificados <- rangos_glucosa[pacientes, 
  on = .(min_glucosa <= glucosa, max_glucosa >= glucosa),
  .(paciente_id, glucosa, categoria)]

print(pacientes_clasificados[order(glucosa)])
```

### 2. **Non-Equi Join para Análisis Temporal**

```{r}
#| label: non-equi-temporal
#| echo: true

# Encontrar transacciones que ocurrieron dentro de una ventana de tiempo
ventana_eventos <- data.table(
  evento = c("Earnings_AAPL", "Split_GOOGL", "Launch_TSLA"),
  fecha_evento = as.Date(c("2024-02-15", "2024-06-10", "2024-09-20")),
  dias_antes = c(5, 3, 7),
  dias_despues = c(5, 3, 7)
)

# Agregar fechas de ventana
ventana_eventos[, `:=`(
  fecha_inicio = fecha_evento - dias_antes,
  fecha_fin = fecha_evento + dias_despues
)]

# Encontrar transacciones dentro de cada ventana
transacciones_ventana <- ventana_eventos[transacciones_fecha,
  on = .(fecha_inicio <= fecha_transaccion, fecha_fin >= fecha_transaccion),
  .(evento, fecha_evento, accion, fecha_transaccion, cantidad, tipo),
  nomatch = NULL]

print(head(transacciones_ventana[order(evento, fecha_transaccion)], 10))
```

## Rolling Joins: La Joya de la Corona {#sec-rolling-joins}

Los rolling joins son perfectos para series temporales, permitiendo unir cada observación con la última disponible:

### 1. **Rolling Join Básico**

```{r}
#| label: rolling-basic
#| echo: true

# Preparar datos con keys
precios_key <- copy(precios_acciones)
transacciones_key <- copy(transacciones_fecha)

setkey(precios_key, accion, fecha)
setkey(transacciones_key, accion, fecha_transaccion)

# Rolling join: para cada transacción, encontrar el último precio disponible
transacciones_con_precio <- precios_key[transacciones_key, roll = TRUE]

# Ver las columnas disponibles primero
cat("Columnas disponibles:", paste(names(transacciones_con_precio), collapse = ", "), "\n")

# El rolling join puede cambiar nombres de columnas, usar nombres disponibles
print(head(transacciones_con_precio[, .(accion, fecha, precio, trans_id, cantidad, tipo)]))
```

### 2. **Rolling Join con Límites de Tiempo**

```{r}
#| label: rolling-limitado
#| echo: true

# Rolling join con límite: solo si el precio es de máximo 7 días antes
transacciones_precio_limitado <- precios_key[transacciones_key, 
                                            roll = 7,  # máximo 7 días
                                            rollends = c(TRUE, TRUE)]

# En rolling joins, las columnas de la tabla de la derecha pueden cambiar de nombre
# Verificar diferencias de fechas usando las columnas disponibles
if("fecha_transaccion" %in% names(transacciones_precio_limitado)) {
  transacciones_precio_limitado[!is.na(precio), 
    diferencia_dias := as.numeric(fecha_transaccion - fecha)]
  
  print(head(transacciones_precio_limitado[
    !is.na(precio), 
    .(accion, fecha, fecha_transaccion, diferencia_dias, precio, cantidad)
  ]))
} else {
  # Si fecha_transaccion no está disponible, usar columnas alternativas
  print(head(transacciones_precio_limitado[
    !is.na(precio), 
    .(accion, fecha, precio, cantidad, trans_id)
  ]))
}
```

### 3. **Rolling Join Bidireccional**

```{r}
#| label: rolling-bidireccional
#| echo: true

# Roll = "nearest" busca el valor más cercano (antes o después)
transacciones_nearest <- precios_key[transacciones_key, roll = "nearest"]

# Usar columnas que sabemos que existen
print(head(transacciones_nearest[, .(accion, fecha, precio, trans_id, cantidad, tipo)]))
```

## Reshape de Datos: `melt()` y `dcast()`

### 1. **De Ancho a Largo con `melt()`**

```{r}
#| label: melt-basico
#| echo: true

# Convertir datos de ventas de formato ancho a largo
ventas_long <- melt(ventas_wide, 
                   id.vars = "producto",
                   variable.name = "periodo", 
                   value.name = "ventas")

print(head(ventas_long, 10))
```

```{r}
#| label: melt-avanzado
#| echo: true

# Melt con patrones complejos para separar año y trimestre
ventas_long[, `:=`(
  trimestre = sub("_.*", "", periodo),
  año = sub(".*_", "", periodo)
)]

print(head(ventas_long))
```

### 2. **De Largo a Ancho con `dcast()`**

```{r}
#| label: dcast-basico
#| echo: true

# Volver a formato ancho
ventas_wide_reconstruido <- dcast(ventas_long, producto ~ periodo, value.var = "ventas")

print(ventas_wide_reconstruido)
```

```{r}
#| label: dcast-agregacion
#| echo: true

# dcast con agregación: ventas totales por año
ventas_por_año <- dcast(ventas_long, producto ~ año, 
                       value.var = "ventas", 
                       fun.aggregate = sum)

print(ventas_por_año)
```

### 3. **Reshape Multivariable**

```{r}
#| label: reshape-multivariable
#| echo: true

# Crear datos con múltiples métricas
datos_multiples <- data.table(
  store = rep(c("A", "B", "C"), each = 4),
  quarter = rep(c("Q1", "Q2", "Q3", "Q4"), 3),
  sales = round(runif(12, 1000, 5000), 0),
  profit = round(runif(12, 100, 800), 0)
)

# Melt múltiples columnas de valor
datos_long_multi <- melt(datos_multiples, 
                        id.vars = c("store", "quarter"),
                        variable.name = "metric",
                        value.name = "amount")

print(head(datos_long_multi))

# Dcast para crear matriz store x metric por quarter
resultado_multi <- dcast(datos_long_multi, store ~ metric + quarter, value.var = "amount")
print(resultado_multi)
```

## Análisis Temporal Avanzado

### 1. **Funciones de Ventana (Window Functions)**

```{r}
#| label: window-functions
#| echo: true

# Calcular medias móviles para precios de acciones
precios_con_ma <- precios_acciones[order(accion, fecha)][,
  `:=`(
    precio_ma_7 = frollmean(precio, 7),
    precio_ma_30 = frollmean(precio, 30),
    precio_lag_1 = shift(precio, 1),
    precio_lead_1 = shift(precio, -1),
    cambio_diario = precio - shift(precio, 1)
  ), by = accion]

print(head(precios_con_ma[!is.na(precio_ma_7), 
                         .(accion, fecha, precio, precio_ma_7, cambio_diario)], 10))
```

### 2. **Análisis de Series Temporales con Sensores**

```{r}
#| label: sensores-analisis
#| echo: true

# Análisis temporal avanzado de sensores
sensores_analisis <- sensores[order(sensor_id, timestamp)][,
  `:=`(
    temp_ma_1h = frollmean(temperatura, 12),  # 12 períodos de 5min = 1h
    temp_ma_6h = frollmean(temperatura, 72),  # 6 horas
    temp_diff = temperatura - shift(temperatura, 1),
    temp_volatilidad = frollapply(temperatura, 12, sd),
    hora = hour(timestamp),
    dia_semana = wday(timestamp, label = TRUE)
  ), by = sensor_id]

# Estadísticas por hora del día
stats_horarios <- sensores_analisis[!is.na(temp_ma_1h), 
  .(
    temp_promedio = round(mean(temperatura), 1),
    temp_volatilidad_promedio = round(mean(temp_volatilidad, na.rm = TRUE), 2),
    lecturas = .N
  ), by = .(sensor_id, hora)]

print(head(stats_horarios[order(sensor_id, hora)], 15))
```

## Ejercicios Avanzados

::: {.callout-note icon="false"}
## 🏋️ Ejercicio 6: Análisis de Riesgo Financiero

Usando `precios_acciones` y `transacciones_fecha`:

1. **Calcular** volatilidad de 30 días para cada acción
2. **Clasificar** acciones por riesgo (Bajo < 15, Medio 15-25, Alto > 25)
3. **Usar non-equi join** para asignar nivel de riesgo a cada transacción
4. **Rolling join** para obtener precio exacto en fecha de transacción
:::

::: {.callout-tip collapse="true"}
## 💡 Solución del Ejercicio 6

```{r}
#| label: solucion-ejercicio-6
#| echo: true

# 1. Calcular volatilidad de 30 días
volatilidades <- precios_acciones[order(accion, fecha)][,
  .(fecha = fecha, volatilidad_30d = frollapply(precio, 30, sd, na.rm = TRUE)),
  by = accion][!is.na(volatilidad_30d)]

# 2. Clasificar por riesgo (usando última volatilidad disponible)
clasificacion_riesgo <- volatilidades[, .SD[.N], by = accion][,
  nivel_riesgo := cut(volatilidad_30d, 
                     breaks = c(0, 15, 25, Inf),
                     labels = c("Bajo", "Medio", "Alto"))]

print("Clasificación de riesgo:")
print(clasificacion_riesgo[, .(accion, volatilidad_30d, nivel_riesgo)])

# 3. Non-equi join para asignar riesgo a transacciones
rangos_riesgo <- data.table(
  min_vol = c(0, 15, 25),
  max_vol = c(15, 25, Inf),
  nivel_riesgo = c("Bajo", "Medio", "Alto")
)

# 4. Pipeline completo con rolling join y clasificación
# Simplificar el pipeline para evitar problemas con non-equi joins complejos
paso1 <- precios_acciones[
  transacciones_fecha, on = .(accion, fecha = fecha_transaccion), roll = TRUE
]

paso2 <- paso1[
  volatilidades[, .SD[.N], by = accion][, .(accion, volatilidad_30d)], 
  on = .(accion)
]

# Clasificar manualmente usando rangos
paso2[, nivel_riesgo := fcase(
  volatilidad_30d < 15, "Bajo",
  volatilidad_30d >= 15 & volatilidad_30d < 25, "Medio",
  volatilidad_30d >= 25, "Alto",
  default = "Sin Clasificar"
)]

resultado_final <- paso2[, .(accion, fecha, precio, tipo, cantidad, volatilidad_30d, nivel_riesgo)]

print("Transacciones con nivel de riesgo:")
print(head(resultado_final, 10))
```
:::

::: {.callout-note icon="false"}
## 🏋️ Ejercicio 7: Reshape y Análisis Temporal

1. **Reshape** los datos de sensores de largo a ancho por sensor_id
2. **Calcular** correlaciones entre sensores  
3. **Crear** un heatmap de correlaciones temporales
:::

::: {.callout-tip collapse="true"}
## 💡 Solución del Ejercicio 7

```{r}
#| label: solucion-ejercicio-7
#| echo: true

# 1. Reshape sensores de largo a ancho
# Crear un dataset más simple y controlado para el ejemplo
set.seed(123)
sensores_ejemplo <- data.table(
  timestamp = rep(seq(as.POSIXct("2024-01-01 00:00:00"), 
                     as.POSIXct("2024-01-01 23:00:00"), 
                     by = "hour"), times = 3),
  sensor_id = rep(c("S001", "S002", "S003"), each = 24),
  temperatura = c(
    rnorm(24, 20, 2),  # S001
    rnorm(24, 22, 1.5),  # S002  
    rnorm(24, 18, 3)   # S003
  )
)

# Hacer reshape
sensores_wide <- dcast(sensores_ejemplo, timestamp ~ sensor_id, value.var = "temperatura")

print("Datos wide (ejemplo):")
print(head(sensores_wide))
cat("Dimensiones de datos wide:", dim(sensores_wide), "\n")

# 2. Calcular matriz de correlaciones
sensor_cols <- c("S001", "S002", "S003")
cat("Calculando correlaciones para:", paste(sensor_cols, collapse = ", "), "\n")

# Verificar que no hay valores faltantes
cat("Valores NA por columna:\n")
print(sapply(sensores_wide[, ..sensor_cols], function(x) sum(is.na(x))))

cor_matrix <- cor(sensores_wide[, ..sensor_cols], use = "complete.obs")
print("Matriz de correlaciones:")
print(round(cor_matrix, 3))

# 3. Preparar datos para heatmap
cor_long <- as.data.table(cor_matrix, keep.rownames = "Sensor1")[,
  melt(.SD, id.vars = "Sensor1", variable.name = "Sensor2", value.name = "Correlacion")]

# Visualizar heatmap
library(ggplot2)
heatmap_cor <- ggplot(cor_long, aes(x = Sensor1, y = Sensor2, fill = Correlacion)) +
  geom_tile() +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0) +
  labs(title = "Correlaciones entre Sensores de Temperatura",
       x = "Sensor", y = "Sensor") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

print(heatmap_cor)
```
:::

## Funciones Avanzadas para Casos Especiales

### 1. **`fifelse()`: Vectorización Condicional Rápida**

```{r}
#| label: fifelse-avanzado
#| echo: true

# fifelse es más rápido que ifelse para data.tables grandes
pacientes[, 
  categoria_riesgo := fifelse(
    glucosa > 140 & presion_sistolica > 130, "Alto Riesgo",
    fifelse(
      glucosa > 100 | presion_sistolica > 120, "Riesgo Moderado",
      "Bajo Riesgo"
    )
  )]

print(pacientes[, .N, by = categoria_riesgo])
```

### 2. **`fcase()`: Múltiples Condiciones**

```{r}
#| label: fcase-ejemplo
#| echo: true

# fcase para múltiples condiciones de forma clara
precios_acciones[, 
  categoria_precio := fcase(
    precio < 100, "Económica",
    precio >= 100 & precio < 300, "Media",
    precio >= 300 & precio < 1000, "Premium",
    precio >= 1000, "Luxury",
    default = "Sin Clasificar"
  )]

print(precios_acciones[, .N, by = .(accion, categoria_precio)])
```

## Próximo Capítulo: Optimización y Performance

En el siguiente capítulo exploraremos:
- **Configuración de performance** con `setDTthreads()`
- **Índices y keys** para búsquedas ultra-rápidas
- **Profiling y benchmarking** de código `data.table`
- **Do's and Don'ts** definitivos

---

::: {.callout-important}
## 🎯 Puntos Clave de Este Capítulo

1. **`.SD` y `.SDcols`** te dan control total sobre operaciones por grupo
2. **Non-equi joins** abren posibilidades para análisis complejos basados en rangos
3. **Rolling joins** son esenciales para series temporales y datos financieros
4. **`melt()`/`dcast()`** transforman la estructura de datos para diferentes análisis
5. **Window functions** (`frollmean`, `shift`) permiten análisis temporal sofisticado
6. **Funciones optimizadas** (`fifelse`, `fcase`) mejoran el rendimiento significativamente
:::

Has dominado las técnicas más avanzadas de `data.table`. En el próximo capítulo aprenderás a optimizar tu código para obtener el máximo rendimiento posible.
