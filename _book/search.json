[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Domina data.table en R",
    "section": "",
    "text": "Prefacio",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#por-qué-data.table",
    "href": "index.html#por-qué-data.table",
    "title": "Domina data.table en R",
    "section": "¿Por qué data.table?",
    "text": "¿Por qué data.table?\nEn el ecosistema de R, cuando hablamos de manipulación eficiente de datos, data.table es el rey indiscutible. No es solo una mejora incremental sobre data.frame - es una reimaginación completa de cómo deberían funcionar las operaciones con datos.\nLos Tres Pilares de data.table\n\n\n\n🚀 Velocidad\n🧠 Memoria\n✍️ Sintaxis\n\n\n\ndata.table está escrito en C y optimizado hasta el último detalle. Para datasets grandes, la diferencia puede ser de segundos vs. horas.\n\n\nSu característica de modificación por referencia significa que no crea copias innecesarias de tus datos. Un dataset de 1GB sigue siendo 1GB, no 3GB.\n\n\nLa sintaxis DT[i, j, by] es consistente y poderosa. Una vez que la dominas, puedes expresar operaciones complejas de forma increíblemente concisa.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#para-quién-es-este-tutorial",
    "href": "index.html#para-quién-es-este-tutorial",
    "title": "Domina data.table en R",
    "section": "¿Para quién es este tutorial?",
    "text": "¿Para quién es este tutorial?\nEste tutorial está diseñado para:\n\n\nUsuarios de R base que quieren acelerar dramáticamente su flujo de trabajo\n\nUsuarios de dplyr que necesitan manejar datasets más grandes\n\nCientíficos de datos que trabajan con millones de filas y necesitan eficiencia\n\nAnalistas que quieren una herramienta más potente para manipulación de datos",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#lo-que-aprenderás",
    "href": "index.html#lo-que-aprenderás",
    "title": "Domina data.table en R",
    "section": "Lo que aprenderás",
    "text": "Lo que aprenderás\nAl final de este tutorial, serás capaz de:\n\n\n\n\n\n\nHabilidades que dominarás 🎯\n\n\n\n\n\n\n✅ Sintaxis fundamental: Dominar DT[i, j, by] como un experto\n✅ Manipulación avanzada: Joins, reshape, y operaciones complejas\n✅ Optimización: Escribir código data.table que vuela\n✅ Integración: Combinar data.table con ggplot2, shiny, y más\n✅ Buenas prácticas: Evitar errores comunes y escribir código mantenible",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#estructura-del-tutorial",
    "href": "index.html#estructura-del-tutorial",
    "title": "Domina data.table en R",
    "section": "Estructura del Tutorial",
    "text": "Estructura del Tutorial\n\nMódulo 1: Fundamentos y Sintaxis Esencial\nEmpezaremos desde cero: qué es un data.table, cómo se diferencia de un data.frame, y cómo dominar la sintaxis DT[i, j, by].\n\nMódulo 2: Manipulación de Datos Intermedia\nEncadenamiento de operaciones, joins básicos, y técnicas que te harán más productivo.\n\nMódulo 3: Técnicas Avanzadas y Funciones Especiales\nLos símbolos especiales (.SD, .N, etc.), joins avanzados, y reshape de datos.\n\nMódulo 4: Optimización y Buenas Prácticas\nCómo escribir código data.table realmente rápido y evitar errores comunes.\n\nMódulo 5: Integración con el Ecosistema R\nUsar data.table con ggplot2, shiny, tidymodels, y otros paquetes populares.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#requisitos-previos",
    "href": "index.html#requisitos-previos",
    "title": "Domina data.table en R",
    "section": "Requisitos Previos",
    "text": "Requisitos Previos\nConocimientos Necesarios\n\n\nR básico: Vectores, listas, funciones básicas\n\ndata.frame básico: Indexación con [filas, columnas]\n\n\nExperiencia recomendada: Haber trabajado con datos reales en R\nSoftware Requerido\n\n# Instalación de paquetes necesarios\ninstall.packages(c(\"data.table\", \"ggplot2\", \"DT\"))\n\n# Verificar versiones\npackageVersion(\"data.table\")  # &gt;= 1.14.0 recomendado",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#convenciones-de-este-tutorial",
    "href": "index.html#convenciones-de-este-tutorial",
    "title": "Domina data.table en R",
    "section": "Convenciones de este Tutorial",
    "text": "Convenciones de este Tutorial\nIconos y Callouts\n\n\n\n\n\n\n💡 Consejo\n\n\n\nConsejos prácticos y mejores prácticas.\n\n\n\n\n\n\n\n\n⚠️ Cuidado\n\n\n\nErrores comunes y cómo evitarlos.\n\n\n\n\n\n\n\n\n📝 Nota\n\n\n\nInformación adicional y contexto.\n\n\n\n\n\n\n\n\n❗ Importante\n\n\n\nConceptos clave que debes recordar.\n\n\nCódigo y Ejercicios\nLos ejercicios prácticos aparecerán en cajas especiales y tendrán sus soluciones explicadas paso a paso. Recomendamos encarecidamente que intentes resolver cada ejercicio antes de ver la solución.\n\n# Los bloques de código incluirán explicaciones detalladas\nlibrary(data.table)\n\n# Ejemplo simple: crear un data.table\ndt_ejemplo &lt;- data.table(\n  id = 1:5,\n  valor = c(10, 20, 30, 40, 50),\n  categoria = c(\"A\", \"B\", \"A\", \"C\", \"B\")\n)\n\nprint(dt_ejemplo)\n#&gt;       id valor categoria\n#&gt;    &lt;int&gt; &lt;num&gt;    &lt;char&gt;\n#&gt; 1:     1    10         A\n#&gt; 2:     2    20         B\n#&gt; 3:     3    30         A\n#&gt; 4:     4    40         C\n#&gt; 5:     5    50         B",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#obtener-ayuda",
    "href": "index.html#obtener-ayuda",
    "title": "Domina data.table en R",
    "section": "Obtener Ayuda",
    "text": "Obtener Ayuda\nSi tienes preguntas durante tu aprendizaje:\n\n\nDocumentación oficial: ?data.table en R\n\nViñetas: browseVignettes(\"data.table\")\n\n\nStack Overflow: Tag [data.table]\n\n\nGitHub: Rdatatable/data.table",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#contribuciones-y-feedback",
    "href": "index.html#contribuciones-y-feedback",
    "title": "Domina data.table en R",
    "section": "Contribuciones y Feedback",
    "text": "Contribuciones y Feedback\nEste tutorial es un proyecto vivo. Si encuentras errores, tienes sugerencias de mejora, o quieres contribuir con ejemplos adicionales, ¡tu participación es bienvenida!\n\n\n\n\n\n\n\n🎯 ¿Listo para comenzar?\n\n\n\nEn el próximo capítulo configuraremos nuestro entorno y crearemos nuestro primer data.table. ¡El viaje hacia la maestría en manipulación de datos comienza ahora!\n\n\n\nInformación del Sistema:\n\n#&gt; 📅 Generado: 20 de agosto de 2025\n#&gt; 🔧 Versión de R: R version 4.4.2 (2024-10-31 ucrt)\n#&gt; 📦 Versión de data.table: 1.17.0\n#&gt; 📦 Versión de Quarto: 1.7.32",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1  Introducción a data.table\n",
    "section": "",
    "text": "1.1 La Historia de data.table\ndata.table nació en 2006 de la frustración de Matt Dowle con la velocidad de operaciones sobre data.frame para datasets grandes. Su visión era simple pero revolucionaria: ¿por qué conformarse con segundos cuando puedes tener milisegundos?\nHoy, más de 15 años después, data.table es la referencia mundial para manipulación de datos de alta performance en R, usado por empresas como Facebook, Netflix, y miles de científicos de datos alrededor del mundo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#qué-hace-a-data.table-especial",
    "href": "intro.html#qué-hace-a-data.table-especial",
    "title": "\n1  Introducción a data.table\n",
    "section": "\n1.2 ¿Qué hace a data.table especial?",
    "text": "1.2 ¿Qué hace a data.table especial?\n\n1.2.1 1. Es un data.frame mejorado 🔧\nUn data.table es un data.frame. Esto significa:\n\n# Creamos un data.table\ndt &lt;- data.table(x = 1:3, y = c(\"A\", \"B\", \"C\"))\n\n# Verificamos su herencia\nclass(dt)\n#&gt; [1] \"data.table\" \"data.frame\"\nis.data.frame(dt)\n#&gt; [1] TRUE\n\nEsta compatibilidad es crucial: puedes usar un data.table en cualquier lugar que espere un data.frame sin problemas.\n\n1.2.2 2. Modificación por referencia 🧠\nLa característica más distintiva de data.table es su capacidad de modificar objetos por referencia, sin crear copias.\n\n# R base: crea una copia completa\ndf &lt;- data.frame(x = 1:1000000, y = rnorm(1000000))\ndf$z &lt;- df$x + df$y  # ¡Copia completa en memoria!\n\n# data.table: modificación in-place\ndt &lt;- data.table(x = 1:1000000, y = rnorm(1000000))\ndt[, z := x + y]     # ¡Sin copias! Modificación directa\n\n\n\n\n\n\n\n💡 Implicaciones de la Modificación por Referencia\n\n\n\n\n\nVentaja: Velocidad extrema y uso eficiente de memoria\n\nCuidado: Los cambios son permanentes, no hay “deshacer” automático\n\nSolución: Usa copy() cuando necesites preservar el original\n\n\n\n\n1.2.3 3. Sintaxis consistente y potente ✍️\nTodo en data.table se reduce a una estructura simple pero poderosa:\n\n# La estructura universal de data.table\nDT[i, j, by]\n\n# i = filas (WHERE)    - \"¿Qué filas me interesan?\"\n# j = columnas (WHAT)  - \"¿Qué quiero hacer?\"  \n# by = grupos (BY)     - \"¿Agrupado por qué?\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#comparación-data.table-vs.-dplyr-vs.-r-base",
    "href": "intro.html#comparación-data.table-vs.-dplyr-vs.-r-base",
    "title": "\n1  Introducción a data.table\n",
    "section": "\n1.3 Comparación: data.table vs. dplyr vs. R base",
    "text": "1.3 Comparación: data.table vs. dplyr vs. R base\nVeamos cómo se comparan las tres principales formas de manipular datos en R:\n\n1.3.1 Tarea: Calcular la media de valor por categoria\n\n\n\nR Base\ndplyr\ndata.table\n\n\n\n\n# R base: verbose y lento\nresultado_base &lt;- aggregate(valor ~ categoria, data = datos, FUN = mean)\nhead(resultado_base)\n#&gt;   categoria    valor\n#&gt; 1         A 100.0053\n#&gt; 2         B 100.0914\n#&gt; 3         C 100.1848\n#&gt; 4         D 100.0232\n#&gt; 5         E 100.0879\n\n\n\n\n# dplyr: legible pero más lento para datos grandes\nresultado_dplyr &lt;- datos %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(media_valor = mean(valor), .groups = 'drop')\n\nhead(resultado_dplyr)\n#&gt; # A tibble: 5 × 2\n#&gt;   categoria media_valor\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;\n#&gt; 1 A                100.\n#&gt; 2 B                100.\n#&gt; 3 C                100.\n#&gt; 4 D                100.\n#&gt; 5 E                100.\n\n\n\n\n# data.table: conciso y ultra rápido\nresultado_dt &lt;- datos_dt[, .(media_valor = mean(valor)), by = categoria]\nhead(resultado_dt)\n#&gt;    categoria media_valor\n#&gt;       &lt;char&gt;       &lt;num&gt;\n#&gt; 1:         C    100.1848\n#&gt; 2:         B    100.0914\n#&gt; 3:         D    100.0232\n#&gt; 4:         A    100.0053\n#&gt; 5:         E    100.0879\n\n\n\n\n\n1.3.2 Comparación de Rendimiento\n\n# Comparamos velocidad (solo con muestra para el ejemplo)\nif(nrow(datos) &gt; 10000) {\n  muestra &lt;- slice_sample(datos, n = 10000)\n  muestra_dt &lt;- as.data.table(muestra)\n  \n  benchmark_resultado &lt;- microbenchmark(\n    \"R Base\" = aggregate(valor ~ categoria, data = muestra, FUN = mean),\n    \"dplyr\" = muestra %&gt;% group_by(categoria) %&gt;% summarise(media = mean(valor), .groups = 'drop'),\n    \"data.table\" = muestra_dt[, .(media = mean(valor)), by = categoria],\n    times = 50\n  )\n  \n  print(benchmark_resultado)\n}\n#&gt; Unit: milliseconds\n#&gt;        expr    min     lq     mean  median     uq    max neval\n#&gt;      R Base 1.2766 1.4461 1.870040 1.82790 2.0006 5.7968    50\n#&gt;       dplyr 1.0564 1.1938 1.330138 1.27525 1.4306 2.0359    50\n#&gt;  data.table 1.2652 1.3448 1.474080 1.46270 1.5597 1.9502    50\n\n\n\n\n\n\n\n📊 Interpretando los Resultados\n\n\n\nEn datasets grandes (millones de filas), data.table puede ser 10-100x más rápido que R base y 2-10x más rápido que dplyr. La diferencia se amplifica con operaciones más complejas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#tu-primer-data.table",
    "href": "intro.html#tu-primer-data.table",
    "title": "\n1  Introducción a data.table\n",
    "section": "\n1.4 Tu Primer data.table\n",
    "text": "1.4 Tu Primer data.table\n\n\n1.4.1 Creación Básica\nExisten varias formas de crear un data.table:\n\n# 1. Desde cero\nmi_dt &lt;- data.table(\n  nombre = c(\"Ana\", \"Juan\", \"María\", \"Carlos\"),\n  edad = c(25, 30, 28, 35),\n  ciudad = c(\"Madrid\", \"Barcelona\", \"Sevilla\", \"Valencia\"),\n  salario = c(35000, 42000, 38000, 50000)\n)\n\nprint(mi_dt)\n#&gt;    nombre  edad    ciudad salario\n#&gt;    &lt;char&gt; &lt;num&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:    Ana    25    Madrid   35000\n#&gt; 2:   Juan    30 Barcelona   42000\n#&gt; 3:  María    28   Sevilla   38000\n#&gt; 4: Carlos    35  Valencia   50000\n\n\n# 2. Convirtiendo un data.frame existente\niris_dt &lt;- as.data.table(iris)\nprint(head(iris_dt))\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt;           &lt;num&gt;       &lt;num&gt;        &lt;num&gt;       &lt;num&gt;  &lt;fctr&gt;\n#&gt; 1:          5.1         3.5          1.4         0.2  setosa\n#&gt; 2:          4.9         3.0          1.4         0.2  setosa\n#&gt; 3:          4.7         3.2          1.3         0.2  setosa\n#&gt; 4:          4.6         3.1          1.5         0.2  setosa\n#&gt; 5:          5.0         3.6          1.4         0.2  setosa\n#&gt; 6:          5.4         3.9          1.7         0.4  setosa\n\n\n# 3. Leyendo un archivo (súper rápido)\ndatos_csv &lt;- fread(\"mi_archivo.csv\")\n\n\n1.4.2 Explorando tu data.table\n\n\n# Información básica\ndim(iris_dt)         # Dimensiones\n#&gt; [1] 150   5\nnames(iris_dt)       # Nombres de columnas\n#&gt; [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"\nstr(iris_dt)         # Estructura\n#&gt; Classes 'data.table' and 'data.frame':   150 obs. of  5 variables:\n#&gt;  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n#&gt;  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n#&gt;  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n#&gt;  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n#&gt;  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  - attr(*, \".internal.selfref\")=&lt;externalptr&gt;\n\n\n# Estadísticas rápidas por grupo\niris_dt[, .N, by = Species]  # Conteo por especie\n#&gt;       Species     N\n#&gt;        &lt;fctr&gt; &lt;int&gt;\n#&gt; 1:     setosa    50\n#&gt; 2: versicolor    50\n#&gt; 3:  virginica    50",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#configuración-del-entorno",
    "href": "intro.html#configuración-del-entorno",
    "title": "\n1  Introducción a data.table\n",
    "section": "\n1.5 Configuración del Entorno",
    "text": "1.5 Configuración del Entorno\nPara aprovechar al máximo data.table, configuremos nuestro entorno:\n\n# 1. Configurar número de threads (para aprovechar múltiples núcleos)\nsetDTthreads(0)  # 0 = usar todos los núcleos disponibles\ngetDTthreads()   # Verificar configuración\n#&gt; [1] 16\n\n# 2. Opciones de visualización\noptions(datatable.print.nrows = 10)     # Mostrar 10 filas\noptions(datatable.print.class = TRUE)   # Mostrar clases de columnas\n\n# 3. Modo verboso para aprendizaje (opcional)\n# options(datatable.verbose = TRUE)  # Descomenta para debug\n\n\n\n\n\n\n\n🚀 Consejo de Performance\n\n\n\nsetDTthreads(0) utiliza todos los núcleos de CPU disponibles. En máquinas con muchos núcleos, esto puede acelerar operaciones hasta 4-8x. Para laptops o uso interactivo, considera setDTthreads(2) para mantener el sistema responsive.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#anatomía-de-la-sintaxis-dti-j-by",
    "href": "intro.html#anatomía-de-la-sintaxis-dti-j-by",
    "title": "\n1  Introducción a data.table\n",
    "section": "\n1.6 Anatomía de la Sintaxis DT[i, j, by]\n",
    "text": "1.6 Anatomía de la Sintaxis DT[i, j, by]\n\nLa sintaxis de data.table puede parecer intimidante al principio, pero es increíblemente lógica:\n\n# Ejemplo con nuestros datos de empleados\nprint(mi_dt)\n#&gt;    nombre  edad    ciudad salario\n#&gt;    &lt;char&gt; &lt;num&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:    Ana    25    Madrid   35000\n#&gt; 2:   Juan    30 Barcelona   42000\n#&gt; 3:  María    28   Sevilla   38000\n#&gt; 4: Carlos    35  Valencia   50000\n\n# i: ¿QUÉ FILAS? (filtrado)\nmi_dt[edad &gt; 28]\n#&gt;    nombre  edad    ciudad salario\n#&gt;    &lt;char&gt; &lt;num&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:   Juan    30 Barcelona   42000\n#&gt; 2: Carlos    35  Valencia   50000\n\n# j: ¿QUÉ HACER? (selección/cálculo)\nmi_dt[, .(nombre, salario)]\n#&gt;    nombre salario\n#&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:    Ana   35000\n#&gt; 2:   Juan   42000\n#&gt; 3:  María   38000\n#&gt; 4: Carlos   50000\n\n# by: ¿AGRUPADO POR QUÉ? (agrupación)\nmi_dt[, mean(salario), by = ciudad]\n#&gt;       ciudad    V1\n#&gt;       &lt;char&gt; &lt;num&gt;\n#&gt; 1:    Madrid 35000\n#&gt; 2: Barcelona 42000\n#&gt; 3:   Sevilla 38000\n#&gt; 4:  Valencia 50000",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#ejercicio-práctico-tu-primera-experiencia",
    "href": "intro.html#ejercicio-práctico-tu-primera-experiencia",
    "title": "\n1  Introducción a data.table\n",
    "section": "\n1.7 Ejercicio Práctico: Tu Primera Experiencia",
    "text": "1.7 Ejercicio Práctico: Tu Primera Experiencia\n\n\n\n\n\n\n🏋️ Ejercicio 1: Explorando los datos de iris\n\n\n\nUsando el data.table iris_dt que creamos:\n\n\nFiltra las filas donde Sepal.Length &gt; 6.0\n\n\nCalcula la media de Petal.Width para cada Species\n\n\nSelecciona solo las columnas que empiecen con “Petal”\n\n¡Intenta resolver cada parte antes de ver la solución!\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 1\n\n\n\n\n\n\n# 1. Filtrar filas\niris_grandes &lt;- iris_dt[Sepal.Length &gt; 6.0]\nprint(nrow(iris_grandes))\n#&gt; [1] 61\n\n# 2. Media de Petal.Width por Species\nmedias_petal &lt;- iris_dt[, .(media_petal_width = mean(Petal.Width)), by = Species]\nprint(medias_petal)\n#&gt;       Species media_petal_width\n#&gt;        &lt;fctr&gt;             &lt;num&gt;\n#&gt; 1:     setosa             0.246\n#&gt; 2: versicolor             1.326\n#&gt; 3:  virginica             2.026\n\n# 3. Seleccionar columnas que empiecen con \"Petal\"\ncolumnas_petal &lt;- iris_dt[, .SD, .SDcols = patterns(\"^Petal\")]\nprint(head(columnas_petal))\n#&gt;    Petal.Length Petal.Width\n#&gt;           &lt;num&gt;       &lt;num&gt;\n#&gt; 1:          1.4         0.2\n#&gt; 2:          1.4         0.2\n#&gt; 3:          1.3         0.2\n#&gt; 4:          1.5         0.2\n#&gt; 5:          1.4         0.2\n#&gt; 6:          1.7         0.4\n\nExplicación: - [Sepal.Length &gt; 6.0] filtra filas por condición lógica - .(media_petal_width = mean(Petal.Width)) crea una nueva columna calculada - patterns(\"^Petal\") usa regex para seleccionar columnas dinámicamente",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#próximos-pasos",
    "href": "intro.html#próximos-pasos",
    "title": "\n1  Introducción a data.table\n",
    "section": "\n1.8 Próximos Pasos",
    "text": "1.8 Próximos Pasos\nHas dado tus primeros pasos en el mundo de data.table. En el siguiente capítulo profundizaremos en cada componente de la sintaxis DT[i, j, by] y descubrirás el verdadero poder de esta herramienta.\n\n1.8.1 Lo que viene\nEn el Capítulo 1 exploraremos: - Filtrado avanzado de filas (i) - Selección y transformación de columnas (j) - Agrupaciones poderosas (by) - Símbolos especiales como .N, .SD, etc.\n\n\n\n\n\n\n\n🎯 Recuerda\n\n\n\ndata.table no es solo una herramienta más rápida - es una forma diferente de pensar sobre la manipulación de datos. La inversión inicial en aprender su sintaxis te pagará dividendos durante toda tu carrera como analista de datos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introducción a `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html",
    "href": "cap01-sintaxis.html",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "",
    "text": "2.1 La Sintaxis DT[i, j, by]: El Corazón de data.table\nTodo en data.table gira alrededor de esta estructura simple pero poderosa. Piensa en ella como una pregunta en tres partes que le haces a tus datos:\n# La estructura universal\nDT[i,           j,              by]\n   ↓            ↓               ↓\n ¿Dónde?    ¿Qué hacer?    ¿Agrupado por?\n(filtros)   (seleccionar/   (variables de\n           transformar)      agrupación)\nCada componente es opcional, lo que hace la sintaxis extremadamente flexible.",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#el-componente-i-selección-y-filtrado-de-filas",
    "href": "cap01-sintaxis.html#el-componente-i-selección-y-filtrado-de-filas",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.2 El Componente i: Selección y Filtrado de Filas",
    "text": "2.2 El Componente i: Selección y Filtrado de Filas\n\n2.2.1 1. Filtrado Básico por Condiciones\n\n\n# Empleados con salario &gt; 45000\nempleados[salario &gt; 45000]\n#&gt;       id nombre departamento salario años_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     4 Carlos           IT   50000        8    2015-09-20\n#&gt; 2:     6  Pedro           IT   55000       10    2013-04-12\n#&gt; 3:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt; 4:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt; 5:    12  Diego         RRHH   52000        8    2016-01-25\n\n\n# Múltiples condiciones: IT con más de 5 años de experiencia\nempleados[departamento == \"IT\" & años_exp &gt; 5]\n#&gt;       id nombre departamento salario años_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     4 Carlos           IT   50000        8    2015-09-20\n#&gt; 2:     5  Lucía           IT   45000        6    2018-11-05\n#&gt; 3:     6  Pedro           IT   55000       10    2013-04-12\n\n\n# Usando %in% para múltiples valores\nempleados[departamento %in% c(\"Ventas\", \"Marketing\")]\n#&gt;       id nombre departamento salario años_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     1    Ana       Ventas   35000        2    2022-01-15\n#&gt; 2:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; 3:     3  María       Ventas   38000        3    2021-07-01\n#&gt; 4:     7 Isabel    Marketing   40000        4    2020-02-28\n#&gt; 5:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt; 6:     9 Carmen    Marketing   41000        3    2021-10-03\n\n\n2.2.2 2. Filtrado por Posición\n\n\n# Primeras 3 filas\nempleados[1:3]\n#&gt;       id nombre departamento salario años_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     1    Ana       Ventas   35000        2    2022-01-15\n#&gt; 2:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; 3:     3  María       Ventas   38000        3    2021-07-01\n\n# Última fila usando .N (número total de filas)\nempleados[.N]\n#&gt;       id nombre departamento salario años_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:    12  Diego         RRHH   52000        8    2016-01-25\n\n# Últimas 3 filas\nempleados[(.N-2):.N]\n#&gt;       id nombre departamento salario años_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt; 2:    11  Laura         RRHH   44000        5    2019-06-18\n#&gt; 3:    12  Diego         RRHH   52000        8    2016-01-25\n\n\n2.2.3 3. Filtrado por Orden\n\n\n# Ordenar por salario (ascendente)\nempleados[order(salario)]\n#&gt;        id nombre departamento salario años_exp fecha_ingreso\n#&gt;     &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt;  1:     1    Ana       Ventas   35000        2    2022-01-15\n#&gt;  2:     3  María       Ventas   38000        3    2021-07-01\n#&gt;  3:     7 Isabel    Marketing   40000        4    2020-02-28\n#&gt;  4:     9 Carmen    Marketing   41000        3    2021-10-03\n#&gt;  5:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; ---                                                         \n#&gt;  8:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt;  9:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt; 10:     4 Carlos           IT   50000        8    2015-09-20\n#&gt; 11:    12  Diego         RRHH   52000        8    2016-01-25\n#&gt; 12:     6  Pedro           IT   55000       10    2013-04-12\n\n# Ordenar por salario descendente\nempleados[order(-salario)]\n#&gt;        id nombre departamento salario años_exp fecha_ingreso\n#&gt;     &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt;  1:     6  Pedro           IT   55000       10    2013-04-12\n#&gt;  2:    12  Diego         RRHH   52000        8    2016-01-25\n#&gt;  3:     4 Carlos           IT   50000        8    2015-09-20\n#&gt;  4:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt;  5:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt; ---                                                         \n#&gt;  8:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt;  9:     9 Carmen    Marketing   41000        3    2021-10-03\n#&gt; 10:     7 Isabel    Marketing   40000        4    2020-02-28\n#&gt; 11:     3  María       Ventas   38000        3    2021-07-01\n#&gt; 12:     1    Ana       Ventas   35000        2    2022-01-15\n\n# Ordenar por múltiples columnas\nempleados[order(departamento, -salario)]\n#&gt;        id nombre departamento salario años_exp fecha_ingreso\n#&gt;     &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt;  1:     6  Pedro           IT   55000       10    2013-04-12\n#&gt;  2:     4 Carlos           IT   50000        8    2015-09-20\n#&gt;  3:     5  Lucía           IT   45000        6    2018-11-05\n#&gt;  4:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt;  5:     9 Carmen    Marketing   41000        3    2021-10-03\n#&gt; ---                                                         \n#&gt;  8:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt;  9:    11  Laura         RRHH   44000        5    2019-06-18\n#&gt; 10:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; 11:     3  María       Ventas   38000        3    2021-07-01\n#&gt; 12:     1    Ana       Ventas   35000        2    2022-01-15\n\n\n\n\n\n\n\n💡 Consejo: Filtrado Eficiente\n\n\n\ndata.table optimiza automáticamente muchas operaciones de filtrado. Para datasets enormes, considera usar setkey() para acelerar filtros repetitivos (lo veremos en capítulos posteriores).",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#el-componente-j-el-poder-de-la-transformación",
    "href": "cap01-sintaxis.html#el-componente-j-el-poder-de-la-transformación",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.3 El Componente j: El Poder de la Transformación",
    "text": "2.3 El Componente j: El Poder de la Transformación\n\n2.3.1 1. Selección Simple de Columnas\n\n\n# Seleccionar una columna (devuelve vector)\nempleados[, salario]\n#&gt;  [1] 35000 42000 38000 50000 45000 55000 40000 47000 41000 48000 44000 52000\n\n# Seleccionar una columna (devolver data.table)\nempleados[, .(salario)]\n#&gt;     salario\n#&gt;       &lt;num&gt;\n#&gt;  1:   35000\n#&gt;  2:   42000\n#&gt;  3:   38000\n#&gt;  4:   50000\n#&gt;  5:   45000\n#&gt; ---        \n#&gt;  8:   47000\n#&gt;  9:   41000\n#&gt; 10:   48000\n#&gt; 11:   44000\n#&gt; 12:   52000\n\n# Múltiples columnas\nempleados[, .(nombre, salario, departamento)]\n#&gt;     nombre salario departamento\n#&gt;     &lt;char&gt;   &lt;num&gt;       &lt;char&gt;\n#&gt;  1:    Ana   35000       Ventas\n#&gt;  2:   Juan   42000       Ventas\n#&gt;  3:  María   38000       Ventas\n#&gt;  4: Carlos   50000           IT\n#&gt;  5:  Lucía   45000           IT\n#&gt; ---                            \n#&gt;  8: Miguel   47000    Marketing\n#&gt;  9: Carmen   41000    Marketing\n#&gt; 10:  Jorge   48000         RRHH\n#&gt; 11:  Laura   44000         RRHH\n#&gt; 12:  Diego   52000         RRHH\n\n\n2.3.2 2. Creación de Nuevas Columnas\n\n\n# Crear columna calculada\nempleados[, .(nombre, salario, salario_anual = salario * 12)]\n#&gt;     nombre salario salario_anual\n#&gt;     &lt;char&gt;   &lt;num&gt;         &lt;num&gt;\n#&gt;  1:    Ana   35000        420000\n#&gt;  2:   Juan   42000        504000\n#&gt;  3:  María   38000        456000\n#&gt;  4: Carlos   50000        600000\n#&gt;  5:  Lucía   45000        540000\n#&gt; ---                             \n#&gt;  8: Miguel   47000        564000\n#&gt;  9: Carmen   41000        492000\n#&gt; 10:  Jorge   48000        576000\n#&gt; 11:  Laura   44000        528000\n#&gt; 12:  Diego   52000        624000\n\n# Múltiples cálculos\nempleados[, .(\n  nombre,\n  salario_mensual = salario,\n  salario_anual = salario * 12,\n  salario_por_año_exp = round(salario / años_exp, 0)\n)]\n#&gt;     nombre salario_mensual salario_anual salario_por_año_exp\n#&gt;     &lt;char&gt;           &lt;num&gt;         &lt;num&gt;               &lt;num&gt;\n#&gt;  1:    Ana           35000        420000               17500\n#&gt;  2:   Juan           42000        504000                8400\n#&gt;  3:  María           38000        456000               12667\n#&gt;  4: Carlos           50000        600000                6250\n#&gt;  5:  Lucía           45000        540000                7500\n#&gt; ---                                                         \n#&gt;  8: Miguel           47000        564000                6714\n#&gt;  9: Carmen           41000        492000               13667\n#&gt; 10:  Jorge           48000        576000                5333\n#&gt; 11:  Laura           44000        528000                8800\n#&gt; 12:  Diego           52000        624000                6500\n\n\n2.3.3 3. Funciones de Agregación\n\n\n# Estadísticas básicas\nempleados[, .(\n  salario_promedio = mean(salario),\n  salario_mediana = median(salario),\n  salario_max = max(salario),\n  salario_min = min(salario),\n  total_empleados = .N\n)]\n#&gt;    salario_promedio salario_mediana salario_max salario_min total_empleados\n#&gt;               &lt;num&gt;           &lt;num&gt;       &lt;num&gt;       &lt;num&gt;           &lt;int&gt;\n#&gt; 1:            44750           44500       55000       35000              12\n\n\n2.3.4 4. El Símbolo Especial .N\n\n.N es una variable especial que representa el número de filas en el grupo actual:\n\n# Contar total de filas\nempleados[, .N]\n#&gt; [1] 12\n\n# Contar empleados por departamento\nempleados[, .N, by = departamento]\n#&gt;    departamento     N\n#&gt;          &lt;char&gt; &lt;int&gt;\n#&gt; 1:       Ventas     3\n#&gt; 2:           IT     3\n#&gt; 3:    Marketing     3\n#&gt; 4:         RRHH     3\n\n# Usar .N en cálculos\nempleados[, .(\n  empleados_total = .N,\n  salario_promedio = mean(salario)\n)]\n#&gt;    empleados_total salario_promedio\n#&gt;              &lt;int&gt;            &lt;num&gt;\n#&gt; 1:              12            44750",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#el-componente-by-agrupaciones-poderosas",
    "href": "cap01-sintaxis.html#el-componente-by-agrupaciones-poderosas",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.4 El Componente by: Agrupaciones Poderosas",
    "text": "2.4 El Componente by: Agrupaciones Poderosas\n\n2.4.1 1. Agrupación Simple\n\n\n# Estadísticas por departamento\nempleados[, .(\n  empleados = .N,\n  salario_promedio = round(mean(salario), 0),\n  salario_total = sum(salario)\n), by = departamento]\n#&gt;    departamento empleados salario_promedio salario_total\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;         &lt;num&gt;\n#&gt; 1:       Ventas         3            38333        115000\n#&gt; 2:           IT         3            50000        150000\n#&gt; 3:    Marketing         3            42667        128000\n#&gt; 4:         RRHH         3            48000        144000\n\n\n2.4.2 2. Agrupación por Múltiples Variables\n\n\n# Crear categorías de experiencia para el ejemplo\nempleados[, categoria_exp := ifelse(años_exp &lt;= 5, \"Junior\", \"Senior\")]\n\n# Agrupar por departamento y categoría de experiencia\nempleados[, .(\n  empleados = .N,\n  salario_promedio = round(mean(salario), 0)\n), by = .(departamento, categoria_exp)]\n#&gt;    departamento categoria_exp empleados salario_promedio\n#&gt;          &lt;char&gt;        &lt;char&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt; 1:       Ventas        Junior         3            38333\n#&gt; 2:           IT        Senior         3            50000\n#&gt; 3:    Marketing        Junior         2            40500\n#&gt; 4:    Marketing        Senior         1            47000\n#&gt; 5:         RRHH        Senior         2            50000\n#&gt; 6:         RRHH        Junior         1            44000\n\n\n2.4.3 3. Agrupación con Expresiones\n\n\n# Agrupar por rangos de salario calculados sobre la marcha\nempleados[, .(\n  empleados = .N,\n  salario_promedio = round(mean(salario), 0)\n), by = .(rango_salario = ifelse(salario &gt; 45000, \"Alto\", \"Medio-Bajo\"))]\n#&gt;    rango_salario empleados salario_promedio\n#&gt;           &lt;char&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt; 1:    Medio-Bajo         7            40714\n#&gt; 2:          Alto         5            50400",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#combinando-los-tres-componentes",
    "href": "cap01-sintaxis.html#combinando-los-tres-componentes",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.5 Combinando los Tres Componentes",
    "text": "2.5 Combinando los Tres Componentes\nLa verdadera potencia surge cuando combinas i, j, y by:\n\n# Filtrar empleados con &gt; 4 años exp, calcular stats por departamento\nempleados[años_exp &gt; 4, .(\n  empleados_experimentados = .N,\n  salario_promedio = round(mean(salario), 0),\n  años_exp_promedio = round(mean(años_exp), 1)\n), by = departamento]\n#&gt;    departamento empleados_experimentados salario_promedio años_exp_promedio\n#&gt;          &lt;char&gt;                    &lt;int&gt;            &lt;num&gt;             &lt;num&gt;\n#&gt; 1:       Ventas                        1            42000               5.0\n#&gt; 2:           IT                        3            50000               8.0\n#&gt; 3:    Marketing                        1            47000               7.0\n#&gt; 4:         RRHH                        3            48000               7.3",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#ejercicios-prácticos",
    "href": "cap01-sintaxis.html#ejercicios-prácticos",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.6 Ejercicios Prácticos",
    "text": "2.6 Ejercicios Prácticos\n\n\n\n\n\n\n🏋️ Ejercicio 1: Dominar la Sintaxis Básica\n\n\n\nUsando el dataset empleados, resuelve:\n\n\nFiltrado: Empleados de “Ventas” o “IT” con salario &gt; 40000\n\nAgregación: Por cada departamento, calcula: empleados totales, salario promedio, y años de experiencia máximo\n\nCombinado: Encuentra empleados con más años de experiencia que el promedio de su departamento\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 1\n\n\n\n\n\n\n# 1. Filtrado avanzado\nempleados_filtrados &lt;- empleados[\n  departamento %in% c(\"Ventas\", \"IT\") & salario &gt; 40000\n]\nprint(empleados_filtrados)\n#&gt;       id nombre departamento salario años_exp fecha_ingreso categoria_exp\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;        &lt;char&gt;\n#&gt; 1:     2   Juan       Ventas   42000        5    2019-03-10        Junior\n#&gt; 2:     4 Carlos           IT   50000        8    2015-09-20        Senior\n#&gt; 3:     5  Lucía           IT   45000        6    2018-11-05        Senior\n#&gt; 4:     6  Pedro           IT   55000       10    2013-04-12        Senior\n\n# 2. Agregación por departamento\nstats_dept &lt;- empleados[, .(\n  total_empleados = .N,\n  salario_promedio = round(mean(salario), 0),\n  años_exp_maximo = max(años_exp)\n), by = departamento]\nprint(stats_dept)\n#&gt;    departamento total_empleados salario_promedio años_exp_maximo\n#&gt;          &lt;char&gt;           &lt;int&gt;            &lt;num&gt;           &lt;num&gt;\n#&gt; 1:       Ventas               3            38333               5\n#&gt; 2:           IT               3            50000              10\n#&gt; 3:    Marketing               3            42667               7\n#&gt; 4:         RRHH               3            48000               9\n\n# 3. Empleados por encima del promedio de experiencia en su departamento\nempleados_promedio_exp &lt;- empleados[, exp_promedio_dept := mean(años_exp), by = departamento][\n  años_exp &gt; exp_promedio_dept, \n  .(nombre, departamento, años_exp, exp_promedio_dept)\n]\nprint(empleados_promedio_exp)\n#&gt;    nombre departamento años_exp exp_promedio_dept\n#&gt;    &lt;char&gt;       &lt;char&gt;    &lt;num&gt;             &lt;num&gt;\n#&gt; 1:   Juan       Ventas        5          3.333333\n#&gt; 2:  Pedro           IT       10          8.000000\n#&gt; 3: Miguel    Marketing        7          4.666667\n#&gt; 4:  Jorge         RRHH        9          7.333333\n#&gt; 5:  Diego         RRHH        8          7.333333",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#patrones-comunes-y-mejores-prácticas",
    "href": "cap01-sintaxis.html#patrones-comunes-y-mejores-prácticas",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.7 Patrones Comunes y Mejores Prácticas",
    "text": "2.7 Patrones Comunes y Mejores Prácticas\n\n2.7.1 1. Piensa en SQL\n\nSi conoces SQL, data.table te resultará familiar:\n\n# SQL: SELECT departamento, AVG(salario) FROM empleados WHERE salario &gt; 40000 GROUP BY departamento\n# data.table:\nempleados[salario &gt; 40000, .(salario_promedio = mean(salario)), by = departamento]\n\n\n2.7.2 2. Usa .() para Múltiples Columnas\n\n.() es tu amigo para selecciones y cálculos múltiples:\n\n# ✅ Correcto: múltiples columnas con nombres descriptivos\nempleados[, .(\n  empleado = nombre,\n  dept = departamento,\n  sueldo = salario,\n  experiencia = años_exp\n)]\n#&gt;     empleado      dept sueldo experiencia\n#&gt;       &lt;char&gt;    &lt;char&gt;  &lt;num&gt;       &lt;num&gt;\n#&gt;  1:      Ana    Ventas  35000           2\n#&gt;  2:     Juan    Ventas  42000           5\n#&gt;  3:    María    Ventas  38000           3\n#&gt;  4:   Carlos        IT  50000           8\n#&gt;  5:    Lucía        IT  45000           6\n#&gt; ---                                      \n#&gt;  8:   Miguel Marketing  47000           7\n#&gt;  9:   Carmen Marketing  41000           3\n#&gt; 10:    Jorge      RRHH  48000           9\n#&gt; 11:    Laura      RRHH  44000           5\n#&gt; 12:    Diego      RRHH  52000           8\n\n\n2.7.3 3. Combina Operaciones de Forma Legible\n\n\n# Ejemplo complejo pero legible\nanalisis_empleados &lt;- empleados[\n  años_exp &gt; 3,                     # i: filtrar por experiencia\n  .(                                # j: calcular métricas\n    empleados = .N,\n    salario_promedio = round(mean(salario), 0),\n    experiencia_total = sum(años_exp),\n    salario_max = max(salario)\n  ),\n  by = departamento                 # by: agrupar por departamento\n][order(-salario_promedio)]         # ordenar por salario desc\n\nprint(analisis_empleados)\n#&gt;    departamento empleados salario_promedio experiencia_total salario_max\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;             &lt;num&gt;       &lt;num&gt;\n#&gt; 1:           IT         3            50000                24       55000\n#&gt; 2:         RRHH         3            48000                22       52000\n#&gt; 3:    Marketing         2            43500                11       47000\n#&gt; 4:       Ventas         1            42000                 5       42000",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#comparación-de-performance",
    "href": "cap01-sintaxis.html#comparación-de-performance",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.8 Comparación de Performance",
    "text": "2.8 Comparación de Performance\nVeamos cómo la sintaxis data.table se compara con alternativas:\n\n# Preparar datos para comparación\nlibrary(microbenchmark)\nventas_sample &lt;- ventas[sample(.N, 10000)]  # Muestra para benchmark\n\n# Comparar diferentes aproximaciones\nbenchmark_sintaxis &lt;- microbenchmark(\n  \"data.table\" = ventas_sample[precio &gt; 100, .(avg_precio = mean(precio)), by = categoria],\n  \"base R\" = aggregate(precio ~ categoria, ventas_sample[ventas_sample$precio &gt; 100, ], mean),\n  times = 20\n)\n\nprint(benchmark_sintaxis)\n#&gt; Unit: milliseconds\n#&gt;        expr    min      lq     mean  median      uq    max neval\n#&gt;  data.table 1.2198 1.46930 1.548200 1.50395 1.67785 1.9922    20\n#&gt;      base R 2.3412 2.55975 3.170085 3.20035 3.53505 4.9892    20",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#próximo-capítulo-símbolos-especiales",
    "href": "cap01-sintaxis.html#próximo-capítulo-símbolos-especiales",
    "title": "\n2  La Sintaxis DT[i, j, by]\n",
    "section": "\n2.9 Próximo Capítulo: Símbolos Especiales",
    "text": "2.9 Próximo Capítulo: Símbolos Especiales\nEn el siguiente capítulo profundizaremos en: - .SD: El subset de datos por grupo - .SDcols: Control granular de columnas - .I y .GRP: Índices y identificadores de grupo - Casos de uso avanzados de estos símbolos\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nDT[i, j, by] es la sintaxis universal - domínala y dominarás data.table\n\n\ni filtra filas - usa condiciones lógicas, posiciones, u ordenamiento\n\nj selecciona/calcula - usa .() para múltiples columnas con nombres\n\nby agrupa datos - puede usar múltiples variables o expresiones\n\n.N cuenta filas - funciona en contexto general o por grupo\n\nCombina libremente - la flexibilidad es el superpoder de data.table\n\n\n\n\nCon estos fundamentos sólidos de la sintaxis DT[i, j, by], estás listo para explorar los símbolos especiales que hacen de data.table una herramienta verdaderamente poderosa.",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html",
    "href": "cap01-simbolos.html",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "",
    "text": "3.1 El Símbolo .SD: Subset of Data\n.SD es quizás el símbolo más poderoso de data.table. Contiene todas las columnas del grupo actual (excepto las variables de agrupación) como un data.table en sí mismo.",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#el-símbolo-.sd-subset-of-data",
    "href": "cap01-simbolos.html#el-símbolo-.sd-subset-of-data",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "",
    "text": "3.1.1 1. Conceptos Fundamentales de .SD\n\n\n# Veamos qué contiene .SD\nempleados_avanzado[, {\n  cat(\"Grupo:\", unique(departamento), \"\\n\")\n  cat(\"Columnas en .SD:\", names(.SD), \"\\n\")\n  cat(\"Filas en .SD:\", nrow(.SD), \"\\n\\n\")\n  # Devolver algo para que funcione el data.table\n  .N\n}, by = departamento]\n#&gt; Grupo: Ventas \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus años_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: IT \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus años_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: Marketing \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus años_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: RRHH \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus años_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: Finanzas \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus años_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4\n#&gt;    departamento    V1\n#&gt;          &lt;char&gt; &lt;int&gt;\n#&gt; 1:       Ventas     4\n#&gt; 2:           IT     4\n#&gt; 3:    Marketing     4\n#&gt; 4:         RRHH     4\n#&gt; 5:     Finanzas     4\n\n\n# Ejemplo práctico: estadísticas de salario por departamento\nstats_salarios &lt;- empleados_avanzado[, {\n  list(\n    empleados = .N,\n    salario_promedio = round(mean(.SD$salario_total), 0),\n    salario_mediana = round(median(.SD$salario_total), 0),\n    salario_max = max(.SD$salario_total),\n    salario_min = min(.SD$salario_total),\n    rango_salario = max(.SD$salario_total) - min(.SD$salario_total)\n  )\n}, by = departamento]\n\nprint(stats_salarios)\n#&gt;    departamento empleados salario_promedio salario_mediana salario_max\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;           &lt;num&gt;       &lt;num&gt;\n#&gt; 1:       Ventas         4            52175           52750       70200\n#&gt; 2:           IT         4            52200           53350       63300\n#&gt; 3:    Marketing         4            55900           57200       60200\n#&gt; 4:         RRHH         4            51550           54100       60600\n#&gt; 5:     Finanzas         4            57875           56600       71800\n#&gt;    salario_min rango_salario\n#&gt;          &lt;num&gt;         &lt;num&gt;\n#&gt; 1:       33000         37200\n#&gt; 2:       38800         24500\n#&gt; 3:       49000         11200\n#&gt; 4:       37400         23200\n#&gt; 5:       46500         25300\n\n\n3.1.2 2. Aplicar Funciones con lapply(.SD, ...)\n\nEl verdadero poder de .SD surge cuando lo combinas con lapply() para aplicar funciones a múltiples columnas:\n\n# Aplicar mean() a todas las columnas numéricas por departamento\nmedias_por_dept &lt;- empleados_avanzado[, \n  lapply(.SD, mean, na.rm = TRUE), \n  by = departamento,\n  .SDcols = is.numeric  # Solo columnas numéricas\n]\n\nprint(medias_por_dept)\n#&gt;    departamento    id salario_base bonus años_exp certificaciones\n#&gt;          &lt;char&gt; &lt;num&gt;        &lt;num&gt; &lt;num&gt;    &lt;num&gt;           &lt;num&gt;\n#&gt; 1:       Ventas   2.5        47475  4700    11.75            2.75\n#&gt; 2:           IT   6.5        45625  6575    11.25            1.00\n#&gt; 3:    Marketing  10.5        49075  6825     3.00            4.75\n#&gt; 4:         RRHH  14.5        44575  6975     9.25            3.25\n#&gt; 5:     Finanzas  18.5        51050  6825     4.75            1.75\n#&gt;    proyectos_completados rating_performance salario_total productividad\n#&gt;                    &lt;num&gt;              &lt;num&gt;         &lt;num&gt;         &lt;num&gt;\n#&gt; 1:                 11.25              3.850         52175        1.1900\n#&gt; 2:                 35.00              4.150         52200        3.1975\n#&gt; 3:                 43.75              4.425         55900       24.6075\n#&gt; 4:                 32.50              4.625         51550       11.7425\n#&gt; 5:                 38.00              3.675         57875       11.3625\n#&gt;    valor_empleado\n#&gt;             &lt;num&gt;\n#&gt; 1:       2443.035\n#&gt; 2:       2415.500\n#&gt; 3:        727.840\n#&gt; 4:       2051.960\n#&gt; 5:       1157.883\n\n\n# Múltiples estadísticas por grupo usando funciones personalizadas\nestadisticas_avanzadas &lt;- empleados_avanzado[, \n  lapply(.SD, function(x) {\n    if(is.numeric(x)) {\n      list(\n        media = round(mean(x, na.rm = TRUE), 2),\n        mediana = round(median(x, na.rm = TRUE), 2),\n        desv_std = round(sd(x, na.rm = TRUE), 2),\n        cv = round(sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE), 3)\n      )\n    } else {\n      list(valores_unicos = length(unique(x)))\n    }\n  }),\n  by = departamento,\n  .SDcols = c(\"salario_total\", \"años_exp\", \"rating_performance\")\n]\n\nprint(estadisticas_avanzadas)\n#&gt;     departamento salario_total años_exp rating_performance\n#&gt;           &lt;char&gt;        &lt;list&gt;   &lt;list&gt;             &lt;list&gt;\n#&gt;  1:       Ventas         52175    11.75               3.85\n#&gt;  2:       Ventas         52750       12                3.7\n#&gt;  3:       Ventas      17803.44     2.99                0.7\n#&gt;  4:       Ventas         0.341    0.254              0.181\n#&gt;  5:           IT         52200    11.25               4.15\n#&gt; ---                                                       \n#&gt; 16:         RRHH         0.194     0.62              0.065\n#&gt; 17:     Finanzas         57875     4.75               3.67\n#&gt; 18:     Finanzas         56600      4.5               3.55\n#&gt; 19:     Finanzas      13198.07      2.5               0.45\n#&gt; 20:     Finanzas         0.228    0.526              0.122\n\n\n3.1.3 3. Transformaciones Complejas con .SD\n\n\n# Normalizar columnas dentro de cada departamento (Z-score)\nempleados_normalizados &lt;- empleados_avanzado[,\n  c(.SD[, 1:2], lapply(.SD[, -(1:2)], function(x) {\n    if(is.numeric(x) && length(unique(x)) &gt; 1) {\n      round((x - mean(x)) / sd(x), 3)\n    } else {\n      x\n    }\n  })),\n  by = departamento\n][order(departamento, id)]\n\n# Mostrar solo algunas columnas para claridad\nprint(empleados_normalizados[, .(departamento, nombre, salario_total, años_exp, rating_performance)])\n#&gt;     departamento     nombre salario_total años_exp rating_performance\n#&gt;           &lt;char&gt;     &lt;char&gt;         &lt;num&gt;    &lt;num&gt;              &lt;num&gt;\n#&gt;  1:     Finanzas Empleado_Q        -0.862   -0.300             -0.833\n#&gt;  2:     Finanzas Empleado_R         0.654    0.100              0.056\n#&gt;  3:     Finanzas Empleado_S         1.055    1.300              1.389\n#&gt;  4:     Finanzas Empleado_T        -0.847   -1.100             -0.611\n#&gt;  5:           IT Empleado_E         0.742   -1.306             -0.691\n#&gt; ---                                                                  \n#&gt; 16:         RRHH Empleado_P        -1.416    0.479             -1.088\n#&gt; 17:       Ventas Empleado_A         1.012   -1.256              0.072\n#&gt; 18:       Ventas Empleado_B        -0.605   -0.251             -0.503\n#&gt; 19:       Ventas Empleado_C        -1.077    0.419             -0.935\n#&gt; 20:       Ventas Empleado_D         0.670    1.088              1.366",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#control-de-columnas-con-.sdcols",
    "href": "cap01-simbolos.html#control-de-columnas-con-.sdcols",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "\n3.2 Control de Columnas con .SDcols\n",
    "text": "3.2 Control de Columnas con .SDcols\n\n.SDcols te permite especificar exactamente qué columnas debe incluir .SD.\n\n3.2.1 1. Formas de Especificar .SDcols\n\n\n# Por nombres de columna\npor_nombres &lt;- empleados_avanzado[,\n  lapply(.SD, mean),\n  by = departamento,\n  .SDcols = c(\"salario_total\", \"años_exp\", \"rating_performance\")\n]\n\n# Por patrones\npor_patrones &lt;- empleados_avanzado[,\n  lapply(.SD, max),\n  by = departamento,\n  .SDcols = patterns(\"salario|rating\")\n]\n\n# Por tipo de datos\npor_tipo &lt;- empleados_avanzado[,\n  lapply(.SD, function(x) length(unique(x))),\n  by = departamento,\n  .SDcols = is.character\n]\n\nprint(\"Por nombres:\")\n#&gt; [1] \"Por nombres:\"\nprint(por_nombres)\n#&gt;    departamento salario_total años_exp rating_performance\n#&gt;          &lt;char&gt;         &lt;num&gt;    &lt;num&gt;              &lt;num&gt;\n#&gt; 1:       Ventas         52175    11.75              3.850\n#&gt; 2:           IT         52200    11.25              4.150\n#&gt; 3:    Marketing         55900     3.00              4.425\n#&gt; 4:         RRHH         51550     9.25              4.625\n#&gt; 5:     Finanzas         57875     4.75              3.675\nprint(\"\\nPor patrones:\")\n#&gt; [1] \"\\nPor patrones:\"\nprint(por_patrones)\n#&gt;    departamento salario_base rating_performance salario_total\n#&gt;          &lt;char&gt;        &lt;num&gt;              &lt;num&gt;         &lt;num&gt;\n#&gt; 1:       Ventas        65000                4.8         70200\n#&gt; 2:           IT        58600                4.8         63300\n#&gt; 3:    Marketing        55400                5.0         60200\n#&gt; 4:         RRHH        53300                5.0         60600\n#&gt; 5:     Finanzas        68500                4.3         71800\nprint(\"\\nPor tipo (character):\")\n#&gt; [1] \"\\nPor tipo (character):\"\nprint(por_tipo)\n#&gt;    departamento nombre departamento nivel\n#&gt;          &lt;char&gt;  &lt;int&gt;        &lt;int&gt; &lt;int&gt;\n#&gt; 1:       Ventas      4            1     4\n#&gt; 2:           IT      4            1     4\n#&gt; 3:    Marketing      4            1     4\n#&gt; 4:         RRHH      4            1     4\n#&gt; 5:     Finanzas      4            1     4\n\n\n3.2.2 2. Casos de Uso Avanzados de .SDcols\n\n\n# Análisis de correlaciones por departamento\ncorrelaciones_dept &lt;- empleados_avanzado[activo == TRUE,  # Solo empleados activos\n{\n  # Seleccionar solo columnas numéricas con variabilidad\n  cols_numericas &lt;- sapply(.SD, function(x) is.numeric(x) && var(x, na.rm = TRUE) &gt; 0)\n  nombres_cols_validas &lt;- names(cols_numericas)[cols_numericas]\n  \n  if(length(nombres_cols_validas) &gt;= 2) {\n    cor_matrix &lt;- cor(.SD[, nombres_cols_validas, with = FALSE])\n    # Extraer correlación específica: salario vs rating (si ambas existen)\n    if(\"salario_total\" %in% nombres_cols_validas && \"rating_performance\" %in% nombres_cols_validas) {\n      correlacion_sal_rating &lt;- round(cor_matrix[\"salario_total\", \"rating_performance\"], 3)\n    } else {\n      correlacion_sal_rating &lt;- NA\n    }\n    list(\n      correlacion_salario_rating = correlacion_sal_rating,\n      num_variables = length(nombres_cols_validas)\n    )\n  } else {\n    list(correlacion_salario_rating = NA, num_variables = length(nombres_cols_validas))\n  }\n},\nby = departamento,\n.SDcols = is.numeric\n]\n\nprint(correlaciones_dept)\n#&gt;    departamento correlacion_salario_rating num_variables\n#&gt;          &lt;char&gt;                      &lt;num&gt;         &lt;int&gt;\n#&gt; 1:       Ventas                      0.586            10\n#&gt; 2:           IT                     -0.399            10\n#&gt; 3:    Marketing                      0.033            10\n#&gt; 4:         RRHH                      0.845            10\n#&gt; 5:     Finanzas                      0.912            10\n\n\n# Selección dinámica de columnas basada en criterios\ncolumnas_con_variacion &lt;- empleados_avanzado[, \n  sapply(.SD, function(x) if(is.numeric(x)) var(x, na.rm = TRUE) &gt; 1000 else FALSE),\n  .SDcols = is.numeric\n]\n\nprint(\"Columnas con alta variación:\")\n#&gt; [1] \"Columnas con alta variación:\"\nprint(names(columnas_con_variacion)[columnas_con_variacion])\n#&gt; [1] \"salario_base\"   \"bonus\"          \"salario_total\"  \"valor_empleado\"\n\n# Usar esas columnas para análisis\nanalisis_alta_variacion &lt;- empleados_avanzado[,\n  lapply(.SD, function(x) c(min = min(x), max = max(x), rango = max(x) - min(x))),\n  .SDcols = names(columnas_con_variacion)[columnas_con_variacion]\n]\n\nprint(analisis_alta_variacion)\n#&gt;    salario_base bonus salario_total valor_empleado\n#&gt;           &lt;num&gt; &lt;num&gt;         &lt;num&gt;          &lt;num&gt;\n#&gt; 1:        30600  2400         33000          301.0\n#&gt; 2:        68500 12300         71800         4615.2\n#&gt; 3:        37900  9900         38800         4314.2",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#el-símbolo-.i-índices-de-fila",
    "href": "cap01-simbolos.html#el-símbolo-.i-índices-de-fila",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "\n3.3 El Símbolo .I: Índices de Fila",
    "text": "3.3 El Símbolo .I: Índices de Fila\n.I contiene los índices (números de fila) de las observaciones del grupo actual en el data.table original.\n\n3.3.1 1. Usos Básicos de .I\n\n\n# Encontrar el índice del empleado con mayor salario por departamento\nindices_top_salario &lt;- empleados_avanzado[,\n  .I[which.max(salario_total)],\n  by = departamento\n]\n\nprint(\"Índices de empleados con mayor salario:\")\n#&gt; [1] \"Índices de empleados con mayor salario:\"\nprint(indices_top_salario)\n#&gt;    departamento    V1\n#&gt;          &lt;char&gt; &lt;int&gt;\n#&gt; 1:       Ventas     1\n#&gt; 2:           IT     7\n#&gt; 3:    Marketing     9\n#&gt; 4:         RRHH    14\n#&gt; 5:     Finanzas    19\n\n# Usar esos índices para extraer las filas completas\ntop_empleados_por_dept &lt;- empleados_avanzado[indices_top_salario$V1]\nprint(\"\\nEmpleados con mayor salario por departamento:\")\n#&gt; [1] \"\\nEmpleados con mayor salario por departamento:\"\nprint(top_empleados_por_dept[, .(departamento, nombre, salario_total)])\n#&gt;    departamento     nombre salario_total\n#&gt;          &lt;char&gt;     &lt;char&gt;         &lt;num&gt;\n#&gt; 1:       Ventas Empleado_A         70200\n#&gt; 2:           IT Empleado_G         63300\n#&gt; 3:    Marketing Empleado_I         60200\n#&gt; 4:         RRHH Empleado_N         60600\n#&gt; 5:     Finanzas Empleado_S         71800\n\n\n3.3.2 2. Casos de Uso Avanzados con .I\n\n\n# Top N empleados por departamento\ntop_2_por_dept &lt;- empleados_avanzado[,\n  .I[order(-salario_total)][1:min(2, .N)],  # Top 2 o todos si hay menos de 2\n  by = departamento\n]\n\nempleados_top2 &lt;- empleados_avanzado[top_2_por_dept$V1]\nprint(\"Top 2 empleados por departamento:\")\n#&gt; [1] \"Top 2 empleados por departamento:\"\nprint(empleados_top2[, .(departamento, nombre, salario_total)][order(departamento, -salario_total)])\n#&gt;     departamento     nombre salario_total\n#&gt;           &lt;char&gt;     &lt;char&gt;         &lt;num&gt;\n#&gt;  1:     Finanzas Empleado_S         71800\n#&gt;  2:     Finanzas Empleado_R         66500\n#&gt;  3:           IT Empleado_G         63300\n#&gt;  4:           IT Empleado_E         61000\n#&gt;  5:    Marketing Empleado_I         60200\n#&gt;  6:    Marketing Empleado_L         59600\n#&gt;  7:         RRHH Empleado_N         60600\n#&gt;  8:         RRHH Empleado_O         55600\n#&gt;  9:       Ventas Empleado_A         70200\n#&gt; 10:       Ventas Empleado_D         64100\n\n\n# Muestreo estratificado usando .I\nset.seed(123)\nmuestra_estratificada &lt;- empleados_avanzado[,\n  .I[sample(.N, size = min(2, .N))],  # 2 empleados por departamento\n  by = departamento\n]\n\nempleados_muestra &lt;- empleados_avanzado[muestra_estratificada$V1]\nprint(\"Muestra estratificada:\")\n#&gt; [1] \"Muestra estratificada:\"\nprint(empleados_muestra[, .(departamento, nombre, años_exp)])\n#&gt;     departamento     nombre años_exp\n#&gt;           &lt;char&gt;     &lt;char&gt;    &lt;int&gt;\n#&gt;  1:       Ventas Empleado_C       13\n#&gt;  2:       Ventas Empleado_D       15\n#&gt;  3:           IT Empleado_G       12\n#&gt;  4:           IT Empleado_F       11\n#&gt;  5:    Marketing Empleado_K        2\n#&gt;  6:    Marketing Empleado_J        7\n#&gt;  7:         RRHH Empleado_N        1\n#&gt;  8:         RRHH Empleado_P       12\n#&gt;  9:     Finanzas Empleado_S        8\n#&gt; 10:     Finanzas Empleado_Q        4",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#el-símbolo-.grp-identificador-de-grupo",
    "href": "cap01-simbolos.html#el-símbolo-.grp-identificador-de-grupo",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "\n3.4 El Símbolo .GRP: Identificador de Grupo",
    "text": "3.4 El Símbolo .GRP: Identificador de Grupo\n.GRP es un contador que asigna un número único e incremental a cada grupo.\n\n3.4.1 1. Usos de .GRP\n\n\n# Asignar ID único a cada departamento\nempleados_con_grupo &lt;- empleados_avanzado[,\n  .(nombre, departamento, grupo_id = .GRP, empleados_en_grupo = .N),\n  by = departamento\n]\n\nprint(empleados_con_grupo)\n#&gt;     departamento     nombre departamento grupo_id empleados_en_grupo\n#&gt;           &lt;char&gt;     &lt;char&gt;       &lt;char&gt;    &lt;int&gt;              &lt;int&gt;\n#&gt;  1:       Ventas Empleado_A       Ventas        1                  4\n#&gt;  2:       Ventas Empleado_B       Ventas        1                  4\n#&gt;  3:       Ventas Empleado_C       Ventas        1                  4\n#&gt;  4:       Ventas Empleado_D       Ventas        1                  4\n#&gt;  5:           IT Empleado_E           IT        2                  4\n#&gt;  6:           IT Empleado_F           IT        2                  4\n#&gt;  7:           IT Empleado_G           IT        2                  4\n#&gt;  8:           IT Empleado_H           IT        2                  4\n#&gt;  9:    Marketing Empleado_I    Marketing        3                  4\n#&gt; 10:    Marketing Empleado_J    Marketing        3                  4\n#&gt; 11:    Marketing Empleado_K    Marketing        3                  4\n#&gt; 12:    Marketing Empleado_L    Marketing        3                  4\n#&gt; 13:         RRHH Empleado_M         RRHH        4                  4\n#&gt; 14:         RRHH Empleado_N         RRHH        4                  4\n#&gt; 15:         RRHH Empleado_O         RRHH        4                  4\n#&gt; 16:         RRHH Empleado_P         RRHH        4                  4\n#&gt; 17:     Finanzas Empleado_Q     Finanzas        5                  4\n#&gt; 18:     Finanzas Empleado_R     Finanzas        5                  4\n#&gt; 19:     Finanzas Empleado_S     Finanzas        5                  4\n#&gt; 20:     Finanzas Empleado_T     Finanzas        5                  4\n#&gt;     departamento     nombre departamento grupo_id empleados_en_grupo\n\n\n# Análisis de transacciones por grupo de cliente\nanalisis_grupos &lt;- transacciones[,\n  .(\n    grupo_cliente = .GRP,\n    num_transacciones = .N,\n    monto_promedio = round(mean(monto_final), 2),\n    primera_compra = min(fecha),\n    ultima_compra = max(fecha)\n  ),\n  by = tipo_cliente\n]\n\nprint(analisis_grupos)\n#&gt;    tipo_cliente grupo_cliente num_transacciones monto_promedio primera_compra\n#&gt;          &lt;char&gt;         &lt;int&gt;             &lt;int&gt;          &lt;num&gt;         &lt;Date&gt;\n#&gt; 1:        Basic             1               502         223.58     2023-01-01\n#&gt; 2:      Regular             2               297         207.99     2023-01-02\n#&gt; 3:      Premium             3               201         219.04     2023-01-02\n#&gt;    ultima_compra\n#&gt;           &lt;Date&gt;\n#&gt; 1:    2023-12-31\n#&gt; 2:    2023-12-31\n#&gt; 3:    2023-12-30",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#combinando-símbolos-casos-de-uso-profesionales",
    "href": "cap01-simbolos.html#combinando-símbolos-casos-de-uso-profesionales",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "\n3.5 Combinando Símbolos: Casos de Uso Profesionales",
    "text": "3.5 Combinando Símbolos: Casos de Uso Profesionales\n\n3.5.1 1. Análisis de Cohortes\n\n\n# Análisis de cohortes de empleados por año de ingreso\nlibrary(lubridate)\n\nanalisis_cohortes &lt;- empleados_avanzado[,\n  .(\n    cohorte_id = .GRP,\n    año_ingreso = year(min(fecha_ingreso)),\n    empleados_iniciales = .N,\n    salario_inicial_promedio = round(mean(salario_base), 0),\n    retencion_actual = round(mean(activo) * 100, 1),\n    performance_promedio = round(mean(rating_performance), 2),\n    # Usando .SD para métricas adicionales\n    experiencia_rango = paste0(min(.SD$años_exp), \"-\", max(.SD$años_exp), \" años\")\n  ),\n  by = .(año_cohorte = year(fecha_ingreso)),\n  .SDcols = \"años_exp\"\n][order(año_cohorte)]\n\nprint(analisis_cohortes)\n#&gt;    año_cohorte cohorte_id año_ingreso empleados_iniciales\n#&gt;          &lt;num&gt;      &lt;int&gt;       &lt;num&gt;               &lt;int&gt;\n#&gt; 1:        2015          1        2015                   1\n#&gt; 2:        2016          7        2016                   4\n#&gt; 3:        2017          8        2017                   2\n#&gt; 4:        2018          3        2018                   3\n#&gt; 5:        2019          6        2019                   1\n#&gt; 6:        2021          2        2021                   3\n#&gt; 7:        2022          5        2022                   3\n#&gt; 8:        2023          4        2023                   3\n#&gt;    salario_inicial_promedio retencion_actual performance_promedio\n#&gt;                       &lt;num&gt;            &lt;num&gt;                &lt;num&gt;\n#&gt; 1:                    65000            100.0                 3.90\n#&gt; 2:                    50875            100.0                 4.30\n#&gt; 3:                    50550            100.0                 4.10\n#&gt; 4:                    36267             66.7                 4.00\n#&gt; 5:                    58600            100.0                 4.30\n#&gt; 6:                    43533            100.0                 4.40\n#&gt; 7:                    51567            100.0                 3.60\n#&gt; 8:                    42967            100.0                 4.43\n#&gt;    experiencia_rango\n#&gt;               &lt;char&gt;\n#&gt; 1:          8-8 años\n#&gt; 2:         1-14 años\n#&gt; 3:          2-2 años\n#&gt; 4:         7-13 años\n#&gt; 5:        12-12 años\n#&gt; 6:         1-11 años\n#&gt; 7:         4-10 años\n#&gt; 8:        11-15 años\n\n\n3.5.2 2. Detección de Outliers por Grupo\n\n\n# Detectar outliers en salario dentro de cada departamento\noutliers_salario &lt;- empleados_avanzado[,\n{\n  Q1 &lt;- quantile(salario_total, 0.25)\n  Q3 &lt;- quantile(salario_total, 0.75)\n  IQR &lt;- Q3 - Q1\n  limite_inferior &lt;- Q1 - 1.5 * IQR\n  limite_superior &lt;- Q3 + 1.5 * IQR\n  \n  outliers_indices &lt;- .I[salario_total &lt; limite_inferior | salario_total &gt; limite_superior]\n  \n  list(\n    departamento = unique(departamento),\n    num_outliers = length(outliers_indices),\n    outliers_ids = if(length(outliers_indices) &gt; 0) list(outliers_indices) else list(integer(0)),\n    limite_inf = round(limite_inferior, 0),\n    limite_sup = round(limite_superior, 0)\n  )\n},\nby = departamento\n]\n\nprint(outliers_salario)\n#&gt;    departamento departamento num_outliers outliers_ids limite_inf limite_sup\n#&gt;          &lt;char&gt;       &lt;char&gt;        &lt;int&gt;       &lt;list&gt;      &lt;num&gt;      &lt;num&gt;\n#&gt; 1:       Ventas       Ventas            0                    -188     105112\n#&gt; 2:           IT           IT            0                   17575      87975\n#&gt; 3:    Marketing    Marketing            0                   43750      69350\n#&gt; 4:         RRHH         RRHH            0                   36725      68925\n#&gt; 5:     Finanzas     Finanzas            0                   14888      99588\n\n# Extraer los outliers reales\noutliers_reales &lt;- unique(unlist(outliers_salario$outliers_ids))\nif(length(outliers_reales) &gt; 0) {\n  empleados_outliers &lt;- empleados_avanzado[outliers_reales]\n  print(\"\\nEmpleados con salarios outliers:\")\n  print(empleados_outliers[, .(nombre, departamento, salario_total)])\n}\n\n\n3.5.3 3. Ventana Móvil con .SD\n\n\n# Análisis de ventana móvil en transacciones\n# Primero ordenamos por fecha\ntransacciones_ordenadas &lt;- transacciones[order(fecha)]\n\n# Crear grupos por mes para simular ventana temporal\nventana_movil &lt;- transacciones_ordenadas[,\n{\n  # Para cada mes, calcular métricas usando .SD\n  current_data &lt;- .SD\n  list(\n    mes = unique(mes),\n    transacciones_mes = .N,\n    monto_total = sum(monto_final),\n    ticket_promedio = round(mean(monto_final), 2),\n    # Diversidad de productos\n    productos_unicos = uniqueN(producto_id),\n    # Análisis de canales usando .SD\n    canal_dominante = names(sort(table(.SD$canal), decreasing = TRUE))[1],\n    concentracion_clientes = round(1 - (uniqueN(cliente_id) / .N), 3)  # Índice de concentración\n  )\n},\nby = .(año = year(fecha), mes),\n.SDcols = c(\"monto_final\", \"producto_id\", \"canal\", \"cliente_id\")\n][order(año, mes)]\n\nprint(ventana_movil)\n#&gt;       año   mes   mes transacciones_mes monto_total ticket_promedio\n#&gt;     &lt;num&gt; &lt;int&gt; &lt;int&gt;             &lt;int&gt;       &lt;num&gt;           &lt;num&gt;\n#&gt;  1:  2023     1     1                86    17489.98          203.37\n#&gt;  2:  2023     2     2                86    18022.41          209.56\n#&gt;  3:  2023     3     3                73    14743.75          201.97\n#&gt;  4:  2023     4     4                87    18146.44          208.58\n#&gt;  5:  2023     5     5                86    17393.11          202.25\n#&gt;  6:  2023     6     6                82    19097.84          232.90\n#&gt;  7:  2023     7     7                79    17723.32          224.35\n#&gt;  8:  2023     8     8                87    18408.98          211.60\n#&gt;  9:  2023     9     9                72    17707.42          245.94\n#&gt; 10:  2023    10    10                88    19787.56          224.86\n#&gt; 11:  2023    11    11                84    18717.37          222.83\n#&gt; 12:  2023    12    12                90    20800.00          231.11\n#&gt;     productos_unicos canal_dominante concentracion_clientes\n#&gt;                &lt;int&gt;          &lt;char&gt;                  &lt;num&gt;\n#&gt;  1:               10          Online                  0.337\n#&gt;  2:               10          Online                  0.326\n#&gt;  3:               10          Online                  0.315\n#&gt;  4:               10          Online                  0.253\n#&gt;  5:               10          Online                  0.395\n#&gt;  6:               10          Online                  0.293\n#&gt;  7:               10          Online                  0.342\n#&gt;  8:               10          Online                  0.322\n#&gt;  9:               10          Online                  0.375\n#&gt; 10:               10          Online                  0.273\n#&gt; 11:               10          Online                  0.274\n#&gt; 12:               10          Online                  0.267",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#ejercicios-prácticos",
    "href": "cap01-simbolos.html#ejercicios-prácticos",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "\n3.6 Ejercicios Prácticos",
    "text": "3.6 Ejercicios Prácticos\n\n\n\n\n\n\n🏋️ Ejercicio 5: Análisis Multidimensional con Símbolos Especiales\n\n\n\nUsando el dataset transacciones, crea un análisis que utilice todos los símbolos especiales:\n\n\nCon .SD: Calcula estadísticas de monto por categoría y canal\n\nCon .SDcols: Analiza solo columnas que contengan “monto” o “descuento”\n\nCon .I: Encuentra las 3 mejores transacciones por categoría\n\nCon .GRP: Asigna IDs únicos a combinaciones categoría-canal\n\nAnálisis combinado: Crea un reporte complejo que use múltiples símbolos\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 5\n\n\n\n\n\n\n# 1. Estadísticas con .SD por categoría y canal\nestadisticas_SD &lt;- transacciones[,\n  lapply(.SD, function(x) {\n    if(is.numeric(x)) {\n      list(\n        promedio = round(mean(x, na.rm = TRUE), 2),\n        mediana = round(median(x, na.rm = TRUE), 2),\n        desv_std = round(sd(x, na.rm = TRUE), 2)\n      )\n    } else {\n      list(valores_unicos = length(unique(x)))\n    }\n  }),\n  by = .(categoria, canal),\n  .SDcols = c(\"monto\", \"monto_final\", \"descuento\")\n]\n\nprint(\"1. Estadísticas por categoría y canal:\")\n#&gt; [1] \"1. Estadísticas por categoría y canal:\"\nprint(head(estadisticas_SD, 8))\n#&gt;      categoria  canal  monto monto_final descuento\n#&gt;         &lt;char&gt; &lt;char&gt; &lt;list&gt;      &lt;list&gt;    &lt;list&gt;\n#&gt; 1:      Sports Online 262.85      224.49      0.15\n#&gt; 2:      Sports Online 251.83      219.81      0.15\n#&gt; 3:      Sports Online    133      116.98      0.09\n#&gt; 4: Electronics Mobile  236.1      198.43      0.15\n#&gt; 5: Electronics Mobile 191.67      152.54      0.14\n#&gt; 6: Electronics Mobile 157.27      130.66      0.09\n#&gt; 7:       Books Mobile 248.05      210.83      0.16\n#&gt; 8:       Books Mobile 244.29       208.4      0.17\n\n# 2. Análisis con .SDcols específicas\nanalisis_montos &lt;- transacciones[,\n  lapply(.SD, function(x) c(\n    min = min(x),\n    max = max(x),\n    rango = max(x) - min(x),\n    coef_var = sd(x) / mean(x)\n  )),\n  by = categoria,\n  .SDcols = patterns(\"monto|descuento\")\n]\n\nprint(\"\\n2. Análisis de montos y descuentos:\")\n#&gt; [1] \"\\n2. Análisis de montos y descuentos:\"\nprint(analisis_montos)\n#&gt;       categoria       monto descuento monto_final\n#&gt;          &lt;char&gt;       &lt;num&gt;     &lt;num&gt;       &lt;num&gt;\n#&gt;  1:      Sports  13.6900000 0.0000000  11.4996000\n#&gt;  2:      Sports 498.1800000 0.3000000 465.4980000\n#&gt;  3:      Sports 484.4900000 0.3000000 453.9984000\n#&gt;  4:      Sports   0.5180114 0.5658237   0.5377436\n#&gt;  5: Electronics  12.2600000 0.0000000  10.4796000\n#&gt;  6: Electronics 498.4300000 0.3000000 481.5900000\n#&gt;  7: Electronics 486.1700000 0.3000000 471.1104000\n#&gt;  8: Electronics   0.5828812 0.5806229   0.5883679\n#&gt;  9:       Books  10.7900000 0.0000000   8.7010000\n#&gt; 10:       Books 499.6700000 0.3000000 480.2000000\n#&gt; 11:       Books 488.8800000 0.3000000 471.4990000\n#&gt; 12:       Books   0.5671143 0.6141504   0.5912270\n#&gt; 13:    Clothing  10.1700000 0.0000000   9.2547000\n#&gt; 14:    Clothing 497.7800000 0.3000000 489.6243000\n#&gt; 15:    Clothing 487.6100000 0.3000000 480.3696000\n#&gt; 16:    Clothing   0.5622603 0.5388315   0.5733788\n\n# 3. Top 3 transacciones por categoría usando .I\nindices_top3 &lt;- transacciones[,\n  .I[order(-monto_final)][1:min(3, .N)],\n  by = categoria\n]\n\ntop3_transacciones &lt;- transacciones[indices_top3$V1]\nprint(\"\\n3. Top 3 transacciones por categoría:\")\n#&gt; [1] \"\\n3. Top 3 transacciones por categoría:\"\nprint(top3_transacciones[, .(categoria, transaction_id, monto_final, producto_id)][order(categoria, -monto_final)])\n#&gt;       categoria transaction_id monto_final producto_id\n#&gt;          &lt;char&gt;          &lt;int&gt;       &lt;num&gt;      &lt;char&gt;\n#&gt;  1:       Books            235    480.2000           D\n#&gt;  2:       Books            826    479.8431           C\n#&gt;  3:       Books            545    475.1424           F\n#&gt;  4:    Clothing            304    489.6243           E\n#&gt;  5:    Clothing            718    486.0300           I\n#&gt;  6:    Clothing            917    473.1660           B\n#&gt;  7: Electronics            788    481.5900           J\n#&gt;  8: Electronics            225    477.9190           E\n#&gt;  9: Electronics            636    476.8132           C\n#&gt; 10:      Sports            148    465.4980           E\n#&gt; 11:      Sports            776    465.4642           H\n#&gt; 12:      Sports             73    462.3894           C\n\n# 4. IDs únicos con .GRP\ngrupos_categoria_canal &lt;- transacciones[,\n  .(\n    grupo_id = .GRP,\n    transacciones = .N,\n    monto_promedio = round(mean(monto_final), 2)\n  ),\n  by = .(categoria, canal)\n][order(grupo_id)]\n\nprint(\"\\n4. IDs de grupos categoría-canal:\")\n#&gt; [1] \"\\n4. IDs de grupos categoría-canal:\"\nprint(grupos_categoria_canal)\n#&gt;       categoria  canal grupo_id transacciones monto_promedio\n#&gt;          &lt;char&gt; &lt;char&gt;    &lt;int&gt;         &lt;int&gt;          &lt;num&gt;\n#&gt;  1:      Sports Online        1           125         224.49\n#&gt;  2: Electronics Mobile        2            49         198.43\n#&gt;  3:       Books Mobile        3            47         210.83\n#&gt;  4: Electronics Online        4           125         228.96\n#&gt;  5: Electronics  Store        5            77         196.52\n#&gt;  6:    Clothing Online        6           121         215.08\n#&gt;  7:       Books  Store        7            77         223.28\n#&gt;  8:       Books Online        8           129         222.99\n#&gt;  9:    Clothing  Store        9            85         200.10\n#&gt; 10:      Sports Mobile       10            48         237.55\n#&gt; 11:      Sports  Store       11            76         222.88\n#&gt; 12:    Clothing Mobile       12            41         225.89\n\n# 5. Análisis combinado ultra-avanzado\nanalisis_completo &lt;- transacciones[,\n{\n  # Usar todos los símbolos en un análisis complejo\n  grupo_id &lt;- .GRP\n  num_trans &lt;- .N\n  \n  # Estadísticas básicas con .SD\n  stats_basicas &lt;- lapply(.SD[, .(monto_final, descuento)], function(x) {\n    c(media = mean(x), mediana = median(x))\n  })\n  \n  # Top performer con .I\n  top_transaction_idx &lt;- .I[which.max(monto_final)]\n  \n  # Análisis de clientes\n  clientes_unicos &lt;- uniqueN(cliente_id)\n  cliente_top &lt;- cliente_id[which.max(monto_final)]\n  \n  list(\n    grupo_id = grupo_id,\n    categoria = unique(categoria),\n    canal = unique(canal),\n    num_transacciones = num_trans,\n    monto_promedio = round(stats_basicas$monto_final[\"media\"], 2),\n    monto_mediana = round(stats_basicas$monto_final[\"mediana\"], 2),\n    descuento_promedio = round(stats_basicas$descuento[\"media\"], 3),\n    clientes_unicos = clientes_unicos,\n    concentracion = round(1 - (clientes_unicos / num_trans), 3),\n    top_transaction_id = transacciones[top_transaction_idx, transaction_id],\n    top_cliente_id = cliente_top,\n    diversidad_productos = uniqueN(producto_id)\n  )\n},\nby = .(categoria, canal),\n.SDcols = c(\"monto_final\", \"descuento\", \"cliente_id\", \"producto_id\")\n][order(-monto_promedio)]\n\nprint(\"\\n5. Análisis completo combinando todos los símbolos:\")\n#&gt; [1] \"\\n5. Análisis completo combinando todos los símbolos:\"\nprint(analisis_completo)\n#&gt;       categoria  canal grupo_id   categoria  canal num_transacciones\n#&gt;          &lt;char&gt; &lt;char&gt;    &lt;int&gt;      &lt;char&gt; &lt;char&gt;             &lt;int&gt;\n#&gt;  1:      Sports Mobile       10      Sports Mobile                48\n#&gt;  2: Electronics Online        4 Electronics Online               125\n#&gt;  3:    Clothing Mobile       12    Clothing Mobile                41\n#&gt;  4:      Sports Online        1      Sports Online               125\n#&gt;  5:       Books  Store        7       Books  Store                77\n#&gt;  6:       Books Online        8       Books Online               129\n#&gt;  7:      Sports  Store       11      Sports  Store                76\n#&gt;  8:    Clothing Online        6    Clothing Online               121\n#&gt;  9:       Books Mobile        3       Books Mobile                47\n#&gt; 10:    Clothing  Store        9    Clothing  Store                85\n#&gt; 11: Electronics Mobile        2 Electronics Mobile                49\n#&gt; 12: Electronics  Store        5 Electronics  Store                77\n#&gt;     monto_promedio monto_mediana descuento_promedio clientes_unicos\n#&gt;              &lt;num&gt;         &lt;num&gt;              &lt;num&gt;           &lt;int&gt;\n#&gt;  1:         237.55        272.55              0.166              39\n#&gt;  2:         228.96        235.17              0.155              77\n#&gt;  3:         225.89        244.68              0.149              34\n#&gt;  4:         224.49        219.81              0.150              76\n#&gt;  5:         223.28        214.69              0.133              54\n#&gt;  6:         222.99        205.71              0.142              69\n#&gt;  7:         222.88        227.40              0.158              52\n#&gt;  8:         215.08        216.92              0.160              66\n#&gt;  9:         210.83        208.40              0.164              35\n#&gt; 10:         200.10        176.29              0.155              57\n#&gt; 11:         198.43        152.54              0.153              33\n#&gt; 12:         196.52        185.82              0.139              58\n#&gt;     concentracion top_transaction_id top_cliente_id diversidad_productos\n#&gt;             &lt;num&gt;              &lt;int&gt;          &lt;int&gt;                &lt;int&gt;\n#&gt;  1:         0.188                776             88                   10\n#&gt;  2:         0.384                 74             74                   10\n#&gt;  3:         0.171                780             76                   10\n#&gt;  4:         0.392                148             53                   10\n#&gt;  5:         0.299                242             57                   10\n#&gt;  6:         0.465                235             99                   10\n#&gt;  7:         0.316                 73             54                   10\n#&gt;  8:         0.455                304             41                   10\n#&gt;  9:         0.255                545             88                   10\n#&gt; 10:         0.329                718             50                   10\n#&gt; 11:         0.327                636             98                   10\n#&gt; 12:         0.247                788             52                   10\n\n# Mostrar tabla final formateada para PDF\nknitr::kable(\n  analisis_completo,\n  caption = \"Análisis Completo por Categoría y Canal\",\n  digits = 2,\n  format.args = list(big.mark = \",\")\n)\n\n\nAnálisis Completo por Categoría y Canal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncategoria\ncanal\ngrupo_id\ncategoria\ncanal\nnum_transacciones\nmonto_promedio\nmonto_mediana\ndescuento_promedio\nclientes_unicos\nconcentracion\ntop_transaction_id\ntop_cliente_id\ndiversidad_productos\n\n\n\nSports\nMobile\n10\nSports\nMobile\n48\n237.55\n272.55\n0.17\n39\n0.19\n776\n88\n10\n\n\nElectronics\nOnline\n4\nElectronics\nOnline\n125\n228.96\n235.17\n0.16\n77\n0.38\n74\n74\n10\n\n\nClothing\nMobile\n12\nClothing\nMobile\n41\n225.89\n244.68\n0.15\n34\n0.17\n780\n76\n10\n\n\nSports\nOnline\n1\nSports\nOnline\n125\n224.49\n219.81\n0.15\n76\n0.39\n148\n53\n10\n\n\nBooks\nStore\n7\nBooks\nStore\n77\n223.28\n214.69\n0.13\n54\n0.30\n242\n57\n10\n\n\nBooks\nOnline\n8\nBooks\nOnline\n129\n222.99\n205.71\n0.14\n69\n0.47\n235\n99\n10\n\n\nSports\nStore\n11\nSports\nStore\n76\n222.88\n227.40\n0.16\n52\n0.32\n73\n54\n10\n\n\nClothing\nOnline\n6\nClothing\nOnline\n121\n215.08\n216.92\n0.16\n66\n0.46\n304\n41\n10\n\n\nBooks\nMobile\n3\nBooks\nMobile\n47\n210.83\n208.40\n0.16\n35\n0.26\n545\n88\n10\n\n\nClothing\nStore\n9\nClothing\nStore\n85\n200.10\n176.29\n0.16\n57\n0.33\n718\n50\n10\n\n\nElectronics\nMobile\n2\nElectronics\nMobile\n49\n198.43\n152.54\n0.15\n33\n0.33\n636\n98\n10\n\n\nElectronics\nStore\n5\nElectronics\nStore\n77\n196.52\n185.82\n0.14\n58\n0.25\n788\n52\n10",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#patrones-avanzados-y-mejores-prácticas",
    "href": "cap01-simbolos.html#patrones-avanzados-y-mejores-prácticas",
    "title": "\n3  Símbolos Especiales en data.table\n",
    "section": "\n3.7 Patrones Avanzados y Mejores Prácticas",
    "text": "3.7 Patrones Avanzados y Mejores Prácticas\n\n3.7.1 1. Funciones Personalizadas con .SD\n\n\n# Crear función personalizada para análisis estadístico\nanalisis_estadistico &lt;- function(dt, by_vars, numeric_cols) {\n  dt[,\n    lapply(.SD, function(x) {\n      if(is.numeric(x) && length(unique(x)) &gt; 1) {\n        list(\n          n = length(x),\n          media = round(mean(x, na.rm = TRUE), 2),\n          mediana = round(median(x, na.rm = TRUE), 2),\n          q25 = round(quantile(x, 0.25, na.rm = TRUE), 2),\n          q75 = round(quantile(x, 0.75, na.rm = TRUE), 2),\n          desv_std = round(sd(x, na.rm = TRUE), 2),\n          cv = round(sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE), 3),\n          asimetria = round((mean(x) - median(x)) / sd(x), 3)\n        )\n      } else {\n        list(valores_unicos = length(unique(x)))\n      }\n    }),\n    by = by_vars,\n    .SDcols = numeric_cols\n  ]\n}\n\n# Aplicar la función\nresultado_personalizado &lt;- analisis_estadistico(\n  empleados_avanzado,\n  by_vars = \"departamento\",\n  numeric_cols = c(\"salario_total\", \"años_exp\", \"rating_performance\")\n)\n\nprint(resultado_personalizado)\n#&gt;     departamento salario_total años_exp rating_performance\n#&gt;           &lt;char&gt;        &lt;list&gt;   &lt;list&gt;             &lt;list&gt;\n#&gt;  1:       Ventas             4        4                  4\n#&gt;  2:       Ventas         52175    11.75               3.85\n#&gt;  3:       Ventas         52750       12                3.7\n#&gt;  4:       Ventas         39300    10.25               3.42\n#&gt;  5:       Ventas         65625     13.5               4.12\n#&gt;  6:       Ventas      17803.44     2.99                0.7\n#&gt;  7:       Ventas         0.341    0.254              0.181\n#&gt;  8:       Ventas        -0.032   -0.084              0.216\n#&gt;  9:           IT             4        4                  4\n#&gt; 10:           IT         52200    11.25               4.15\n#&gt; 11:           IT         53350     11.5               4.05\n#&gt; 12:           IT         43975    10.75               3.77\n#&gt; 13:           IT         61575       12               4.42\n#&gt; 14:           IT      11866.76     0.96               0.51\n#&gt; 15:           IT         0.227    0.085              0.122\n#&gt; 16:           IT        -0.097   -0.261              0.197\n#&gt; 17:    Marketing             4        4                  4\n#&gt; 18:    Marketing         55900        3               4.42\n#&gt; 19:    Marketing         57200        2               4.45\n#&gt; 20:    Marketing         53350     1.75               4.25\n#&gt; 21:    Marketing         59750     3.25               4.62\n#&gt; 22:    Marketing       5196.15     2.71               0.49\n#&gt; 23:    Marketing         0.093    0.903              0.111\n#&gt; 24:    Marketing         -0.25    0.369             -0.051\n#&gt; 25:         RRHH             4        4                  4\n#&gt; 26:         RRHH         51550     9.25               4.62\n#&gt; 27:         RRHH         54100       11                4.6\n#&gt; 28:         RRHH         48800     7.75               4.45\n#&gt; 29:         RRHH         56850     12.5               4.78\n#&gt; 30:         RRHH       9993.83     5.74                0.3\n#&gt; 31:         RRHH         0.194     0.62              0.065\n#&gt; 32:         RRHH        -0.255   -0.305              0.084\n#&gt; 33:     Finanzas             4        4                  4\n#&gt; 34:     Finanzas         57875     4.75               3.67\n#&gt; 35:     Finanzas         56600      4.5               3.55\n#&gt; 36:     Finanzas         46650      3.5               3.38\n#&gt; 37:     Finanzas         67825     5.75               3.85\n#&gt; 38:     Finanzas      13198.07      2.5               0.45\n#&gt; 39:     Finanzas         0.228    0.526              0.122\n#&gt; 40:     Finanzas         0.097      0.1              0.278\n#&gt;     departamento salario_total años_exp rating_performance\n\n\n3.7.2 2. Optimización de Performance\n\n\n# ✅ HACER: Usar .SDcols para limitar columnas\n# Más eficiente\nempleados[, lapply(.SD, mean), by = dept, .SDcols = c(\"sal\", \"exp\")]\n\n# ❌ NO HACER: Procesar todas las columnas innecesariamente\n# Menos eficiente\nempleados[, lapply(.SD, mean), by = dept]\n\n# ✅ HACER: Combinar operaciones en una sola expresión\n# Más eficiente\nempleados[, {\n  list(\n    media_sal = mean(salario),\n    max_exp = max(años_exp),\n    grupo_id = .GRP\n  )\n}, by = dept]\n\n# ❌ NO HACER: Múltiples pasadas por los datos\n# Menos eficiente\nmedia_sal &lt;- empleados[, mean(salario), by = dept]\nmax_exp &lt;- empleados[, max(años_exp), by = dept]\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\n.SD es un mini-data.table con los datos del grupo actual - úsalo con lapply() para operaciones múltiples\n\n.SDcols controla qué columnas incluye .SD - esencial para performance y precisión\n\n.I te da los índices reales - perfecto para top-N, muestreo y filtrado avanzado\n\n.GRP asigna IDs únicos a grupos - útil para tracking y análisis de cohortes\n\nCombinar símbolos permite análisis complejos en una sola expresión\n\nPerformance: Limita .SDcols y combina operaciones para máxima eficiencia\n\n\n\nCon el dominio de estos símbolos especiales, tienes las herramientas para realizar análisis de datos sofisticados y eficientes. En el próximo módulo exploraremos técnicas de manipulación intermedia como encadenamiento y joins.\n[{“content”: “Reorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos”, “status”: “completed”, “id”: “1”}, {“content”: “Crear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1”, “status”: “completed”, “id”: “1-new”}, {“content”: “Reorganizar M0f3dulo 2: dividir en encadenamiento y joins”, “status”: “in_progress”, “id”: “2”}, {“content”: “Reorganizar M0f3dulo 3: dividir en joins avanzados, funciones especiales y reshape”, “status”: “pending”, “id”: “3”}, {“content”: “Reorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas”, “status”: “pending”, “id”: “4”}, {“content”: “Reorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones”, “status”: “pending”, “id”: “5”}]",
    "crumbs": [
      "**Módulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Símbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html",
    "href": "cap02-encadenamiento.html",
    "title": "\n4  Encadenamiento de Operaciones (Chaining)\n",
    "section": "",
    "text": "4.1 Conceptos Fundamentales del Encadenamiento\nEl encadenamiento en data.table permite ejecutar múltiples operaciones secuenciales en una sola expresión usando la sintaxis DT[...][...][...]. Cada conjunto de corchetes opera sobre el resultado del anterior.",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#conceptos-fundamentales-del-encadenamiento",
    "href": "cap02-encadenamiento.html#conceptos-fundamentales-del-encadenamiento",
    "title": "\n4  Encadenamiento de Operaciones (Chaining)\n",
    "section": "",
    "text": "4.1.1 1. Encadenamiento Básico\n\n\n# Operaciones separadas (tradicional)\npaso1 &lt;- empleados[salario &gt; 45000]  # Filtrar\npaso2 &lt;- paso1[, .(empleados = .N, salario_promedio = mean(salario)), by = departamento]  # Agrupar\nresultado_separado &lt;- paso2[order(-salario_promedio)]  # Ordenar\n\n# Misma operación encadenada\nresultado_encadenado &lt;- empleados[\n  salario &gt; 45000\n][\n  , .(empleados = .N, salario_promedio = round(mean(salario), 0)), by = departamento\n][\n  order(-salario_promedio)\n]\n\nprint(\"Resultado con encadenamiento:\")\n#&gt; [1] \"Resultado con encadenamiento:\"\nprint(resultado_encadenado)\n#&gt;    departamento empleados salario_promedio\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt; 1:       Ventas         3            74700\n#&gt; 2:         RRHH         3            68933\n#&gt; 3:     Finanzas         3            63533\n#&gt; 4:    Marketing         4            61750\n#&gt; 5:           IT         3            61633\n\n\n4.1.2 2. Ventajas del Encadenamiento\n\n\n# Ejemplo que muestra las ventajas\nanalisis_productividad &lt;- empleados[\n  activo == TRUE & años_exp &gt;= 3     # Solo empleados activos con experiencia\n][\n  , productividad_ajustada := pmin(productividad, 5)  # Ajustar outliers\n][\n  , .(\n    empleados = .N,\n    productividad_media = round(mean(productividad_ajustada), 2),\n    salario_total_grupo = sum(salario_total),\n    proyectos_totales = sum(proyectos)\n  ), by = .(departamento, nivel)\n][\n  productividad_media &gt; 1.5          # Solo grupos productivos\n][\n  order(departamento, -productividad_media)\n][\n  , ranking := 1:.N                  # Agregar ranking\n]\n\nprint(analisis_productividad)\n#&gt;    departamento   nivel empleados productividad_media salario_total_grupo\n#&gt;          &lt;char&gt;  &lt;char&gt;     &lt;int&gt;               &lt;num&gt;               &lt;num&gt;\n#&gt; 1:     Finanzas  Junior         1                5.00               79000\n#&gt; 2:           IT  Senior         1                5.00               63700\n#&gt; 3:           IT Manager         1                4.00               50300\n#&gt; 4:    Marketing    Lead         1                2.08               64000\n#&gt; 5:    Marketing Manager         1                1.60               78200\n#&gt; 6:         RRHH  Junior         1                3.00               82500\n#&gt; 7:       Ventas  Junior         1                2.09               89300\n#&gt;    proyectos_totales ranking\n#&gt;                &lt;int&gt;   &lt;int&gt;\n#&gt; 1:                19       1\n#&gt; 2:                22       2\n#&gt; 3:                24       3\n#&gt; 4:                25       4\n#&gt; 5:                 8       5\n#&gt; 6:                12       6\n#&gt; 7:                23       7\n\n\n\n\n\n\n\n💡 ¿Por qué encadenar?\n\n\n\n\n\nMenos variables temporales - No necesitas almacenar resultados intermedios\n\nCódigo más compacto - Múltiples operaciones en una expresión\n\nMejor rendimiento - Menos copias en memoria\n\nFlujo lógico claro - Lee de arriba abajo como una receta",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#comparación-con-dplyr-pipes",
    "href": "cap02-encadenamiento.html#comparación-con-dplyr-pipes",
    "title": "\n4  Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.2 Comparación con dplyr Pipes",
    "text": "4.2 Comparación con dplyr Pipes\nComparemos las dos aproximaciones principales para operaciones secuenciales:\n\n4.2.1 1. Sintaxis Lado a Lado\n\n\n\ndata.table (Chaining)\ndplyr (Pipes)\n\n\n\n\n# Pipeline complejo con data.table\npipeline_dt &lt;- ventas[\n  año == 2024 & valor_neto &gt; 1000    # Filtrar ventas importantes de 2024\n][\n  , .(\n    ventas_totales = sum(valor_neto),\n    unidades_totales = sum(cantidad),\n    transacciones = .N,\n    ticket_promedio = round(mean(valor_neto), 2)\n  ), by = .(region, producto)\n][\n  ventas_totales &gt; 10000             # Solo combinaciones significativas\n][\n  order(region, -ventas_totales)\n][\n  , rank_en_region := rank(-ventas_totales), by = region\n][\n  rank_en_region &lt;= 3                # Top 3 productos por región\n]\n\nprint(head(pipeline_dt, 12))\n#&gt;     region   producto ventas_totales unidades_totales transacciones\n#&gt;     &lt;char&gt;     &lt;char&gt;          &lt;num&gt;            &lt;int&gt;         &lt;int&gt;\n#&gt;  1: Centro Accesorios      1050344.8             1151           199\n#&gt;  2: Centro Smartphone      1023300.8             1023           171\n#&gt;  3: Centro     Tablet       874227.4              916           162\n#&gt;  4:   Este Smartphone       989853.6             1048           182\n#&gt;  5:   Este     Laptop       941461.4              984           164\n#&gt; ---                                                                \n#&gt;  8:  Norte Accesorios       922333.3             1026           168\n#&gt;  9:  Norte     Tablet       909612.5              953           172\n#&gt; 10:  Oeste     Laptop      1161534.8             1270           203\n#&gt; 11:  Oeste Smartphone       993922.4             1104           178\n#&gt; 12:  Oeste Accesorios       950027.6             1048           183\n#&gt;     ticket_promedio rank_en_region\n#&gt;               &lt;num&gt;          &lt;num&gt;\n#&gt;  1:         5278.11              1\n#&gt;  2:         5984.22              2\n#&gt;  3:         5396.47              3\n#&gt;  4:         5438.76              1\n#&gt;  5:         5740.62              2\n#&gt; ---                               \n#&gt;  8:         5490.08              2\n#&gt;  9:         5288.44              3\n#&gt; 10:         5721.85              1\n#&gt; 11:         5583.83              2\n#&gt; 12:         5191.41              3\n\n\n\n\n# Mismo pipeline con dplyr\npipeline_dplyr &lt;- ventas %&gt;%\n  filter(año == 2024, valor_neto &gt; 1000) %&gt;%\n  group_by(region, producto) %&gt;%\n  summarise(\n    ventas_totales = sum(valor_neto),\n    unidades_totales = sum(cantidad),\n    transacciones = n(),\n    ticket_promedio = round(mean(valor_neto), 2),\n    .groups = 'drop'\n  ) %&gt;%\n  filter(ventas_totales &gt; 10000) %&gt;%\n  arrange(region, desc(ventas_totales)) %&gt;%\n  group_by(region) %&gt;%\n  mutate(rank_en_region = rank(desc(ventas_totales))) %&gt;%\n  filter(rank_en_region &lt;= 3) %&gt;%\n  ungroup()\n\nprint(head(as.data.table(pipeline_dplyr), 12))\n#&gt;     region   producto ventas_totales unidades_totales transacciones\n#&gt;     &lt;char&gt;     &lt;char&gt;          &lt;num&gt;            &lt;int&gt;         &lt;int&gt;\n#&gt;  1: Centro Accesorios      1050344.8             1151           199\n#&gt;  2: Centro Smartphone      1023300.8             1023           171\n#&gt;  3: Centro     Tablet       874227.4              916           162\n#&gt;  4:   Este Smartphone       989853.6             1048           182\n#&gt;  5:   Este     Laptop       941461.4              984           164\n#&gt; ---                                                                \n#&gt;  8:  Norte Accesorios       922333.3             1026           168\n#&gt;  9:  Norte     Tablet       909612.5              953           172\n#&gt; 10:  Oeste     Laptop      1161534.8             1270           203\n#&gt; 11:  Oeste Smartphone       993922.4             1104           178\n#&gt; 12:  Oeste Accesorios       950027.6             1048           183\n#&gt;     ticket_promedio rank_en_region\n#&gt;               &lt;num&gt;          &lt;num&gt;\n#&gt;  1:         5278.11              1\n#&gt;  2:         5984.22              2\n#&gt;  3:         5396.47              3\n#&gt;  4:         5438.76              1\n#&gt;  5:         5740.62              2\n#&gt; ---                               \n#&gt;  8:         5490.08              2\n#&gt;  9:         5288.44              3\n#&gt; 10:         5721.85              1\n#&gt; 11:         5583.83              2\n#&gt; 12:         5191.41              3\n\n\n\n\n\n4.2.2 2. Benchmark de Performance\n\n\n# Crear dataset más grande para benchmark significativo\nset.seed(123)\nventas_grandes &lt;- data.table(\n  id = 1:100000,\n  categoria = sample(LETTERS[1:5], 100000, replace = TRUE),\n  valor = runif(100000, 10, 1000),\n  fecha = sample(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-12-31\"), by = \"day\"), 100000, replace = TRUE)\n)\nventas_grandes[, año := year(fecha)]\n\n# Benchmark\nbenchmark_pipes &lt;- microbenchmark(\n  \"data.table_chain\" = ventas_grandes[año == 2024][, .(suma = sum(valor)), by = categoria][order(-suma)],\n  \"dplyr_pipes\" = ventas_grandes %&gt;% filter(año == 2024) %&gt;% group_by(categoria) %&gt;% summarise(suma = sum(valor), .groups = 'drop') %&gt;% arrange(desc(suma)),\n  times = 20\n)\n\nprint(benchmark_pipes)\n#&gt; Unit: milliseconds\n#&gt;              expr    min      lq     mean  median      uq    max neval\n#&gt;  data.table_chain 2.6527 2.80095 3.096565 2.98645 3.06400 4.7616    20\n#&gt;       dplyr_pipes 2.6597 2.92150 3.697215 3.43110 4.01295 6.8438    20",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#patrones-avanzados-de-encadenamiento",
    "href": "cap02-encadenamiento.html#patrones-avanzados-de-encadenamiento",
    "title": "\n4  Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.3 Patrones Avanzados de Encadenamiento",
    "text": "4.3 Patrones Avanzados de Encadenamiento\n\n4.3.1 1. Encadenamiento con Modificación por Referencia\n\n\n# Combinar := con encadenamiento para análisis iterativo\nempleados_analisis &lt;- copy(empleados)[\n  , salario_z := scale(salario_total)[,1], by = departamento  # Z-score por depto\n][\n  , categoria_performance := cut(salario_z, breaks = c(-Inf, -1, 1, Inf), \n                                labels = c(\"Bajo\", \"Medio\", \"Alto\"))\n][\n  , .(\n    empleados = .N,\n    salario_promedio = round(mean(salario_total), 0),\n    performance_dist = paste(table(categoria_performance), collapse = \"/\")\n  ), by = .(departamento, categoria_performance)\n][\n  order(departamento, categoria_performance)\n]\n\nprint(empleados_analisis)\n#&gt;     departamento categoria_performance empleados salario_promedio\n#&gt;           &lt;char&gt;                &lt;fctr&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt;  1:     Finanzas                  Bajo         1            39000\n#&gt;  2:     Finanzas                 Medio         3            71167\n#&gt;  3:           IT                  Bajo         1            50300\n#&gt;  4:           IT                 Medio         2            63500\n#&gt;  5:           IT                  Alto         1            72700\n#&gt;  6:    Marketing                  Bajo         1            64000\n#&gt;  7:    Marketing                 Medio         3            75167\n#&gt;  8:         RRHH                 Medio         3            62933\n#&gt;  9:         RRHH                  Alto         1            89500\n#&gt; 10:       Ventas                  Bajo         1            59100\n#&gt; 11:       Ventas                 Medio         3            84667\n#&gt;     performance_dist\n#&gt;               &lt;char&gt;\n#&gt;  1:            1/0/0\n#&gt;  2:            0/1/0\n#&gt;  3:            1/0/0\n#&gt;  4:            0/1/0\n#&gt;  5:            0/0/1\n#&gt;  6:            1/0/0\n#&gt;  7:            0/1/0\n#&gt;  8:            0/1/0\n#&gt;  9:            0/0/1\n#&gt; 10:            1/0/0\n#&gt; 11:            0/1/0\n\n\n4.3.2 2. Encadenamiento con Validaciones\n\n\n# Pipeline con validaciones integradas\npipeline_validado &lt;- ventas[\n  !is.na(valor_neto) & valor_neto &gt; 0     # Validar datos básicos\n][\n  , .N, by = año                           # Verificar distribución temporal\n][\n  , {\n    cat(\"Distribución por año:\\n\")\n    print(.SD)\n    if(min(N) &lt; 100) warning(\"Pocos datos en algunos años\")\n    .SD\n  }\n][\n  # Continuar con el análisis principal\n  , .(años_con_datos = .N, transacciones_totales = sum(N))\n]\n#&gt; Distribución por año:\n#&gt;      año     N\n#&gt;    &lt;int&gt; &lt;int&gt;\n#&gt; 1:  2023  4962\n#&gt; 2:  2024  5038\n\nprint(pipeline_validado)\n#&gt;    años_con_datos transacciones_totales\n#&gt;             &lt;int&gt;                 &lt;int&gt;\n#&gt; 1:              2                 10000\n\n\n4.3.3 3. Encadenamiento con Análisis Exploratorio\n\n\n# Pipeline de análisis exploratorio\neda_pipeline &lt;- ventas[\n  sample(.N, 5000)                    # Muestra para EDA rápido\n][\n  , .(\n    valores_unicos = uniqueN(cliente_id),\n    valor_promedio = round(mean(valor_neto), 2),\n    valor_mediana = round(median(valor_neto), 2),\n    outliers_superiores = sum(valor_neto &gt; quantile(valor_neto, 0.95))\n  ), by = .(region, categoria)\n][\n  , coef_variacion := round((valor_promedio - valor_mediana) / valor_promedio, 3)\n][\n  order(-valores_unicos)\n][\n  , {\n    cat(\"Top regiones-categorías por diversidad de clientes:\\n\")\n    print(.SD[1:5])\n    .SD\n  }\n]\n#&gt; Top regiones-categorías por diversidad de clientes:\n#&gt;    region categoria valores_unicos valor_promedio valor_mediana\n#&gt;    &lt;char&gt;    &lt;char&gt;          &lt;int&gt;          &lt;num&gt;         &lt;num&gt;\n#&gt; 1:  Oeste Servicios            259        4661.32       3620.13\n#&gt; 2:  Norte  Hardware            255        4513.11       3287.83\n#&gt; 3:  Oeste  Hardware            249        4866.92       3741.86\n#&gt; 4:   Este  Software            247        4632.75       3713.56\n#&gt; 5: Centro  Software            246        4679.73       3562.80\n#&gt;    outliers_superiores coef_variacion\n#&gt;                  &lt;int&gt;          &lt;num&gt;\n#&gt; 1:                  19          0.223\n#&gt; 2:                  18          0.271\n#&gt; 3:                  18          0.231\n#&gt; 4:                  18          0.198\n#&gt; 5:                  17          0.239\n\n\n4.3.4 4. Encadenamiento con Funciones Personalizadas\n\n\n# Definir función auxiliar\ncalcular_metricas_avanzadas &lt;- function(valores) {\n  list(\n    media = round(mean(valores), 2),\n    percentil_95 = round(quantile(valores, 0.95), 2),\n    coef_asimetria = round((mean(valores) - median(valores)) / sd(valores), 3),\n    outliers_count = sum(valores &gt; (mean(valores) + 2 * sd(valores)))\n  )\n}\n\n# Pipeline con función personalizada\nmetricas_avanzadas &lt;- ventas[\n  año == 2024 & !is.na(valor_neto)\n][\n  , calcular_metricas_avanzadas(valor_neto), by = .(region, trimestre)\n][\n  outliers_count &gt; 5                 # Solo regiones/trimestres con anomalías\n][\n  order(region, trimestre)\n]\n\nprint(metricas_avanzadas)\n#&gt;     region trimestre   media percentil_95 coef_asimetria outliers_count\n#&gt;     &lt;char&gt;     &lt;int&gt;   &lt;num&gt;        &lt;num&gt;          &lt;num&gt;          &lt;int&gt;\n#&gt;  1: Centro         1 4512.27     12113.24          0.276             14\n#&gt;  2: Centro         2 4379.47     12860.78          0.303             13\n#&gt;  3: Centro         3 4586.36     12705.74          0.346             16\n#&gt;  4: Centro         4 5031.66     13807.56          0.272             18\n#&gt;  5:   Este         1 4647.60     12434.10          0.265             14\n#&gt; ---                                                                    \n#&gt; 16:  Oeste         4 4629.18     13104.52          0.269             17\n#&gt; 17:    Sur         1 5657.17     14089.79          0.278             13\n#&gt; 18:    Sur         2 4854.70     12187.45          0.212             11\n#&gt; 19:    Sur         3 5142.59     13569.57          0.337              9\n#&gt; 20:    Sur         4 4893.29     12974.33          0.307             13",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#técnicas-de-debugging-en-encadenamientos",
    "href": "cap02-encadenamiento.html#técnicas-de-debugging-en-encadenamientos",
    "title": "\n4  Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.4 Técnicas de Debugging en Encadenamientos",
    "text": "4.4 Técnicas de Debugging en Encadenamientos\n\n4.4.1 1. Inspección Intermedia\n\n\n# Técnica: usar {} para inspeccionar pasos intermedios\ndebug_pipeline &lt;- empleados[\n  salario_total &gt; 50000\n][\n  , {\n    cat(\"Después del filtro:\", .N, \"filas\\n\")\n    .SD\n  }\n][\n  , .(empleados = .N, salario_avg = mean(salario_total)), by = departamento\n][\n  , {\n    cat(\"Después de agrupar:\", nrow(.SD), \"grupos\\n\")\n    print(.SD)\n    .SD\n  }\n][\n  order(-salario_avg)\n]\n#&gt; Después del filtro: 19 filas\n#&gt; Después de agrupar: 5 grupos\n#&gt;    departamento empleados salario_avg\n#&gt;          &lt;char&gt;     &lt;int&gt;       &lt;num&gt;\n#&gt; 1:       Ventas         4    78275.00\n#&gt; 2:           IT         4    62500.00\n#&gt; 3:    Marketing         4    72375.00\n#&gt; 4:         RRHH         4    69575.00\n#&gt; 5:     Finanzas         3    71166.67\n\n\n4.4.2 2. Validaciones en Cadena\n\n\n# Pipeline robusto con validaciones\npipeline_robusto &lt;- ventas[\n  año %in% 2023:2024                      # Años válidos\n][\n  , if(.N == 0) stop(\"No hay datos después del filtro de años\") else .SD\n][\n  !is.na(valor_neto) & valor_neto &gt; 0     # Valores válidos\n][\n  , if(.N &lt; 1000) warning(\"Pocos datos para análisis confiable\") else .SD\n][\n  , .(ventas = sum(valor_neto), transacciones = .N), by = .(año, region)\n][\n  ventas &gt; 0                              # Verificar resultados lógicos\n]\n\nprint(pipeline_robusto)\n#&gt;       año region  ventas transacciones\n#&gt;     &lt;int&gt; &lt;char&gt;   &lt;num&gt;         &lt;int&gt;\n#&gt;  1:  2023    Sur 4770068           958\n#&gt;  2:  2024 Centro 4669677          1005\n#&gt;  3:  2024  Norte 4571534           985\n#&gt;  4:  2024   Este 4589704           979\n#&gt;  5:  2023 Centro 4841287           986\n#&gt;  6:  2023   Este 4799598           993\n#&gt;  7:  2024    Sur 5136588           996\n#&gt;  8:  2024  Oeste 5059483          1073\n#&gt;  9:  2023  Norte 4917000          1016\n#&gt; 10:  2023  Oeste 4672004          1009",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#ejercicios-prácticos",
    "href": "cap02-encadenamiento.html#ejercicios-prácticos",
    "title": "\n4  Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.5 Ejercicios Prácticos",
    "text": "4.5 Ejercicios Prácticos\n\n\n\n\n\n\n🏋️ Ejercicio 6: Pipeline de Análisis de Ventas\n\n\n\nUsando el dataset ventas, crea un pipeline encadenado que:\n\n\nFiltre ventas del último trimestre de 2024\n\nCalcule métricas por vendedor y región\n\nIdentifique vendedores top (&gt; percentil 80 en ventas)\n\nCree ranking por región\n\nGenere un reporte final con formato\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 6\n\n\n\n\n\n\n# Pipeline complejo de análisis de ventas\nreporte_ventas &lt;- ventas[\n  año == 2024 & trimestre == 4           # 1. Q4 2024\n][\n  , .(                                    # 2. Métricas por vendedor-región\n    ventas_totales = sum(valor_neto),\n    unidades_vendidas = sum(cantidad),\n    transacciones = .N,\n    ticket_promedio = round(mean(valor_neto), 2),\n    mejor_producto = names(sort(table(producto), decreasing = TRUE))[1]\n  ), by = .(vendedor_id, region)\n][\n  ventas_totales &gt; quantile(ventas_totales, 0.8)  # 3. Top performers (percentil 80)\n][\n  order(region, -ventas_totales)\n][\n  , ranking_regional := 1:.N, by = region         # 4. Ranking por región\n][\n  , .(                                    # 5. Reporte final formateado\n    Region = region,\n    Vendedor = paste0(\"ID_\", vendedor_id),\n    Ranking = ranking_regional,\n    Ventas = paste0(\"$\", format(round(ventas_totales, 0), big.mark = \",\")),\n    Unidades = format(unidades_vendidas, big.mark = \",\"),\n    Transacciones = transacciones,\n    Ticket_Avg = paste0(\"$\", ticket_promedio),\n    Top_Producto = mejor_producto,\n    Performance = ifelse(ranking_regional == 1, \"★★★\", \n                        ifelse(ranking_regional &lt;= 3, \"★★\", \"★\"))\n  )\n][\n  order(Region, Ranking)\n]\n\nprint(reporte_ventas)\n#&gt;     Region Vendedor Ranking  Ventas Unidades Transacciones Ticket_Avg\n#&gt;     &lt;char&gt;   &lt;char&gt;   &lt;int&gt;  &lt;char&gt;   &lt;char&gt;         &lt;int&gt;     &lt;char&gt;\n#&gt;  1: Centro    ID_21       1 $57,943       62             8   $7242.93\n#&gt;  2: Centro    ID_23       2 $55,866       56            10   $5586.62\n#&gt;  3: Centro    ID_22       3 $50,392       63             8   $6299.04\n#&gt;  4: Centro     ID_9       4 $47,863       44             6   $7977.08\n#&gt;  5: Centro    ID_24       5 $47,785       37             8   $5973.07\n#&gt;  6: Centro    ID_36       6 $45,849       44             7   $6549.82\n#&gt;  7: Centro    ID_12       7 $45,062       79            11   $4096.56\n#&gt;  8: Centro    ID_27       8 $43,315       48             9   $4812.83\n#&gt;  9: Centro    ID_28       9 $43,007       43             8   $5375.83\n#&gt; 10: Centro    ID_48      10 $40,534       44             8   $5066.81\n#&gt; 11: Centro    ID_38      11 $39,617       53             9   $4401.87\n#&gt; 12: Centro    ID_41      12 $38,036       64             9    $4226.2\n#&gt; 13:   Este     ID_4       1 $60,526       80            12   $5043.81\n#&gt; 14:   Este     ID_1       2 $59,086       49            10   $5908.63\n#&gt; 15:   Este     ID_6       3 $44,048       34             7   $6292.61\n#&gt; 16:   Este    ID_45       4 $41,654       53             7   $5950.57\n#&gt; 17:   Este    ID_27       5 $41,578       39             7   $5939.73\n#&gt; 18:   Este    ID_37       6 $41,310       49             9   $4590.03\n#&gt; 19:   Este    ID_50       7 $40,439       33             8   $5054.91\n#&gt; 20:   Este    ID_11       8 $38,579       41             7   $5511.27\n#&gt; 21:   Este     ID_3       9 $38,573       45             8   $4821.65\n#&gt; 22:   Este    ID_44      10 $37,725       46             7   $5389.32\n#&gt; 23:  Norte     ID_5       1 $61,248       55             9   $6805.35\n#&gt; 24:  Norte    ID_10       2 $58,480       60            10   $5848.04\n#&gt; 25:  Norte    ID_40       3 $52,650       53             8   $6581.22\n#&gt; 26:  Norte    ID_46       4 $43,763       44             7   $6251.83\n#&gt; 27:  Norte     ID_6       5 $43,651       50            12    $3637.6\n#&gt; 28:  Norte    ID_31       6 $41,523       37             6   $6920.42\n#&gt; 29:  Oeste    ID_36       1 $52,220       48             6    $8703.3\n#&gt; 30:  Oeste    ID_24       2 $49,463       58             9   $5495.85\n#&gt; 31:  Oeste     ID_1       3 $49,336       62             9   $5481.81\n#&gt; 32:  Oeste    ID_43       4 $48,605       59            11   $4418.62\n#&gt; 33:  Oeste    ID_48       5 $47,777       52             9    $5308.6\n#&gt; 34:  Oeste    ID_40       6 $45,381       47             9   $5042.38\n#&gt; 35:  Oeste    ID_47       7 $45,205       58             9   $5022.72\n#&gt; 36:  Oeste    ID_23       8 $44,807       55            12   $3733.94\n#&gt; 37:  Oeste    ID_32       9 $44,092       49             8   $5511.46\n#&gt; 38:  Oeste     ID_4      10 $43,620       52             7   $6231.43\n#&gt; 39:  Oeste    ID_18      11 $43,598       36             5    $8719.6\n#&gt; 40:  Oeste    ID_12      12 $43,212       35             7   $6173.21\n#&gt; 41:  Oeste    ID_42      13 $42,199       45             7   $6028.39\n#&gt; 42:  Oeste     ID_3      14 $41,547       35             7   $5935.25\n#&gt; 43:  Oeste    ID_13      15 $39,928       32             6   $6654.71\n#&gt; 44:    Sur     ID_3       1 $52,542       43             7   $7506.06\n#&gt; 45:    Sur     ID_7       2 $45,035       39             9   $5003.94\n#&gt; 46:    Sur    ID_24       3 $42,631       34             7    $6090.2\n#&gt; 47:    Sur     ID_5       4 $41,461       42            11   $3769.21\n#&gt; 48:    Sur    ID_43       5 $41,168       38             7   $5881.16\n#&gt; 49:    Sur    ID_48       6 $39,735       39             7   $5676.37\n#&gt; 50:    Sur    ID_28       7 $39,045       29             5   $7809.03\n#&gt;     Region Vendedor Ranking  Ventas Unidades Transacciones Ticket_Avg\n#&gt;     Top_Producto Performance\n#&gt;           &lt;char&gt;      &lt;char&gt;\n#&gt;  1:       Laptop         ★★★\n#&gt;  2:       Tablet          ★★\n#&gt;  3:      Desktop          ★★\n#&gt;  4:   Smartphone           ★\n#&gt;  5:      Desktop           ★\n#&gt;  6:   Accesorios           ★\n#&gt;  7:   Smartphone           ★\n#&gt;  8:       Laptop           ★\n#&gt;  9:   Accesorios           ★\n#&gt; 10:       Tablet           ★\n#&gt; 11:       Tablet           ★\n#&gt; 12:       Tablet           ★\n#&gt; 13:   Smartphone         ★★★\n#&gt; 14:      Desktop          ★★\n#&gt; 15:      Desktop          ★★\n#&gt; 16:   Smartphone           ★\n#&gt; 17:      Desktop           ★\n#&gt; 18:       Laptop           ★\n#&gt; 19:      Desktop           ★\n#&gt; 20:      Desktop           ★\n#&gt; 21:       Laptop           ★\n#&gt; 22:       Laptop           ★\n#&gt; 23:   Accesorios         ★★★\n#&gt; 24:   Smartphone          ★★\n#&gt; 25:       Laptop          ★★\n#&gt; 26:       Laptop           ★\n#&gt; 27:       Laptop           ★\n#&gt; 28:       Laptop           ★\n#&gt; 29:   Smartphone         ★★★\n#&gt; 30:       Laptop          ★★\n#&gt; 31:   Accesorios          ★★\n#&gt; 32:   Smartphone           ★\n#&gt; 33:      Desktop           ★\n#&gt; 34:   Accesorios           ★\n#&gt; 35:       Laptop           ★\n#&gt; 36:       Laptop           ★\n#&gt; 37:       Laptop           ★\n#&gt; 38:       Laptop           ★\n#&gt; 39:      Desktop           ★\n#&gt; 40:       Laptop           ★\n#&gt; 41:   Accesorios           ★\n#&gt; 42:       Laptop           ★\n#&gt; 43:   Smartphone           ★\n#&gt; 44:   Accesorios         ★★★\n#&gt; 45:       Tablet          ★★\n#&gt; 46:   Accesorios          ★★\n#&gt; 47:       Tablet           ★\n#&gt; 48:   Accesorios           ★\n#&gt; 49:   Accesorios           ★\n#&gt; 50:       Laptop           ★\n#&gt;     Top_Producto Performance\n\n# Mostrar tabla del reporte formateada para PDF\nknitr::kable(\n  reporte_ventas,\n  caption = \"Reporte de Top Performers Q4 2024\",\n  digits = 2,\n  format.args = list(big.mark = \",\")\n)\n\n\nReporte de Top Performers Q4 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nVendedor\nRanking\nVentas\nUnidades\nTransacciones\nTicket_Avg\nTop_Producto\nPerformance\n\n\n\nCentro\nID_21\n1\n$57,943\n62\n8\n$7242.93\nLaptop\n★★★\n\n\nCentro\nID_23\n2\n$55,866\n56\n10\n$5586.62\nTablet\n★★\n\n\nCentro\nID_22\n3\n$50,392\n63\n8\n$6299.04\nDesktop\n★★\n\n\nCentro\nID_9\n4\n$47,863\n44\n6\n$7977.08\nSmartphone\n★\n\n\nCentro\nID_24\n5\n$47,785\n37\n8\n$5973.07\nDesktop\n★\n\n\nCentro\nID_36\n6\n$45,849\n44\n7\n$6549.82\nAccesorios\n★\n\n\nCentro\nID_12\n7\n$45,062\n79\n11\n$4096.56\nSmartphone\n★\n\n\nCentro\nID_27\n8\n$43,315\n48\n9\n$4812.83\nLaptop\n★\n\n\nCentro\nID_28\n9\n$43,007\n43\n8\n$5375.83\nAccesorios\n★\n\n\nCentro\nID_48\n10\n$40,534\n44\n8\n$5066.81\nTablet\n★\n\n\nCentro\nID_38\n11\n$39,617\n53\n9\n$4401.87\nTablet\n★\n\n\nCentro\nID_41\n12\n$38,036\n64\n9\n$4226.2\nTablet\n★\n\n\nEste\nID_4\n1\n$60,526\n80\n12\n$5043.81\nSmartphone\n★★★\n\n\nEste\nID_1\n2\n$59,086\n49\n10\n$5908.63\nDesktop\n★★\n\n\nEste\nID_6\n3\n$44,048\n34\n7\n$6292.61\nDesktop\n★★\n\n\nEste\nID_45\n4\n$41,654\n53\n7\n$5950.57\nSmartphone\n★\n\n\nEste\nID_27\n5\n$41,578\n39\n7\n$5939.73\nDesktop\n★\n\n\nEste\nID_37\n6\n$41,310\n49\n9\n$4590.03\nLaptop\n★\n\n\nEste\nID_50\n7\n$40,439\n33\n8\n$5054.91\nDesktop\n★\n\n\nEste\nID_11\n8\n$38,579\n41\n7\n$5511.27\nDesktop\n★\n\n\nEste\nID_3\n9\n$38,573\n45\n8\n$4821.65\nLaptop\n★\n\n\nEste\nID_44\n10\n$37,725\n46\n7\n$5389.32\nLaptop\n★\n\n\nNorte\nID_5\n1\n$61,248\n55\n9\n$6805.35\nAccesorios\n★★★\n\n\nNorte\nID_10\n2\n$58,480\n60\n10\n$5848.04\nSmartphone\n★★\n\n\nNorte\nID_40\n3\n$52,650\n53\n8\n$6581.22\nLaptop\n★★\n\n\nNorte\nID_46\n4\n$43,763\n44\n7\n$6251.83\nLaptop\n★\n\n\nNorte\nID_6\n5\n$43,651\n50\n12\n$3637.6\nLaptop\n★\n\n\nNorte\nID_31\n6\n$41,523\n37\n6\n$6920.42\nLaptop\n★\n\n\nOeste\nID_36\n1\n$52,220\n48\n6\n$8703.3\nSmartphone\n★★★\n\n\nOeste\nID_24\n2\n$49,463\n58\n9\n$5495.85\nLaptop\n★★\n\n\nOeste\nID_1\n3\n$49,336\n62\n9\n$5481.81\nAccesorios\n★★\n\n\nOeste\nID_43\n4\n$48,605\n59\n11\n$4418.62\nSmartphone\n★\n\n\nOeste\nID_48\n5\n$47,777\n52\n9\n$5308.6\nDesktop\n★\n\n\nOeste\nID_40\n6\n$45,381\n47\n9\n$5042.38\nAccesorios\n★\n\n\nOeste\nID_47\n7\n$45,205\n58\n9\n$5022.72\nLaptop\n★\n\n\nOeste\nID_23\n8\n$44,807\n55\n12\n$3733.94\nLaptop\n★\n\n\nOeste\nID_32\n9\n$44,092\n49\n8\n$5511.46\nLaptop\n★\n\n\nOeste\nID_4\n10\n$43,620\n52\n7\n$6231.43\nLaptop\n★\n\n\nOeste\nID_18\n11\n$43,598\n36\n5\n$8719.6\nDesktop\n★\n\n\nOeste\nID_12\n12\n$43,212\n35\n7\n$6173.21\nLaptop\n★\n\n\nOeste\nID_42\n13\n$42,199\n45\n7\n$6028.39\nAccesorios\n★\n\n\nOeste\nID_3\n14\n$41,547\n35\n7\n$5935.25\nLaptop\n★\n\n\nOeste\nID_13\n15\n$39,928\n32\n6\n$6654.71\nSmartphone\n★\n\n\nSur\nID_3\n1\n$52,542\n43\n7\n$7506.06\nAccesorios\n★★★\n\n\nSur\nID_7\n2\n$45,035\n39\n9\n$5003.94\nTablet\n★★\n\n\nSur\nID_24\n3\n$42,631\n34\n7\n$6090.2\nAccesorios\n★★\n\n\nSur\nID_5\n4\n$41,461\n42\n11\n$3769.21\nTablet\n★\n\n\nSur\nID_43\n5\n$41,168\n38\n7\n$5881.16\nAccesorios\n★\n\n\nSur\nID_48\n6\n$39,735\n39\n7\n$5676.37\nAccesorios\n★\n\n\nSur\nID_28\n7\n$39,045\n29\n5\n$7809.03\nLaptop\n★\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n🏋️ Ejercicio 7: Análisis de Cohortes con Encadenamiento\n\n\n\nCrea un análisis de cohortes de empleados:\n\n\nAgrupa empleados por año de ingreso\n\nCalcula retención, salarios promedios, y promociones\n\nIdentifica cohortes exitosas vs. problemáticas\n\nGenera insights automáticos\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 7\n\n\n\n\n\n\n# Análisis de cohortes con encadenamiento\nlibrary(lubridate)\n\nanalisis_cohortes &lt;- empleados[\n  !is.na(fecha_ingreso)                    # 1. Datos válidos\n][\n  , año_ingreso := year(fecha_ingreso)     # Extraer año de cohorte\n][\n  , años_en_empresa := round(as.numeric(Sys.Date() - fecha_ingreso) / 365, 1)\n][\n  , .(                                     # 2. Métricas por cohorte\n    empleados_iniciales = .N,\n    empleados_activos = sum(activo),\n    retencion_pct = round(mean(activo) * 100, 1),\n    salario_inicial_avg = round(mean(salario), 0),\n    salario_actual_avg = round(mean(salario_total), 0),\n    crecimiento_salarial = round(mean(salario_total) / mean(salario) - 1, 2),\n    años_promedio = round(mean(años_en_empresa), 1),\n    productividad_avg = round(mean(productividad), 2),\n    managers_promocionados = sum(nivel == \"Manager\")\n  ), by = año_ingreso\n][\n  empleados_iniciales &gt;= 2                 # Solo cohortes con suficientes datos\n][\n  , `:=`(                                 # 3. Clasificar cohortes\n    categoria_retencion = cut(retencion_pct, \n                             breaks = c(0, 70, 90, 100), \n                             labels = c(\"Problemática\", \"Regular\", \"Exitosa\")),\n    categoria_crecimiento = ifelse(crecimiento_salarial &gt; 0.15, \"Alto\", \n                                 ifelse(crecimiento_salarial &gt; 0.05, \"Medio\", \"Bajo\"))\n  )\n][\n  order(año_ingreso)\n][\n  , {                                     # 4. Generar insights automáticos\n    cat(\"=== INSIGHTS DE COHORTES ===\\n\\n\")\n    \n    cohorte_mejor &lt;- .SD[which.max(retencion_pct * crecimiento_salarial)]\n    cohorte_peor &lt;- .SD[which.min(retencion_pct * (1 + crecimiento_salarial))]\n    \n    cat(\"🏆 MEJOR COHORTE:\", cohorte_mejor$año_ingreso, \"\\n\")\n    cat(\"   • Retención:\", cohorte_mejor$retencion_pct, \"%\\n\")\n    cat(\"   • Crecimiento salarial:\", cohorte_mejor$crecimiento_salarial * 100, \"%\\n\\n\")\n    \n    cat(\"⚠️  COHORTE PROBLEMÁTICA:\", cohorte_peor$año_ingreso, \"\\n\")\n    cat(\"   • Retención:\", cohorte_peor$retencion_pct, \"%\\n\")\n    cat(\"   • Crecimiento salarial:\", cohorte_peor$crecimiento_salarial * 100, \"%\\n\\n\")\n    \n    cat(\"📊 RESUMEN GENERAL:\\n\")\n    cat(\"   • Retención promedio:\", round(mean(retencion_pct), 1), \"%\\n\")\n    cat(\"   • Cohortes exitosas:\", sum(categoria_retencion == \"Exitosa\"), \"de\", .N, \"\\n\")\n    cat(\"   • Managers promocionados:\", sum(managers_promocionados), \"total\\n\\n\")\n    \n    .SD\n  }\n]\n#&gt; === INSIGHTS DE COHORTES ===\n#&gt; \n#&gt; 🏆 MEJOR COHORTE: 2022 \n#&gt;    • Retención: 100 %\n#&gt;    • Crecimiento salarial: 21 %\n#&gt; \n#&gt; ⚠️  COHORTE PROBLEMÁTICA: 2023 \n#&gt;    • Retención: 66.7 %\n#&gt;    • Crecimiento salarial: 15 %\n#&gt; \n#&gt; 📊 RESUMEN GENERAL:\n#&gt;    • Retención promedio: 83.3 %\n#&gt;    • Cohortes exitosas: 2 de 5 \n#&gt;    • Managers promocionados: 4 total\n\nprint(analisis_cohortes[, .(año_ingreso, empleados_iniciales, retencion_pct, \n                           crecimiento_salarial, categoria_retencion, categoria_crecimiento)])\n#&gt;    año_ingreso empleados_iniciales retencion_pct crecimiento_salarial\n#&gt;          &lt;num&gt;               &lt;int&gt;         &lt;num&gt;                &lt;num&gt;\n#&gt; 1:        2019                   6          83.3                 0.10\n#&gt; 2:        2020                   3         100.0                 0.09\n#&gt; 3:        2021                   3          66.7                 0.18\n#&gt; 4:        2022                   4         100.0                 0.21\n#&gt; 5:        2023                   3          66.7                 0.15\n#&gt;    categoria_retencion categoria_crecimiento\n#&gt;                 &lt;fctr&gt;                &lt;char&gt;\n#&gt; 1:             Regular                 Medio\n#&gt; 2:             Exitosa                 Medio\n#&gt; 3:        Problemática                  Alto\n#&gt; 4:             Exitosa                  Alto\n#&gt; 5:        Problemática                 Medio",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#mejores-prácticas-para-encadenamiento",
    "href": "cap02-encadenamiento.html#mejores-prácticas-para-encadenamiento",
    "title": "\n4  Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.6 Mejores Prácticas para Encadenamiento",
    "text": "4.6 Mejores Prácticas para Encadenamiento\n\n4.6.1 1. Legibilidad vs. Performance\n\n\n# ✅ HACER: Encadenamiento legible con líneas separadas\nresultado &lt;- datos[\n  filtro_simple & condicion_clara\n][\n  , .(metrica1 = func1(col1), metrica2 = func2(col2)), by = grupo\n][\n  order(-metrica1)\n][\n  1:10\n]\n\n# ❌ EVITAR: Una línea muy larga\nresultado &lt;- datos[filtro & condicion][, .(m1 = f1(c1), m2 = f2(c2)), by = g][order(-m1)][1:10]\n\n# ✅ HACER: Comentarios para pasos complejos\nresultado &lt;- datos[\n  filtro_complejo                    # Paso 1: filtrar casos válidos\n][\n  , calculo_complejo(), by = grupo   # Paso 2: agregaciones por grupo\n][\n  post_procesamiento()               # Paso 3: ajustes finales\n]\n\n\n4.6.2 2. Cuándo NO usar encadenamiento\n\n\n# ❌ Evitar: Lógica muy compleja en una cadena\n# Mejor usar pasos separados para debugging\npaso1 &lt;- datos[filtro_complejo_con_multiples_condiciones]\npaso2 &lt;- paso1[, calculo_muy_complejo_con_multiples_funciones(), by = multiples_grupos]\npaso3 &lt;- paso2[post_procesamiento_complejo_con_validaciones()]\n\n# ❌ Evitar: Cadenas que modifican el objeto original sin copy()\n# Peligroso si necesitas preservar datos originales\ndatos_originales[, nueva_col := calculo()][filtro][, otra_col := otro_calculo()]\n\n# ✅ Hacer: Usar copy() cuando modifiques\ndatos_procesados &lt;- copy(datos_originales)[\n  , nueva_col := calculo()\n][\n  filtro\n][\n  , otra_col := otro_calculo()\n]\n\n\n4.6.3 3. Optimización de Performance\n\n\n# ✅ HACER: Filtrar temprano para reducir datos\ndatos[\n  filtro_restrictivo               # Reduce datos primero\n][\n  calculo_costoso(), by = grupo    # Luego opera en menos datos\n]\n\n# ❌ EVITAR: Cálculos costosos antes de filtrar\ndatos[\n  calculo_costoso(), by = grupo    # Opera en todos los datos\n][\n  filtro_restrictivo               # Filtra después\n]\n\n# ✅ HACER: Usar .SDcols para limitar columnas en operaciones costosas\ndatos[\n  filtro\n][\n  , lapply(.SD, operacion_costosa), by = grupo, .SDcols = columnas_necesarias\n]\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nEl encadenamiento hace el código más conciso y eficiente al eliminar variables temporales\n\nCada [...] opera sobre el resultado del anterior, creando un flujo lógico claro\n\nPerformance: data.table chaining es más rápido que dplyr pipes para la mayoría de operaciones\n\nLegibilidad: Usar líneas separadas y comentarios para encadenamientos complejos\n\nDebugging: Insertar {} para inspeccionar resultados intermedios\n\nFiltrar temprano para optimizar performance en cadenas largas\n\n\n\nEl encadenamiento es una técnica fundamental que, una vez dominada, hace que tu código data.table sea más elegante y eficiente. En el próximo capítulo exploraremos cómo combinar múltiples tablas usando joins.",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html",
    "href": "cap02-joins.html",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "",
    "text": "5.1 Fundamentos de Joins en data.table\ndata.table ofrece múltiples métodos para realizar joins, cada uno optimizado para diferentes casos de uso. La elección del método correcto puede marcar la diferencia entre segundos y minutos en datasets grandes.",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#fundamentos-de-joins-en-data.table",
    "href": "cap02-joins.html#fundamentos-de-joins-en-data.table",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "",
    "text": "5.1.1 1. Tipos de Joins: Conceptos Básicos\n\n\n# Mostrar las tablas base\ncat(\"=== EMPLEADOS ===\\n\")\n#&gt; === EMPLEADOS ===\nprint(empleados[1:5, .(emp_id, nombre, departamento_id, salario)])\n#&gt;    emp_id     nombre departamento_id salario\n#&gt;     &lt;int&gt;     &lt;char&gt;           &lt;int&gt;   &lt;num&gt;\n#&gt; 1:      1 Empleado_A               2   39500\n#&gt; 2:      2 Empleado_B               5   62200\n#&gt; 3:      3 Empleado_C               5   69000\n#&gt; 4:      4 Empleado_D               4   66900\n#&gt; 5:      5 Empleado_E               1   46700\n\ncat(\"\\n=== DEPARTAMENTOS ===\\n\") \n#&gt; \n#&gt; === DEPARTAMENTOS ===\nprint(departamentos[, .(dept_id, nombre_dept, ubicacion)])\n#&gt;    dept_id nombre_dept ubicacion\n#&gt;      &lt;int&gt;      &lt;char&gt;    &lt;char&gt;\n#&gt; 1:       1  Ingeniería    Madrid\n#&gt; 2:       2      Ventas Barcelona\n#&gt; 3:       3   Marketing   Sevilla\n#&gt; 4:       4        RRHH  Valencia\n#&gt; 5:       5    Finanzas    Bilbao\n\ncat(\"\\n=== EVALUACIONES (parcial) ===\\n\")\n#&gt; \n#&gt; === EVALUACIONES (parcial) ===\nprint(evaluaciones[1:5, .(empleado_id, puntuacion, fecha_evaluacion)])\n#&gt;    empleado_id puntuacion fecha_evaluacion\n#&gt;          &lt;int&gt;      &lt;num&gt;           &lt;Date&gt;\n#&gt; 1:           2        3.8       2023-12-22\n#&gt; 2:          15        4.3       2023-12-01\n#&gt; 3:          14        4.1       2023-12-22\n#&gt; 4:           7        4.8       2024-02-09\n#&gt; 5:           4        4.1       2023-12-15",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#joins-con-merge-el-método-tradicional",
    "href": "cap02-joins.html#joins-con-merge-el-método-tradicional",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.2 Joins con merge(): El Método Tradicional",
    "text": "5.2 Joins con merge(): El Método Tradicional\nLa función merge() es familiar para usuarios de R base y ofrece una sintaxis clara para joins simples.\n\n5.2.1 1. Inner Join Básico\n\n\n# Inner join: solo registros que existen en ambas tablas\nempleados_con_dept &lt;- merge(empleados, departamentos, \n                           by.x = \"departamento_id\", by.y = \"dept_id\")\n\ncat(\"Empleados con información de departamento (Inner Join):\\n\")\n#&gt; Empleados con información de departamento (Inner Join):\nprint(empleados_con_dept[1:6, .(nombre, nombre_dept, salario, ubicacion)])\n#&gt;        nombre nombre_dept salario ubicacion\n#&gt;        &lt;char&gt;      &lt;char&gt;   &lt;num&gt;    &lt;char&gt;\n#&gt; 1: Empleado_E  Ingeniería   46700    Madrid\n#&gt; 2: Empleado_G  Ingeniería   67600    Madrid\n#&gt; 3: Empleado_A      Ventas   39500 Barcelona\n#&gt; 4: Empleado_H      Ventas   35000 Barcelona\n#&gt; 5: Empleado_I      Ventas   35800 Barcelona\n#&gt; 6: Empleado_N      Ventas   62000 Barcelona\n\n\n5.2.2 2. Todos los Tipos de Joins con merge()\n\n\n# Comparar diferentes tipos de joins\ninner_join &lt;- merge(empleados, evaluaciones, \n                   by.x = \"emp_id\", by.y = \"empleado_id\")\ncat(\"Inner join (empleados con evaluación):\", nrow(inner_join), \"filas\\n\")\n#&gt; Inner join (empleados con evaluación): 12 filas\n\nleft_join &lt;- merge(empleados, evaluaciones, \n                  by.x = \"emp_id\", by.y = \"empleado_id\", all.x = TRUE)\ncat(\"Left join (todos los empleados):\", nrow(left_join), \"filas\\n\")\n#&gt; Left join (todos los empleados): 19 filas\n\nright_join &lt;- merge(empleados, evaluaciones, \n                   by.x = \"emp_id\", by.y = \"empleado_id\", all.y = TRUE)\ncat(\"Right join (todas las evaluaciones):\", nrow(right_join), \"filas\\n\")\n#&gt; Right join (todas las evaluaciones): 12 filas\n\nfull_join &lt;- merge(empleados, evaluaciones, \n                  by.x = \"emp_id\", by.y = \"empleado_id\", all = TRUE)\ncat(\"Full join (empleados + evaluaciones):\", nrow(full_join), \"filas\\n\")\n#&gt; Full join (empleados + evaluaciones): 19 filas\n\n# Mostrar ejemplo de left join\nprint(left_join[1:8, .(nombre, nivel, puntuacion, fecha_evaluacion)])\n#&gt;        nombre  nivel puntuacion fecha_evaluacion\n#&gt;        &lt;char&gt; &lt;char&gt;      &lt;num&gt;           &lt;Date&gt;\n#&gt; 1: Empleado_A Senior         NA             &lt;NA&gt;\n#&gt; 2: Empleado_B Junior        3.8       2023-12-22\n#&gt; 3: Empleado_B Junior        4.6       2023-12-08\n#&gt; 4: Empleado_C Senior        3.4       2023-12-15\n#&gt; 5: Empleado_D Junior        4.1       2023-12-15\n#&gt; 6: Empleado_E   Lead         NA             &lt;NA&gt;\n#&gt; 7: Empleado_F   Lead         NA             &lt;NA&gt;\n#&gt; 8: Empleado_G   Lead        4.8       2024-02-09\n\n\n5.2.3 3. Joins por Múltiples Columnas\n\n\n# Crear tabla de ejemplo con múltiples keys\nhistorico_salarios &lt;- data.table(\n  empleado_id = rep(c(1, 2, 3), each = 2),\n  departamento_id = rep(c(1, 2, 1), each = 2),\n  año = rep(c(2023, 2024), times = 3),\n  salario_historico = c(40000, 42000, 45000, 47000, 38000, 40000)\n)\n\n# Join por múltiples columnas\njoin_multiple &lt;- merge(empleados[1:3, .(emp_id, nombre, departamento_id)], \n                      historico_salarios, \n                      by.x = c(\"emp_id\", \"departamento_id\"), \n                      by.y = c(\"empleado_id\", \"departamento_id\"))\n\nprint(join_multiple)\n#&gt; data.table vacía (0 filas y 5 columnas): emp_id,departamento_id,nombre,año,salario_historico",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#joins-optimizados-con-setkey",
    "href": "cap02-joins.html#joins-optimizados-con-setkey",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.3 Joins Optimizados con setkey()\n",
    "text": "5.3 Joins Optimizados con setkey()\n\nPara datasets grandes y joins repetitivos, establecer keys proporciona un rendimiento excepcional.\n\n5.3.1 1. Estableciendo Keys y Sintaxis X[Y]\n\n\n# Hacer copias para no modificar originales\nemp_key &lt;- copy(empleados)\ndept_key &lt;- copy(departamentos)\n\n# Establecer keys (ordena físicamente las tablas)\nsetkey(emp_key, departamento_id)\nsetkey(dept_key, dept_id)\n\n# Verificar que las keys están establecidas\ncat(\"Key de empleados:\", key(emp_key), \"\\n\")\n#&gt; Key de empleados: departamento_id\ncat(\"Key de departamentos:\", key(dept_key), \"\\n\")\n#&gt; Key de departamentos: dept_id\n\n# Join ultra-rápido con sintaxis X[Y]\nresultado_key_join &lt;- dept_key[emp_key]\n\nprint(resultado_key_join[1:6, .(nombre, nombre_dept, salario, presupuesto)])\n#&gt;        nombre nombre_dept salario presupuesto\n#&gt;        &lt;char&gt;      &lt;char&gt;   &lt;num&gt;       &lt;num&gt;\n#&gt; 1: Empleado_E  Ingeniería   46700       8e+05\n#&gt; 2: Empleado_G  Ingeniería   67600       8e+05\n#&gt; 3: Empleado_A      Ventas   39500       6e+05\n#&gt; 4: Empleado_H      Ventas   35000       6e+05\n#&gt; 5: Empleado_I      Ventas   35800       6e+05\n#&gt; 6: Empleado_N      Ventas   62000       6e+05\n\n\n5.3.2 2. Ventajas de las Keys\n\n\n# Las tablas con key están ordenadas físicamente\ncat(\"Empleados ordenados por departamento_id:\\n\")\n#&gt; Empleados ordenados por departamento_id:\nprint(emp_key[, .(emp_id, nombre, departamento_id)])\n#&gt; Clave &lt;departamento_id&gt;\n#&gt;     emp_id     nombre departamento_id\n#&gt;      &lt;int&gt;     &lt;char&gt;           &lt;int&gt;\n#&gt;  1:      5 Empleado_E               1\n#&gt;  2:      7 Empleado_G               1\n#&gt;  3:      1 Empleado_A               2\n#&gt;  4:      8 Empleado_H               2\n#&gt;  5:      9 Empleado_I               2\n#&gt; ---                                  \n#&gt; 11:      2 Empleado_B               5\n#&gt; 12:      3 Empleado_C               5\n#&gt; 13:      6 Empleado_F               5\n#&gt; 14:     10 Empleado_J               5\n#&gt; 15:     12 Empleado_L               5\n\ncat(\"\\nDepartamentos ordenados por dept_id:\\n\") \n#&gt; \n#&gt; Departamentos ordenados por dept_id:\nprint(dept_key[, .(dept_id, nombre_dept)])\n#&gt; Clave &lt;dept_id&gt;\n#&gt;    dept_id nombre_dept\n#&gt;      &lt;int&gt;      &lt;char&gt;\n#&gt; 1:       1  Ingeniería\n#&gt; 2:       2      Ventas\n#&gt; 3:       3   Marketing\n#&gt; 4:       4        RRHH\n#&gt; 5:       5    Finanzas\n\n# Acceso ultra-rápido por key\ndepartamento_2 &lt;- dept_key[2]  # Busca dept_id == 2\nempleados_dept_2 &lt;- emp_key[2]  # Busca departamento_id == 2\n\ncat(\"\\nEmpleados del departamento 2:\\n\")\n#&gt; \n#&gt; Empleados del departamento 2:\nprint(empleados_dept_2[, .(nombre, nivel, salario)])\n#&gt;        nombre  nivel salario\n#&gt;        &lt;char&gt; &lt;char&gt;   &lt;num&gt;\n#&gt; 1: Empleado_G   Lead   67600\n\n\n5.3.3 3. Múltiples Keys\n\n\n# Establecer múltiples columnas como key\nsetkey(asignaciones, empleado_id, proyecto_id)\n\n# Buscar por key compuesta\nasignacion_especifica &lt;- asignaciones[.(1, 2)]  # empleado 1, proyecto 2\nprint(asignacion_especifica)\n#&gt; Clave &lt;empleado_id, proyecto_id&gt;\n#&gt;    asignacion_id empleado_id proyecto_id horas_asignadas fecha_asignacion\n#&gt;            &lt;int&gt;       &lt;int&gt;       &lt;int&gt;           &lt;int&gt;           &lt;Date&gt;\n#&gt; 1:            NA           1           2              NA             &lt;NA&gt;\n#&gt;    rol_proyecto\n#&gt;          &lt;char&gt;\n#&gt; 1:         &lt;NA&gt;\n\n# Búsquedas parciales\nasignaciones_emp_1 &lt;- asignaciones[.(1)]  # Solo empleado 1\ncat(\"Asignaciones del empleado 1:\", nrow(asignaciones_emp_1), \"proyectos\\n\")\n#&gt; Asignaciones del empleado 1: 3 proyectos",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#sintaxis-on-joins-flexibles-sin-keys",
    "href": "cap02-joins.html#sintaxis-on-joins-flexibles-sin-keys",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.4 Sintaxis on: Joins Flexibles sin Keys",
    "text": "5.4 Sintaxis on: Joins Flexibles sin Keys\nLa sintaxis on permite joins puntuales sin necesidad de establecer keys.\n\n5.4.1 1. Join Básico con on\n\n\n# Join sin modificar las tablas originales\nresultado_on &lt;- empleados[departamentos, on = .(departamento_id = dept_id)]\n\nprint(resultado_on[1:6, .(nombre, nombre_dept, salario, ubicacion)])\n#&gt;        nombre nombre_dept salario ubicacion\n#&gt;        &lt;char&gt;      &lt;char&gt;   &lt;num&gt;    &lt;char&gt;\n#&gt; 1: Empleado_E  Ingeniería   46700    Madrid\n#&gt; 2: Empleado_G  Ingeniería   67600    Madrid\n#&gt; 3: Empleado_A      Ventas   39500 Barcelona\n#&gt; 4: Empleado_H      Ventas   35000 Barcelona\n#&gt; 5: Empleado_I      Ventas   35800 Barcelona\n#&gt; 6: Empleado_N      Ventas   62000 Barcelona\n\n\n5.4.2 2. Join con Renombrado de Columnas\n\n\n# Join con selección y renombrado\nempleados_completo &lt;- empleados[\n  departamentos, \n  on = .(departamento_id = dept_id)\n][\n  , .(\n    empleado = nombre,\n    departamento = nombre_dept, \n    salario,\n    presupuesto_dept = presupuesto,\n    ubicacion,\n    ratio_salario_presupuesto = round(salario / presupuesto * 100, 3)\n  )\n]\n\nprint(empleados_completo[order(-ratio_salario_presupuesto)][1:6])\n#&gt;      empleado departamento salario presupuesto_dept ubicacion\n#&gt;        &lt;char&gt;       &lt;char&gt;   &lt;num&gt;            &lt;num&gt;    &lt;char&gt;\n#&gt; 1: Empleado_M         RRHH   73900            3e+05  Valencia\n#&gt; 2: Empleado_D         RRHH   66900            3e+05  Valencia\n#&gt; 3: Empleado_C     Finanzas   69000            5e+05    Bilbao\n#&gt; 4: Empleado_B     Finanzas   62200            5e+05    Bilbao\n#&gt; 5: Empleado_F     Finanzas   59600            5e+05    Bilbao\n#&gt; 6: Empleado_K    Marketing   46600            4e+05   Sevilla\n#&gt;    ratio_salario_presupuesto\n#&gt;                        &lt;num&gt;\n#&gt; 1:                    24.633\n#&gt; 2:                    22.300\n#&gt; 3:                    13.800\n#&gt; 4:                    12.440\n#&gt; 5:                    11.920\n#&gt; 6:                    11.650\n\n\n5.4.3 3. Joins con Condiciones Adicionales\n\n\n# Join con filtro simultáneo\nempleados_evaluados_reciente &lt;- empleados[\n  evaluaciones[fecha_evaluacion &gt;= \"2024-01-01\"], \n  on = .(emp_id = empleado_id)\n][\n  !is.na(puntuacion)  # Solo empleados con evaluación\n][\n  , .(nombre, nivel, puntuacion, fecha_evaluacion)\n][\n  order(-puntuacion)\n]\n\nprint(empleados_evaluados_reciente)\n#&gt;        nombre  nivel puntuacion fecha_evaluacion\n#&gt;        &lt;char&gt; &lt;char&gt;      &lt;num&gt;           &lt;Date&gt;\n#&gt; 1: Empleado_G   Lead        4.8       2024-02-09\n#&gt; 2: Empleado_M Senior        4.8       2024-02-09\n#&gt; 3: Empleado_O   Lead        4.6       2024-01-19\n#&gt; 4: Empleado_O   Lead        3.7       2024-02-16",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#update-joins-la-característica-estrella",
    "href": "cap02-joins.html#update-joins-la-característica-estrella",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.5 Update Joins: La Característica Estrella",
    "text": "5.5 Update Joins: La Característica Estrella\nLos update joins permiten modificar una tabla basándose en valores de otra tabla de forma eficiente.\n\n5.5.1 1. Update Join Básico\n\n\n# Crear tabla de bonos\nbonos_dept &lt;- data.table(\n  dept_id = 1:5,\n  bono_porcentaje = c(0.15, 0.20, 0.12, 0.18, 0.16),\n  bono_fijo = c(5000, 7000, 4000, 6000, 5500)\n)\n\n# Hacer copia para update join\nemp_con_bonus &lt;- copy(empleados)\n\n# Update join: agregar columnas basadas en departamento\nemp_con_bonus[bonos_dept, on = .(departamento_id = dept_id), \n              `:=`(\n                bono_porcentaje = i.bono_porcentaje,\n                bono_calculado = salario * i.bono_porcentaje + i.bono_fijo\n              )]\n\nprint(emp_con_bonus[1:6, .(nombre, departamento_id, salario, bono_porcentaje, bono_calculado)])\n#&gt;        nombre departamento_id salario bono_porcentaje bono_calculado\n#&gt;        &lt;char&gt;           &lt;int&gt;   &lt;num&gt;           &lt;num&gt;          &lt;num&gt;\n#&gt; 1: Empleado_A               2   39500            0.20          14900\n#&gt; 2: Empleado_B               5   62200            0.16          15452\n#&gt; 3: Empleado_C               5   69000            0.16          16540\n#&gt; 4: Empleado_D               4   66900            0.18          18042\n#&gt; 5: Empleado_E               1   46700            0.15          12005\n#&gt; 6: Empleado_F               5   59600            0.16          15036\n\n\n5.5.2 2. Update Join Condicional\n\n\n# Update join solo para ciertos empleados\nemp_con_bonus[bonos_dept, on = .(departamento_id = dept_id), \n              bono_extra := ifelse(i.bono_porcentaje &gt; 0.15 & salario &gt; 50000, \n                                  2000, 0)]\n\nprint(emp_con_bonus[bono_extra &gt; 0, .(nombre, departamento_id, salario, bono_extra)])\n#&gt;        nombre departamento_id salario bono_extra\n#&gt;        &lt;char&gt;           &lt;int&gt;   &lt;num&gt;      &lt;num&gt;\n#&gt; 1: Empleado_B               5   62200       2000\n#&gt; 2: Empleado_C               5   69000       2000\n#&gt; 3: Empleado_D               4   66900       2000\n#&gt; 4: Empleado_F               5   59600       2000\n#&gt; 5: Empleado_J               5   52600       2000\n#&gt; 6: Empleado_M               4   73900       2000\n#&gt; 7: Empleado_N               2   62000       2000\n#&gt; 8: Empleado_O               2   62200       2000\n\n\n5.5.3 3. Update Join con Agregaciones\n\n\n# Calcular estadísticas por departamento\nstats_dept &lt;- empleados[, .(\n  empleados_count = .N,\n  salario_promedio_dept = round(mean(salario), 0),\n  salario_max_dept = max(salario)\n), by = departamento_id]\n\n# Update join con estadísticas\nemp_con_bonus[stats_dept, on = .(departamento_id), \n              `:=`(\n                empleados_en_dept = i.empleados_count,\n                percentil_en_dept = round(salario / i.salario_max_dept * 100, 1),\n                vs_promedio_dept = salario - i.salario_promedio_dept\n              )]\n\nprint(emp_con_bonus[1:8, .(nombre, departamento_id, salario, empleados_en_dept, \n                           percentil_en_dept, vs_promedio_dept)])\n#&gt;        nombre departamento_id salario empleados_en_dept percentil_en_dept\n#&gt;        &lt;char&gt;           &lt;int&gt;   &lt;num&gt;             &lt;int&gt;             &lt;num&gt;\n#&gt; 1: Empleado_A               2   39500                 5              63.5\n#&gt; 2: Empleado_B               5   62200                 5              90.1\n#&gt; 3: Empleado_C               5   69000                 5             100.0\n#&gt; 4: Empleado_D               4   66900                 2              90.5\n#&gt; 5: Empleado_E               1   46700                 2              69.1\n#&gt; 6: Empleado_F               5   59600                 5              86.4\n#&gt; 7: Empleado_G               1   67600                 2             100.0\n#&gt; 8: Empleado_H               2   35000                 5              56.3\n#&gt;    vs_promedio_dept\n#&gt;               &lt;num&gt;\n#&gt; 1:            -7400\n#&gt; 2:             5120\n#&gt; 3:            11920\n#&gt; 4:            -3500\n#&gt; 5:           -10450\n#&gt; 6:             2520\n#&gt; 7:            10450\n#&gt; 8:           -11900",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#joins-múltiples-y-encadenamiento",
    "href": "cap02-joins.html#joins-múltiples-y-encadenamiento",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.6 Joins Múltiples y Encadenamiento",
    "text": "5.6 Joins Múltiples y Encadenamiento\nCombinando múltiples tablas en operaciones complejas.\n\n5.6.1 1. Joins Encadenados\n\n\n# Pipeline complejo: empleados -&gt; departamentos -&gt; proyectos -&gt; evaluaciones\nanalisis_completo &lt;- empleados[\n  departamentos, on = .(departamento_id = dept_id)        # Join 1: empleados + departamentos\n][\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE  # Join 2: + asignaciones\n][\n  proyectos, on = .(proyecto_id), allow.cartesian = TRUE   # Join 3: + proyectos  \n][\n  evaluaciones, on = .(emp_id = empleado_id)               # Join 4: + evaluaciones\n][\n  !is.na(puntuacion)                                       # Solo empleados evaluados\n][\n  , .(\n    empleado = nombre,\n    departamento = nombre_dept,\n    proyecto = nombre_proyecto,\n    horas_asignadas,\n    rol_proyecto,\n    puntuacion,\n    salario,\n    presupuesto_proyecto\n  )\n][\n  order(empleado, proyecto)\n]\n\nprint(head(analisis_completo, 10))\n#&gt;       empleado departamento   proyecto horas_asignadas rol_proyecto puntuacion\n#&gt;         &lt;char&gt;       &lt;char&gt;     &lt;char&gt;           &lt;int&gt;       &lt;char&gt;      &lt;num&gt;\n#&gt;  1: Empleado_B     Finanzas Proyecto_G              39        Líder        3.8\n#&gt;  2: Empleado_B     Finanzas Proyecto_G              39        Líder        4.6\n#&gt;  3: Empleado_B     Finanzas Proyecto_H              37       Tester        3.8\n#&gt;  4: Empleado_B     Finanzas Proyecto_H              37       Tester        4.6\n#&gt;  5: Empleado_B     Finanzas Proyecto_J              14       Tester        3.8\n#&gt;  6: Empleado_B     Finanzas Proyecto_J              14       Tester        4.6\n#&gt;  7: Empleado_B     Finanzas Proyecto_L              21     Analista        3.8\n#&gt;  8: Empleado_B     Finanzas Proyecto_L              21     Analista        4.6\n#&gt;  9: Empleado_C     Finanzas Proyecto_L              16        Líder        3.4\n#&gt; 10: Empleado_D         RRHH Proyecto_A              36     Analista        4.1\n#&gt;     salario presupuesto_proyecto\n#&gt;       &lt;num&gt;                &lt;num&gt;\n#&gt;  1:   62200               276000\n#&gt;  2:   62200               276000\n#&gt;  3:   62200               260000\n#&gt;  4:   62200               260000\n#&gt;  5:   62200               172000\n#&gt;  6:   62200               172000\n#&gt;  7:   62200               286000\n#&gt;  8:   62200               286000\n#&gt;  9:   69000               286000\n#&gt; 10:   66900               251000\n\n\n5.6.2 2. Agregaciones Complejas con Múltiples Joins\n\n\n# Análisis de productividad por departamento\nproductividad_dept &lt;- empleados[\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE\n][\n  proyectos, on = .(proyecto_id)\n][\n  departamentos, on = .(departamento_id = dept_id)\n][\n  , .(\n    empleados_únicos = uniqueN(emp_id),\n    proyectos_únicos = uniqueN(proyecto_id),\n    horas_totales = sum(horas_asignadas),\n    presupuesto_total = sum(presupuesto_proyecto),\n    proyectos_completados = sum(estado == \"Completado\")\n  ), by = .(departamento_id, nombre_dept)\n][\n  , `:=`(\n    horas_por_empleado = round(horas_totales / empleados_únicos, 1),\n    proyectos_por_empleado = round(proyectos_únicos / empleados_únicos, 2),\n    tasa_completación = round(proyectos_completados / proyectos_únicos * 100, 1)\n  )\n][\n  order(-tasa_completación)\n]\n\nprint(productividad_dept)\n#&gt;    departamento_id nombre_dept empleados_únicos proyectos_únicos horas_totales\n#&gt;              &lt;int&gt;      &lt;char&gt;            &lt;int&gt;            &lt;int&gt;         &lt;int&gt;\n#&gt; 1:               2      Ventas                5                6           257\n#&gt; 2:               5    Finanzas                5                6           186\n#&gt; 3:               1  Ingeniería                2                4            82\n#&gt; 4:               4        RRHH                2                2            71\n#&gt; 5:               3   Marketing                1                1            NA\n#&gt;    presupuesto_total proyectos_completados horas_por_empleado\n#&gt;                &lt;num&gt;                 &lt;int&gt;              &lt;num&gt;\n#&gt; 1:           1748000                     4               51.4\n#&gt; 2:           1902000                     2               37.2\n#&gt; 3:            894000                     1               41.0\n#&gt; 4:            323000                     0               35.5\n#&gt; 5:                NA                    NA                 NA\n#&gt;    proyectos_por_empleado tasa_completación\n#&gt;                     &lt;num&gt;             &lt;num&gt;\n#&gt; 1:                    1.2              66.7\n#&gt; 2:                    1.2              33.3\n#&gt; 3:                    2.0              25.0\n#&gt; 4:                    1.0               0.0\n#&gt; 5:                    1.0                NA",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#casos-especiales-joins-con-diferentes-estructuras",
    "href": "cap02-joins.html#casos-especiales-joins-con-diferentes-estructuras",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.7 Casos Especiales: Joins con Diferentes Estructuras",
    "text": "5.7 Casos Especiales: Joins con Diferentes Estructuras\n\n5.7.1 1. Self-Joins: Jerarquías\n\n\n# Self-join para obtener información de managers\nempleados_con_manager &lt;- empleados[\n  empleados[, .(manager_emp_id = emp_id, manager_nombre = nombre, manager_nivel = nivel)], \n  on = .(manager_id = manager_emp_id)\n][\n  , .(empleado = nombre, nivel, salario, \n      manager = manager_nombre, manager_nivel)\n][\n  !is.na(manager)  # Solo empleados con manager\n][\n  order(manager, empleado)\n]\n\nprint(empleados_con_manager)\n#&gt;       empleado  nivel salario    manager manager_nivel\n#&gt;         &lt;char&gt; &lt;char&gt;   &lt;num&gt;     &lt;char&gt;        &lt;char&gt;\n#&gt;  1: Empleado_B Junior   62200 Empleado_A        Senior\n#&gt;  2: Empleado_C Senior   69000 Empleado_A        Senior\n#&gt;  3:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_B        Junior\n#&gt;  4:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_C        Senior\n#&gt;  5: Empleado_E   Lead   46700 Empleado_D        Junior\n#&gt; ---                                                   \n#&gt; 14: Empleado_L Senior   42000 Empleado_K        Junior\n#&gt; 15:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_L        Senior\n#&gt; 16: Empleado_N Junior   62000 Empleado_M        Senior\n#&gt; 17: Empleado_O   Lead   62200 Empleado_N        Junior\n#&gt; 18:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_O          Lead\n\n\n5.7.2 2. Many-to-Many Joins\n\n\n# Análisis de empleados en múltiples proyectos\nempleados_multiproyecto &lt;- asignaciones[, .N, by = empleado_id][N &gt; 1]\n\ndetalle_multiproyecto &lt;- empleados[empleados_multiproyecto, on = .(emp_id = empleado_id)][\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE\n][\n  proyectos, on = .(proyecto_id)\n][\n  , .(\n    empleado = nombre,\n    nivel,\n    proyecto = nombre_proyecto,\n    horas_asignadas,\n    rol_proyecto,\n    estado_proyecto = estado\n  )\n][\n  order(empleado, proyecto)\n]\n\nprint(head(detalle_multiproyecto, 12))\n#&gt;       empleado  nivel   proyecto horas_asignadas  rol_proyecto estado_proyecto\n#&gt;         &lt;char&gt; &lt;char&gt;     &lt;char&gt;           &lt;int&gt;        &lt;char&gt;          &lt;char&gt;\n#&gt;  1: Empleado_A Senior Proyecto_C              34        Tester      Completado\n#&gt;  2: Empleado_A Senior Proyecto_E              34        Tester         Pausado\n#&gt;  3: Empleado_A Senior Proyecto_J              19      Analista   Planificación\n#&gt;  4: Empleado_B Junior Proyecto_G              39         Líder      Completado\n#&gt;  5: Empleado_B Junior Proyecto_H              37        Tester        En Curso\n#&gt; ---                                                                           \n#&gt;  8: Empleado_E   Lead Proyecto_G              17         Líder      Completado\n#&gt;  9: Empleado_E   Lead Proyecto_H              38         Líder        En Curso\n#&gt; 10: Empleado_E   Lead Proyecto_L              10      Analista        En Curso\n#&gt; 11: Empleado_I Junior Proyecto_C              10 Desarrollador      Completado\n#&gt; 12: Empleado_I Junior Proyecto_D              40        Tester        En Curso\n\n# Resumen por empleado\nresumen_multiproyecto &lt;- detalle_multiproyecto[, .(\n  proyectos_total = .N,\n  horas_totales = sum(horas_asignadas),\n  roles_únicos = uniqueN(rol_proyecto),\n  proyectos_completados = sum(estado_proyecto == \"Completado\")\n), by = .(empleado, nivel)][\n  order(-horas_totales)\n]\n\nprint(resumen_multiproyecto)\n#&gt;      empleado  nivel proyectos_total horas_totales roles_únicos\n#&gt;        &lt;char&gt; &lt;char&gt;           &lt;int&gt;         &lt;int&gt;        &lt;int&gt;\n#&gt; 1: Empleado_B Junior               4           111            3\n#&gt; 2: Empleado_A Senior               3            87            2\n#&gt; 3: Empleado_I Junior               3            72            2\n#&gt; 4: Empleado_E   Lead               3            65            2\n#&gt; 5:       &lt;NA&gt;   &lt;NA&gt;              12            NA            5\n#&gt;    proyectos_completados\n#&gt;                    &lt;int&gt;\n#&gt; 1:                     1\n#&gt; 2:                     1\n#&gt; 3:                     1\n#&gt; 4:                     1\n#&gt; 5:                     3",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#comparación-de-performance-entre-métodos",
    "href": "cap02-joins.html#comparación-de-performance-entre-métodos",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.8 Comparación de Performance entre Métodos",
    "text": "5.8 Comparación de Performance entre Métodos\n\n# Preparar datasets para benchmark\nclientes_sample &lt;- clientes_info[sample(.N, 500)]\ntrans_sample &lt;- transacciones_grandes[sample(.N, 25000)]\n\n# Copias para diferentes métodos\nclientes_key &lt;- copy(clientes_sample)\ntrans_key &lt;- copy(trans_sample)\nsetkey(clientes_key, cliente_id)\nsetkey(trans_key, cliente_id)\n\n# Benchmark de diferentes métodos\nbenchmark_joins &lt;- microbenchmark(\n  \"merge()\" = merge(trans_sample, clientes_sample, by = \"cliente_id\"),\n  \"X[Y, on=]\" = trans_sample[clientes_sample, on = .(cliente_id)],\n  \"setkey + X[Y]\" = clientes_key[trans_key],\n  times = 10\n)\n\nprint(benchmark_joins)\n#&gt; Unit: microseconds\n#&gt;           expr    min     lq    mean  median     uq    max neval\n#&gt;        merge() 2345.5 2402.3 2644.50 2508.10 2532.2 4229.3    10\n#&gt;      X[Y, on=] 1337.7 1381.6 1415.98 1421.45 1452.7 1484.1    10\n#&gt;  setkey + X[Y]  978.3 1011.7 1241.62 1037.55 1127.5 2904.0    10\n\n# Mostrar eficiencia relativa\nbenchmark_summary &lt;- as.data.table(summary(benchmark_joins))\nprint(benchmark_summary[, .(expr, median, relative_speed = round(median / min(median), 2))])\n#&gt;             expr  median relative_speed\n#&gt;           &lt;fctr&gt;   &lt;num&gt;          &lt;num&gt;\n#&gt; 1:       merge() 2508.10           2.42\n#&gt; 2:     X[Y, on=] 1421.45           1.37\n#&gt; 3: setkey + X[Y] 1037.55           1.00",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#ejercicios-prácticos",
    "href": "cap02-joins.html#ejercicios-prácticos",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.9 Ejercicios Prácticos",
    "text": "5.9 Ejercicios Prácticos\n\n\n\n\n\n\n🏋️ Ejercicio 8: Pipeline de Joins Complejo\n\n\n\nUsando las tablas disponibles, crea un análisis que:\n\n\nUna empleados con sus departamentos y evaluaciones\n\nFiltre solo empleados con evaluación &gt; 4.0\n\nAgregue información de proyectos asignados\n\nCalcule métricas de productividad por departamento\n\nGenere un ranking de departamentos por performance\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 8\n\n\n\n\n\n\n# Pipeline completo de joins y análisis\nranking_departamentos &lt;- empleados[\n  evaluaciones[puntuacion &gt; 4.0], on = .(emp_id = empleado_id)  # 1. Join + filtro\n][\n  departamentos, on = .(departamento_id = dept_id)              # 2. Agregar info departamental\n][\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE  # 3. Proyectos asignados\n][\n  proyectos, on = .(proyecto_id)                                # 4. Info de proyectos\n][\n  , .(                                                          # 5. Métricas por departamento\n    empleados_alto_performance = uniqueN(emp_id),\n    puntuacion_promedio = round(mean(puntuacion), 2),\n    salario_promedio = round(mean(salario), 0),\n    horas_totales_asignadas = sum(horas_asignadas),\n    proyectos_gestionados = uniqueN(proyecto_id),\n    presupuesto_total_proyectos = sum(presupuesto_proyecto),\n    proyectos_completados = sum(estado == \"Completado\"),\n    presupuesto_departamental = first(presupuesto)\n  ), by = .(departamento_id, nombre_dept, ubicacion)\n][\n  , `:=`(                                                      # 6. Cálculos de productividad\n    horas_por_empleado = round(horas_totales_asignadas / empleados_alto_performance, 1),\n    proyectos_por_empleado = round(proyectos_gestionados / empleados_alto_performance, 2),\n    tasa_completación = round(proyectos_completados / proyectos_gestionados * 100, 1),\n    eficiencia_presupuestal = round((proyectos_completados * presupuesto_total_proyectos) / presupuesto_departamental, 2)\n  )\n][\n  , score_performance := round(                                # 7. Score compuesto\n    (puntuacion_promedio * 20) + \n    (tasa_completación * 0.5) + \n    (eficiencia_presupuestal * 10), 1\n  )\n][\n  order(-score_performance)                                    # 8. Ranking final\n][\n  , ranking := 1:.N\n]\n\nprint(ranking_departamentos[, .(\n  ranking, nombre_dept, ubicacion, empleados_alto_performance,\n  puntuacion_promedio, tasa_completación, eficiencia_presupuestal, score_performance\n)])\n#&gt;    ranking nombre_dept ubicacion empleados_alto_performance puntuacion_promedio\n#&gt;      &lt;int&gt;      &lt;char&gt;    &lt;char&gt;                      &lt;int&gt;               &lt;num&gt;\n#&gt; 1:       1    Finanzas    Bilbao                          2                4.50\n#&gt; 2:       2      Ventas Barcelona                          2                4.33\n#&gt; 3:       3  Ingeniería    Madrid                          1                4.80\n#&gt; 4:       4        RRHH  Valencia                          2                4.45\n#&gt; 5:       5        &lt;NA&gt;      &lt;NA&gt;                          8                  NA\n#&gt;    tasa_completación eficiencia_presupuestal score_performance\n#&gt;                &lt;num&gt;                   &lt;num&gt;             &lt;num&gt;\n#&gt; 1:              75.0                    9.28             220.3\n#&gt; 2:              50.0                    1.21             123.7\n#&gt; 3:               0.0                    0.00              96.0\n#&gt; 4:               0.0                    0.00              89.0\n#&gt; 5:              36.4                      NA                NA\n\n# Crear visualización del ranking\ncat(\"\\n🏆 RANKING DE DEPARTAMENTOS POR PERFORMANCE:\\n\")\n#&gt; \n#&gt; 🏆 RANKING DE DEPARTAMENTOS POR PERFORMANCE:\nfor(i in 1:nrow(ranking_departamentos)) {\n  dept &lt;- ranking_departamentos[i]\n  medal &lt;- ifelse(i == 1, \"🥇\", ifelse(i == 2, \"🥈\", ifelse(i == 3, \"🥉\", paste0(\"#\", i))))\n  cat(sprintf(\"%s %s (%s) - Score: %.1f\\n\", medal, dept$nombre_dept, dept$ubicacion, dept$score_performance))\n  cat(sprintf(\"   • %d empleados alto performance, %.1f%% completación\\n\", \n              dept$empleados_alto_performance, dept$tasa_completación))\n}\n#&gt; 🥇 Finanzas (Bilbao) - Score: 220.3\n#&gt;    • 2 empleados alto performance, 75.0% completación\n#&gt; 🥈 Ventas (Barcelona) - Score: 123.7\n#&gt;    • 2 empleados alto performance, 50.0% completación\n#&gt; 🥉 Ingeniería (Madrid) - Score: 96.0\n#&gt;    • 1 empleados alto performance, 0.0% completación\n#&gt; #4 RRHH (Valencia) - Score: 89.0\n#&gt;    • 2 empleados alto performance, 0.0% completación\n#&gt; #5 NA (NA) - Score: NA\n#&gt;    • 8 empleados alto performance, 36.4% completación\n\n\n\n\n\n\n\n\n\n\n🏋️ Ejercicio 9: Update Joins Avanzados\n\n\n\n\n\nCrea una tabla de ajustes salariales por departamento\n\nUsa update joins para aplicar los ajustes\n\nCalcula el impacto presupuestal por departamento\n\nIdentifica empleados que necesitan reclasificación de nivel\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 9\n\n\n\n\n\n\n# 1. Crear tabla de ajustes salariales\najustes_salariales &lt;- data.table(\n  dept_id = 1:5,\n  nombre_dept = c(\"Ingeniería\", \"Ventas\", \"Marketing\", \"RRHH\", \"Finanzas\"),\n  ajuste_porcentaje = c(0.08, 0.12, 0.06, 0.10, 0.07),  # 8%, 12%, 6%, 10%, 7%\n  bono_retencion = c(3000, 5000, 2000, 2500, 4000),\n  criterio_nivel = c(65000, 55000, 45000, 50000, 60000)  # Umbral para nivel Senior+\n)\n\nprint(\"Ajustes salariales por departamento:\")\n#&gt; [1] \"Ajustes salariales por departamento:\"\nprint(ajustes_salariales)\n#&gt;    dept_id nombre_dept ajuste_porcentaje bono_retencion criterio_nivel\n#&gt;      &lt;int&gt;      &lt;char&gt;             &lt;num&gt;          &lt;num&gt;          &lt;num&gt;\n#&gt; 1:       1  Ingeniería              0.08           3000          65000\n#&gt; 2:       2      Ventas              0.12           5000          55000\n#&gt; 3:       3   Marketing              0.06           2000          45000\n#&gt; 4:       4        RRHH              0.10           2500          50000\n#&gt; 5:       5    Finanzas              0.07           4000          60000\n\n# 2. Aplicar ajustes usando update joins\nempleados_ajuste &lt;- copy(empleados)\n\n# Update join principal\nempleados_ajuste[ajustes_salariales, on = .(departamento_id = dept_id),\n                 `:=`(\n                   salario_anterior = salario,\n                   ajuste_pct = i.ajuste_porcentaje,\n                   salario_ajustado = salario * (1 + i.ajuste_porcentaje),\n                   bono_retencion = i.bono_retencion,\n                   umbral_senior = i.criterio_nivel\n                 )]\n\n# Update join condicional para bonos extra\nempleados_ajuste[nivel %in% c(\"Lead\", \"Manager\") & salario_ajustado &gt; 60000, \n                 bono_extra := salario_ajustado * 0.05]\nempleados_ajuste[is.na(bono_extra), bono_extra := 0]\n\n# 3. Calcular impacto presupuestal\nimpacto_presupuestal &lt;- empleados_ajuste[\n  departamentos, on = .(departamento_id = dept_id)\n][\n  , .(\n    empleados = .N,\n    salario_total_anterior = sum(salario_anterior),\n    salario_total_nuevo = sum(salario_ajustado),\n    bonos_retencion = sum(bono_retencion),\n    bonos_extra = sum(bono_extra),\n    presupuesto_dept = first(presupuesto)\n  ), by = .(departamento_id, nombre_dept)\n][\n  , `:=`(\n    incremento_salarial = salario_total_nuevo - salario_total_anterior,\n    costo_total_ajuste = (salario_total_nuevo - salario_total_anterior) + bonos_retencion + bonos_extra,\n    impacto_presupuestal_pct = round(((salario_total_nuevo - salario_total_anterior) + bonos_retencion + bonos_extra) / presupuesto_dept * 100, 2)\n  )\n][\n  order(-costo_total_ajuste)\n]\n\nprint(\"\\n3. Impacto presupuestal por departamento:\")\n#&gt; [1] \"\\n3. Impacto presupuestal por departamento:\"\nprint(impacto_presupuestal[, .(nombre_dept, empleados, incremento_salarial, \n                               costo_total_ajuste, impacto_presupuestal_pct)])\n#&gt;    nombre_dept empleados incremento_salarial costo_total_ajuste\n#&gt;         &lt;char&gt;     &lt;int&gt;               &lt;num&gt;              &lt;num&gt;\n#&gt; 1:      Ventas         5               28140            56623.2\n#&gt; 2:    Finanzas         5               19978            43166.6\n#&gt; 3:        RRHH         2               14080            19080.0\n#&gt; 4:  Ingeniería         2                9144            18794.4\n#&gt; 5:   Marketing         1                2796             4796.0\n#&gt;    impacto_presupuestal_pct\n#&gt;                       &lt;num&gt;\n#&gt; 1:                     9.44\n#&gt; 2:                     8.63\n#&gt; 3:                     6.36\n#&gt; 4:                     2.35\n#&gt; 5:                     1.20\n\n# 4. Identificar empleados para reclasificación\nreclasificacion &lt;- empleados_ajuste[, .(\n  nombre,\n  departamento_id,\n  nivel_actual = nivel,\n  salario_ajustado,\n  umbral_senior,\n  necesita_reclasificacion = salario_ajustado &gt;= umbral_senior & nivel == \"Junior\"\n)][necesita_reclasificacion == TRUE]\n\nif(nrow(reclasificacion) &gt; 0) {\n  cat(\"\\n4. Empleados que necesitan reclasificación:\\n\")\n  print(reclasificacion[, .(nombre, nivel_actual, salario_ajustado, umbral_senior)])\n} else {\n  cat(\"\\n4. No hay empleados que requieran reclasificación inmediata.\\n\")\n}\n#&gt; \n#&gt; 4. Empleados que necesitan reclasificación:\n#&gt;        nombre nivel_actual salario_ajustado umbral_senior\n#&gt;        &lt;char&gt;       &lt;char&gt;            &lt;num&gt;         &lt;num&gt;\n#&gt; 1: Empleado_B       Junior            66554         60000\n#&gt; 2: Empleado_D       Junior            73590         50000\n#&gt; 3: Empleado_K       Junior            49396         45000\n#&gt; 4: Empleado_N       Junior            69440         55000\n\n# Resumen ejecutivo\ncat(\"\\n📊 RESUMEN EJECUTIVO DEL AJUSTE SALARIAL:\\n\")\n#&gt; \n#&gt; 📊 RESUMEN EJECUTIVO DEL AJUSTE SALARIAL:\ncat(sprintf(\"• Total empleados afectados: %d\\n\", nrow(empleados_ajuste)))\n#&gt; • Total empleados afectados: 15\ncat(sprintf(\"• Incremento salarial total: $%s\\n\", \n            format(sum(impacto_presupuestal$incremento_salarial), big.mark = \",\")))\n#&gt; • Incremento salarial total: $74,138\ncat(sprintf(\"• Costo total del ajuste: $%s\\n\", \n            format(sum(impacto_presupuestal$costo_total_ajuste), big.mark = \",\")))\n#&gt; • Costo total del ajuste: $142,460.2\ncat(sprintf(\"• Departamento más impactado: %s (%.2f%% del presupuesto)\\n\",\n            impacto_presupuestal[1, nombre_dept], impacto_presupuestal[1, impacto_presupuestal_pct]))\n#&gt; • Departamento más impactado: Ventas (9.44% del presupuesto)",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#mejores-prácticas-para-joins",
    "href": "cap02-joins.html#mejores-prácticas-para-joins",
    "title": "\n5  Uniones de Datos (Joins)\n",
    "section": "\n5.10 Mejores Prácticas para Joins",
    "text": "5.10 Mejores Prácticas para Joins\n\n5.10.1 1. Elección del Método Adecuado\n\n\n# ✅ Para joins únicos: usar \"on =\"\nresultado &lt;- tabla1[tabla2, on = .(key)]\n\n# ✅ Para joins repetitivos en datos grandes: usar setkey\nsetkey(tabla1, key)\nsetkey(tabla2, key)\nresultado &lt;- tabla2[tabla1]\n\n# ✅ Para análisis exploratorio: usar merge()\nresultado &lt;- merge(tabla1, tabla2, by = \"key\")\n\n# ✅ Para modificar tabla existente: usar update join\ntabla1[tabla2, on = .(key), nueva_col := i.columna]\n\n\n5.10.2 2. Gestión de Memoria en Joins\n\n\n# ✅ HACER: Filtrar antes de join\ntabla_pequeña &lt;- tabla_grande[filtro_importante]\nresultado &lt;- tabla_pequeña[otra_tabla, on = .(key)]\n\n# ❌ EVITAR: Join primero, filtrar después\nresultado &lt;- tabla_grande[otra_tabla, on = .(key)][filtro_importante]\n\n# ✅ HACER: Usar .SDcols para limitar columnas en joins complejos\nresultado &lt;- tabla1[tabla2, on = .(key), .SDcols = columnas_necesarias]\n\n\n5.10.3 3. Troubleshooting de Joins\n\n\n# Diagnosticar problemas de joins\ncat(\"Claves duplicadas en tabla1:\", anyDuplicated(tabla1, by = \"key\"), \"\\n\")\ncat(\"Claves faltantes:\", sum(is.na(tabla1$key)), \"\\n\")\ncat(\"Rango de keys:\", range(tabla1$key, na.rm = TRUE), \"\\n\")\n\n# Verificar resultado de join\ncat(\"Filas antes del join:\", nrow(tabla1), \"\\n\")\ncat(\"Filas después del join:\", nrow(resultado), \"\\n\")\ncat(\"Columnas agregadas:\", ncol(resultado) - ncol(tabla1), \"\\n\")\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nmerge() es intuitivo para joins simples, setkey() es óptimo para datos grandes\n\nSintaxis on ofrece flexibilidad sin modificar las tablas originales\n\nUpdate joins con := permiten modificar tablas de forma eficiente\n\nLa elección del método depende del tamaño de datos y frecuencia de uso\n\nFiltrar antes de join mejora significativamente el rendimiento\n\nAlways verify el resultado de joins complejos para evitar cartesian products\n\n\n\n[{“content”: “Reorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos”, “status”: “completed”, “id”: “1”}, {“content”: “Crear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1”, “status”: “completed”, “id”: “1-new”}, {“content”: “Reorganizar M0f3dulo 2: dividir en encadenamiento y joins”, “status”: “completed”, “id”: “2”}, {“content”: “Reorganizar M0f3dulo 3: dividir en joins avanzados, funciones especiales y reshape”, “status”: “in_progress”, “id”: “3”}, {“content”: “Reorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas”, “status”: “pending”, “id”: “4”}, {“content”: “Reorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones”, “status”: “pending”, “id”: “5”}]",
    "crumbs": [
      "**Módulo 2**: Manipulación de Datos Intermedia",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html",
    "href": "cap03-joins-avanzados.html",
    "title": "\n6  Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "",
    "text": "6.1 Non-Equi Joins: Más Allá de la Igualdad\nLos non-equi joins permiten unir tablas basándose en rangos, desigualdades y condiciones complejas. Son especialmente útiles en análisis médico, financiero y clasificación por rangos.",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#non-equi-joins-más-allá-de-la-igualdad",
    "href": "cap03-joins-avanzados.html#non-equi-joins-más-allá-de-la-igualdad",
    "title": "\n6  Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "",
    "text": "6.1.1 1. Conceptos Fundamentales\n\nUn non-equi join utiliza operadores de comparación (&lt;=, &gt;=, &lt;, &gt;) en lugar de igualdad (==):\n\n# Ejemplo simple: clasificar pacientes por IMC\nrangos_imc &lt;- rangos_medicos[parametro == \"IMC\"]\nprint(\"Rangos de IMC:\")\n#&gt; [1] \"Rangos de IMC:\"\nprint(rangos_imc)\n#&gt;    parametro valor_min valor_max     categoria nivel_riesgo\n#&gt;       &lt;char&gt;     &lt;num&gt;     &lt;num&gt;        &lt;char&gt;       &lt;char&gt;\n#&gt; 1:       IMC       0.0      18.4   Bajo/Normal         Bajo\n#&gt; 2:       IMC      18.5      24.9 Normal/Óptimo       Normal\n#&gt; 3:       IMC      25.0       Inf   Alto/Riesgo         Alto\n\n# Non-equi join básico\npacientes_clasificados_imc &lt;- rangos_imc[pacientes_clinica,\n  on = .(valor_min &lt;= imc, valor_max &gt;= imc),\n  .(paciente_id, nombre, imc, categoria, nivel_riesgo)]\n\nprint(\"Pacientes clasificados por IMC:\")\n#&gt; [1] \"Pacientes clasificados por IMC:\"\nprint(head(pacientes_clasificados_imc[order(imc)], 10))\n#&gt;     paciente_id      nombre   imc   categoria nivel_riesgo\n#&gt;           &lt;int&gt;      &lt;char&gt; &lt;num&gt;      &lt;char&gt;       &lt;char&gt;\n#&gt;  1:          69 Paciente_69   8.6 Bajo/Normal         Bajo\n#&gt;  2:           5  Paciente_5  11.2 Bajo/Normal         Bajo\n#&gt;  3:          98 Paciente_98  11.7 Bajo/Normal         Bajo\n#&gt;  4:          57 Paciente_57  12.2 Bajo/Normal         Bajo\n#&gt;  5:          46 Paciente_46  13.1 Bajo/Normal         Bajo\n#&gt;  6:          73 Paciente_73  13.9 Bajo/Normal         Bajo\n#&gt;  7:          66 Paciente_66  14.7 Bajo/Normal         Bajo\n#&gt;  8:          90 Paciente_90  14.7 Bajo/Normal         Bajo\n#&gt;  9:           7  Paciente_7  15.5 Bajo/Normal         Bajo\n#&gt; 10:          65 Paciente_65  15.7 Bajo/Normal         Bajo\n\n\n6.1.2 2. Non-Equi Join con Múltiples Condiciones\n\n\n# Clasificar pacientes por múltiples parámetros simultáneamente\n# Crear función auxiliar para clasificar\nclasificar_parametro &lt;- function(dt, param_name, value_col) {\n  rangos &lt;- rangos_medicos[parametro == param_name]\n  resultado &lt;- rangos[dt, on = c(\"valor_min\" = paste0(value_col, \"&gt;=\"), \"valor_max\" = paste0(value_col, \"&lt;=\")),\n                     .(paciente_id, parametro, categoria, nivel_riesgo),\n                     nomatch = NULL]\n  return(resultado)\n}\n\n# Clasificar por glucosa\npacientes_glucosa &lt;- rangos_medicos[parametro == \"Glucosa\"][pacientes_clinica,\n  on = .(valor_min &lt;= glucosa, valor_max &gt;= glucosa),\n  .(paciente_id, parametro = \"Glucosa\", valor = glucosa, categoria, nivel_riesgo)]\n\n# Clasificar por presión sistólica\npacientes_presion &lt;- rangos_medicos[parametro == \"Presión\"][pacientes_clinica,\n  on = .(valor_min &lt;= presion_sistolica, valor_max &gt;= presion_sistolica),  \n  .(paciente_id, parametro = \"Presion\", valor = presion_sistolica, categoria, nivel_riesgo)]\n\n# Combinar clasificaciones\ntodas_clasificaciones &lt;- rbind(\n  pacientes_glucosa[!is.na(categoria)],\n  pacientes_presion[!is.na(categoria)]\n)\n\n# Resumen de riesgos por paciente\nresumen_riesgo_pacientes &lt;- todas_clasificaciones[,\n  .(\n    parametros_evaluados = .N,\n    riesgos_altos = sum(nivel_riesgo == \"Alto\"),\n    riesgos_normales = sum(nivel_riesgo == \"Normal\"),\n    clasificacion_general = fcase(\n      sum(nivel_riesgo == \"Alto\") &gt;= 2, \"Alto Riesgo Múltiple\",\n      sum(nivel_riesgo == \"Alto\") == 1, \"Riesgo Moderado\", \n      default = \"Bajo Riesgo\"\n    )\n  ), by = paciente_id]\n\nprint(\"Resumen de riesgos por paciente:\")\n#&gt; [1] \"Resumen de riesgos por paciente:\"\nprint(head(resumen_riesgo_pacientes[order(-riesgos_altos)], 10))\n#&gt;     paciente_id parametros_evaluados riesgos_altos riesgos_normales\n#&gt;           &lt;int&gt;                &lt;int&gt;         &lt;int&gt;            &lt;int&gt;\n#&gt;  1:           1                    2             2                0\n#&gt;  2:           2                    2             2                0\n#&gt;  3:           4                    2             2                0\n#&gt;  4:           8                    2             2                0\n#&gt;  5:           9                    2             2                0\n#&gt;  6:          12                    2             2                0\n#&gt;  7:          16                    2             2                0\n#&gt;  8:          18                    2             2                0\n#&gt;  9:          19                    2             2                0\n#&gt; 10:          20                    2             2                0\n#&gt;     clasificacion_general\n#&gt;                    &lt;char&gt;\n#&gt;  1:  Alto Riesgo Múltiple\n#&gt;  2:  Alto Riesgo Múltiple\n#&gt;  3:  Alto Riesgo Múltiple\n#&gt;  4:  Alto Riesgo Múltiple\n#&gt;  5:  Alto Riesgo Múltiple\n#&gt;  6:  Alto Riesgo Múltiple\n#&gt;  7:  Alto Riesgo Múltiple\n#&gt;  8:  Alto Riesgo Múltiple\n#&gt;  9:  Alto Riesgo Múltiple\n#&gt; 10:  Alto Riesgo Múltiple\n\n\n6.1.3 3. Non-Equi Join para Ventanas Temporales\n\n\n# Encontrar todas las operaciones que ocurrieron dentro de ventanas de eventos\noperaciones_en_ventanas &lt;- eventos_mercado[operaciones_trading,\n  on = .(ticker_afectado = ticker,\n         fecha_inicio_ventana &lt;= fecha_operacion,\n         fecha_fin_ventana &gt;= fecha_operacion),\n  .(evento_id, tipo_evento, fecha_evento, impacto_esperado,\n    operacion_id, fecha_operacion, tipo, cantidad, precio_limite),\n  nomatch = NULL]\n\n# Análisis de comportamiento en ventanas de eventos\ncomportamiento_eventos &lt;- operaciones_en_ventanas[,\n  .(\n    operaciones_total = .N,\n    operaciones_compra = sum(tipo == \"COMPRA\"),\n    operaciones_venta = sum(tipo == \"VENTA\"),\n    volumen_total = sum(cantidad),\n    precio_promedio = round(mean(precio_limite), 2),\n    dias_promedio_evento = round(mean(as.numeric(abs(fecha_operacion - fecha_evento))), 1)\n  ), by = .(tipo_evento, impacto_esperado)]\n\nprint(\"Comportamiento de trading en ventanas de eventos:\")\n#&gt; [1] \"Comportamiento de trading en ventanas de eventos:\"\nprint(comportamiento_eventos[order(-volumen_total)])\n#&gt;       tipo_evento impacto_esperado operaciones_total operaciones_compra\n#&gt;            &lt;char&gt;           &lt;char&gt;             &lt;int&gt;              &lt;int&gt;\n#&gt; 1:       Earnings         Positivo                 7                  4\n#&gt; 2:       Earnings           Neutro                 9                  7\n#&gt; 3:         Merger         Positivo                 8                  4\n#&gt; 4:   FDA_Approval         Positivo                 7                  3\n#&gt; 5:   FDA_Approval           Neutro                 5                  5\n#&gt; 6:          Split         Positivo                 6                  3\n#&gt; 7:         Merger           Neutro                 1                  1\n#&gt; 8: Product_Launch         Positivo                 2                  0\n#&gt; 9:       Earnings         Negativo                 1                  1\n#&gt;    operaciones_venta volumen_total precio_promedio dias_promedio_evento\n#&gt;                &lt;int&gt;         &lt;num&gt;           &lt;num&gt;                &lt;num&gt;\n#&gt; 1:                 3          5550         1114.30                  3.1\n#&gt; 2:                 2          3150         1407.04                  4.3\n#&gt; 3:                 4          3100         1581.95                  5.1\n#&gt; 4:                 4          2400         1328.23                  3.1\n#&gt; 5:                 0          1950         1803.68                  4.8\n#&gt; 6:                 3          1200         1841.82                  4.8\n#&gt; 7:                 0          1000         2428.78                  2.0\n#&gt; 8:                 2           600         1234.13                  2.0\n#&gt; 9:                 0           500         1804.09                  5.0",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#rolling-joins-la-joya-para-series-temporales",
    "href": "cap03-joins-avanzados.html#rolling-joins-la-joya-para-series-temporales",
    "title": "\n6  Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.2 Rolling Joins: La Joya para Series Temporales",
    "text": "6.2 Rolling Joins: La Joya para Series Temporales\nLos rolling joins son perfectos para conectar cada observación con el último valor disponible en el tiempo.\n\n6.2.1 1. Rolling Join Básico\n\n\n# Preparar datos con keys para rolling join\nprecios_key &lt;- copy(precios_historicos)\noperaciones_key &lt;- copy(operaciones_trading)\n\n# Establecer keys compuestas: ticker + fecha\nsetkey(precios_key, ticker, fecha)\nsetkey(operaciones_key, ticker, fecha_operacion)\n\n# Rolling join: obtener el último precio disponible para cada operación\noperaciones_con_precio &lt;- precios_key[operaciones_key, roll = TRUE]\n\n# Verificar estructura del resultado\nprint(\"Columnas disponibles después del rolling join:\")\n#&gt; [1] \"Columnas disponibles después del rolling join:\"\nprint(names(operaciones_con_precio))\n#&gt; [1] \"fecha\"         \"ticker\"        \"precio_cierre\" \"volumen\"      \n#&gt; [5] \"operacion_id\"  \"tipo\"          \"cantidad\"      \"precio_limite\"\n#&gt; [9] \"trader_id\"\nprint(\"Primeras filas para entender la estructura:\")\n#&gt; [1] \"Primeras filas para entender la estructura:\"\nprint(head(operaciones_con_precio, 3))\n#&gt; Clave &lt;ticker, fecha&gt;\n#&gt;         fecha ticker precio_cierre  volumen operacion_id   tipo cantidad\n#&gt;        &lt;Date&gt; &lt;char&gt;         &lt;num&gt;    &lt;num&gt;        &lt;int&gt; &lt;char&gt;    &lt;num&gt;\n#&gt; 1: 2024-01-01   AAPL        155.41 15619654          471 COMPRA       50\n#&gt; 2: 2024-01-04   AAPL        157.65 42789129          437 COMPRA      100\n#&gt; 3: 2024-01-06   AAPL        170.90  4219831           37  VENTA       50\n#&gt;    precio_limite trader_id\n#&gt;            &lt;num&gt;    &lt;char&gt;\n#&gt; 1:       1827.71        T5\n#&gt; 2:       2802.78       T18\n#&gt; 3:        971.83        T9\n\n# En un rolling join X[Y], el resultado incluye todas las columnas de Y más las de X\n# Las columnas de la fecha de Y se mantienen, no se prefijan con i.\nprint(\"Operaciones con precios históricos (rolling join):\")\n#&gt; [1] \"Operaciones con precios históricos (rolling join):\"\nif(\"fecha_operacion\" %in% names(operaciones_con_precio)) {\n  # Si fecha_operacion existe directamente\n  print(head(operaciones_con_precio[, .(ticker, fecha, precio_cierre, \n                                       operacion_id, fecha_operacion, tipo, cantidad)], 10))\n  # Calcular diferencia temporal\n  operaciones_con_precio[, dias_diferencia := as.numeric(fecha_operacion - fecha)]\n} else {\n  # Buscar columnas con fecha en el nombre\n  fecha_cols &lt;- grep(\"fecha\", names(operaciones_con_precio), value = TRUE)\n  print(paste(\"Columnas con 'fecha' encontradas:\", paste(fecha_cols, collapse = \", \")))\n  \n  # Mostrar primeras columnas disponibles\n  print(head(operaciones_con_precio[, 1:min(8, ncol(operaciones_con_precio))], 10))\n}\n#&gt; [1] \"Columnas con 'fecha' encontradas: fecha\"\n#&gt; Clave &lt;ticker, fecha&gt;\n#&gt;          fecha ticker precio_cierre  volumen operacion_id   tipo cantidad\n#&gt;         &lt;Date&gt; &lt;char&gt;         &lt;num&gt;    &lt;num&gt;        &lt;int&gt; &lt;char&gt;    &lt;num&gt;\n#&gt;  1: 2024-01-01   AAPL        155.41 15619654          471 COMPRA       50\n#&gt;  2: 2024-01-04   AAPL        157.65 42789129          437 COMPRA      100\n#&gt;  3: 2024-01-06   AAPL        170.90  4219831           37  VENTA       50\n#&gt;  4: 2024-01-17   AAPL        144.56 22593327          260 COMPRA      100\n#&gt;  5: 2024-01-21   AAPL        136.44 22967352           35 COMPRA      200\n#&gt;  6: 2024-01-25   AAPL        146.15 16764243          362  VENTA     1000\n#&gt;  7: 2024-01-26   AAPL        138.94 25121176          302 COMPRA      100\n#&gt;  8: 2024-01-28   AAPL        142.77  4554781          102 COMPRA      100\n#&gt;  9: 2024-02-01   AAPL        125.12 39017505          135 COMPRA      100\n#&gt; 10: 2024-02-12   AAPL        130.18  3604906          237 COMPRA      200\n#&gt;     precio_limite\n#&gt;             &lt;num&gt;\n#&gt;  1:       1827.71\n#&gt;  2:       2802.78\n#&gt;  3:        971.83\n#&gt;  4:        740.76\n#&gt;  5:        463.55\n#&gt;  6:       1978.25\n#&gt;  7:        758.49\n#&gt;  8:       2694.70\n#&gt;  9:       1218.84\n#&gt; 10:       1558.66\n\n# Estadísticas de la calidad del match (solo si dias_diferencia fue creada)\nif(\"dias_diferencia\" %in% names(operaciones_con_precio)) {\n  cat(\"Estadísticas del rolling join:\\n\")\n  cat(\"• Operaciones con precio exacto (mismo día):\", sum(operaciones_con_precio$dias_diferencia == 0, na.rm = TRUE), \"\\n\")\n  cat(\"• Operaciones con precio de días anteriores:\", sum(operaciones_con_precio$dias_diferencia &gt; 0, na.rm = TRUE), \"\\n\")\n  cat(\"• Diferencia promedio en días:\", round(mean(operaciones_con_precio$dias_diferencia, na.rm = TRUE), 1), \"\\n\")\n} else {\n  cat(\"La variable dias_diferencia no pudo ser creada debido a problemas con las columnas de fecha.\\n\")\n}\n#&gt; La variable dias_diferencia no pudo ser creada debido a problemas con las columnas de fecha.\n\n\n6.2.2 2. Rolling Join con Límites Temporales\n\n\n# Rolling join con límite: solo usar precios de máximo 7 días anteriores\noperaciones_precio_limitado &lt;- precios_key[operaciones_key, \n                                          roll = 7,  # máximo 7 días\n                                          rollends = c(TRUE, TRUE)]\n\n# Comparar con rolling join ilimitado\nmatches_limitado &lt;- sum(!is.na(operaciones_precio_limitado$precio_cierre))\nmatches_ilimitado &lt;- sum(!is.na(operaciones_con_precio$precio_cierre))\n\ncat(\"Comparación de rolling joins:\\n\")\n#&gt; Comparación de rolling joins:\ncat(\"• Matches con rolling limitado (7 días):\", matches_limitado, \"\\n\") \n#&gt; • Matches con rolling limitado (7 días): 111\ncat(\"• Matches con rolling ilimitado:\", matches_ilimitado, \"\\n\")\n#&gt; • Matches con rolling ilimitado: 291\ncat(\"• Diferencia:\", matches_ilimitado - matches_limitado, \"operaciones\\n\")\n#&gt; • Diferencia: 180 operaciones\n\n# Analizar operaciones sin match en rolling limitado\noperaciones_sin_precio &lt;- operaciones_precio_limitado[is.na(precio_cierre)]\nif(nrow(operaciones_sin_precio) &gt; 0) {\n  cat(\"• Operaciones sin precio (primeros días del año o fines de semana largos):\", nrow(operaciones_sin_precio), \"\\n\")\n}\n#&gt; • Operaciones sin precio (primeros días del año o fines de semana largos): 389\n\n\n6.2.3 3. Rolling Join Bidireccional (Nearest)\n\n\n# Rolling join \"nearest\": buscar el precio más cercano (antes o después)\noperaciones_nearest &lt;- precios_key[operaciones_key, roll = \"nearest\"]\n\n# Comparar diferentes tipos de rolling join\ncomparacion_rolling &lt;- data.table(\n  Tipo_Rolling = c(\"Backward (TRUE)\", \"Limited (7 days)\", \"Nearest\"),\n  Matches = c(\n    sum(!is.na(operaciones_con_precio$precio_cierre)),\n    sum(!is.na(operaciones_precio_limitado$precio_cierre)), \n    sum(!is.na(operaciones_nearest$precio_cierre))\n  ),\n  Cobertura_Pct = round(c(\n    mean(!is.na(operaciones_con_precio$precio_cierre)) * 100,\n    mean(!is.na(operaciones_precio_limitado$precio_cierre)) * 100,\n    mean(!is.na(operaciones_nearest$precio_cierre)) * 100\n  ), 1)\n)\n\nprint(\"Comparación de tipos de rolling join:\")\n#&gt; [1] \"Comparación de tipos de rolling join:\"\nprint(comparacion_rolling)\n#&gt;        Tipo_Rolling Matches Cobertura_Pct\n#&gt;              &lt;char&gt;   &lt;int&gt;         &lt;num&gt;\n#&gt; 1:  Backward (TRUE)     291          58.2\n#&gt; 2: Limited (7 days)     111          22.2\n#&gt; 3:          Nearest     500         100.0\n\n\n6.2.4 4. Rolling Join con Sensores IoT\n\n\n# Caso práctico: asociar eventos de mantenimiento con lecturas de sensores\nsetkey(sensores_iot, sensor_id, timestamp)\nsetkey(mantenimiento, sensor_id, fecha_mantenimiento)\n\n# Rolling join para obtener la última lectura antes del mantenimiento\nlecturas_pre_mantenimiento &lt;- sensores_iot[mantenimiento, roll = TRUE]\n\n# Verificar estructura del resultado\nprint(\"Columnas disponibles después del rolling join de sensores:\")\n#&gt; [1] \"Columnas disponibles después del rolling join de sensores:\"\nprint(names(lecturas_pre_mantenimiento))\n#&gt; [1] \"timestamp\"          \"sensor_id\"          \"valor\"             \n#&gt; [4] \"ubicacion\"          \"mantenimiento_id\"   \"tipo_mantenimiento\"\n#&gt; [7] \"duracion_horas\"\n\n# Análisis del estado de sensores antes del mantenimiento\nif(\"fecha_mantenimiento\" %in% names(lecturas_pre_mantenimiento)) {\n  # Si fecha_mantenimiento existe directamente\n  analisis_pre_mantenimiento &lt;- lecturas_pre_mantenimiento[!is.na(valor),\n    .(\n      valor_promedio_pre = round(mean(valor), 2),\n      valor_min_pre = min(valor),\n      valor_max_pre = max(valor),\n      eventos_mantenimiento = .N,\n      tiempo_promedio_desde_lectura = round(mean(as.numeric(fecha_mantenimiento - timestamp) / 60), 1) # minutos\n    ), by = .(sensor_id, tipo_mantenimiento)]\n} else {\n  # Buscar columnas con fecha o mantenimiento en el nombre\n  fecha_cols &lt;- grep(\"fecha|mantenimiento\", names(lecturas_pre_mantenimiento), value = TRUE)\n  print(paste(\"Columnas con 'fecha' o 'mantenimiento' encontradas:\", paste(fecha_cols, collapse = \", \")))\n  \n  # Análisis simplificado sin cálculo temporal\n  analisis_pre_mantenimiento &lt;- lecturas_pre_mantenimiento[!is.na(valor),\n    .(\n      valor_promedio_pre = round(mean(valor), 2),\n      valor_min_pre = min(valor),\n      valor_max_pre = max(valor),\n      eventos_mantenimiento = .N\n    ), by = .(sensor_id, tipo_mantenimiento)]\n}\n#&gt; [1] \"Columnas con 'fecha' o 'mantenimiento' encontradas: mantenimiento_id, tipo_mantenimiento\"\n\nprint(\"Análisis de sensores antes del mantenimiento:\")\n#&gt; [1] \"Análisis de sensores antes del mantenimiento:\"\nprint(analisis_pre_mantenimiento[order(sensor_id, tipo_mantenimiento)])\n#&gt;       sensor_id tipo_mantenimiento valor_promedio_pre valor_min_pre\n#&gt;          &lt;char&gt;             &lt;char&gt;              &lt;num&gt;         &lt;num&gt;\n#&gt;  1:    HUMID_01        Calibracion              82.65         82.65\n#&gt;  2:    HUMID_01          Reemplazo             290.32         24.02\n#&gt;  3: PRESSURE_01           Limpieza             508.30         20.37\n#&gt;  4: PRESSURE_01          Reemplazo              19.74         19.74\n#&gt;  5:     TEMP_01        Calibracion             992.82        992.82\n#&gt;  6:     TEMP_01           Limpieza              22.69         22.69\n#&gt;  7:     TEMP_01          Reemplazo             529.52         55.85\n#&gt;  8:     TEMP_02        Calibracion              73.00         73.00\n#&gt;  9:     TEMP_02           Limpieza              21.75         20.97\n#&gt; 10:     TEMP_02          Reemplazo              29.41         20.87\n#&gt;     valor_max_pre eventos_mantenimiento\n#&gt;             &lt;num&gt;                 &lt;int&gt;\n#&gt;  1:         82.65                     1\n#&gt;  2:       1035.33                     4\n#&gt;  3:        996.24                     2\n#&gt;  4:         19.74                     1\n#&gt;  5:        992.82                     1\n#&gt;  6:         22.69                     1\n#&gt;  7:       1003.20                     2\n#&gt;  8:         73.00                     1\n#&gt;  9:         22.45                     3\n#&gt; 10:         51.82                     4",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#update-joins-avanzados-con-condiciones",
    "href": "cap03-joins-avanzados.html#update-joins-avanzados-con-condiciones",
    "title": "\n6  Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.3 Update Joins Avanzados con Condiciones",
    "text": "6.3 Update Joins Avanzados con Condiciones\n\n6.3.1 1. Update Join Condicional\n\n\n# Update join para marcar operaciones riesgosas\n# Crear tabla de límites de riesgo por ticker\nlimites_riesgo &lt;- data.table(\n  ticker = c(\"AAPL\", \"GOOGL\", \"MSFT\", \"TSLA\", \"AMZN\"),\n  precio_max_seguro = c(200, 3000, 400, 250, 150),\n  volumen_max_seguro = c(1000, 500, 800, 2000, 1200)\n)\n\n# Hacer copia para update join\noperaciones_riesgo &lt;- copy(operaciones_trading)\n\n# Update join condicional\noperaciones_riesgo[limites_riesgo, on = .(ticker),\n                  `:=`(\n                    precio_limite_riesgoso = i.precio_max_seguro &lt; precio_limite,\n                    volumen_riesgoso = i.volumen_max_seguro &lt; cantidad,\n                    limite_precio_ref = i.precio_max_seguro,\n                    limite_volumen_ref = i.volumen_max_seguro\n                  )]\n\n# Clasificar nivel de riesgo general\noperaciones_riesgo[, nivel_riesgo := fcase(\n  precio_limite_riesgoso & volumen_riesgoso, \"Alto Riesgo\",\n  precio_limite_riesgoso | volumen_riesgoso, \"Riesgo Moderado\",\n  default = \"Bajo Riesgo\"\n)]\n\n# Resumen de riesgos\nresumen_riesgos &lt;- operaciones_riesgo[, .N, by = .(ticker, nivel_riesgo)][order(ticker, nivel_riesgo)]\nprint(\"Distribución de riesgo por ticker:\")\n#&gt; [1] \"Distribución de riesgo por ticker:\"\nprint(resumen_riesgos)\n#&gt;     ticker    nivel_riesgo     N\n#&gt;     &lt;char&gt;          &lt;char&gt; &lt;int&gt;\n#&gt;  1:   AAPL     Bajo Riesgo     3\n#&gt;  2:   AAPL Riesgo Moderado    91\n#&gt;  3:   AMZN     Bajo Riesgo     1\n#&gt;  4:   AMZN Riesgo Moderado   105\n#&gt;  5:  GOOGL     Bajo Riesgo    83\n#&gt;  6:  GOOGL Riesgo Moderado    21\n#&gt;  7:   MSFT     Alto Riesgo    16\n#&gt;  8:   MSFT     Bajo Riesgo     9\n#&gt;  9:   MSFT Riesgo Moderado    74\n#&gt; 10:   TSLA     Bajo Riesgo     3\n#&gt; 11:   TSLA Riesgo Moderado    94\n\n\n6.3.2 2. Update Join con Agregaciones Complejas\n\n\n# Calcular estadísticas móviles y actualizar tabla principal\nestadisticas_ticker &lt;- operaciones_trading[,\n  .(\n    operaciones_historicas = .N,\n    precio_promedio_historico = round(mean(precio_limite), 2),\n    volumen_promedio_historico = round(mean(cantidad), 0),\n    precio_max_historico = max(precio_limite),\n    precio_min_historico = min(precio_limite),\n    ratio_compra_venta = round(mean(tipo == \"COMPRA\"), 2)\n  ), by = ticker]\n\n# Update join para agregar contexto histórico\noperaciones_riesgo[estadisticas_ticker, on = .(ticker),\n                  `:=`(\n                    percentil_precio = round((precio_limite - i.precio_min_historico) / \n                                           (i.precio_max_historico - i.precio_min_historico) * 100, 1),\n                    precio_vs_promedio = round(precio_limite / i.precio_promedio_historico, 2),\n                    volumen_vs_promedio = round(cantidad / i.volumen_promedio_historico, 2),\n                    operaciones_ticker_total = i.operaciones_historicas\n                  )]\n\nprint(\"Operaciones con contexto histórico:\")\n#&gt; [1] \"Operaciones con contexto histórico:\"\nprint(head(operaciones_riesgo[, .(ticker, precio_limite, percentil_precio, \n                                 precio_vs_promedio, volumen_vs_promedio, nivel_riesgo)], 10))\n#&gt;     ticker precio_limite percentil_precio precio_vs_promedio\n#&gt;     &lt;char&gt;         &lt;num&gt;            &lt;num&gt;              &lt;num&gt;\n#&gt;  1:   AAPL       2596.34             87.1               1.60\n#&gt;  2:   MSFT       2878.99             97.6               1.82\n#&gt;  3:   MSFT        264.94              5.7               0.17\n#&gt;  4:   AAPL       2745.92             92.4               1.69\n#&gt;  5:   AMZN       2631.01             87.5               1.66\n#&gt;  6:   TSLA       1407.00             45.3               0.92\n#&gt;  7:   AMZN       2465.81             81.7               1.56\n#&gt;  8:  GOOGL       1629.14             53.4               1.09\n#&gt;  9:  GOOGL        910.92             28.1               0.61\n#&gt; 10:   TSLA       2405.32             80.6               1.58\n#&gt;     volumen_vs_promedio    nivel_riesgo\n#&gt;                   &lt;num&gt;          &lt;char&gt;\n#&gt;  1:                2.34 Riesgo Moderado\n#&gt;  2:                0.14 Riesgo Moderado\n#&gt;  3:                0.14     Bajo Riesgo\n#&gt;  4:                2.34 Riesgo Moderado\n#&gt;  5:                0.12 Riesgo Moderado\n#&gt;  6:                0.29 Riesgo Moderado\n#&gt;  7:                0.25 Riesgo Moderado\n#&gt;  8:                2.70 Riesgo Moderado\n#&gt;  9:                0.27     Bajo Riesgo\n#&gt; 10:                0.15 Riesgo Moderado",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#casos-de-uso-complejos-combinando-técnicas",
    "href": "cap03-joins-avanzados.html#casos-de-uso-complejos-combinando-técnicas",
    "title": "\n6  Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.4 Casos de Uso Complejos: Combinando Técnicas",
    "text": "6.4 Casos de Uso Complejos: Combinando Técnicas\n\n6.4.1 1. Pipeline Completo: Finanzas\n\n\n# Pipeline complejo que combina non-equi y rolling joins\n# Paso a paso para facilitar el debugging\nstep1 &lt;- operaciones_trading[\n  # 1. Rolling join para obtener precios históricos\n  precios_historicos, on = .(ticker, fecha_operacion = fecha), roll = TRUE\n][\n  # 2. Filtrar solo operaciones con precio disponible\n  !is.na(precio_cierre)\n][\n  # 3. Calcular métricas de trading\n  , `:=`(\n    diferencia_precio = round(precio_limite - precio_cierre, 2),\n    ratio_precio = round(precio_limite / precio_cierre, 3),\n    valor_operacion = precio_limite * cantidad\n  )\n]\n\n# Verificar columnas antes del non-equi join\nprint(\"Columnas disponibles antes del non-equi join:\")\nprint(names(step1))\n\nstep2 &lt;- step1[\n  # 4. Non-equi join con eventos de mercado para ventanas temporales\n  eventos_mercado, \n  on = .(ticker = ticker_afectado,\n         fecha_operacion &gt;= fecha_inicio_ventana,\n         fecha_operacion &lt;= fecha_fin_ventana),\n  allow.cartesian = TRUE\n]\n\n# Verificar columnas después del non-equi join\nprint(\"Columnas disponibles después del non-equi join:\")\nprint(names(step2))\n\n# Determinar qué columna usar para ticker en la agrupación\nticker_col &lt;- if(\"ticker_afectado\" %in% names(step2)) \"ticker_afectado\" else \"ticker\"\n\n# 5. Agregar análisis por evento\nif(\"ticker_afectado\" %in% names(step2)) {\n  pipeline_financiero &lt;- step2[\n    , .(\n      operaciones_en_ventana = .N,\n      valor_total = sum(valor_operacion),\n      precio_promedio_limite = round(mean(precio_limite), 2),\n      precio_promedio_mercado = round(mean(precio_cierre), 2),\n      spread_promedio = round(mean(abs(diferencia_precio)), 2),\n      operaciones_compra = sum(tipo == \"COMPRA\"),\n      operaciones_venta = sum(tipo == \"VENTA\")\n    ), by = .(evento_id, tipo_evento, ticker_afectado, impacto_esperado)\n  ][\n    operaciones_en_ventana &gt;= 3  # Solo eventos con suficiente actividad\n  ][\n    order(-valor_total)\n  ]\n} else {\n  # Usar ticker en lugar de ticker_afectado\n  pipeline_financiero &lt;- step2[\n    , .(\n      operaciones_en_ventana = .N,\n      valor_total = sum(valor_operacion),\n      precio_promedio_limite = round(mean(precio_limite), 2),\n      precio_promedio_mercado = round(mean(precio_cierre), 2),\n      spread_promedio = round(mean(abs(diferencia_precio)), 2),\n      operaciones_compra = sum(tipo == \"COMPRA\"),\n      operaciones_venta = sum(tipo == \"VENTA\")\n    ), by = .(evento_id, tipo_evento, ticker, impacto_esperado)\n  ][\n    operaciones_en_ventana &gt;= 3  # Solo eventos con suficiente actividad\n  ][\n    order(-valor_total)\n  ]\n}\n\nprint(\"Análisis de trading en ventanas de eventos:\")\nprint(head(pipeline_financiero, 10))\n\n# # Crear tabla interactiva del análisis (comentado para PDF)\n# DT::datatable(\n#   pipeline_financiero,\n#   caption = \"Análisis de Trading en Ventanas de Eventos de Mercado\",\n#   options = list(pageLength = 8, scrollX = TRUE)\n# ) %&gt;%\n#   DT::formatCurrency(\"valor_total\", currency = \"$\") %&gt;%\n#   DT::formatRound(c(\"precio_promedio_limite\", \"precio_promedio_mercado\", \"spread_promedio\"), digits = 2)\n\n\n6.4.2 2. Pipeline Médico Avanzado\n\n\n# Pipeline médico combinando múltiples non-equi joins\nevaluacion_medica_completa &lt;- pacientes_clinica[\n  # Añadir columna de edad en décadas para agrupación\n  , decada := paste0(floor(edad/10)*10, \"s\")\n][\n  # 1. Clasificar por IMC\n  rangos_medicos[parametro == \"IMC\"], \n  on = .(imc &gt;= valor_min, imc &lt;= valor_max),\n  .(paciente_id, nombre, edad, decada, peso, altura, imc, \n    categoria_imc = categoria, riesgo_imc = nivel_riesgo,\n    glucosa, presion_sistolica, colesterol)\n][\n  # 2. Clasificar por glucosa  \n  rangos_medicos[parametro == \"Glucosa\"],\n  on = .(glucosa &gt;= valor_min, glucosa &lt;= valor_max),\n  .(paciente_id, nombre, edad, decada, peso, altura, imc, \n    categoria_imc, riesgo_imc, glucosa,\n    categoria_glucosa = i.categoria, riesgo_glucosa = i.nivel_riesgo,\n    presion_sistolica, colesterol)\n][\n  # 3. Clasificar por presión\n  rangos_medicos[parametro == \"Presión\"],\n  on = .(presion_sistolica &gt;= valor_min, presion_sistolica &lt;= valor_max),\n  .(paciente_id, nombre, edad, decada, peso, altura, imc,\n    categoria_imc, riesgo_imc, glucosa, categoria_glucosa, riesgo_glucosa,\n    presion_sistolica, categoria_presion = i.categoria, riesgo_presion = i.nivel_riesgo,\n    colesterol)\n][\n  # 4. Calcular score de riesgo compuesto\n  , `:=`(\n    factores_riesgo_alto = (riesgo_imc == \"Alto\") + (riesgo_glucosa == \"Alto\") + (riesgo_presion == \"Alto\"),\n    factores_riesgo_total = 3,\n    score_riesgo = (\n      (riesgo_imc == \"Alto\") * 3 + (riesgo_imc == \"Normal\") * 1 +\n      (riesgo_glucosa == \"Alto\") * 3 + (riesgo_glucosa == \"Normal\") * 1 +\n      (riesgo_presion == \"Alto\") * 3 + (riesgo_presion == \"Normal\") * 1\n    )\n  )\n][\n  # 5. Clasificación final de riesgo\n  , clasificacion_final := fcase(\n    factores_riesgo_alto &gt;= 2, \"Paciente Alto Riesgo - Seguimiento Inmediato\",\n    factores_riesgo_alto == 1, \"Paciente Riesgo Moderado - Seguimiento Regular\", \n    score_riesgo &gt;= 6, \"Paciente Bajo Riesgo - Seguimiento Rutinario\",\n    default = \"Paciente Muy Bajo Riesgo - Seguimiento Anual\"\n  )\n][\n  order(-score_riesgo)\n]\n\n# Resumen por grupo de edad\nresumen_por_decada &lt;- evaluacion_medica_completa[,\n  .(\n    pacientes = .N,\n    edad_promedio = round(mean(edad), 1),\n    imc_promedio = round(mean(imc), 1),\n    alto_riesgo = sum(factores_riesgo_alto &gt;= 2),\n    riesgo_moderado = sum(factores_riesgo_alto == 1),\n    bajo_riesgo = sum(factores_riesgo_alto == 0),\n    score_riesgo_promedio = round(mean(score_riesgo), 1)\n  ), by = decada][order(decada)]\n\nprint(\"Resumen de evaluación médica por década:\")\nprint(resumen_por_decada)\n\nprint(\"\\nPacientes de mayor riesgo:\")\nprint(head(evaluacion_medica_completa[factores_riesgo_alto &gt;= 2, \n                                     .(nombre, edad, factores_riesgo_alto, score_riesgo, clasificacion_final)], 8))",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#ejercicios-prácticos",
    "href": "cap03-joins-avanzados.html#ejercicios-prácticos",
    "title": "\n6  Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.5 Ejercicios Prácticos",
    "text": "6.5 Ejercicios Prácticos\n\n\n\n\n\n\n🏋️ Ejercicio 10: Sistema de Alertas de Trading\n\n\n\nUsando los datasets de precios y operaciones:\n\n\nRolling join para obtener precios en tiempo real\n\nNon-equi join para identificar operaciones en rangos de volatilidad alta\n\nUpdate join para calcular PnL potencial\n\nCrear sistema de alertas basado en múltiples condiciones\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 10\n\n\n\n\n\n\n# Sistema completo de alertas de trading\n# 1. Calcular volatilidad histórica\nvolatilidad_historica &lt;- precios_historicos[order(ticker, fecha)][,\n  .(fecha, volatilidad_10d = frollapply(precio_cierre, 10, sd, na.rm = TRUE)),\n  by = ticker][!is.na(volatilidad_10d)]\n\n# 2. Definir rangos de volatilidad para non-equi join\nrangos_volatilidad &lt;- data.table(\n  nivel = c(\"Baja\", \"Media\", \"Alta\", \"Extrema\"),\n  vol_min = c(0, 5, 15, 30),\n  vol_max = c(5, 15, 30, Inf),\n  factor_riesgo = c(1, 2, 3, 4)\n)\n\n# 3. Pipeline completo del sistema de alertas\nsistema_alertas &lt;- operaciones_trading[\n  # Rolling join con precios históricos\n  precios_historicos, on = .(ticker, fecha_operacion = fecha), roll = TRUE\n][\n  !is.na(precio_cierre)  # Solo operaciones con precio disponible\n][\n  # Rolling join con volatilidad\n  volatilidad_historica, on = .(ticker, fecha_operacion = fecha), roll = TRUE\n][\n  !is.na(volatilidad_10d)  # Solo con volatilidad calculada\n][\n  # Non-equi join para clasificar por volatilidad\n  rangos_volatilidad, on = .(volatilidad_10d &gt;= vol_min, volatilidad_10d &lt;= vol_max),\n  .(operacion_id, ticker, fecha_operacion, tipo, cantidad, precio_limite, precio_cierre,\n    volatilidad_10d, nivel_volatilidad = nivel, factor_riesgo)\n][\n  # 4. Calcular métricas de riesgo y PnL potencial\n  , `:=`(\n    diferencia_precio = precio_limite - precio_cierre,\n    pnl_potencial_pct = round((precio_limite - precio_cierre) / precio_cierre * 100, 2),\n    valor_operacion = precio_limite * cantidad,\n    riesgo_volatilidad = volatilidad_10d * factor_riesgo,\n    spread_pct = round(abs(precio_limite - precio_cierre) / precio_cierre * 100, 2)\n  )\n][\n  # 5. Sistema de alertas basado en múltiples condiciones\n  , alerta_tipo := fcase(\n    # Alerta crítica: alta volatilidad + spread alto + operación grande\n    nivel_volatilidad %in% c(\"Alta\", \"Extrema\") & spread_pct &gt; 5 & valor_operacion &gt; 100000,\n    \"CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\",\n    \n    # Alerta alta: precio muy diferente del mercado\n    abs(pnl_potencial_pct) &gt; 10 & valor_operacion &gt; 50000,\n    \"ALTA - Precio Fuera de Rango + Volumen Significativo\",\n    \n    # Alerta media: volatilidad alta\n    nivel_volatilidad %in% c(\"Alta\", \"Extrema\") & valor_operacion &gt; 25000,\n    \"MEDIA - Alta Volatilidad\",\n    \n    # Alerta baja: spread moderado\n    spread_pct &gt; 3 & valor_operacion &gt; 10000,\n    \"BAJA - Spread Moderado\",\n    \n    default = \"SIN ALERTA\"\n  )\n][\n  # 6. Filtrar solo operaciones con alertas\n  alerta_tipo != \"SIN ALERTA\"\n][\n  order(-riesgo_volatilidad, -valor_operacion)\n][\n  # 7. Agregar prioridad numérica para ordenamiento\n  , prioridad := fcase(\n    grepl(\"CRÍTICA\", alerta_tipo), 1,\n    grepl(\"ALTA\", alerta_tipo), 2, \n    grepl(\"MEDIA\", alerta_tipo), 3,\n    grepl(\"BAJA\", alerta_tipo), 4,\n    default = 5\n  )\n][\n  order(prioridad, -valor_operacion)\n]\n\n# Dashboard de alertas\ncat(\"🚨 SISTEMA DE ALERTAS DE TRADING 🚨\\n\\n\")\n#&gt; 🚨 SISTEMA DE ALERTAS DE TRADING 🚨\n\n# Resumen por tipo de alerta\nresumen_alertas &lt;- sistema_alertas[, .(\n  operaciones = .N,\n  valor_total = sum(valor_operacion),\n  volatilidad_promedio = round(mean(volatilidad_10d), 2),\n  spread_promedio = round(mean(spread_pct), 2)\n), by = .(alerta_tipo, prioridad)][order(prioridad)]\n\nprint(\"RESUMEN DE ALERTAS:\")\n#&gt; [1] \"RESUMEN DE ALERTAS:\"\nprint(resumen_alertas)\n#&gt;                                                alerta_tipo prioridad\n#&gt;                                                     &lt;char&gt;     &lt;num&gt;\n#&gt; 1: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto         1\n#&gt; 2:    ALTA - Precio Fuera de Rango + Volumen Significativo         2\n#&gt; 3:                                MEDIA - Alta Volatilidad         3\n#&gt; 4:                                  BAJA - Spread Moderado         4\n#&gt;    operaciones valor_total volatilidad_promedio spread_promedio\n#&gt;          &lt;int&gt;       &lt;num&gt;                &lt;num&gt;           &lt;num&gt;\n#&gt; 1:          61    41874580                16.23          319.11\n#&gt; 2:         197   100551879                 5.58          500.71\n#&gt; 3:          10      353714                15.00          116.39\n#&gt; 4:          59     7979808                 6.78          172.47\n\ncat(\"\\n📊 TOP 10 OPERACIONES DE MAYOR RIESGO:\\n\")\n#&gt; \n#&gt; 📊 TOP 10 OPERACIONES DE MAYOR RIESGO:\nprint(sistema_alertas[1:10, .(\n  Ticker = ticker, \n  Tipo = tipo,\n  Valor = paste0(\"$\", format(valor_operacion, big.mark = \",\")),\n  Spread = paste0(spread_pct, \"%\"),\n  Volatilidad = paste0(round(volatilidad_10d, 1)),\n  Alerta = alerta_tipo\n)])\n#&gt;     Ticker   Tipo      Valor  Spread Volatilidad\n#&gt;     &lt;char&gt; &lt;char&gt;     &lt;char&gt;  &lt;char&gt;      &lt;char&gt;\n#&gt;  1:   TSLA  VENTA $2,161,110 683.66%          15\n#&gt;  2:   TSLA  VENTA $2,161,110 680.32%          15\n#&gt;  3:   TSLA  VENTA $2,161,110 623.26%          15\n#&gt;  4:   TSLA  VENTA $2,161,110 518.59%          15\n#&gt;  5:   TSLA  VENTA $2,161,110 544.22%          15\n#&gt;  6:   TSLA  VENTA $2,161,110 514.93%          15\n#&gt;  7:  GOOGL COMPRA $1,463,000  47.18%          15\n#&gt;  8:  GOOGL COMPRA $1,463,000  46.66%          15\n#&gt;  9:  GOOGL COMPRA $1,463,000  47.21%          15\n#&gt; 10:   TSLA COMPRA $1,350,470  351.9%          15\n#&gt;                                                      Alerta\n#&gt;                                                      &lt;char&gt;\n#&gt;  1: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  2: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  3: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  4: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  5: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  6: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  7: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  8: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  9: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt; 10: CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n\n# # Crear tabla interactiva (comentado para PDF)\n# DT::datatable(\n#   sistema_alertas[1:20],\n#   caption = \"Sistema de Alertas de Trading - Top 20 Operaciones de Riesgo\",\n#   options = list(pageLength = 10, scrollX = TRUE)\n# ) %&gt;%\n#   DT::formatCurrency(\"valor_operacion\", currency = \"$\") %&gt;%\n#   DT::formatRound(c(\"volatilidad_10d\", \"spread_pct\"), digits = 2) %&gt;%\n#   DT::formatStyle(\n#     \"alerta_tipo\",\n#     backgroundColor = DT::styleEqual(\n#       c(\"CRÍTICA - Alta Volatilidad + Spread Alto + Volumen Alto\",\n#         \"ALTA - Precio Fuera de Rango + Volumen Significativo\", \n#         \"MEDIA - Alta Volatilidad\",\n#         \"BAJA - Spread Moderado\"),\n#       c(\"red\", \"orange\", \"yellow\", \"lightblue\")\n#     )\n#   )",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#mejores-prácticas-para-joins-avanzados",
    "href": "cap03-joins-avanzados.html#mejores-prácticas-para-joins-avanzados",
    "title": "\n6  Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.6 Mejores Prácticas para Joins Avanzados",
    "text": "6.6 Mejores Prácticas para Joins Avanzados\n\n6.6.1 1. Performance y Optimización\n\n\n# ✅ HACER: Establecer keys antes de rolling joins repetitivos\nsetkey(tabla_temporal, id, timestamp)\nsetkey(tabla_eventos, id, fecha_evento)\nresultado &lt;- tabla_temporal[tabla_eventos, roll = TRUE]\n\n# ✅ HACER: Filtrar antes de joins complejos\ntabla_filtrada &lt;- tabla_grande[fecha &gt;= fecha_inicio & fecha &lt;= fecha_fin]\nresultado &lt;- tabla_filtrada[otra_tabla, on = .(columna)]\n\n# ✅ HACER: Usar nomatch = NULL para inner joins en non-equi\nresultado &lt;- tabla1[tabla2, on = .(col1 &gt;= min_val, col1 &lt;= max_val), nomatch = NULL]\n\n# ❌ EVITAR: Non-equi joins sin filtros previos en tablas enormes\n# Puede generar productos cartesianos masivos\n\n\n6.6.2 2. Manejo de Casos Edge\n\n\n# ✅ HACER: Validar resultados de rolling joins\nresultado &lt;- tabla1[tabla2, roll = TRUE]\ncat(\"Matches encontrados:\", sum(!is.na(resultado$columna_tabla1)), \"\\n\")\ncat(\"Matches perdidos:\", sum(is.na(resultado$columna_tabla1)), \"\\n\")\n\n# ✅ HACER: Establecer límites razonables en rolling joins\nresultado &lt;- tabla1[tabla2, roll = 7]  # máximo 7 unidades de tiempo\n\n# ✅ HACER: Verificar cartesian products en non-equi joins\nif(nrow(resultado) &gt; nrow(tabla2) * 2) {\n  warning(\"Posible cartesian product no deseado\")\n}\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nNon-equi joins permiten uniones basadas en rangos y desigualdades - perfectos para clasificaciones médicas y financieras\n\nRolling joins son esenciales para series temporales - conectan cada punto con el último valor disponible\n\nCombinar técnicas (non-equi + rolling + update) permite análisis muy sofisticados\n\nPerformance: Establecer keys apropiadas es crucial para joins avanzados\n\nValidación: Siempre verificar resultados para evitar cartesian products no deseados\n\nCasos de uso reales: Finanzas, medicina, IoT - cualquier dominio con rangos temporales o de valores\n\n\n\nLos joins avanzados son herramientas poderosas que abren posibilidades analíticas únicas. En el próximo capítulo exploraremos las funciones especiales que complementan estos joins para análisis aún más sofisticados.\n[{“content”: “Reorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos”, “status”: “completed”, “id”: “1”}, {“content”: “Crear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1”, “status”: “completed”, “id”: “1-new”}, {“content”: “Reorganizar M0f3dulo 2: dividir en encadenamiento y joins”, “status”: “completed”, “id”: “2”}, {“content”: “Crear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3”, “status”: “completed”, “id”: “3-1”}, {“content”: “Crear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3”, “status”: “in_progress”, “id”: “3-2”}, {“content”: “Crear cap03-reshape.qmd para reshape del M0f3dulo 3”, “status”: “pending”, “id”: “3-3”}, {“content”: “Reorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas”, “status”: “pending”, “id”: “4”}, {“content”: “Reorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones”, “status”: “pending”, “id”: “5”}]",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html",
    "href": "cap03-funciones-especiales.html",
    "title": "\n7  Funciones Especiales y Análisis Temporal\n",
    "section": "",
    "text": "7.1 Funciones de Ventana (Window Functions)\nLas funciones de ventana permiten realizar cálculos sobre un conjunto de filas relacionadas con la fila actual, sin colapsar el resultado como lo harían las funciones de agregación.",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones Especiales y Análisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#funciones-de-ventana-window-functions",
    "href": "cap03-funciones-especiales.html#funciones-de-ventana-window-functions",
    "title": "\n7  Funciones Especiales y Análisis Temporal\n",
    "section": "",
    "text": "7.1.1 1. shift(): Valores Anteriores y Posteriores\n\n\n# Calcular cambios diarios en precios\nprecios_con_lag &lt;- precios_diarios[order(ticker, fecha)][,\n  `:=`(\n    precio_anterior = shift(precio_cierre, 1),          # t-1\n    precio_siguiente = shift(precio_cierre, -1),        # t+1\n    precio_3_dias_antes = shift(precio_cierre, 3),      # t-3\n    volumen_anterior = shift(volumen, 1)\n  ), by = ticker]\n\n# Calcular métricas de cambio\nprecios_con_lag[, `:=`(\n  cambio_diario = precio_cierre - precio_anterior,\n  cambio_pct = round((precio_cierre - precio_anterior) / precio_anterior * 100, 2),\n  volatilidad_3d = round(abs(precio_cierre - precio_3_dias_antes) / precio_3_dias_antes * 100, 2),\n  cambio_volumen = volumen - volumen_anterior\n)]\n\nprint(\"Análisis de cambios diarios:\")\n#&gt; [1] \"Análisis de cambios diarios:\"\nprint(head(precios_con_lag[!is.na(precio_anterior), \n                          .(ticker, fecha, precio_cierre, cambio_diario, cambio_pct, volatilidad_3d)], 10))\n#&gt;     ticker      fecha precio_cierre cambio_diario cambio_pct volatilidad_3d\n#&gt;     &lt;char&gt;     &lt;Date&gt;         &lt;num&gt;         &lt;num&gt;      &lt;num&gt;          &lt;num&gt;\n#&gt;  1:   AAPL 2024-01-02      183.4407     2.3071617       1.27             NA\n#&gt;  2:   AAPL 2024-01-03      181.4614    -1.9792962      -1.08             NA\n#&gt;  3:   AAPL 2024-01-04      182.1432     0.6817462       0.38           0.56\n#&gt;  4:   AAPL 2024-01-05      184.6943     2.5510975       1.40           0.68\n#&gt;  5:   AAPL 2024-01-06      187.7013     3.0069915       1.63           3.44\n#&gt;  6:   AAPL 2024-01-07      190.0722     2.3709305       1.26           4.35\n#&gt;  7:   AAPL 2024-01-08      188.8158    -1.2563592      -0.66           2.23\n#&gt;  8:   AAPL 2024-01-09      188.3688    -0.4470651      -0.24           0.36\n#&gt;  9:   AAPL 2024-01-10      185.8614    -2.5073326      -1.33           2.22\n#&gt; 10:   AAPL 2024-01-11      180.8085    -5.0529325      -2.72           4.24\n\n\n7.1.2 2. frollmean() y Medias Móviles\n\n\n# Múltiples medias móviles para análisis técnico\nprecios_ma &lt;- precios_diarios[order(ticker, fecha)][,\n  `:=`(\n    ma_5 = frollmean(precio_cierre, 5),           # Media móvil 5 días\n    ma_20 = frollmean(precio_cierre, 20),         # Media móvil 20 días\n    ma_50 = frollmean(precio_cierre, 50),         # Media móvil 50 días\n    volume_ma_10 = frollmean(volumen, 10),        # Media móvil volumen 10 días\n    volatilidad_20 = frollapply(precio_cierre, 20, sd, na.rm = TRUE)  # Volatilidad 20 días\n  ), by = ticker]\n\n# Señales técnicas basadas en cruces de medias móviles\nprecios_ma[!is.na(ma_50), `:=`(\n  señal_alcista = ma_5 &gt; ma_20 & ma_20 &gt; ma_50,\n  señal_bajista = ma_5 &lt; ma_20 & ma_20 &lt; ma_50,\n  precio_sobre_ma20 = precio_cierre &gt; ma_20,\n  volumen_alto = volumen &gt; volume_ma_10 * 1.5\n)]\n\n# Resumen de señales por ticker\nseñales_resumen &lt;- precios_ma[!is.na(señal_alcista), .(\n  dias_analizados = .N,\n  señales_alcistas = sum(señal_alcista, na.rm = TRUE),\n  señales_bajistas = sum(señal_bajista, na.rm = TRUE),\n  dias_sobre_ma20 = sum(precio_sobre_ma20, na.rm = TRUE),\n  volatilidad_promedio = round(mean(volatilidad_20, na.rm = TRUE), 2)\n), by = ticker]\n\nprint(\"Resumen de señales técnicas:\")\n#&gt; [1] \"Resumen de señales técnicas:\"\nprint(señales_resumen)\n#&gt;    ticker dias_analizados señales_alcistas señales_bajistas dias_sobre_ma20\n#&gt;    &lt;char&gt;           &lt;int&gt;            &lt;int&gt;            &lt;int&gt;           &lt;int&gt;\n#&gt; 1:   AAPL             133               80               19              93\n#&gt; 2:  GOOGL             133               63               19              81\n#&gt; 3:   MSFT             133               85               17              84\n#&gt; 4:   NVDA             133               34               41              77\n#&gt;    volatilidad_promedio\n#&gt;                   &lt;num&gt;\n#&gt; 1:                 3.67\n#&gt; 2:                15.24\n#&gt; 3:                 5.17\n#&gt; 4:                21.08\n\n\n7.1.3 3. frollapply(): Funciones Personalizadas\n\n\n# Funciones personalizadas para análisis de ventana\nprecios_estadisticas &lt;- precios_diarios[order(ticker, fecha)][,\n  `:=`(\n    rango_10d = frollapply(precio_cierre, 10, function(x) max(x) - min(x)),\n    percentil_75_20d = frollapply(precio_cierre, 20, function(x) quantile(x, 0.75, na.rm = TRUE)),\n    coef_variacion_15d = frollapply(precio_cierre, 15, function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)),\n    precio_z_score_30d = frollapply(precio_cierre, 30, function(x) {\n      if(length(x) &lt; 30) return(NA)\n      (tail(x, 1) - mean(x)) / sd(x)\n    }),\n    tendencia_5d = frollapply(precio_cierre, 5, function(x) {\n      if(length(x) &lt; 5) return(NA)\n      lm_result &lt;- lm(x ~ seq_along(x))\n      coef(lm_result)[2]  # Pendiente\n    })\n  ), by = ticker]\n\n# Análisis de distribuciones y outliers\nanalisis_outliers &lt;- precios_estadisticas[!is.na(precio_z_score_30d), .(\n  ticker,\n  fecha,\n  precio_cierre,\n  z_score = round(precio_z_score_30d, 2),\n  coef_var = round(coef_variacion_15d, 3),\n  tendencia = round(tendencia_5d, 4),\n  outlier_extremo = abs(precio_z_score_30d) &gt; 2\n)][outlier_extremo == TRUE][order(-abs(z_score))]\n\nprint(\"Precios con comportamiento outlier (|z-score| &gt; 2):\")\n#&gt; [1] \"Precios con comportamiento outlier (|z-score| &gt; 2):\"\nprint(head(analisis_outliers, 10))\n#&gt;     ticker      fecha precio_cierre z_score coef_var tendencia outlier_extremo\n#&gt;     &lt;char&gt;     &lt;Date&gt;         &lt;num&gt;   &lt;num&gt;    &lt;num&gt;     &lt;num&gt;          &lt;lgcl&gt;\n#&gt;  1:   MSFT 2024-05-20      457.1759    3.62    0.007    1.9420            TRUE\n#&gt;  2:   MSFT 2024-06-08      431.7858   -3.00    0.015   -2.5880            TRUE\n#&gt;  3:   MSFT 2024-03-08      433.9277    2.92    0.019    5.5208            TRUE\n#&gt;  4:   MSFT 2024-03-07      428.3405    2.76    0.014    2.8564            TRUE\n#&gt;  5:   MSFT 2024-06-09      430.4144   -2.72    0.017   -3.3287            TRUE\n#&gt;  6:   AAPL 2024-05-29      196.4133    2.65    0.027    2.5945            TRUE\n#&gt;  7:   MSFT 2024-04-14      445.9479    2.64    0.015    2.6979            TRUE\n#&gt;  8:  GOOGL 2024-02-19     2892.6715    2.61    0.005    6.6683            TRUE\n#&gt;  9:   AAPL 2024-06-26      214.5298    2.58    0.023    1.7983            TRUE\n#&gt; 10:   NVDA 2024-05-13      546.1066   -2.57    0.024   -1.1179            TRUE",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones Especiales y Análisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#funciones-condicionales-optimizadas",
    "href": "cap03-funciones-especiales.html#funciones-condicionales-optimizadas",
    "title": "\n7  Funciones Especiales y Análisis Temporal\n",
    "section": "\n7.2 Funciones Condicionales Optimizadas",
    "text": "7.2 Funciones Condicionales Optimizadas\n\n7.2.1 1. fifelse(): Condicionales Rápidas\n\n\n# Comparación de rendimiento: fifelse vs ifelse\nclientes_clasificacion &lt;- copy(clientes_retencion)\n\n# fifelse para clasificaciones múltiples y anidadas\nclientes_clasificacion[, `:=`(\n  segmento_edad = fifelse(\n    edad &lt; 25, \"Joven\",\n    fifelse(edad &lt; 45, \"Adulto\", \"Senior\")\n  ),\n  categoria_ingresos = fifelse(\n    ingresos_mensuales &lt; 2000, \"Bajos\",\n    fifelse(ingresos_mensuales &lt; 5000, \"Medios\", \"Altos\")\n  ),\n  tipo_cliente = fifelse(\n    plan == \"Empresarial\", \"Corporativo\",\n    fifelse(activo & ingresos_mensuales &gt; 3000, \"Premium_Activo\", \"Estándar\")\n  )\n)]\n\n# Análisis de segmentos\nsegmentos_analisis &lt;- clientes_clasificacion[, .(\n  clientes = .N,\n  ingresos_promedio = round(mean(ingresos_mensuales), 0),\n  tasa_actividad = round(mean(activo) * 100, 1),\n  planes_premium = sum(plan %in% c(\"Premium\", \"Empresarial\"))\n), by = .(segmento_edad, categoria_ingresos, tipo_cliente)]\n\nprint(\"Análisis de segmentos de clientes:\")\n#&gt; [1] \"Análisis de segmentos de clientes:\"\nprint(segmentos_analisis[order(-clientes)])\n#&gt;     segmento_edad categoria_ingresos   tipo_cliente clientes ingresos_promedio\n#&gt;            &lt;char&gt;             &lt;char&gt;         &lt;char&gt;    &lt;int&gt;             &lt;num&gt;\n#&gt;  1:        Senior              Altos Premium_Activo      191             13130\n#&gt;  2:        Adulto              Altos Premium_Activo      116             12750\n#&gt;  3:        Senior              Bajos       Estándar       96              1301\n#&gt;  4:        Senior             Medios Premium_Activo       74              3916\n#&gt;  5:        Senior             Medios       Estándar       72              2973\n#&gt; ---                                                                           \n#&gt; 20:         Joven              Altos       Estándar        9             12540\n#&gt; 21:         Joven              Altos    Corporativo        6             11067\n#&gt; 22:         Joven             Medios    Corporativo        4              3249\n#&gt; 23:        Adulto              Bajos    Corporativo        4              1292\n#&gt; 24:         Joven              Bajos    Corporativo        1              1952\n#&gt;     tasa_actividad planes_premium\n#&gt;              &lt;num&gt;          &lt;int&gt;\n#&gt;  1:          100.0             71\n#&gt;  2:          100.0             41\n#&gt;  3:           68.8             26\n#&gt;  4:          100.0             22\n#&gt;  5:           50.0             28\n#&gt; ---                              \n#&gt; 20:            0.0              0\n#&gt; 21:           33.3              6\n#&gt; 22:          100.0              4\n#&gt; 23:           75.0              4\n#&gt; 24:            0.0              1\n\n\n7.2.2 2. fcase(): Múltiples Condiciones Elegantes\n\n\n# Sistema de scoring complejo con fcase\nclientes_clasificacion[, score_retencion := fcase(\n  # Casos de alto valor\n  plan == \"Empresarial\" & activo & ingresos_mensuales &gt; 5000, 95,\n  plan == \"Premium\" & activo & ingresos_mensuales &gt; 3000, 85,\n  plan == \"Básico\" & activo & ingresos_mensuales &gt; 4000, 80,\n  \n  # Casos de riesgo medio\n  !activo & ingresos_mensuales &gt; 3000 & !is.na(fecha_ultima_actividad), 60,\n  activo & ingresos_mensuales &lt; 2000, 55,\n  \n  # Casos de alto riesgo\n  !activo & is.na(fecha_ultima_actividad), 20,\n  !activo & ingresos_mensuales &lt; 2000, 15,\n  \n  # Caso por defecto\n  default = 50\n)]\n\n# Estrategia de retención basada en score\nclientes_clasificacion[, estrategia_retencion := fcase(\n  score_retencion &gt;= 90, \"Mantener_Premium\",\n  score_retencion &gt;= 70, \"Fidelizar_Activo\", \n  score_retencion &gt;= 50, \"Reactivar_Moderado\",\n  score_retencion &gt;= 30, \"Reactivar_Intensivo\",\n  default = \"Evaluar_Cancelación\"\n)]\n\n# Resumen estratégico\nresumen_estrategia &lt;- clientes_clasificacion[, .(\n  clientes = .N,\n  score_promedio = round(mean(score_retencion), 1),\n  ingresos_totales = sum(ingresos_mensuales),\n  valor_cliente_promedio = round(mean(ingresos_mensuales), 0)\n), by = estrategia_retencion][order(-score_promedio)]\n\nprint(\"Estrategias de retención por score:\")\n#&gt; [1] \"Estrategias de retención por score:\"\nprint(resumen_estrategia)\n#&gt;    estrategia_retencion clientes score_promedio ingresos_totales\n#&gt;                  &lt;char&gt;    &lt;int&gt;          &lt;num&gt;            &lt;num&gt;\n#&gt; 1:     Mantener_Premium       21           95.0           243714\n#&gt; 2:     Fidelizar_Activo      430           82.0          5089950\n#&gt; 3:   Reactivar_Moderado      306           52.4           667565\n#&gt; 4:  Evaluar_Cancelación      243           20.0          1853637\n#&gt;    valor_cliente_promedio\n#&gt;                     &lt;num&gt;\n#&gt; 1:                  11605\n#&gt; 2:                  11837\n#&gt; 3:                   2182\n#&gt; 4:                   7628\n\n\n7.2.3 3. between(): Rangos Eficientes\n\n\n# Usar between para clasificaciones por rangos\ntransacciones_analisis &lt;- copy(transacciones_comportamiento)\n\ntransacciones_analisis[, `:=`(\n  # Clasificación por monto usando between\n  categoria_monto = fcase(\n    between(monto, 0, 20), \"Micro\",\n    between(monto, 20.01, 100), \"Pequeña\", \n    between(monto, 100.01, 500), \"Mediana\",\n    between(monto, 500.01, 2000), \"Grande\",\n    monto &gt; 2000, \"Muy Grande\",\n    default = \"Sin Clasificar\"\n  ),\n  \n  # Clasificación temporal\n  hora = hour(fecha_transaccion),\n  franja_horaria = fcase(\n    between(hour(fecha_transaccion), 6, 11), \"Mañana\",\n    between(hour(fecha_transaccion), 12, 17), \"Tarde\", \n    between(hour(fecha_transaccion), 18, 22), \"Noche\",\n    default = \"Madrugada\"\n  ),\n  \n  # Día de la semana\n  dia_semana = wday(fecha_transaccion, label = TRUE),\n  es_fin_semana = wday(fecha_transaccion) %in% c(1, 7)\n)]\n\n# Análisis de patrones de comportamiento\npatrones_comportamiento &lt;- transacciones_analisis[, .(\n  transacciones = .N,\n  monto_promedio = round(mean(monto), 2),\n  monto_mediana = round(median(monto), 2),\n  monto_total = round(sum(monto), 2)\n), by = .(categoria_monto, franja_horaria, es_fin_semana)][\n  order(-transacciones)\n]\n\nprint(\"Patrones de comportamiento transaccional:\")\n#&gt; [1] \"Patrones de comportamiento transaccional:\"\nprint(head(patrones_comportamiento, 12))\n#&gt;     categoria_monto franja_horaria es_fin_semana transacciones monto_promedio\n#&gt;              &lt;char&gt;         &lt;char&gt;        &lt;lgcl&gt;         &lt;int&gt;          &lt;num&gt;\n#&gt;  1:         Pequeña      Madrugada         FALSE           537          49.61\n#&gt;  2:         Pequeña          Tarde         FALSE           466          50.91\n#&gt;  3:         Pequeña         Mañana         FALSE           439          51.73\n#&gt;  4:         Pequeña          Noche         FALSE           362          50.49\n#&gt;  5:         Mediana      Madrugada         FALSE           308         199.17\n#&gt; ---                                                                          \n#&gt;  8:         Mediana         Mañana         FALSE           211         197.70\n#&gt;  9:           Micro      Madrugada         FALSE           204          11.42\n#&gt; 10:         Mediana          Noche         FALSE           202         200.49\n#&gt; 11:           Micro          Tarde         FALSE           187          11.64\n#&gt; 12:           Micro         Mañana         FALSE           181          11.72\n#&gt;     monto_mediana monto_total\n#&gt;             &lt;num&gt;       &lt;num&gt;\n#&gt;  1:         46.62    26642.18\n#&gt;  2:         45.80    23722.06\n#&gt;  3:         48.07    22711.20\n#&gt;  4:         46.15    18276.34\n#&gt;  5:        166.66    61345.74\n#&gt; ---                          \n#&gt;  8:        161.64    41715.23\n#&gt;  9:         11.62     2330.31\n#&gt; 10:        169.60    40499.76\n#&gt; 11:         11.99     2176.52\n#&gt; 12:         11.66     2121.67",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones Especiales y Análisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#funciones-de-agregación-especiales",
    "href": "cap03-funciones-especiales.html#funciones-de-agregación-especiales",
    "title": "\n7  Funciones Especiales y Análisis Temporal\n",
    "section": "\n7.3 Funciones de Agregación Especiales",
    "text": "7.3 Funciones de Agregación Especiales\n\n7.3.1 1. frank(): Rankings y Percentiles\n\n\n# Rankings complejos con frank()\nrankings_clientes &lt;- clientes_clasificacion[, `:=`(\n  # Ranking por ingresos (descendente)\n  rank_ingresos = frank(-ingresos_mensuales),\n  rank_ingresos_pct = frank(-ingresos_mensuales / .N * 100),\n  \n  # Ranking por score de retención\n  rank_retencion = frank(-score_retencion),\n  \n  # Ranking dentro de cada plan\n  rank_en_plan = frank(.SD[,-ingresos_mensuales, by = plan]),\n  rank_en_pais = frank(.SD[,-ingresos_mensuales, by = pais])\n)]\n\n# Top performers por categoría\ntop_performers &lt;- rankings_clientes[rank_ingresos &lt;= 50, .(\n  cliente_id, plan, pais, ingresos_mensuales, score_retencion,\n  rank_global = rank_ingresos,\n  rank_en_plan, rank_en_pais,\n  percentil_ingresos = round(100 - rank_ingresos_pct, 1)\n)][order(rank_global)]\n\nprint(\"Top 10 clientes por ingresos:\")\n#&gt; [1] \"Top 10 clientes por ingresos:\"\nprint(head(top_performers, 10))\n#&gt;     cliente_id    plan      pais ingresos_mensuales score_retencion rank_global\n#&gt;          &lt;int&gt;  &lt;char&gt;    &lt;char&gt;              &lt;num&gt;           &lt;num&gt;       &lt;num&gt;\n#&gt;  1:        780  Básico    España             114272              80           1\n#&gt;  2:        579  Básico    México             112313              20           2\n#&gt;  3:        862  Básico Argentina              93104              80           3\n#&gt;  4:        537 Premium    España              74834              20           4\n#&gt;  5:        204 Premium Argentina              66981              85           5\n#&gt;  6:        559 Premium Argentina              64783              85           6\n#&gt;  7:        370  Básico     Chile              63261              80           7\n#&gt;  8:        447 Premium    España              58316              85           8\n#&gt;  9:        220  Básico  Colombia              47912              80           9\n#&gt; 10:        522  Básico    México              44810              80          10\n#&gt;     rank_en_plan rank_en_pais percentil_ingresos\n#&gt;            &lt;num&gt;        &lt;num&gt;              &lt;num&gt;\n#&gt;  1:          270          797                 99\n#&gt;  2:          408          448                 98\n#&gt;  3:          430          401                 97\n#&gt;  4:          575          597                 96\n#&gt;  5:          833          159                 95\n#&gt;  6:          223          588                 94\n#&gt;  7:          500          198                 93\n#&gt;  8:          229          612                 92\n#&gt;  9:          979           80                 91\n#&gt; 10:           16          485                 90\n\n\n7.3.2 2. rleid(): Identificación de Runs\n\n\n# Identificar secuencias de comportamiento con rleid()\nsensores_runs &lt;- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(\n  # Clasificar temperatura en rangos\n  temp_categoria = fcase(\n    temperatura &lt; 18, \"Baja\",\n    between(temperatura, 18, 22), \"Normal\",\n    between(temperatura, 22, 26), \"Alta\",\n    temperatura &gt; 26, \"Muy Alta\",\n    default = \"Sin Datos\"\n  )\n)][, `:=`(\n  # Identificar runs (secuencias consecutivas)\n  run_id = rleid(temp_categoria),\n  # También podemos identificar runs de tendencia\n  tendencia = fcase(\n    temperatura &gt; shift(temperatura, 1), \"Subida\",\n    temperatura &lt; shift(temperatura, 1), \"Bajada\", \n    default = \"Estable\"\n  )\n), by = sensor_id][, `:=`(\n  run_tendencia = rleid(tendencia)\n), by = sensor_id]\n\n# Análisis de runs de temperatura\nanalisis_runs &lt;- sensores_runs[!is.na(temperatura), .(\n  duracion_run = .N,\n  temp_promedio = round(mean(temperatura, na.rm = TRUE), 1),\n  temp_min = round(min(temperatura, na.rm = TRUE), 1),\n  temp_max = round(max(temperatura, na.rm = TRUE), 1),\n  inicio_run = min(timestamp),\n  fin_run = max(timestamp)\n), by = .(sensor_id, temp_categoria, run_id)][\n  duracion_run &gt;= 4  # Solo runs de al menos 4 mediciones (1 hora)\n][order(sensor_id, -duracion_run)]\n\nprint(\"Runs de temperatura más largos:\")\n#&gt; [1] \"Runs de temperatura más largos:\"\nprint(head(analisis_runs, 12))\n#&gt;     sensor_id temp_categoria run_id duracion_run temp_promedio temp_min\n#&gt;        &lt;char&gt;         &lt;char&gt;  &lt;int&gt;        &lt;int&gt;         &lt;num&gt;    &lt;num&gt;\n#&gt;  1:    TEMP_A           Baja     82           31          15.8     13.4\n#&gt;  2:    TEMP_A           Baja    126           31          15.7     13.4\n#&gt;  3:    TEMP_A           Baja    144           31          15.8     13.2\n#&gt;  4:    TEMP_A           Alta    118           30          24.1     22.5\n#&gt;  5:    TEMP_A           Baja     20           28          15.9     13.5\n#&gt; ---                                                                    \n#&gt;  8:    TEMP_A           Alta    132           22          24.4     22.5\n#&gt;  9:    TEMP_A           Baja    106           21          15.5     13.2\n#&gt; 10:    TEMP_A           Alta     48           20          24.0     22.1\n#&gt; 11:    TEMP_A           Alta     94           19          24.2     22.3\n#&gt; 12:    TEMP_A           Alta     26           18          23.9     22.2\n#&gt;     temp_max          inicio_run             fin_run\n#&gt;        &lt;num&gt;              &lt;POSc&gt;              &lt;POSc&gt;\n#&gt;  1:     17.9 2024-06-04 14:30:00 2024-06-04 22:00:00\n#&gt;  2:     18.0 2024-06-06 14:15:00 2024-06-06 21:45:00\n#&gt;  3:     17.7 2024-06-07 14:00:00 2024-06-07 21:30:00\n#&gt;  4:     25.8 2024-06-06 02:30:00 2024-06-06 09:45:00\n#&gt;  5:     18.0 2024-06-01 15:15:00 2024-06-01 22:00:00\n#&gt; ---                                                 \n#&gt;  8:     26.0 2024-06-07 02:00:00 2024-06-07 07:15:00\n#&gt;  9:     17.3 2024-06-05 15:00:00 2024-06-05 20:00:00\n#&gt; 10:     25.5 2024-06-03 05:45:00 2024-06-03 10:30:00\n#&gt; 11:     26.0 2024-06-05 05:00:00 2024-06-05 09:30:00\n#&gt; 12:     25.7 2024-06-02 01:45:00 2024-06-02 06:00:00\n\n\n7.3.3 3. uniqueN(): Conteos de Únicos Eficientes\n\n\n# Análisis de diversidad con uniqueN()\ndiversidad_transacciones &lt;- transacciones_analisis[, .(\n  # Diversidad básica\n  transacciones_totales = .N,\n  categorias_usadas = uniqueN(categoria),\n  comercios_visitados = uniqueN(comercio_id),\n  metodos_pago_usados = uniqueN(metodo_pago),\n  \n  # Métricas de comportamiento\n  dias_activos = uniqueN(as.Date(fecha_transaccion)),\n  horas_activas = uniqueN(hour(fecha_transaccion)),\n  monto_promedio = round(mean(monto), 2),\n  \n  # Diversidad temporal\n  meses_activos = uniqueN(month(fecha_transaccion)),\n  dias_semana_activos = uniqueN(wday(fecha_transaccion))\n), by = cliente_id]\n\n# Calcular índices de diversidad\ndiversidad_transacciones[, `:=`(\n  indice_diversidad_categoria = round(categorias_usadas / 5 * 100, 1),  # 5 categorías posibles\n  indice_diversidad_temporal = round(horas_activas / 24 * 100, 1),      # 24 horas posibles\n  indice_actividad = round(dias_activos / 180 * 100, 1),                # ~180 días en periodo\n  score_engagement = round((categorias_usadas * 10) + (dias_activos * 2) + (comercios_visitados * 3), 0)\n)]\n\n# Clasificar clientes por engagement\ndiversidad_transacciones[, categoria_engagement := fcase(\n  score_engagement &gt; 200, \"Muy Alto\",\n  score_engagement &gt; 100, \"Alto\",\n  score_engagement &gt; 50, \"Medio\", \n  score_engagement &gt; 20, \"Bajo\",\n  default = \"Muy Bajo\"\n)]\n\n# Resumen por categoría de engagement\nresumen_engagement &lt;- diversidad_transacciones[, .(\n  clientes = .N,\n  transacciones_promedio = round(mean(transacciones_totales), 1),\n  diversidad_categoria_promedio = round(mean(indice_diversidad_categoria), 1),\n  score_promedio = round(mean(score_engagement), 0)\n), by = categoria_engagement][order(-score_promedio)]\n\nprint(\"Análisis de engagement de clientes:\")\n#&gt; [1] \"Análisis de engagement de clientes:\"\nprint(resumen_engagement)\n#&gt;    categoria_engagement clientes transacciones_promedio\n#&gt;                  &lt;char&gt;    &lt;int&gt;                  &lt;num&gt;\n#&gt; 1:                 Alto       10                   11.7\n#&gt; 2:                Medio      582                    6.3\n#&gt; 3:                 Bajo      352                    3.3\n#&gt; 4:             Muy Bajo       46                    1.3\n#&gt;    diversidad_categoria_promedio score_promedio\n#&gt;                            &lt;num&gt;          &lt;num&gt;\n#&gt; 1:                         100.0            107\n#&gt; 2:                          74.8             68\n#&gt; 3:                          48.0             40\n#&gt; 4:                          20.0             16",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones Especiales y Análisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#análisis-temporal-avanzado",
    "href": "cap03-funciones-especiales.html#análisis-temporal-avanzado",
    "title": "\n7  Funciones Especiales y Análisis Temporal\n",
    "section": "\n7.4 Análisis Temporal Avanzado",
    "text": "7.4 Análisis Temporal Avanzado\n\n7.4.1 1. Detección de Anomalías Temporales\n\n\n# Sistema de detección de anomalías para sensores\nanomalias_sensores &lt;- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(\n  # Medias móviles para diferentes ventanas\n  temp_ma_short = frollmean(temperatura, 4, na.rm = TRUE),    # 1 hora\n  temp_ma_long = frollmean(temperatura, 24, na.rm = TRUE),    # 6 horas\n  temp_sd_window = frollapply(temperatura, 12, sd, na.rm = TRUE), # Desviación móvil\n  \n  # Cambios absolutos\n  cambio_temp = abs(temperatura - shift(temperatura, 1)),\n  cambio_temp_2 = abs(temperatura - shift(temperatura, 2))\n), by = sensor_id][, `:=`(\n  # Detección de anomalías\n  anomalia_spike = cambio_temp &gt; 3,  # Cambio súbito &gt; 3 grados\n  anomalia_drift = !is.na(temp_ma_long) & abs(temperatura - temp_ma_long) &gt; 5, # Desviación &gt; 5 grados de media larga\n  anomalia_variabilidad = !is.na(temp_sd_window) & temp_sd_window &gt; 2 # Alta variabilidad\n  \n \n)]\n\n# Score compuesto de anomalía\nanomalias_sensores[, score_anomalia := (as.numeric(anomalia_spike) * 3) + \n                  (as.numeric(anomalia_drift) * 2) + \n                  (as.numeric(anomalia_variabilidad) * 1)]\n\n\n# Resumen de anomalías por sensor\nresumen_anomalias &lt;- anomalias_sensores[!is.na(temperatura), .(\n  lecturas_totales = .N,\n  anomalias_spike = sum(anomalia_spike, na.rm = TRUE),\n  anomalias_drift = sum(anomalia_drift, na.rm = TRUE),\n  anomalias_variabilidad = sum(anomalia_variabilidad, na.rm = TRUE),\n  score_promedio = round(mean(score_anomalia, na.rm = TRUE), 2),\n  temp_min = round(min(temperatura, na.rm = TRUE), 1),\n  temp_max = round(max(temperatura, na.rm = TRUE), 1)\n), by = .(sensor_id, ubicacion)]\n\nprint(\"Resumen de anomalías por sensor:\")\n#&gt; [1] \"Resumen de anomalías por sensor:\"\nprint(resumen_anomalias)\n#&gt;    sensor_id ubicacion lecturas_totales anomalias_spike anomalias_drift\n#&gt;       &lt;char&gt;    &lt;char&gt;            &lt;int&gt;           &lt;int&gt;           &lt;int&gt;\n#&gt; 1:    TEMP_A Almacén_A              672              19               8\n#&gt; 2:    TEMP_B Almacén_B              672              10               0\n#&gt; 3:    TEMP_C Almacén_C              672               0               0\n#&gt;    anomalias_variabilidad score_promedio temp_min temp_max\n#&gt;                     &lt;int&gt;          &lt;num&gt;    &lt;num&gt;    &lt;num&gt;\n#&gt; 1:                      1           0.11     13.2     27.2\n#&gt; 2:                      0           0.04     16.5     27.1\n#&gt; 3:                      0           0.00     15.9     38.8\n\n# Top anomalías individuales\ntop_anomalias &lt;- anomalias_sensores[score_anomalia &gt;= 2, .(\n  sensor_id, timestamp, temperatura, temp_ma_long, \n  cambio_temp, score_anomalia\n)][order(-score_anomalia)]\n\nif(nrow(top_anomalias) &gt; 0) {\n  print(\"\\nTop anomalías detectadas:\")\n  print(head(top_anomalias, 8))\n} else {\n  cat(\"\\nNo se detectaron anomalías significativas (score &gt;= 2)\\n\")\n}\n#&gt; [1] \"\\nTop anomalías detectadas:\"\n#&gt;    sensor_id           timestamp temperatura temp_ma_long cambio_temp\n#&gt;       &lt;char&gt;              &lt;POSc&gt;       &lt;num&gt;        &lt;num&gt;       &lt;num&gt;\n#&gt; 1:    TEMP_A 2024-06-01 15:30:00    13.50388     19.24389    3.124197\n#&gt; 2:    TEMP_A 2024-06-06 02:30:00    25.62026     19.74337    4.480706\n#&gt; 3:    TEMP_A 2024-06-07 15:00:00    13.46347     19.12156    3.591262\n#&gt; 4:    TEMP_A 2024-06-01 02:00:00    20.49440           NA    3.496907\n#&gt; 5:    TEMP_A 2024-06-01 05:00:00    26.15761           NA    3.017316\n#&gt; 6:    TEMP_A 2024-06-02 08:00:00    22.85221     24.44104    3.189825\n#&gt; 7:    TEMP_A 2024-06-02 17:15:00    17.92243     17.55434    3.547180\n#&gt; 8:    TEMP_A 2024-06-03 19:15:00    17.64803     16.20537    3.936311\n#&gt;    score_anomalia\n#&gt;             &lt;num&gt;\n#&gt; 1:              5\n#&gt; 2:              5\n#&gt; 3:              5\n#&gt; 4:              3\n#&gt; 5:              3\n#&gt; 6:              3\n#&gt; 7:              3\n#&gt; 8:              3\n\n\n7.4.2 2. Análisis de Ciclos y Estacionalidad\n\n\n# Análisis de patrones cíclicos en datos de sensores\npatrones_ciclicos &lt;- sensores_temperatura[!is.na(temperatura)][, `:=`(\n  hora = hour(timestamp),\n  dia = as.numeric(as.Date(timestamp) - min(as.Date(timestamp))) + 1,\n  minuto_del_dia = hour(timestamp) * 60 + minute(timestamp)\n)][, .(\n  temperatura_promedio = round(mean(temperatura), 1),\n  temperatura_sd = round(sd(temperatura), 2),\n  lecturas = .N\n), by = .(sensor_id, hora)]\n\n# Identificar patrones horarios\npatrones_resumen &lt;- patrones_ciclicos[, .(\n  hora_mas_fria = hora[which.min(temperatura_promedio)],\n  temp_mas_fria = min(temperatura_promedio),\n  hora_mas_calida = hora[which.max(temperatura_promedio)],\n  temp_mas_calida = max(temperatura_promedio),\n  amplitud_termica = round(max(temperatura_promedio) - min(temperatura_promedio), 1),\n  variabilidad_promedio = round(mean(temperatura_sd), 2)\n), by = sensor_id]\n\nprint(\"Patrones térmicos diarios por sensor:\")\n#&gt; [1] \"Patrones térmicos diarios por sensor:\"\nprint(patrones_resumen)\n#&gt;    sensor_id hora_mas_fria temp_mas_fria hora_mas_calida temp_mas_calida\n#&gt;       &lt;char&gt;         &lt;int&gt;         &lt;num&gt;           &lt;int&gt;           &lt;num&gt;\n#&gt; 1:    TEMP_A            17          15.1               5            25.0\n#&gt; 2:    TEMP_B            10          19.0              22            25.1\n#&gt; 3:    TEMP_C             4          23.3              21            26.1\n#&gt;    amplitud_termica variabilidad_promedio\n#&gt;               &lt;num&gt;                 &lt;num&gt;\n#&gt; 1:              9.9                  1.01\n#&gt; 2:              6.1                  0.84\n#&gt; 3:              2.8                  5.23",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones Especiales y Análisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#ejercicios-prácticos",
    "href": "cap03-funciones-especiales.html#ejercicios-prácticos",
    "title": "\n7  Funciones Especiales y Análisis Temporal\n",
    "section": "\n7.5 Ejercicios Prácticos",
    "text": "7.5 Ejercicios Prácticos\n\n\n\n\n\n\n🏋️ Ejercicio 11: Sistema de Alertas de Anomalías\n\n\n\nUsando los datasets de sensores y transacciones:\n\n\nImplementa un sistema de detección de anomalías multicapa\n\nUsa frollapply() para ventanas personalizadas de detección\n\nClasifica anomalías con fcase() por severidad\n\nGenera alertas automáticas con rleid() para secuencias anómalas\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 11\n\n\n\n\n\n\n# Sistema completo de detección de anomalías multicapa\n# CAPA 1: Anomalías estadísticas\nsistema_anomalias &lt;- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(\n  # Ventanas de referencia\n  temp_ma_1h = frollmean(temperatura, 4, na.rm = TRUE),\n  temp_ma_6h = frollmean(temperatura, 24, na.rm = TRUE), \n  temp_ma_24h = frollmean(temperatura, 96, na.rm = TRUE),\n  \n  # Medidas de variabilidad\n  temp_sd_1h = frollapply(temperatura, 4, sd, na.rm = TRUE),\n  temp_sd_6h = frollapply(temperatura, 24, sd, na.rm = TRUE),\n  \n  # Percentiles móviles\n  temp_p25_6h = frollapply(temperatura, 24, function(x) quantile(x, 0.25, na.rm = TRUE)),\n  temp_p75_6h = frollapply(temperatura, 24, function(x) quantile(x, 0.75, na.rm = TRUE)),\n  \n  # Cambios temporales\n  cambio_15min = abs(temperatura - shift(temperatura, 1)),\n  cambio_1h = abs(temperatura - shift(temperatura, 4)),\n  tendencia_1h = frollapply(temperatura, 4, function(x) {\n    if(length(x) &lt; 4) return(0)\n    lm(x ~ seq_along(x))$coefficients[2]\n  })\n), by = sensor_id][, `:=`(\n  # CAPA 2: Detección de anomalías específicas\n  anomalia_spike = cambio_15min &gt; 5,  # Cambio súbito &gt; 5°C\n  anomalia_drift = !is.na(temp_ma_6h) & abs(temperatura - temp_ma_6h) &gt; 4, # Drift &gt; 4°C\n  anomalia_variabilidad = !is.na(temp_sd_1h) & temp_sd_1h &gt; 3, # Alta variabilidad\n  anomalia_outlier = !is.na(temp_p25_6h) & !is.na(temp_p75_6h) & \n                    (temperatura &lt; (temp_p25_6h - 1.5*(temp_p75_6h - temp_p25_6h)) |\n                     temperatura &gt; (temp_p75_6h + 1.5*(temp_p75_6h - temp_p25_6h))),\n  anomalia_tendencia = !is.na(tendencia_1h) & abs(tendencia_1h) &gt; 1, # Tendencia &gt; 1°C/15min\n  anomalia_frozen = !is.na(temp_sd_1h) & temp_sd_1h &lt; 0.1 & !is.na(temperatura)  # Sensor \"congelado\"\n)]\n\n# CAPA 3: Clasificación por severidad con fcase()\nsistema_anomalias[, `:=`(\n  # Score compuesto\n  score_anomalia = (as.numeric(anomalia_spike) * 5) + \n                  (as.numeric(anomalia_drift) * 3) +\n                  (as.numeric(anomalia_variabilidad) * 2) +\n                  (as.numeric(anomalia_outlier) * 2) +\n                  (as.numeric(anomalia_tendencia) * 4) +\n                  (as.numeric(anomalia_frozen) * 6)\n)][, severidad := fcase(\n  score_anomalia &gt;= 10, \"CRÍTICA\",\n  score_anomalia &gt;= 6, \"ALTA\", \n  score_anomalia &gt;= 3, \"MEDIA\",\n  score_anomalia &gt;= 1, \"BAJA\",\n  default = \"NORMAL\"\n)]\n\n# CAPA 4: Detección de secuencias anómalas con rleid()\nsistema_anomalias[, `:=`(\n  es_anomalo = severidad != \"NORMAL\",\n  secuencia_id = rleid(severidad != \"NORMAL\")\n), by = sensor_id]\n\n# Análisis de secuencias anómalas\nsecuencias_anomalas &lt;- sistema_anomalias[es_anomalo == TRUE, .(\n  duracion_minutos = .N * 15,  # 15 min por medición\n  severidad_maxima = severidad[which.max(score_anomalia)],\n  score_maximo = max(score_anomalia),\n  score_promedio = round(mean(score_anomalia), 1),\n  temp_min = round(min(temperatura, na.rm = TRUE), 1),\n  temp_max = round(max(temperatura, na.rm = TRUE), 1),\n  inicio = min(timestamp),\n  fin = max(timestamp),\n  tipos_anomalia = paste(unique(c(\n    if(any(anomalia_spike)) \"SPIKE\",\n    if(any(anomalia_drift)) \"DRIFT\", \n    if(any(anomalia_variabilidad)) \"VARIABILIDAD\",\n    if(any(anomalia_outlier)) \"OUTLIER\",\n    if(any(anomalia_tendencia)) \"TENDENCIA\",\n    if(any(anomalia_frozen)) \"FROZEN\"\n  )), collapse = \", \")\n), by = .(sensor_id, secuencia_id)][\n  duracion_minutos &gt;= 30  # Solo secuencias de al menos 30 minutos\n][order(-score_maximo)]\n\n# SISTEMA DE ALERTAS AUTOMÁTICAS\ncat(\"🚨 SISTEMA DE ALERTAS DE ANOMALÍAS 🚨\\n\\n\")\n#&gt; 🚨 SISTEMA DE ALERTAS DE ANOMALÍAS 🚨\n\n# Alertas activas por sensor\nalertas_activas &lt;- sistema_anomalias[es_anomalo == TRUE, .N, by = .(sensor_id, severidad)][order(sensor_id, severidad)]\n\nif(nrow(alertas_activas) &gt; 0) {\n  cat(\"ALERTAS ACTIVAS POR SENSOR:\\n\")\n  print(alertas_activas)\n} else {\n  cat(\"✅ No hay alertas activas en este momento.\\n\")\n}\n#&gt; ALERTAS ACTIVAS POR SENSOR:\n#&gt;    sensor_id severidad     N\n#&gt;       &lt;char&gt;    &lt;char&gt; &lt;int&gt;\n#&gt; 1:    TEMP_A      ALTA    12\n#&gt; 2:    TEMP_A      BAJA    13\n#&gt; 3:    TEMP_A     MEDIA    66\n#&gt; 4:    TEMP_B      ALTA     5\n#&gt; 5:    TEMP_B      BAJA    17\n#&gt; 6:    TEMP_B     MEDIA     7\n#&gt; 7:    TEMP_C      ALTA     7\n#&gt; 8:    TEMP_C      BAJA    34\n\n# Top secuencias críticas\nif(nrow(secuencias_anomalas) &gt; 0) {\n  cat(\"\\n🔥 TOP SECUENCIAS ANÓMALAS:\\n\")\n  print(head(secuencias_anomalas[, .(sensor_id, severidad_maxima, duracion_minutos, \n                                    score_maximo, tipos_anomalia, inicio)], 8))\n} else {\n  cat(\"\\n✅ No se detectaron secuencias anómalas significativas.\\n\")\n}\n#&gt; \n#&gt; 🔥 TOP SECUENCIAS ANÓMALAS:\n#&gt;    sensor_id severidad_maxima duracion_minutos score_maximo\n#&gt;       &lt;char&gt;           &lt;char&gt;            &lt;num&gt;        &lt;num&gt;\n#&gt; 1:    TEMP_A             ALTA               30            9\n#&gt; 2:    TEMP_A             ALTA               30            7\n#&gt; 3:    TEMP_A             ALTA               45            7\n#&gt; 4:    TEMP_A             ALTA               30            6\n#&gt; 5:    TEMP_A             ALTA               30            6\n#&gt; 6:    TEMP_A             ALTA               30            6\n#&gt; 7:    TEMP_B             ALTA               30            6\n#&gt; 8:    TEMP_B             ALTA               30            6\n#&gt;               tipos_anomalia              inicio\n#&gt;                       &lt;char&gt;              &lt;POSc&gt;\n#&gt; 1: DRIFT, OUTLIER, TENDENCIA 2024-06-01 15:30:00\n#&gt; 2:          DRIFT, TENDENCIA 2024-06-04 11:15:00\n#&gt; 3:          DRIFT, TENDENCIA 2024-06-04 13:00:00\n#&gt; 4:        OUTLIER, TENDENCIA 2024-06-01 08:45:00\n#&gt; 5:        OUTLIER, TENDENCIA 2024-06-01 23:00:00\n#&gt; 6:        OUTLIER, TENDENCIA 2024-06-06 22:00:00\n#&gt; 7:        OUTLIER, TENDENCIA 2024-06-03 06:15:00\n#&gt; 8:             DRIFT, FROZEN 2024-06-07 20:00:00\n\n# Resumen estadístico\nresumen_sistema &lt;- sistema_anomalias[!is.na(temperatura), .(\n  lecturas_totales = .N,\n  anomalias_detectadas = sum(es_anomalo),\n  pct_anomalias = round(mean(es_anomalo) * 100, 2),\n  score_promedio = round(mean(score_anomalia), 2)\n), by = sensor_id]\n\ncat(\"\\n📊 RESUMEN DEL SISTEMA:\\n\")\n#&gt; \n#&gt; 📊 RESUMEN DEL SISTEMA:\nprint(resumen_sistema)\n#&gt;    sensor_id lecturas_totales anomalias_detectadas pct_anomalias score_promedio\n#&gt;       &lt;char&gt;            &lt;int&gt;                &lt;int&gt;         &lt;num&gt;          &lt;num&gt;\n#&gt; 1:    TEMP_A              672                   91         13.54             NA\n#&gt; 2:    TEMP_B              672                   29          4.32             NA\n#&gt; 3:    TEMP_C              672                   41          6.10             NA\n\n# # Crear tabla interactiva de secuencias críticas (comentado para PDF)\n# if(nrow(secuencias_anomalas) &gt; 0) {\n#   DT::datatable(\n#     secuencias_anomalas[1:min(20, nrow(secuencias_anomalas))],\n#     caption = \"Secuencias Anómalas Detectadas - Sistema Multicapa\",\n#     options = list(pageLength = 10, scrollX = TRUE)\n#   ) %&gt;%\n#     DT::formatStyle(\n#       \"severidad_maxima\",\n#       backgroundColor = DT::styleEqual(\n#         c(\"CRÍTICA\", \"ALTA\", \"MEDIA\", \"BAJA\"),\n#         c(\"red\", \"orange\", \"yellow\", \"lightblue\")\n#       )\n#     )\n# }\n\n\n\n\n\n\n\n\n\n\n🏋️ Ejercicio 12: Análisis de Supervivencia de Clientes\n\n\n\n\n\nCalcula métricas temporales con shift() y funciones de ventana\n\nIdentifica patrones de churn usando rleid() para secuencias de inactividad\n\nClasifica riesgo de abandono con fcase() múltiples criterios\n\nGenera score predictivo combinando múltiples señales\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 12\n\n\n\n\n\n\n# Análisis de supervivencia y predicción de churn\n# 1. Preparar datos temporales con métricas de ventana\nanalisis_supervivencia &lt;- clientes_retencion[, `:=`(\n  dias_desde_registro = as.numeric(as.Date(\"2024-06-30\") - fecha_registro),\n  dias_desde_ultima_actividad = fifelse(\n    is.na(fecha_ultima_actividad), \n    as.numeric(as.Date(\"2024-06-30\") - fecha_registro),\n    as.numeric(as.Date(\"2024-06-30\") - fecha_ultima_actividad)\n  )\n)]\n\n# Combinar con datos transaccionales para análisis de comportamiento\ncomportamiento_clientes &lt;- transacciones_comportamiento[, .(\n  transacciones_totales = .N,\n  gasto_total = sum(monto),\n  gasto_promedio = round(mean(monto), 2),\n  dias_activos = uniqueN(as.Date(fecha_transaccion)),\n  categorias_usadas = uniqueN(categoria),\n  ultima_transaccion = max(as.Date(fecha_transaccion)),\n  primera_transaccion = min(as.Date(fecha_transaccion))\n), by = cliente_id]\n\n# Join con datos de clientes\nsupervivencia_completa &lt;- analisis_supervivencia[\n  comportamiento_clientes, on = .(cliente_id), nomatch = NULL\n][, `:=`(\n  dias_desde_primera_trans = as.numeric(as.Date(\"2024-06-30\") - primera_transaccion),\n  dias_desde_ultima_trans = as.numeric(as.Date(\"2024-06-30\") - ultima_transaccion),\n  frecuencia_transaccional = round(transacciones_totales / dias_activos, 2)\n)]\n\n# 2. Identificar patrones de declive con funciones de ventana\n# Simular datos de actividad mensual para análisis temporal\nactividad_mensual &lt;- supervivencia_completa[, .(\n  cliente_id, activo, ingresos_mensuales, gasto_total, transacciones_totales\n)][, .(\n  cliente_id, \n  mes = rep(1:6, .N),\n  actividad_simulada = as.numeric(activo) * exp(-abs(rnorm(.N * 6, 0, 0.3))),\n  gasto_simulado = rep(gasto_total / 6, 6) * exp(rnorm(.N * 6, 0, 0.4))\n), by = cliente_id][order(cliente_id, mes)]\n\n# Aplicar funciones de ventana para detectar tendencias\nactividad_tendencias &lt;- actividad_mensual[, `:=`(\n  actividad_ma3 = frollmean(actividad_simulada, 3),\n  gasto_ma3 = frollmean(gasto_simulado, 3),\n  actividad_anterior = shift(actividad_simulada, 1),\n  gasto_anterior = shift(gasto_simulado, 1),\n  tendencia_actividad = actividad_simulada - shift(actividad_simulada, 1),\n  secuencia_declive = rleid(actividad_simulada &lt; shift(actividad_simulada, 1))\n), by = cliente_id]\n\n# 3. Análisis de riesgo de churn con múltiples criterios\nmodelo_churn &lt;- supervivencia_completa[, `:=`(\n  # Señales de riesgo temporal\n  riesgo_inactividad = fcase(\n    dias_desde_ultima_trans &gt; 90, \"ALTO\",\n    dias_desde_ultima_trans &gt; 60, \"MEDIO\",\n    dias_desde_ultima_trans &gt; 30, \"BAJO\",\n    default = \"MÍNIMO\"\n  ),\n  \n  # Señales de comportamiento\n  riesgo_engagement = fcase(\n    frecuencia_transaccional &lt; 0.1 & categorias_usadas &lt;= 2, \"ALTO\",\n    frecuencia_transaccional &lt; 0.3 & categorias_usadas &lt;= 3, \"MEDIO\", \n    frecuencia_transaccional &lt; 0.5, \"BAJO\",\n    default = \"MÍNIMO\"\n  ),\n  \n  # Señales económicas\n  riesgo_economico = fcase(\n    gasto_promedio &lt; ingresos_mensuales * 0.01, \"ALTO\",  # Gasta &lt;1% de ingresos\n    gasto_promedio &lt; ingresos_mensuales * 0.03, \"MEDIO\", # Gasta &lt;3% de ingresos\n    gasto_promedio &lt; ingresos_mensuales * 0.05, \"BAJO\",  # Gasta &lt;5% de ingresos\n    default = \"MÍNIMO\"\n  ),\n  \n  # Señal de valor del cliente\n  valor_cliente = round((gasto_total / dias_activos) * (ingresos_mensuales / 1000), 0)\n)][, `:=`(\n  # Score compuesto de riesgo de churn\n  score_churn = (\n    (riesgo_inactividad == \"ALTO\") * 40 + (riesgo_inactividad == \"MEDIO\") * 25 + (riesgo_inactividad == \"BAJO\") * 10 +\n    (riesgo_engagement == \"ALTO\") * 30 + (riesgo_engagement == \"MEDIO\") * 20 + (riesgo_engagement == \"BAJO\") * 10 +\n    (riesgo_economico == \"ALTO\") * 20 + (riesgo_economico == \"MEDIO\") * 12 + (riesgo_economico == \"BAJO\") * 5 +\n    ifelse(!activo, 25, 0)  # Penalización por inactividad actual\n  )\n)][, `:=`(\n  # 4. Clasificación final y estrategia\n  clasificacion_churn = fcase(\n    score_churn &gt;= 80, \"CHURN_INMEDIATO\",\n    score_churn &gt;= 60, \"ALTO_RIESGO\", \n    score_churn &gt;= 40, \"RIESGO_MODERADO\",\n    score_churn &gt;= 20, \"BAJO_RIESGO\",\n    default = \"SALUDABLE\"\n  ),\n  \n  estrategia_retencion = fcase(\n    score_churn &gt;= 80, \"Contacto_Inmediato + Oferta_Especial\",\n    score_churn &gt;= 60, \"Programa_Reactivación + Descuentos\",\n    score_churn &gt;= 40, \"Comunicación_Personalizada\", \n    score_churn &gt;= 20, \"Monitoreo_Activo\",\n    default = \"Mantenimiento_Rutinario\"\n  )\n)]\n\n# Análisis de resultados\ncat(\"📈 ANÁLISIS DE SUPERVIVENCIA DE CLIENTES 📈\\n\\n\")\n#&gt; 📈 ANÁLISIS DE SUPERVIVENCIA DE CLIENTES 📈\n\n# Distribución por clasificación\ndistribucion_churn &lt;- modelo_churn[, .N, by = clasificacion_churn][order(-N)]\ncat(\"DISTRIBUCIÓN POR RIESGO DE CHURN:\\n\")\n#&gt; DISTRIBUCIÓN POR RIESGO DE CHURN:\nprint(distribucion_churn)\n#&gt;    clasificacion_churn     N\n#&gt;                 &lt;char&gt; &lt;int&gt;\n#&gt; 1:         BAJO_RIESGO   429\n#&gt; 2:           SALUDABLE   357\n#&gt; 3:     RIESGO_MODERADO   154\n#&gt; 4:         ALTO_RIESGO    43\n#&gt; 5:     CHURN_INMEDIATO     7\n\n# Estadísticas por grupo de riesgo\nstats_por_riesgo &lt;- modelo_churn[, .(\n  clientes = .N,\n  score_promedio = round(mean(score_churn), 1),\n  ingresos_promedio = round(mean(ingresos_mensuales), 0),\n  valor_cliente_promedio = round(mean(valor_cliente), 0),\n  dias_inactividad_promedio = round(mean(dias_desde_ultima_trans), 0),\n  tasa_actividad_actual = round(mean(activo) * 100, 1)\n), by = clasificacion_churn][order(-score_promedio)]\n\ncat(\"\\n📊 ESTADÍSTICAS POR GRUPO DE RIESGO:\\n\")\n#&gt; \n#&gt; 📊 ESTADÍSTICAS POR GRUPO DE RIESGO:\nprint(stats_por_riesgo)\n#&gt;    clasificacion_churn clientes score_promedio ingresos_promedio\n#&gt;                 &lt;char&gt;    &lt;int&gt;          &lt;num&gt;             &lt;num&gt;\n#&gt; 1:     CHURN_INMEDIATO        7           85.0             18915\n#&gt; 2:         ALTO_RIESGO       43           64.4              9790\n#&gt; 3:     RIESGO_MODERADO      154           46.8             11013\n#&gt; 4:         BAJO_RIESGO      429           26.6              9481\n#&gt; 5:           SALUDABLE      357            8.2              4040\n#&gt;    valor_cliente_promedio dias_inactividad_promedio tasa_actividad_actual\n#&gt;                     &lt;num&gt;                     &lt;num&gt;                 &lt;num&gt;\n#&gt; 1:                    645                       127                   0.0\n#&gt; 2:                   1094                       103                  48.8\n#&gt; 3:                    991                        58                  40.3\n#&gt; 4:                    955                        30                  71.8\n#&gt; 5:                    576                        18                 100.0\n\n# Clientes críticos que requieren atención inmediata\nclientes_criticos &lt;- modelo_churn[clasificacion_churn %in% c(\"CHURN_INMEDIATO\", \"ALTO_RIESGO\"), .(\n  cliente_id, plan, pais, ingresos_mensuales, valor_cliente, \n  score_churn, clasificacion_churn, estrategia_retencion,\n  dias_inactividad = dias_desde_ultima_trans\n)][order(-score_churn)]\n\ncat(\"\\n🚨 CLIENTES QUE REQUIEREN ATENCIÓN INMEDIATA:\\n\")\n#&gt; \n#&gt; 🚨 CLIENTES QUE REQUIEREN ATENCIÓN INMEDIATA:\nprint(head(clientes_criticos, 10))\n#&gt;     cliente_id        plan      pais ingresos_mensuales valor_cliente\n#&gt;          &lt;int&gt;      &lt;char&gt;    &lt;char&gt;              &lt;num&gt;         &lt;num&gt;\n#&gt;  1:        717     Premium Argentina              28491           180\n#&gt;  2:        677 Empresarial  Colombia               8912           276\n#&gt;  3:        368      Básico  Colombia               4248           167\n#&gt;  4:        474      Básico     Chile               4957           178\n#&gt;  5:        351      Básico     Chile               2693            18\n#&gt;  6:        205      Básico    España               8272           684\n#&gt;  7:        537     Premium    España              74834          3011\n#&gt;  8:        488     Premium    México               4999           453\n#&gt;  9:         31      Básico    España               4424           258\n#&gt; 10:        905      Básico     Chile               2805            91\n#&gt;     score_churn clasificacion_churn                 estrategia_retencion\n#&gt;           &lt;num&gt;              &lt;char&gt;                               &lt;char&gt;\n#&gt;  1:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  2:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  3:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  4:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  5:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  6:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  7:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  8:          77         ALTO_RIESGO   Programa_Reactivación + Descuentos\n#&gt;  9:          77         ALTO_RIESGO   Programa_Reactivación + Descuentos\n#&gt; 10:          77         ALTO_RIESGO   Programa_Reactivación + Descuentos\n#&gt;     dias_inactividad\n#&gt;                &lt;num&gt;\n#&gt;  1:              105\n#&gt;  2:              144\n#&gt;  3:              129\n#&gt;  4:               92\n#&gt;  5:              156\n#&gt;  6:              146\n#&gt;  7:              117\n#&gt;  8:               91\n#&gt;  9:               95\n#&gt; 10:              118\n\n# ROI potencial de estrategias de retención\nroi_estrategias &lt;- modelo_churn[, .(\n  clientes_objetivo = .N,\n  valor_total_riesgo = sum(valor_cliente),\n  valor_promedio_cliente = round(mean(valor_cliente), 0),\n  inversion_retencion_estimada = .N * fcase(\n    unique(clasificacion_churn) == \"CHURN_INMEDIATO\", 200,\n    unique(clasificacion_churn) == \"ALTO_RIESGO\", 100,\n    unique(clasificacion_churn) == \"RIESGO_MODERADO\", 50,\n    default = 20\n  ),\n  roi_potencial = round((sum(valor_cliente) * 0.7) / (.N * fcase(\n    unique(clasificacion_churn) == \"CHURN_INMEDIATO\", 200,\n    unique(clasificacion_churn) == \"ALTO_RIESGO\", 100, \n    unique(clasificacion_churn) == \"RIESGO_MODERADO\", 50,\n    default = 20\n  )), 1)\n), by = .(clasificacion_churn, estrategia_retencion)][order(-roi_potencial)]\n\ncat(\"\\n💰 ANÁLISIS DE ROI DE ESTRATEGIAS:\\n\")\n#&gt; \n#&gt; 💰 ANÁLISIS DE ROI DE ESTRATEGIAS:\nprint(roi_estrategias)\n#&gt;    clasificacion_churn                 estrategia_retencion clientes_objetivo\n#&gt;                 &lt;char&gt;                               &lt;char&gt;             &lt;int&gt;\n#&gt; 1:         BAJO_RIESGO                     Monitoreo_Activo               429\n#&gt; 2:           SALUDABLE              Mantenimiento_Rutinario               357\n#&gt; 3:     RIESGO_MODERADO           Comunicación_Personalizada               154\n#&gt; 4:         ALTO_RIESGO   Programa_Reactivación + Descuentos                43\n#&gt; 5:     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial                 7\n#&gt;    valor_total_riesgo valor_promedio_cliente inversion_retencion_estimada\n#&gt;                 &lt;num&gt;                  &lt;num&gt;                        &lt;num&gt;\n#&gt; 1:             409510                    955                         8580\n#&gt; 2:             205785                    576                         7140\n#&gt; 3:             152686                    991                         7700\n#&gt; 4:              47050                   1094                         4300\n#&gt; 5:               4514                    645                         1400\n#&gt;    roi_potencial\n#&gt;            &lt;num&gt;\n#&gt; 1:          33.4\n#&gt; 2:          20.2\n#&gt; 3:          13.9\n#&gt; 4:           7.7\n#&gt; 5:           2.3\n\n\n\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nFunciones de ventana (shift, frollmean, frollapply) permiten análisis temporal sofisticado sin colapsar datos\n\nFunciones condicionales (fifelse, fcase, between) optimizan clasificaciones complejas\n\nFunciones de agregación especiales (frank, rleid, uniqueN) revelan patrones ocultos en los datos\n\nAnálisis temporal combina múltiples técnicas para detección de anomalías y predicción\n\nPerformance: Estas funciones están altamente optimizadas y son significativamente más rápidas que alternativas de R base\n\nCasos de uso reales: Finanzas, IoT, análisis de comportamiento - las aplicaciones son ilimitadas\n\n\n\nLas funciones especiales de data.table te dan superpoderes para análisis complejos. En el próximo capítulo exploraremos las técnicas de reshape que complementan perfectamente estas funciones para transformaciones de datos avanzadas.\n[{“content”: “Reorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos”, “status”: “completed”, “id”: “1”}, {“content”: “Crear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1”, “status”: “completed”, “id”: “1-new”}, {“content”: “Reorganizar M0f3dulo 2: dividir en encadenamiento y joins”, “status”: “completed”, “id”: “2”}, {“content”: “Crear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3”, “status”: “completed”, “id”: “3-1”}, {“content”: “Crear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3”, “status”: “completed”, “id”: “3-2”}, {“content”: “Crear cap03-reshape.qmd para reshape del M0f3dulo 3”, “status”: “in_progress”, “id”: “3-3”}, {“content”: “Reorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas”, “status”: “pending”, “id”: “4”}, {“content”: “Reorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones”, “status”: “pending”, “id”: “5”}]",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Funciones Especiales y Análisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html",
    "href": "cap03-reshape.html",
    "title": "\n8  Remodelación de Datos: melt() y dcast()\n",
    "section": "",
    "text": "8.1 Conceptos Fundamentales: Wide vs Long\nAntes de explorar melt() y dcast(), es crucial entender cuándo y por qué transformar estructuras de datos:\n# Ejemplo simple: formato wide\ndatos_wide_ejemplo &lt;- data.table(\n  estudiante = c(\"Ana\", \"Juan\", \"María\"),\n  matematicas = c(85, 90, 78),\n  ciencias = c(88, 85, 92),\n  historia = c(82, 88, 89)\n)\n\nprint(\"Formato WIDE (típico de Excel):\")\n#&gt; [1] \"Formato WIDE (típico de Excel):\"\nprint(datos_wide_ejemplo)\n#&gt;    estudiante matematicas ciencias historia\n#&gt;        &lt;char&gt;       &lt;num&gt;    &lt;num&gt;    &lt;num&gt;\n#&gt; 1:        Ana          85       88       82\n#&gt; 2:       Juan          90       85       88\n#&gt; 3:      María          78       92       89\n\n# Convertir a formato long\ndatos_long_ejemplo &lt;- melt(datos_wide_ejemplo, \n                          id.vars = \"estudiante\",\n                          variable.name = \"materia\", \n                          value.name = \"calificacion\")\n\nprint(\"\\nFormato LONG (ideal para análisis):\")\n#&gt; [1] \"\\nFormato LONG (ideal para análisis):\"\nprint(datos_long_ejemplo)\n#&gt;    estudiante     materia calificacion\n#&gt;        &lt;char&gt;      &lt;fctr&gt;        &lt;num&gt;\n#&gt; 1:        Ana matematicas           85\n#&gt; 2:       Juan matematicas           90\n#&gt; 3:      María matematicas           78\n#&gt; 4:        Ana    ciencias           88\n#&gt; 5:       Juan    ciencias           85\n#&gt; 6:      María    ciencias           92\n#&gt; 7:        Ana    historia           82\n#&gt; 8:       Juan    historia           88\n#&gt; 9:      María    historia           89",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Remodelación de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#conceptos-fundamentales-wide-vs-long",
    "href": "cap03-reshape.html#conceptos-fundamentales-wide-vs-long",
    "title": "\n8  Remodelación de Datos: melt() y dcast()\n",
    "section": "",
    "text": "Formato Wide (ancho): Cada variable tiene su propia columna. Fácil de leer pero difícil de analizar estadísticamente.\n\nFormato Long (largo): Las observaciones se “apilan” en filas. Ideal para análisis estadístico y visualización.",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Remodelación de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#melt-de-ancho-a-largo",
    "href": "cap03-reshape.html#melt-de-ancho-a-largo",
    "title": "\n8  Remodelación de Datos: melt() y dcast()\n",
    "section": "\n8.2 melt(): De Ancho a Largo",
    "text": "8.2 melt(): De Ancho a Largo\n\n8.2.1 1. melt() Básico\n\n\n# Transformar datos de ventas trimestrales\nventas_long &lt;- melt(ventas_trimestral_wide,\n                   id.vars = c(\"producto\", \"categoria\", \"precio_unitario\"),\n                   variable.name = \"periodo_metrica\", \n                   value.name = \"valor\")\n\nprint(\"Datos transformados a formato largo:\")\n#&gt; [1] \"Datos transformados a formato largo:\"\nprint(head(ventas_long, 12))\n#&gt;       producto    categoria precio_unitario  periodo_metrica  valor\n#&gt;         &lt;char&gt;       &lt;char&gt;           &lt;num&gt;           &lt;fctr&gt;  &lt;num&gt;\n#&gt;  1:     Laptop Computadoras            1200 Q1_2023_unidades    150\n#&gt;  2:    Desktop Computadoras             800 Q1_2023_unidades     80\n#&gt;  3:     Tablet Computadoras             400 Q1_2023_unidades    200\n#&gt;  4: Smartphone      Móviles             600 Q1_2023_unidades    300\n#&gt;  5:    Monitor  Periféricos             300 Q1_2023_unidades    120\n#&gt; ---                                                                \n#&gt;  8:  Impresora      Oficina             200 Q1_2023_unidades     60\n#&gt;  9:     Router        Redes             150 Q1_2023_unidades     90\n#&gt; 10:     Cámara   Multimedia             250 Q1_2023_unidades     70\n#&gt; 11:     Laptop Computadoras            1200  Q1_2023_revenue 180000\n#&gt; 12:    Desktop Computadoras             800  Q1_2023_revenue  64000\n\n# Ver la estructura completa\ncat(\"Dimensiones originales:\", dim(ventas_trimestral_wide), \"\\n\")\n#&gt; Dimensiones originales: 10 13\ncat(\"Dimensiones después de melt:\", dim(ventas_long), \"\\n\")\n#&gt; Dimensiones después de melt: 100 5\n\n\n8.2.2 2. Separar Variables Complejas\n\n\n# Separar periodo y métrica de la variable compuesta\nventas_long_separada &lt;- ventas_long[, `:=`(\n  periodo = sub(\"_unidades|_revenue\", \"\", periodo_metrica),\n  metrica = ifelse(grepl(\"unidades\", periodo_metrica), \"unidades\", \"revenue\")\n)]\n\nprint(\"Datos con variables separadas:\")\n#&gt; [1] \"Datos con variables separadas:\"\nprint(head(ventas_long_separada, 12))\n#&gt;       producto    categoria precio_unitario  periodo_metrica  valor periodo\n#&gt;         &lt;char&gt;       &lt;char&gt;           &lt;num&gt;           &lt;fctr&gt;  &lt;num&gt;  &lt;char&gt;\n#&gt;  1:     Laptop Computadoras            1200 Q1_2023_unidades    150 Q1_2023\n#&gt;  2:    Desktop Computadoras             800 Q1_2023_unidades     80 Q1_2023\n#&gt;  3:     Tablet Computadoras             400 Q1_2023_unidades    200 Q1_2023\n#&gt;  4: Smartphone      Móviles             600 Q1_2023_unidades    300 Q1_2023\n#&gt;  5:    Monitor  Periféricos             300 Q1_2023_unidades    120 Q1_2023\n#&gt; ---                                                                        \n#&gt;  8:  Impresora      Oficina             200 Q1_2023_unidades     60 Q1_2023\n#&gt;  9:     Router        Redes             150 Q1_2023_unidades     90 Q1_2023\n#&gt; 10:     Cámara   Multimedia             250 Q1_2023_unidades     70 Q1_2023\n#&gt; 11:     Laptop Computadoras            1200  Q1_2023_revenue 180000 Q1_2023\n#&gt; 12:    Desktop Computadoras             800  Q1_2023_revenue  64000 Q1_2023\n#&gt;      metrica\n#&gt;       &lt;char&gt;\n#&gt;  1: unidades\n#&gt;  2: unidades\n#&gt;  3: unidades\n#&gt;  4: unidades\n#&gt;  5: unidades\n#&gt; ---         \n#&gt;  8: unidades\n#&gt;  9: unidades\n#&gt; 10: unidades\n#&gt; 11:  revenue\n#&gt; 12:  revenue\n\n# Limpiar columna temporal\nventas_long_separada[, periodo_metrica := NULL]\n\n\n8.2.3 3. melt() con Patrones\n\n\n# Melt usando patrones para múltiples tipos de variables\nempleados_long &lt;- melt(empleados_metricas,\n                      id.vars = c(\"empleado_id\", \"nombre\", \"departamento\", \"nivel\", \"salario_base\"),\n                      measure = patterns(\n                        bonus = \"^bonus_\",\n                        evaluacion = \"^evaluacion_\", \n                        proyectos = \"^proyectos_\"\n                      ),\n                      variable.name = \"trimestre\",\n                      value.name = c(\"bonus\", \"evaluacion\", \"proyectos\"))\n\n# Limpiar nombres de trimestre\nempleados_long[, trimestre := paste0(\"Q\", trimestre)]\n\nprint(\"Empleados con múltiples métricas en formato largo:\")\n#&gt; [1] \"Empleados con múltiples métricas en formato largo:\"\nprint(head(empleados_long, 12))\n#&gt;     empleado_id     nombre departamento   nivel salario_base trimestre bonus\n#&gt;          &lt;char&gt;     &lt;char&gt;       &lt;char&gt;  &lt;char&gt;        &lt;num&gt;    &lt;char&gt; &lt;num&gt;\n#&gt;  1:     EMP_001 Empleado_A       Ventas  Junior        72700        Q1   378\n#&gt;  2:     EMP_002 Empleado_B       Ventas  Senior        49400        Q1   896\n#&gt;  3:     EMP_003 Empleado_C       Ventas    Lead        65600        Q1  5443\n#&gt;  4:     EMP_004 Empleado_D       Ventas Manager        66400        Q1  6800\n#&gt;  5:     EMP_005 Empleado_E       Ventas  Junior        55600        Q1  6379\n#&gt; ---                                                                         \n#&gt;  8:     EMP_008 Empleado_H           IT Manager        48600        Q1  6525\n#&gt;  9:     EMP_009 Empleado_I           IT  Junior        74400        Q1     4\n#&gt; 10:     EMP_010 Empleado_J           IT  Senior        40400        Q1   169\n#&gt; 11:     EMP_011 Empleado_K    Marketing    Lead        75600        Q1  3529\n#&gt; 12:     EMP_012 Empleado_L    Marketing Manager        77900        Q1  2322\n#&gt;     evaluacion proyectos\n#&gt;          &lt;num&gt;     &lt;int&gt;\n#&gt;  1:        3.6         7\n#&gt;  2:        4.3         1\n#&gt;  3:        3.4         6\n#&gt;  4:        4.1         5\n#&gt;  5:        3.5         2\n#&gt; ---                     \n#&gt;  8:        3.1         2\n#&gt;  9:        3.5         1\n#&gt; 10:        4.6         3\n#&gt; 11:        3.2         1\n#&gt; 12:        4.2         1\n\n\n8.2.4 4. melt() Avanzado para Sensores\n\n\n# Melt complejo para datos de sensores múltiples\nsensores_long &lt;- melt(sensores_multiples,\n                     id.vars = c(\"timestamp\", \"ubicacion\"),\n                     variable.name = \"sensor_completo\",\n                     value.name = \"medicion\")[, `:=`(\n  # Extraer tipo de sensor y número\n  tipo_sensor = sub(\"_[0-9]+$\", \"\", sensor_completo),\n  numero_sensor = as.numeric(sub(\".*_\", \"\", sensor_completo))\n)][, sensor_completo := NULL]  # Limpiar columna temporal\n\nprint(\"Sensores en formato largo:\")\n#&gt; [1] \"Sensores en formato largo:\"\nprint(head(sensores_long, 15))\n#&gt;               timestamp    ubicacion medicion tipo_sensor numero_sensor\n#&gt;                  &lt;POSc&gt;       &lt;char&gt;    &lt;num&gt;      &lt;char&gt;         &lt;num&gt;\n#&gt;  1: 2024-01-01 00:00:00 Planta_Norte     19.9 sensor_temp             1\n#&gt;  2: 2024-01-01 06:00:00 Planta_Norte     19.9 sensor_temp             1\n#&gt;  3: 2024-01-01 12:00:00 Planta_Norte     24.5 sensor_temp             1\n#&gt;  4: 2024-01-01 18:00:00 Planta_Norte     23.4 sensor_temp             1\n#&gt;  5: 2024-01-02 00:00:00 Planta_Norte     24.1 sensor_temp             1\n#&gt; ---                                                                    \n#&gt; 11: 2024-01-03 12:00:00 Planta_Norte     23.5 sensor_temp             1\n#&gt; 12: 2024-01-03 18:00:00 Planta_Norte     23.6 sensor_temp             1\n#&gt; 13: 2024-01-04 00:00:00 Planta_Norte     21.1 sensor_temp             1\n#&gt; 14: 2024-01-04 06:00:00 Planta_Norte     21.3 sensor_temp             1\n#&gt; 15: 2024-01-04 12:00:00 Planta_Norte     20.3 sensor_temp             1\n\n# Estadísticas por tipo de sensor\nstats_sensores &lt;- sensores_long[, .(\n  mediciones = .N,\n  promedio = round(mean(medicion, na.rm = TRUE), 2),\n  minimo = round(min(medicion, na.rm = TRUE), 2),\n  maximo = round(max(medicion, na.rm = TRUE), 2),\n  desviacion = round(sd(medicion, na.rm = TRUE), 2)\n), by = .(tipo_sensor, ubicacion)]\n\nprint(\"\\nEstadísticas por tipo de sensor y ubicación:\")\n#&gt; [1] \"\\nEstadísticas por tipo de sensor y ubicación:\"\nprint(stats_sensores)\n#&gt;       tipo_sensor     ubicacion mediciones promedio minimo maximo desviacion\n#&gt;            &lt;char&gt;        &lt;char&gt;      &lt;int&gt;    &lt;num&gt;  &lt;num&gt;  &lt;num&gt;      &lt;num&gt;\n#&gt; 1:    sensor_temp  Planta_Norte         56    21.08   13.5   27.1       3.38\n#&gt; 2:    sensor_temp    Planta_Sur         56    21.15   13.1   26.4       3.31\n#&gt; 3:    sensor_temp Planta_Centro         56    21.24   14.5   26.9       3.21\n#&gt; 4: sensor_humedad  Planta_Norte         56    64.10   42.9   79.8       8.65\n#&gt; 5: sensor_humedad    Planta_Sur         56    64.20   42.6   77.6      10.36\n#&gt; 6: sensor_humedad Planta_Centro         56    58.45   40.7   78.6       9.29\n#&gt; 7: sensor_presion  Planta_Norte         56  1021.35  999.9 1044.3      11.25\n#&gt; 8: sensor_presion    Planta_Sur         56  1007.93  987.8 1033.3      12.23\n#&gt; 9: sensor_presion Planta_Centro         56  1020.05  997.3 1040.6      11.55",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Remodelación de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#dcast-de-largo-a-ancho",
    "href": "cap03-reshape.html#dcast-de-largo-a-ancho",
    "title": "\n8  Remodelación de Datos: melt() y dcast()\n",
    "section": "\n8.3 dcast(): De Largo a Ancho",
    "text": "8.3 dcast(): De Largo a Ancho\n\n8.3.1 1. dcast() Básico\n\n\n# Reconstruir formato ancho desde formato largo\nventas_reconstruida &lt;- dcast(ventas_long_separada, \n                            producto + categoria + precio_unitario ~ periodo + metrica,\n                            value.var = \"valor\")\n\nprint(\"Datos reconstruidos a formato ancho:\")\n#&gt; [1] \"Datos reconstruidos a formato ancho:\"\nprint(head(ventas_reconstruida))\n#&gt; Clave &lt;producto, categoria, precio_unitario&gt;\n#&gt;     producto    categoria precio_unitario Q1_2023_revenue Q1_2023_unidades\n#&gt;       &lt;char&gt;       &lt;char&gt;           &lt;num&gt;           &lt;num&gt;            &lt;num&gt;\n#&gt; 1:    Cámara   Multimedia             250           17500               70\n#&gt; 2:   Desktop Computadoras             800           64000               80\n#&gt; 3: Impresora      Oficina             200           12000               60\n#&gt; 4:    Laptop Computadoras            1200          180000              150\n#&gt; 5:   Monitor  Periféricos             300           36000              120\n#&gt; 6:     Mouse  Periféricos              25           11250              450\n#&gt;    Q1_2024_revenue Q1_2024_unidades Q2_2023_revenue Q2_2023_unidades\n#&gt;              &lt;num&gt;            &lt;num&gt;           &lt;num&gt;            &lt;num&gt;\n#&gt; 1:           20000               80           18750               75\n#&gt; 2:           68000               85           60000               75\n#&gt; 3:           15000               75           11000               55\n#&gt; 4:          228000              190          216000              180\n#&gt; 5:           51000              170           42000              140\n#&gt; 6:           13750              550           12000              480\n#&gt;    Q3_2023_revenue Q3_2023_unidades Q4_2023_revenue Q4_2023_unidades\n#&gt;              &lt;num&gt;            &lt;num&gt;           &lt;num&gt;            &lt;num&gt;\n#&gt; 1:           21250               85           22500               90\n#&gt; 2:           72000               90           76000               95\n#&gt; 3:           14000               70           16000               80\n#&gt; 4:          240000              200          264000              220\n#&gt; 5:           48000              160           54000              180\n#&gt; 6:           12500              500           15000              600\n\n# Verificar que coincide con datos originales\ncat(\"¿Reconstrucción exitosa?\", \n    nrow(ventas_reconstruida) == nrow(ventas_trimestral_wide) && \n    ncol(ventas_reconstruida) &gt;= ncol(ventas_trimestral_wide) - 2, \"\\n\")\n#&gt; ¿Reconstrucción exitosa? TRUE\n\n\n8.3.2 2. dcast() con Agregación\n\n\n# Crear tabla resumen: promedio por producto y año\nventas_resumen_anual &lt;- ventas_long_separada[, \n  año := ifelse(grepl(\"2023\", periodo), \"2023\", \"2024\")\n][, .(\n  valor_promedio = round(mean(valor), 0)\n), by = .(producto, categoria, año, metrica)]\n\n# Convertir a formato ancho con agregación\nresumen_wide &lt;- dcast(ventas_resumen_anual,\n                     producto + categoria ~ año + metrica,\n                     value.var = \"valor_promedio\")\n\nprint(\"Resumen anual en formato ancho:\")\n#&gt; [1] \"Resumen anual en formato ancho:\"\nprint(resumen_wide)\n#&gt; Clave &lt;producto, categoria&gt;\n#&gt;       producto    categoria 2023_revenue 2023_unidades 2024_revenue\n#&gt;         &lt;char&gt;       &lt;char&gt;        &lt;num&gt;         &lt;num&gt;        &lt;num&gt;\n#&gt;  1:     Cámara   Multimedia        20000            80        20000\n#&gt;  2:    Desktop Computadoras        68000            85        68000\n#&gt;  3:  Impresora      Oficina        13250            66        15000\n#&gt;  4:     Laptop Computadoras       225000           188       228000\n#&gt;  5:    Monitor  Periféricos        45000           150        51000\n#&gt;  6:      Mouse  Periféricos        12688           508        13750\n#&gt;  7:     Router        Redes        14438            96        15750\n#&gt;  8: Smartphone      Móviles       205500           342       228000\n#&gt;  9:     Tablet Computadoras        76000           190        80000\n#&gt; 10:    Teclado  Periféricos        21250           425        22500\n#&gt;     2024_unidades\n#&gt;             &lt;num&gt;\n#&gt;  1:            80\n#&gt;  2:            85\n#&gt;  3:            75\n#&gt;  4:           190\n#&gt;  5:           170\n#&gt;  6:           550\n#&gt;  7:           105\n#&gt;  8:           380\n#&gt;  9:           200\n#&gt; 10:           450\n\n\n8.3.3 3. dcast() con Funciones de Agregación Personalizadas\n\n\n# Análisis completo de empleados por departamento\nempleados_analisis &lt;- dcast(empleados_long,\n                           departamento + nivel ~ .,\n                           value.var = c(\"bonus\", \"evaluacion\", \"proyectos\"),\n                           fun.aggregate = list(\n                             mean = mean,\n                             max = max,\n                             min = min\n                           ))\n\nprint(\"Análisis agregado de empleados:\")\n#&gt; [1] \"Análisis agregado de empleados:\"\nprint(empleados_analisis)\n#&gt; Clave &lt;departamento, nivel&gt;\n#&gt;     departamento   nivel bonus_mean evaluacion_mean proyectos_mean bonus_max\n#&gt;           &lt;char&gt;  &lt;char&gt;      &lt;num&gt;           &lt;num&gt;          &lt;num&gt;     &lt;num&gt;\n#&gt;  1:           IT  Junior    2997.50           4.200          3.250      6544\n#&gt;  2:           IT    Lead    8586.00           3.750          7.750     14636\n#&gt;  3:           IT Manager    5640.25           3.950          4.750      8626\n#&gt;  4:           IT  Senior    5855.50           4.350          4.125     12881\n#&gt;  5:    Marketing  Junior    5739.75           4.150          4.250      9434\n#&gt; ---                                                                         \n#&gt; 12:         RRHH  Senior    4420.25           3.275          6.500      7729\n#&gt; 13:       Ventas  Junior    5225.00           4.200          5.875     10347\n#&gt; 14:       Ventas    Lead    5906.00           4.000          6.250      7472\n#&gt; 15:       Ventas Manager    4664.00           3.750          5.250      7673\n#&gt; 16:       Ventas  Senior    4700.00           3.975          2.750      9105\n#&gt;     evaluacion_max proyectos_max bonus_min evaluacion_min proyectos_min\n#&gt;              &lt;num&gt;         &lt;int&gt;     &lt;num&gt;          &lt;num&gt;         &lt;int&gt;\n#&gt;  1:            4.9             7         4            3.5             1\n#&gt;  2:            4.2            12      4157            3.3             5\n#&gt;  3:            4.7             9      2792            3.1             1\n#&gt;  4:            5.0             8       169            3.2             1\n#&gt;  5:            4.8             9      1410            3.2             2\n#&gt; ---                                                                    \n#&gt; 12:            3.4            12       431            3.1             1\n#&gt; 13:            4.9            12       378            3.5             2\n#&gt; 14:            4.7             9      4470            3.3             3\n#&gt; 15:            4.1            11       264            3.4             1\n#&gt; 16:            4.6             5       896            3.3             1\n\n\n8.3.4 4. Tablas de Contingencia con dcast()\n\n\n# Transformar encuesta a formato largo primero\nencuesta_long &lt;- melt(encuesta_satisfaccion,\n                     id.vars = c(\"respuesta_id\", \"cliente_id\", \"fecha_encuesta\", \"edad\", \"genero\", \"region\"),\n                     measure.vars = patterns(\"^satisfaccion_\", \"gasto_mensual\"),\n                     variable.name = \"aspecto_satisfaccion\",\n                     value.name = c(\"puntuacion\", \"gasto_mensual\"))\n\n# Limpiar nombres de aspectos\nencuesta_long[, aspecto := sub(\"satisfaccion_\", \"\", aspecto_satisfaccion)]\n\n# Crear tabla de contingencia: región vs aspecto (promedio de satisfacción)\ntabla_contingencia &lt;- dcast(encuesta_long,\n                           region ~ aspecto,\n                           value.var = \"puntuacion\", \n                           fun.aggregate = mean)\n\nprint(\"Tabla de contingencia: Satisfacción promedio por región y aspecto:\")\n#&gt; [1] \"Tabla de contingencia: Satisfacción promedio por región y aspecto:\"\nprint(tabla_contingencia)\n#&gt; Clave &lt;region&gt;\n#&gt;    region        1        2        3        4\n#&gt;    &lt;char&gt;    &lt;num&gt;    &lt;num&gt;    &lt;num&gt;    &lt;num&gt;\n#&gt; 1:   Este 3.791667 3.875000 3.750000 3.375000\n#&gt; 2:  Norte 3.700000 3.500000 3.150000 3.150000\n#&gt; 3:  Oeste 3.750000 3.718750 3.062500 3.375000\n#&gt; 4:    Sur 4.083333 3.791667 3.208333 3.416667\n\n# Matriz de correlación usando dcast\n# Primero, crear datos en formato adecuado\nmatriz_correlacion_data &lt;- encuesta_long[, .(\n  satisfaccion_promedio = mean(puntuacion)\n), by = .(cliente_id, aspecto)]\n\nmatriz_correlacion_wide &lt;- dcast(matriz_correlacion_data,\n                                cliente_id ~ aspecto,\n                                value.var = \"satisfaccion_promedio\")\n\n# Calcular correlaciones\ncor_matrix &lt;- cor(matriz_correlacion_wide[, -\"cliente_id\"], use = \"complete.obs\")\nprint(\"\\nMatriz de correlaciones entre aspectos:\")\n#&gt; [1] \"\\nMatriz de correlaciones entre aspectos:\"\nprint(round(cor_matrix, 3))\n#&gt;        1      2      3      4\n#&gt; 1  1.000  0.153  0.228 -0.311\n#&gt; 2  0.153  1.000 -0.127 -0.090\n#&gt; 3  0.228 -0.127  1.000 -0.175\n#&gt; 4 -0.311 -0.090 -0.175  1.000",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Remodelación de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#casos-de-uso-avanzados",
    "href": "cap03-reshape.html#casos-de-uso-avanzados",
    "title": "\n8  Remodelación de Datos: melt() y dcast()\n",
    "section": "\n8.4 Casos de Uso Avanzados",
    "text": "8.4 Casos de Uso Avanzados\n\n8.4.1 1. Reportes Ejecutivos Dinámicos\n\n\n# Crear reporte ejecutivo completo combinando melt/dcast\nreporte_ejecutivo &lt;- ventas_long_separada[\n  # Calcular métricas adicionales\n  , `:=`(\n    año = ifelse(grepl(\"2023\", periodo), \"2023\", \"2024\"),\n    trimestre_num = as.numeric(substr(periodo, 2, 2))\n  )\n][\n  # Agrupar y calcular KPIs\n  , .(\n    valor_total = sum(valor),\n    productos_activos = uniqueN(producto)\n  ), by = .(categoria, año, metrica)\n]\n\n# Crear formato ancho para reporte\nreporte_ejecutivo &lt;-  dcast(reporte_ejecutivo, categoria ~ año + metrica, value.var = \"valor_total\")\n\nprint(\"Reporte Ejecutivo de Ventas:\")\n#&gt; [1] \"Reporte Ejecutivo de Ventas:\"\nprint(reporte_ejecutivo)\n#&gt; Clave &lt;categoria&gt;\n#&gt;       categoria 2023_revenue 2023_unidades 2024_revenue 2024_unidades\n#&gt;          &lt;char&gt;        &lt;num&gt;         &lt;num&gt;        &lt;num&gt;         &lt;num&gt;\n#&gt; 1: Computadoras      1476000          1850       376000           475\n#&gt; 2:   Multimedia        80000           320        20000            80\n#&gt; 3:      Móviles       822000          1370       228000           380\n#&gt; 4:      Oficina        53000           265        15000            75\n#&gt; 5:  Periféricos       315750          4330        87250          1170\n#&gt; 6:        Redes        57750           385        15750           105\n\n# Calcular crecimiento año sobre año\nreporte_con_crecimiento &lt;- copy(reporte_ejecutivo)[, `:=`(\n  crecimiento_revenue = round((get(\"2024_revenue\") - get(\"2023_revenue\")) / get(\"2023_revenue\") * 100, 1),\n  crecimiento_unidades = round((get(\"2024_unidades\") - get(\"2023_unidades\")) / get(\"2023_unidades\") * 100, 1)\n)]\n\nprint(\"\\nReporte con análisis de crecimiento:\")\n#&gt; [1] \"\\nReporte con análisis de crecimiento:\"\nprint(reporte_con_crecimiento[, .(categoria, \n                                 revenue_2023 = `2023_revenue`, \n                                 revenue_2024 = `2024_revenue`,\n                                 crecimiento_revenue,\n                                 crecimiento_unidades)])\n#&gt; Clave &lt;categoria&gt;\n#&gt;       categoria revenue_2023 revenue_2024 crecimiento_revenue\n#&gt;          &lt;char&gt;        &lt;num&gt;        &lt;num&gt;               &lt;num&gt;\n#&gt; 1: Computadoras      1476000       376000               -74.5\n#&gt; 2:   Multimedia        80000        20000               -75.0\n#&gt; 3:      Móviles       822000       228000               -72.3\n#&gt; 4:      Oficina        53000        15000               -71.7\n#&gt; 5:  Periféricos       315750        87250               -72.4\n#&gt; 6:        Redes        57750        15750               -72.7\n#&gt;    crecimiento_unidades\n#&gt;                   &lt;num&gt;\n#&gt; 1:                -74.3\n#&gt; 2:                -75.0\n#&gt; 3:                -72.3\n#&gt; 4:                -71.7\n#&gt; 5:                -73.0\n#&gt; 6:                -72.7\n\n\n8.4.2 2. Dashboard de Sensores en Tiempo Real\n\n\n# Crear dashboard de estado actual de sensores\nestado_actual_sensores &lt;- sensores_long[\n  # Obtener última lectura por sensor\n  , .SD[.N], by = .(ubicacion, tipo_sensor, numero_sensor)\n][\n  # Clasificar estado según rangos normales\n  , estado := fcase(\n    tipo_sensor == \"sensor_temp\" & (medicion &lt; 15 | medicion &gt; 30), \"ALERTA\",\n    tipo_sensor == \"sensor_humedad\" & (medicion &lt; 30 | medicion &gt; 80), \"ALERTA\", \n    tipo_sensor == \"sensor_presion\" & (medicion &lt; 1000 | medicion &gt; 1030), \"ALERTA\",\n    default = \"NORMAL\"\n  )\n]\n\n# Dashboard en formato ancho\ndashboard_wide &lt;- dcast(estado_actual_sensores,\n                       ubicacion ~ tipo_sensor + numero_sensor,\n                       value.var = \"medicion\")\n\nprint(\"Dashboard de Sensores (valores actuales):\")\n#&gt; [1] \"Dashboard de Sensores (valores actuales):\"\nprint(dashboard_wide)\n#&gt; Clave &lt;ubicacion&gt;\n#&gt;        ubicacion sensor_humedad_1 sensor_humedad_2 sensor_presion_1\n#&gt;           &lt;char&gt;            &lt;num&gt;            &lt;num&gt;            &lt;num&gt;\n#&gt; 1: Planta_Centro             60.5             74.1           1006.4\n#&gt; 2:  Planta_Norte             42.9             58.0           1012.8\n#&gt; 3:    Planta_Sur             71.0             60.6           1015.7\n#&gt;    sensor_presion_2 sensor_temp_1 sensor_temp_2\n#&gt;               &lt;num&gt;         &lt;num&gt;         &lt;num&gt;\n#&gt; 1:            998.2          19.9          25.7\n#&gt; 2:            999.9          18.4          25.8\n#&gt; 3:           1029.3          19.4          26.0\n\n# Tabla de alertas\nalertas_sensores &lt;- estado_actual_sensores[estado == \"ALERTA\"]\nif(nrow(alertas_sensores) &gt; 0) {\n  print(\"\\n🚨 ALERTAS ACTIVAS:\")\n  print(alertas_sensores[, .(ubicacion, tipo_sensor, numero_sensor, medicion, timestamp)])\n} else {\n  cat(\"\\n✅ Todos los sensores operan en rangos normales\\n\")\n}\n#&gt; [1] \"\\n🚨 ALERTAS ACTIVAS:\"\n#&gt;        ubicacion    tipo_sensor numero_sensor medicion           timestamp\n#&gt;           &lt;char&gt;         &lt;char&gt;         &lt;num&gt;    &lt;num&gt;              &lt;POSc&gt;\n#&gt; 1:  Planta_Norte sensor_presion             2    999.9 2024-01-07 18:00:00\n#&gt; 2: Planta_Centro sensor_presion             2    998.2 2024-01-07 18:00:00\n\n\n8.4.3 3. Análisis Multivariable de Encuestas\n\n\n# Análisis completo de satisfacción por segmentos\nanalisis_satisfaccion &lt;- encuesta_long[\n  # Agregar segmentación demográfica\n  , `:=`(\n    grupo_edad = cut(edad, breaks = c(0, 30, 45, 60, 100), \n                    labels = c(\"Joven\", \"Adulto\", \"Maduro\", \"Senior\")),\n    gasto_categoria = cut(gasto_mensual, breaks = c(0, 100, 300, 500, Inf),\n                         labels = c(\"Bajo\", \"Medio\", \"Alto\", \"Premium\"))\n  )\n][\n  # Calcular satisfacción promedio por segmento y aspecto\n  , .(\n    satisfaccion_promedio = round(mean(puntuacion), 2),\n    respuestas = .N\n  ), by = .(region, grupo_edad, gasto_categoria, aspecto)\n]\n\n# Crear matriz de satisfacción: aspecto vs segmento\nmatriz_satisfaccion &lt;- dcast(analisis_satisfaccion,\n                            region + grupo_edad + gasto_categoria ~ aspecto,\n                            value.var = \"satisfaccion_promedio\",\n                            fun.aggregate = mean)\n\nprint(\"Matriz de satisfacción por segmento:\")\n#&gt; [1] \"Matriz de satisfacción por segmento:\"\nprint(head(matriz_satisfaccion, 10))\n#&gt; Clave &lt;region, grupo_edad, gasto_categoria&gt;\n#&gt;     region grupo_edad gasto_categoria     1     2     3     4\n#&gt;     &lt;char&gt;     &lt;fctr&gt;          &lt;fctr&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n#&gt;  1:   Este      Joven            &lt;NA&gt;   NaN  4.00  4.00  3.50\n#&gt;  2:   Este      Joven            Bajo  4.00   NaN   NaN   NaN\n#&gt;  3:   Este      Joven           Medio  2.50   NaN   NaN   NaN\n#&gt;  4:   Este      Joven            Alto  4.00   NaN   NaN   NaN\n#&gt;  5:   Este      Joven         Premium  2.00   NaN   NaN   NaN\n#&gt;  6:   Este     Adulto            &lt;NA&gt;   NaN  3.57  3.14  3.00\n#&gt;  7:   Este     Adulto            Bajo  3.00   NaN   NaN   NaN\n#&gt;  8:   Este     Adulto           Medio  4.67   NaN   NaN   NaN\n#&gt;  9:   Este     Adulto            Alto  4.67   NaN   NaN   NaN\n#&gt; 10:   Este     Maduro            &lt;NA&gt;   NaN  4.17  3.83  3.33\n\n# Verificar qué columnas se crearon después del dcast\nprint(\"Columnas en matriz_satisfaccion:\")\n#&gt; [1] \"Columnas en matriz_satisfaccion:\"\nprint(names(matriz_satisfaccion))\n#&gt; [1] \"region\"          \"grupo_edad\"      \"gasto_categoria\" \"1\"              \n#&gt; [5] \"2\"               \"3\"               \"4\"\n\n# Identificar segmentos críticos (satisfacción baja en múltiples aspectos)\n# Primero verificar qué columnas de aspectos existen\ncolumnas_aspectos &lt;- names(matriz_satisfaccion)[!names(matriz_satisfaccion) %in% c(\"region\", \"grupo_edad\", \"gasto_categoria\")]\nprint(paste(\"Columnas de aspectos encontradas:\", paste(columnas_aspectos, collapse = \", \")))\n#&gt; [1] \"Columnas de aspectos encontradas: 1, 2, 3, 4\"\n\nif(length(columnas_aspectos) &gt;= 4) {\n  # Si tenemos las 4 columnas esperadas (entrega, precio, producto, servicio)\n  segmentos_criticos &lt;- matriz_satisfaccion[\n    # Calcular score de satisfacción general usando las columnas que existen\n    , satisfaccion_general := round(rowMeans(.SD, na.rm = TRUE), 2), .SDcols = columnas_aspectos\n  ][\n    satisfaccion_general &lt; 3.5  # Umbral crítico\n  ][order(satisfaccion_general)]\n} else {\n  # Si no tenemos todas las columnas, usar un enfoque más simple\n  cat(\"No se encontraron todas las columnas de aspectos esperadas. Usando análisis simplificado.\\n\")\n  segmentos_criticos &lt;- matriz_satisfaccion[1:0]  # Tabla vacía para evitar errores\n}\n\nif(nrow(segmentos_criticos) &gt; 0) {\n  print(\"\\n⚠️ SEGMENTOS CRÍTICOS (satisfacción &lt; 3.5):\")\n  print(segmentos_criticos[, .(region, grupo_edad, gasto_categoria, satisfaccion_general)])\n} else {\n  cat(\"\\n✅ No hay segmentos con satisfacción crítica\\n\")\n}\n#&gt; [1] \"\\n⚠️ SEGMENTOS CRÍTICOS (satisfacción &lt; 3.5):\"\n#&gt;     region grupo_edad gasto_categoria satisfaccion_general\n#&gt;     &lt;char&gt;     &lt;fctr&gt;          &lt;fctr&gt;                &lt;num&gt;\n#&gt;  1:   Este      Joven         Premium                 2.00\n#&gt;  2:   Este     Maduro         Premium                 2.00\n#&gt;  3:   Este      Joven           Medio                 2.50\n#&gt;  4:  Norte     Maduro         Premium                 2.50\n#&gt;  5:   Este     Adulto            Bajo                 3.00\n#&gt;  6:  Norte      Joven           Medio                 3.00\n#&gt;  7:  Norte     Adulto            Alto                 3.00\n#&gt;  8:  Oeste      Joven           Medio                 3.00\n#&gt;  9:  Oeste     Maduro           Medio                 3.00\n#&gt; 10:  Oeste     Senior           Medio                 3.00\n#&gt; 11:  Oeste     Senior         Premium                 3.00\n#&gt; 12:    Sur      Joven            Alto                 3.00\n#&gt; 13:    Sur     Maduro            Bajo                 3.00\n#&gt; 14:  Norte      Joven            &lt;NA&gt;                 3.14\n#&gt; 15:   Este     Adulto            &lt;NA&gt;                 3.24\n#&gt; 16:   Este     Maduro           Medio                 3.25\n#&gt; 17:  Norte     Senior            &lt;NA&gt;                 3.25\n#&gt; 18:  Oeste     Maduro            &lt;NA&gt;                 3.29\n#&gt; 19:  Norte     Maduro            &lt;NA&gt;                 3.33\n#&gt; 20:    Sur     Senior            &lt;NA&gt;                 3.33\n#&gt; 21:  Oeste     Adulto            &lt;NA&gt;                 3.34\n#&gt; 22:  Norte     Adulto            &lt;NA&gt;                 3.39\n#&gt; 23:    Sur     Maduro            &lt;NA&gt;                 3.39\n#&gt; 24:    Sur     Adulto            &lt;NA&gt;                 3.46\n#&gt; 25:  Oeste     Senior            &lt;NA&gt;                 3.48\n#&gt;     region grupo_edad gasto_categoria satisfaccion_general",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Remodelación de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#ejercicios-prácticos",
    "href": "cap03-reshape.html#ejercicios-prácticos",
    "title": "\n8  Remodelación de Datos: melt() y dcast()\n",
    "section": "\n8.5 Ejercicios Prácticos",
    "text": "8.5 Ejercicios Prácticos\n\n\n\n\n\n\n🏋️ Ejercicio 13: Pipeline Completo de Reshape\n\n\n\nUsando los datos de empleados:\n\n\nmelt() para convertir a formato largo\n\nAgregar nuevas variables derivadas usando :=\n\n\ndcast() para crear múltiples vistas agregadas\n\nGenerar reporte ejecutivo combinando ambas técnicas\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 13\n\n\n\n\n\n\n# 1. Pipeline completo de reshape para análisis de empleados\n# Paso 1: melt() para formato largo\nempleados_melted &lt;- melt(empleados_metricas,\n                        id.vars = c(\"empleado_id\", \"nombre\", \"departamento\", \"nivel\", \"salario_base\"),\n                        measure = patterns(\n                          bonus = \"^bonus_Q\",\n                          evaluacion = \"^evaluacion_Q\",\n                          proyectos = \"^proyectos_Q\"\n                        ),\n                        variable.name = \"trimestre_num\",\n                        value.name = c(\"bonus\", \"evaluacion\", \"proyectos\"))\n\n# 2. Agregar variables derivadas\nempleados_enriquecido &lt;- empleados_melted[, `:=`(\n  trimestre = paste0(\"Q\", trimestre_num),\n  compensacion_total = salario_base / 4 + bonus,  # Salario trimestral + bonus\n  productividad = round(proyectos / (evaluacion + 0.1), 2),  # Proyectos por punto de evaluación\n  categoria_performance = fcase(\n    evaluacion &gt;= 4.5, \"Excelente\",\n    evaluacion &gt;= 4.0, \"Muy Bueno\", \n    evaluacion &gt;= 3.5, \"Bueno\",\n    evaluacion &gt;= 3.0, \"Satisfactorio\",\n    default = \"Necesita Mejora\"\n  ),\n  rango_bonus = fcase(\n    bonus &gt;= 10000, \"Alto\",\n    bonus &gt;= 5000, \"Medio\",\n    bonus &gt; 0, \"Bajo\", \n    default = \"Sin Bonus\"\n  )\n)]\n\n# 3. Crear múltiples vistas con dcast()\n\n# Vista 1: Performance promedio por departamento y nivel\nperformance_depto &lt;- dcast(empleados_enriquecido,\n                          departamento + nivel ~ .,\n                          value.var = c(\"evaluacion\", \"productividad\", \"compensacion_total\"),\n                          fun.aggregate = list(mean = mean, max = max))\n\ncat(\"📊 VISTA 1: PERFORMANCE POR DEPARTAMENTO Y NIVEL\\n\")\n#&gt; 📊 VISTA 1: PERFORMANCE POR DEPARTAMENTO Y NIVEL\nprint(performance_depto[order(departamento, nivel)])\n#&gt; Key: &lt;departamento, nivel&gt;\n#&gt;     departamento   nivel evaluacion_mean productividad_mean\n#&gt;           &lt;char&gt;  &lt;char&gt;           &lt;num&gt;              &lt;num&gt;\n#&gt;  1:           IT  Junior          4.2000            0.71000\n#&gt;  2:           IT    Lead          3.7500            2.04750\n#&gt;  3:           IT Manager          3.9500            1.15250\n#&gt;  4:           IT  Senior          4.3500            1.01125\n#&gt;  5:    Marketing  Junior          4.1500            1.06250\n#&gt;  6:    Marketing    Lead          4.0875            0.94000\n#&gt;  7:    Marketing Manager          3.9500            1.49250\n#&gt;  8:    Marketing  Senior          3.8250            0.94250\n#&gt;  9:         RRHH  Junior          4.1250            1.39500\n#&gt; 10:         RRHH    Lead          3.9500            1.62750\n#&gt; 11:         RRHH Manager          4.1250            1.24500\n#&gt; 12:         RRHH  Senior          3.2750            1.93250\n#&gt; 13:       Ventas  Junior          4.2000            1.41250\n#&gt; 14:       Ventas    Lead          4.0000            1.61750\n#&gt; 15:       Ventas Manager          3.7500            1.36250\n#&gt; 16:       Ventas  Senior          3.9750            0.73000\n#&gt;     compensacion_total_mean evaluacion_max productividad_max\n#&gt;                       &lt;num&gt;          &lt;num&gt;             &lt;num&gt;\n#&gt;  1:                21597.50            4.9              1.40\n#&gt;  2:                22011.00            4.2              3.43\n#&gt;  3:                17790.25            4.7              1.89\n#&gt;  4:                19230.50            5.0              2.42\n#&gt;  5:                22414.75            4.8              2.20\n#&gt;  6:                22367.50            4.8              1.74\n#&gt;  7:                25912.75            4.5              3.03\n#&gt;  8:                19200.50            4.7              1.88\n#&gt;  9:                13780.00            4.7              2.44\n#&gt; 10:                17059.75            4.6              2.55\n#&gt; 11:                20527.75            4.8              2.05\n#&gt; 12:                22870.25            3.4              3.53\n#&gt; 13:                21262.50            4.9              3.33\n#&gt; 14:                22306.00            4.7              2.65\n#&gt; 15:                21264.00            4.1              2.97\n#&gt; 16:                17050.00            4.6              1.47\n#&gt;     compensacion_total_max\n#&gt;                      &lt;num&gt;\n#&gt;  1:                  25144\n#&gt;  2:                  28061\n#&gt;  3:                  20776\n#&gt;  4:                  26428\n#&gt;  5:                  26109\n#&gt;  6:                  27178\n#&gt;  7:                  33112\n#&gt;  8:                  22337\n#&gt;  9:                  21079\n#&gt; 10:                  24833\n#&gt; 11:                  26727\n#&gt; 12:                  26179\n#&gt; 13:                  26904\n#&gt; 14:                  23872\n#&gt; 15:                  24273\n#&gt; 16:                  21455\n\n# Vista 2: Evolución trimestral por empleado (transpuesta)\nevolucion_empleados &lt;- dcast(empleados_enriquecido[departamento == \"IT\"],  # Solo IT para ejemplo\n                            nombre ~ trimestre,\n                            value.var = \"evaluacion\",\n                            fun.aggregate = mean)\n\ncat(\"\\n📈 VISTA 2: EVOLUCIÓN DE EVALUACIONES - DEPARTAMENTO IT\\n\")\n#&gt; \n#&gt; 📈 VISTA 2: EVOLUCIÓN DE EVALUACIONES - DEPARTAMENTO IT\nprint(evolucion_empleados)\n#&gt; Key: &lt;nombre&gt;\n#&gt;        nombre    Q1    Q2    Q3    Q4\n#&gt;        &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n#&gt; 1: Empleado_F   4.6   3.2   4.9   4.7\n#&gt; 2: Empleado_G   3.3   4.2   4.1   3.4\n#&gt; 3: Empleado_H   3.1   4.7   3.6   4.4\n#&gt; 4: Empleado_I   3.5   4.9   4.1   4.3\n#&gt; 5: Empleado_J   4.6   5.0   3.8   4.0\n\n# Vista 3: Matriz de categorías (contingencia)\nmatriz_categorias &lt;- dcast(empleados_enriquecido,\n                          departamento ~ categoria_performance,\n                          value.var = \"empleado_id\",\n                          fun.aggregate = function(x) length(unique(x)))\n\ncat(\"\\n🎯 VISTA 3: MATRIZ DE CATEGORÍAS DE PERFORMANCE\\n\")\n#&gt; \n#&gt; 🎯 VISTA 3: MATRIZ DE CATEGORÍAS DE PERFORMANCE\nprint(matriz_categorias)\n#&gt; Key: &lt;departamento&gt;\n#&gt;    departamento Bueno Excelente Muy Bueno Satisfactorio\n#&gt;          &lt;char&gt; &lt;int&gt;     &lt;int&gt;     &lt;int&gt;         &lt;int&gt;\n#&gt; 1:           IT     3         4         4             3\n#&gt; 2:    Marketing     3         5         5             4\n#&gt; 3:         RRHH     2         3         4             4\n#&gt; 4:       Ventas     4         4         3             3\n\n# 4. Reporte ejecutivo combinando técnicas\ncat(\"\\n📋 REPORTE EJECUTIVO DE RRHH\\n\")\n#&gt; \n#&gt; 📋 REPORTE EJECUTIVO DE RRHH\n\n# KPIs generales\nkpis_generales &lt;- empleados_enriquecido[, .(\n  empleados_unicos = uniqueN(empleado_id),\n  evaluacion_promedio = round(mean(evaluacion), 2),\n  bonus_promedio = round(mean(bonus), 0),\n  proyectos_promedio = round(mean(proyectos), 1),\n  compensacion_promedio = round(mean(compensacion_total), 0)\n)]\n\ncat(\"KPIs GENERALES:\\n\")\n#&gt; KPIs GENERALES:\ncat(\"• Empleados analizados:\", kpis_generales$empleados_unicos, \"\\n\")\n#&gt; • Empleados analizados: 20\ncat(\"• Evaluación promedio:\", kpis_generales$evaluacion_promedio, \"/5.0\\n\")\n#&gt; • Evaluación promedio: 4.02 /5.0\ncat(\"• Bonus promedio trimestral:\", scales::dollar(kpis_generales$bonus_promedio), \"\\n\")\n#&gt; • Bonus promedio trimestral: $5,465\ncat(\"• Proyectos promedio por trimestre:\", kpis_generales$proyectos_promedio, \"\\n\")\n#&gt; • Proyectos promedio por trimestre: 5.1\ncat(\"• Compensación total promedio:\", scales::dollar(kpis_generales$compensacion_promedio), \"\\n\\n\")\n#&gt; • Compensación total promedio: $20,502\n\n# Top performers\ntop_performers &lt;- empleados_enriquecido[, .(\n  evaluacion_promedio = round(mean(evaluacion), 2),\n  productividad_promedio = round(mean(productividad), 2),\n  bonus_total = sum(bonus)\n), by = .(empleado_id, nombre, departamento)][\n  order(-evaluacion_promedio, -productividad_promedio)\n][1:5]\n\ncat(\"🏆 TOP 5 PERFORMERS:\\n\")\n#&gt; 🏆 TOP 5 PERFORMERS:\nfor(i in 1:nrow(top_performers)) {\n  emp &lt;- top_performers[i]\n  cat(sprintf(\"%d. %s (%s) - Eval: %.1f, Productividad: %.1f, Bonus Total: %s\\n\",\n              i, emp$nombre, emp$departamento, emp$evaluacion_promedio, \n              emp$productividad_promedio, scales::dollar(emp$bonus_total)))\n}\n#&gt; 1. Empleado_P (RRHH) - Eval: 4.4, Productividad: 1.3, Bonus Total: $23,858\n#&gt; 2. Empleado_J (IT) - Eval: 4.3, Productividad: 1.2, Bonus Total: $23,002\n#&gt; 3. Empleado_F (IT) - Eval: 4.3, Productividad: 0.9, Bonus Total: $23,842\n#&gt; 4. Empleado_O (Marketing) - Eval: 4.2, Productividad: 1.0, Bonus Total: $27,901\n#&gt; 5. Empleado_E (Ventas) - Eval: 4.2, Productividad: 0.8, Bonus Total: $28,921\n\n# Análisis por departamento\nanalisis_depto &lt;- empleados_enriquecido[, .(\n  empleados = uniqueN(empleado_id),\n  evaluacion_promedio = round(mean(evaluacion), 2),\n  empleados_excelentes = sum(categoria_performance == \"Excelente\"),\n  tasa_excelencia = round(mean(categoria_performance == \"Excelente\") * 100, 1),\n  presupuesto_bonus = sum(bonus)\n), by = departamento][order(-tasa_excelencia)]\n\ncat(\"\\n🏢 ANÁLISIS POR DEPARTAMENTO:\\n\")\n#&gt; \n#&gt; 🏢 ANÁLISIS POR DEPARTAMENTO:\nprint(analisis_depto)\n#&gt;    departamento empleados evaluacion_promedio empleados_excelentes\n#&gt;          &lt;char&gt;     &lt;int&gt;               &lt;num&gt;                &lt;int&gt;\n#&gt; 1:       Ventas         5                4.03                    7\n#&gt; 2:           IT         5                4.12                    7\n#&gt; 3:    Marketing         5                4.02                    7\n#&gt; 4:         RRHH         5                3.92                    3\n#&gt;    tasa_excelencia presupuesto_bonus\n#&gt;              &lt;num&gt;             &lt;num&gt;\n#&gt; 1:              35            102880\n#&gt; 2:              35            115739\n#&gt; 3:              35            115452\n#&gt; 4:              15            103162\n\n# Recomendaciones automáticas\ncat(\"\\n💡 RECOMENDACIONES AUTOMÁTICAS:\\n\")\n#&gt; \n#&gt; 💡 RECOMENDACIONES AUTOMÁTICAS:\n\n# Departamento con mejor performance\nmejor_depto &lt;- analisis_depto[1, departamento]\npeor_depto &lt;- analisis_depto[.N, departamento]\n\ncat(\"• Mejores prácticas de\", mejor_depto, \"podrían replicarse en otros departamentos\\n\")\n#&gt; • Mejores prácticas de Ventas podrían replicarse en otros departamentos\ncat(\"• Departamento\", peor_depto, \"requiere plan de mejora en evaluaciones\\n\")\n#&gt; • Departamento RRHH requiere plan de mejora en evaluaciones\n\n# Empleados que necesitan atención\nempleados_atencion &lt;- empleados_enriquecido[\n  categoria_performance %in% c(\"Necesita Mejora\", \"Satisfactorio\"), \n  uniqueN(empleado_id), \n  by = departamento\n][V1 &gt; 0]\n\nif(nrow(empleados_atencion) &gt; 0) {\n  cat(\"• Revisar planes de desarrollo individual en:\", paste(empleados_atencion$departamento, collapse = \", \"), \"\\n\")\n}\n#&gt; • Revisar planes de desarrollo individual en: Ventas, IT, Marketing, RRHH\n\n# # Crear tabla interactiva del reporte (comentado para PDF)\n# DT::datatable(\n#   performance_depto,\n#   caption = \"Dashboard Ejecutivo de Performance - RRHH\",\n#   options = list(pageLength = 10, scrollX = TRUE)\n# ) %&gt;%\n#   DT::formatRound(c(\"evaluacion_mean\", \"productividad_mean\"), digits = 2) %&gt;%\n#   DT::formatCurrency(\"compensacion_total_mean\", currency = \"$\")\n\n\n\n\n\n\n\n\n\n\n🏋️ Ejercicio 14: Análisis de Series Temporales con Reshape\n\n\n\n\n\nReshape datos de sensores para análisis temporal\n\nCrear ventanas móviles después del reshape\n\nDetectar anomalías por tipo de sensor\n\nGenerar reporte de alertas en formato ejecutivo\n\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 14\n\n\n\n\n\n\n# 1. Análisis temporal completo con reshape\n# Preparar datos base con información temporal\nsensores_temporal &lt;- sensores_long[, `:=`(\n  fecha = as.Date(timestamp),\n  hora = hour(timestamp),\n  dia_semana = wday(timestamp, label = TRUE)\n)]\n\n# 2. Crear ventanas móviles por tipo de sensor\nsensores_con_ventanas &lt;- sensores_temporal[order(ubicacion, tipo_sensor, numero_sensor, timestamp)][, `:=`(\n  # Ventanas móviles de 24 horas (4 mediciones = 24 horas con datos cada 6h)\n  media_24h = frollmean(medicion, 4, na.rm = TRUE),\n  media_48h = frollmean(medicion, 8, na.rm = TRUE),\n  desv_24h = frollapply(medicion, 4, sd, na.rm = TRUE),\n  \n  # Cambios temporales\n  cambio_6h = abs(medicion - shift(medicion, 1)),\n  cambio_24h = abs(medicion - shift(medicion, 4)),\n  \n  # Tendencia\n  tendencia_24h = frollapply(medicion, 4, function(x) {\n    if(length(x) &lt; 4) return(0)\n    lm(x ~ seq_along(x))$coefficients[2]\n  })\n), by = .(ubicacion, tipo_sensor, numero_sensor)]\n\n# 3. Detección de anomalías por tipo de sensor\nsensores_con_anomalias &lt;- sensores_con_ventanas[, `:=`(\n  # Rangos normales específicos por tipo\n  limite_inferior = fcase(\n    tipo_sensor == \"sensor_temp\", 15,\n    tipo_sensor == \"sensor_humedad\", 30,\n    tipo_sensor == \"sensor_presion\", 1000,\n    default = -Inf\n  ),\n  limite_superior = fcase(\n    tipo_sensor == \"sensor_temp\", 30,\n    tipo_sensor == \"sensor_humedad\", 80, \n    tipo_sensor == \"sensor_presion\", 1030,\n    default = Inf\n  )\n)][, `:=`(\n  # Detectar anomalías\n  anomalia_rango = medicion &lt; limite_inferior | medicion &gt; limite_superior,\n  anomalia_cambio_subito = !is.na(cambio_6h) & cambio_6h &gt; fcase(\n    tipo_sensor == \"sensor_temp\", 5,\n    tipo_sensor == \"sensor_humedad\", 15,\n    tipo_sensor == \"sensor_presion\", 20,\n    default = Inf\n  ),\n  anomalia_desviacion = !is.na(media_24h) & !is.na(desv_24h) & \n                       abs(medicion - media_24h) &gt; 2 * desv_24h,\n  anomalia_tendencia = !is.na(tendencia_24h) & abs(tendencia_24h) &gt; fcase(\n    tipo_sensor == \"sensor_temp\", 1,\n    tipo_sensor == \"sensor_humedad\", 3,\n    tipo_sensor == \"sensor_presion\", 5,\n    default = Inf\n  )\n)][, `:=`(\n  # Score compuesto de anomalía\n  score_anomalia = (as.numeric(anomalia_rango) * 4) +\n                  (as.numeric(anomalia_cambio_subito) * 3) +\n                  (as.numeric(anomalia_desviacion) * 2) + \n                  (as.numeric(anomalia_tendencia) * 1),\n  \n  # Clasificación de severidad\n  severidad_anomalia = fcase(\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 6, \"CRÍTICA\",\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 4, \"ALTA\",\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 2, \"MEDIA\",\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 1, \"BAJA\",\n    default = \"NORMAL\"\n  )\n)]\n\n# 4. Generar reporte ejecutivo de alertas\ncat(\"🚨 REPORTE DE ALERTAS - SISTEMA DE SENSORES 🚨\\n\")\n#&gt; 🚨 REPORTE DE ALERTAS - SISTEMA DE SENSORES 🚨\ncat(rep(\"=\", 60), \"\\n\\n\")\n#&gt; = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n\n# Resumen general usando reshape\nresumen_alertas &lt;- sensores_con_anomalias[severidad_anomalia != \"NORMAL\", .N, \n                                         by = .(ubicacion, tipo_sensor, severidad_anomalia)]\n\nif(nrow(resumen_alertas) &gt; 0) {\n  # Crear matriz de alertas con dcast\n  matriz_alertas &lt;- dcast(resumen_alertas,\n                         ubicacion + tipo_sensor ~ severidad_anomalia,\n                         value.var = \"N\",\n                         fill = 0)\n  \n  cat(\"📊 MATRIZ DE ALERTAS ACTIVAS:\\n\")\n  print(matriz_alertas)\n} else {\n  cat(\"✅ No hay alertas activas en el sistema\\n\")\n}\n#&gt; 📊 MATRIZ DE ALERTAS ACTIVAS:\n#&gt; Key: &lt;ubicacion, tipo_sensor&gt;\n#&gt;        ubicacion    tipo_sensor  ALTA  BAJA CRÍTICA\n#&gt;           &lt;char&gt;         &lt;char&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;\n#&gt; 1: Planta_Centro sensor_humedad     0     3       0\n#&gt; 2: Planta_Centro sensor_presion    16     3       0\n#&gt; 3: Planta_Centro    sensor_temp     2    15       0\n#&gt; 4:  Planta_Norte sensor_humedad     0     3       0\n#&gt; 5:  Planta_Norte sensor_presion    12     1       1\n#&gt; 6:  Planta_Norte    sensor_temp     2    10       0\n#&gt; 7:    Planta_Sur sensor_humedad     0     3       0\n#&gt; 8:    Planta_Sur sensor_presion    16     0       0\n#&gt; 9:    Planta_Sur    sensor_temp     2     7       0\n\n# Estado actual por sensor (usando reshape)\nestado_actual &lt;- sensores_con_anomalias[, .SD[.N], \n                                       by = .(ubicacion, tipo_sensor, numero_sensor)][, .(\n  ubicacion, tipo_sensor, numero_sensor, timestamp, medicion, \n  severidad_anomalia, score_anomalia\n)]\n\n# Convertir a formato wide para dashboard\ndashboard_estado &lt;- dcast(estado_actual,\n                         ubicacion ~ tipo_sensor + numero_sensor,\n                         value.var = \"medicion\")\n\ncat(\"\\n🏢 ESTADO ACTUAL POR UBICACIÓN:\\n\")\n#&gt; \n#&gt; 🏢 ESTADO ACTUAL POR UBICACIÓN:\nprint(dashboard_estado)\n#&gt; Key: &lt;ubicacion&gt;\n#&gt;        ubicacion sensor_humedad_1 sensor_humedad_2 sensor_presion_1\n#&gt;           &lt;char&gt;            &lt;num&gt;            &lt;num&gt;            &lt;num&gt;\n#&gt; 1: Planta_Centro             60.5             74.1           1006.4\n#&gt; 2:  Planta_Norte             42.9             58.0           1012.8\n#&gt; 3:    Planta_Sur             71.0             60.6           1015.7\n#&gt;    sensor_presion_2 sensor_temp_1 sensor_temp_2\n#&gt;               &lt;num&gt;         &lt;num&gt;         &lt;num&gt;\n#&gt; 1:            998.2          19.9          25.7\n#&gt; 2:            999.9          18.4          25.8\n#&gt; 3:           1029.3          19.4          26.0\n\n# Top alertas críticas\nalertas_criticas &lt;- sensores_con_anomalias[\n  severidad_anomalia %in% c(\"CRÍTICA\", \"ALTA\")\n][order(-score_anomalia, -timestamp)][1:min(10, .N)]\n\nif(nrow(alertas_criticas) &gt; 0) {\n  cat(\"\\n🔥 TOP ALERTAS CRÍTICAS:\\n\")\n  print(alertas_criticas[, .(\n    Ubicación = ubicacion,\n    Sensor = paste(tipo_sensor, numero_sensor),\n    Timestamp = timestamp,\n    Medición = medicion,\n    Severidad = severidad_anomalia,\n    Score = score_anomalia\n  )])\n}\n#&gt; \n#&gt; 🔥 TOP ALERTAS CRÍTICAS:\n#&gt;         Ubicación           Sensor           Timestamp Medición Severidad Score\n#&gt;            &lt;char&gt;           &lt;char&gt;              &lt;POSc&gt;    &lt;num&gt;    &lt;char&gt; &lt;num&gt;\n#&gt;  1:  Planta_Norte sensor_presion 1 2024-01-04 00:00:00   1044.3   CRÍTICA     7\n#&gt;  2: Planta_Centro    sensor_temp 1 2024-01-06 00:00:00     14.5      ALTA     5\n#&gt;  3:  Planta_Norte    sensor_temp 1 2024-01-06 00:00:00     13.5      ALTA     5\n#&gt;  4:  Planta_Norte sensor_presion 1 2024-01-03 00:00:00   1035.1      ALTA     5\n#&gt;  5:  Planta_Norte sensor_presion 1 2024-01-02 18:00:00   1038.1      ALTA     5\n#&gt;  6: Planta_Centro sensor_presion 2 2024-01-07 18:00:00    998.2      ALTA     4\n#&gt;  7:  Planta_Norte sensor_presion 2 2024-01-07 18:00:00    999.9      ALTA     4\n#&gt;  8:    Planta_Sur sensor_presion 2 2024-01-07 12:00:00   1031.5      ALTA     4\n#&gt;  9: Planta_Centro sensor_presion 2 2024-01-07 00:00:00    997.3      ALTA     4\n#&gt; 10:    Planta_Sur sensor_presion 2 2024-01-07 00:00:00   1033.3      ALTA     4\n\n# Análisis de tendencias por tipo usando melt/dcast\ntendencias_tipo &lt;- sensores_con_anomalias[!is.na(tendencia_24h), .(\n  tendencia_promedio = round(mean(tendencia_24h, na.rm = TRUE), 4),\n  medicion_promedio = round(mean(medicion, na.rm = TRUE), 2),\n  anomalias_total = sum(severidad_anomalia != \"NORMAL\")\n), by = .(ubicacion, tipo_sensor)]\n\n# Formato wide para comparación\ntendencias_wide &lt;- dcast(tendencias_tipo,\n                        ubicacion ~ tipo_sensor,\n                        value.var = \"tendencia_promedio\")\n\ncat(\"\\n📈 TENDENCIAS PROMEDIO POR UBICACIÓN (24h):\\n\")\n#&gt; \n#&gt; 📈 TENDENCIAS PROMEDIO POR UBICACIÓN (24h):\nprint(tendencias_wide)\n#&gt; Key: &lt;ubicacion&gt;\n#&gt;        ubicacion sensor_humedad sensor_presion sensor_temp\n#&gt;           &lt;char&gt;          &lt;num&gt;          &lt;num&gt;       &lt;num&gt;\n#&gt; 1: Planta_Centro        -0.0194        -0.7440     -0.0484\n#&gt; 2:  Planta_Norte        -0.7072        -0.4502     -0.0448\n#&gt; 3:    Planta_Sur         0.5846         0.5512     -0.0688\n\n# Recomendaciones automáticas\ncat(\"\\n💡 RECOMENDACIONES AUTOMÁTICAS:\\n\")\n#&gt; \n#&gt; 💡 RECOMENDACIONES AUTOMÁTICAS:\n\n# Sensores con más anomalías\nsensores_problematicos &lt;- sensores_con_anomalias[, .(\n  anomalias = sum(severidad_anomalia != \"NORMAL\")\n), by = .(ubicacion, tipo_sensor, numero_sensor)][anomalias &gt; 0][order(-anomalias)]\n\nif(nrow(sensores_problematicos) &gt; 0) {\n  top_problematico &lt;- sensores_problematicos[1]\n  cat(\"• Revisar sensor\", paste(top_problematico$tipo_sensor, top_problematico$numero_sensor), \n      \"en\", top_problematico$ubicacion, \"con\", top_problematico$anomalias, \"anomalías\\n\")\n}\n#&gt; • Revisar sensor sensor_presion 1 en Planta_Centro con 15 anomalías\n\n# Ubicación con más problemas\nubicacion_problemas &lt;- sensores_con_anomalias[, .(\n  anomalias_total = sum(severidad_anomalia != \"NORMAL\")\n), by = ubicacion][order(-anomalias_total)]\n\nif(nrow(ubicacion_problemas) &gt; 0 && ubicacion_problemas[1, anomalias_total] &gt; 0) {\n  cat(\"• Priorizar mantenimiento en\", ubicacion_problemas[1, ubicacion], \n      \"con\", ubicacion_problemas[1, anomalias_total], \"anomalías totales\\n\")\n}\n#&gt; • Priorizar mantenimiento en Planta_Centro con 39 anomalías totales\n\ncat(\"• Siguiente revisión recomendada: en 6 horas\\n\")\n#&gt; • Siguiente revisión recomendada: en 6 horas\n\n# # Tabla interactiva de alertas críticas (comentado para PDF)\n# if(nrow(alertas_criticas) &gt; 0) {\n#   DT::datatable(\n#     alertas_criticas[, .(ubicacion, tipo_sensor, numero_sensor, timestamp, \n#                         medicion, severidad_anomalia, score_anomalia)],\n#     caption = \"Alertas Críticas del Sistema de Sensores\",\n#     options = list(pageLength = 10, scrollX = TRUE)\n#   ) %&gt;%\n#     DT::formatStyle(\n#       \"severidad_anomalia\",\n#       backgroundColor = DT::styleEqual(\n#         c(\"CRÍTICA\", \"ALTA\", \"MEDIA\", \"BAJA\"),\n#         c(\"red\", \"orange\", \"yellow\", \"lightblue\")\n#       )\n#     ) %&gt;%\n#     DT::formatRound(\"medicion\", digits = 2)\n# }",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Remodelación de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#mejores-prácticas-para-reshape",
    "href": "cap03-reshape.html#mejores-prácticas-para-reshape",
    "title": "\n8  Remodelación de Datos: melt() y dcast()\n",
    "section": "\n8.6 Mejores Prácticas para Reshape",
    "text": "8.6 Mejores Prácticas para Reshape\n\n8.6.1 1. Cuándo Usar Cada Técnica\n\n\n# ✅ Usar melt() cuando:\n# - Necesitas análisis estadístico o visualización con ggplot2\n# - Quieres aplicar funciones por grupos de variables\n# - Los datos vienen de Excel/reportes en formato ancho\ndatos_para_analisis &lt;- melt(datos_wide, id.vars = \"identificador\")\n\n# ✅ Usar dcast() cuando:  \n# - Necesitas crear reportes ejecutivos o dashboards\n# - Quieres matrices de correlación o contingencia\n# - Necesitas format de \"tabla dinámica\" para presentación\nreporte_ejecutivo &lt;- dcast(datos_long, fila ~ columna, value.var = \"valor\")\n\n# ✅ Combinar ambos para:\n# - Pipelines de transformación complejos\n# - Análisis que requieren múltiples vistas de los mismos datos\npipeline_completo &lt;- datos %&gt;% melt(...) %&gt;% \n  enriquecer(...) %&gt;% dcast(...)\n\n\n8.6.2 2. Performance y Memoria\n\n\n# ✅ HACER: Especificar measure.vars explícitamente\nmelt(dt, measure.vars = c(\"col1\", \"col2\", \"col3\"))  # Más rápido\n\n# ❌ EVITAR: Melt sin especificar columnas\nmelt(dt)  # Puede incluir columnas no deseadas\n\n# ✅ HACER: Usar patterns() para múltiples tipos de variables  \nmelt(dt, measure = patterns(\"^bonus_\", \"^eval_\"))\n\n# ✅ HACER: Limpiar datos después de reshape\ndatos_melted[, columna_temp := NULL]  # Eliminar columnas temporales\n\n\n8.6.3 3. Manejo de Valores Faltantes\n\n\n# ✅ Control de NAs en dcast\ndcast(dt, row ~ col, value.var = \"val\", fill = 0)  # Llenar con 0\ndcast(dt, row ~ col, value.var = \"val\", drop = FALSE)  # Mantener combinaciones vacías\n\n# ✅ Manejo de NAs después de melt\ndatos_melted[!is.na(value)]  # Filtrar NAs\ndatos_melted[, value := nafill(value, fill = 0)]  # Llenar NAs\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nmelt() convierte datos anchos a largos - esencial para análisis estadístico y visualización\n\ndcast() convierte datos largos a anchos - perfecto para reportes y dashboards ejecutivos\n\n\nPatrones complejos con patterns() permiten reshape de múltiples tipos de variables simultáneamente\n\nFunciones de agregación en dcast() crean resúmenes poderosos durante el reshape\n\nCombinar ambas técnicas permite pipelines de transformación muy sofisticados\n\nPerformance: Especificar columnas explícitamente mejora velocidad y memoria\n\n\n\n[{“content”: “Reorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos”, “status”: “completed”, “id”: “1”}, {“content”: “Crear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1”, “status”: “completed”, “id”: “1-new”}, {“content”: “Reorganizar M0f3dulo 2: dividir en encadenamiento y joins”, “status”: “completed”, “id”: “2”}, {“content”: “Crear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3”, “status”: “completed”, “id”: “3-1”}, {“content”: “Crear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3”, “status”: “completed”, “id”: “3-2”}, {“content”: “Crear cap03-reshape.qmd para reshape del M0f3dulo 3”, “status”: “completed”, “id”: “3-3”}, {“content”: “Reorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas”, “status”: “in_progress”, “id”: “4”}, {“content”: “Reorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones”, “status”: “pending”, “id”: “5”}]",
    "crumbs": [
      "**Módulo 3**: Técnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Remodelación de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html",
    "href": "cap04-performance.html",
    "title": "\n9  Optimización de Performance\n",
    "section": "",
    "text": "9.1 Configuración de Threading para Múltiples Núcleos\nEl threading automático de data.table puede acelerar dramáticamente las operaciones en máquinas multi-core.",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimización de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#configuración-de-threading-para-múltiples-núcleos",
    "href": "cap04-performance.html#configuración-de-threading-para-múltiples-núcleos",
    "title": "\n9  Optimización de Performance\n",
    "section": "",
    "text": "9.1.1 1. Configuración Óptima de Threads\n\n\n# Evaluar configuración del sistema\ncat(\"=== CONFIGURACIÓN DEL SISTEMA ===\\n\")\n#&gt; === CONFIGURACIÓN DEL SISTEMA ===\ncat(\"CPU cores disponibles:\", parallel::detectCores(), \"\\n\")\n#&gt; CPU cores disponibles: 16\ncat(\"CPU cores con hyperthreading:\", parallel::detectCores(logical = TRUE), \"\\n\")\n#&gt; CPU cores con hyperthreading: 16\ncat(\"Threads configurados en data.table:\", getDTthreads(), \"\\n\")\n#&gt; Threads configurados en data.table: 8\n\n# Función para determinar configuración óptima\ndetermine_optimal_threads &lt;- function() {\n  max_cores &lt;- parallel::detectCores(logical = FALSE)  # Cores físicos\n  \n  if(max_cores &lt;= 2) {\n    return(max_cores)\n  } else if(max_cores &lt;= 4) {\n    return(max_cores)\n  } else if(max_cores &lt;= 8) {\n    return(max_cores - 1)  # Dejar un core libre\n  } else {\n    return(min(8, max_cores - 2))  # Para sistemas muy grandes, no usar todos\n  }\n}\n\noptimal_threads &lt;- determine_optimal_threads()\ncat(\"Configuración recomendada:\", optimal_threads, \"threads\\n\")\n#&gt; Configuración recomendada: 7 threads\n\n# Aplicar configuración óptima\nsetDTthreads(optimal_threads)\ncat(\"Configuración aplicada:\", getDTthreads(), \"threads\\n\")\n#&gt; Configuración aplicada: 7 threads\n\n\n9.1.2 2. Benchmark de Threading Performance\n\n\n# Función para benchmark con diferentes configuraciones de threads\nbenchmark_threading &lt;- function(n_threads, dataset_size = 500000) {\n  setDTthreads(n_threads)\n  dt_sample &lt;- big_dataset[sample(.N, dataset_size)]\n  \n  # Operaciones que se benefician del threading\n  tiempo_agregacion &lt;- system.time({\n    result_agg &lt;- dt_sample[, .(\n      mean_value = mean(value_numeric),\n      sum_amount = sum(amount),\n      count_records = .N,\n      median_value = median(value_numeric)\n    ), by = .(group_major, group_minor)]\n  })\n  \n  tiempo_sort &lt;- system.time({\n    result_sort &lt;- dt_sample[order(-value_numeric, group_major)]\n  })\n  \n  return(list(\n    threads = n_threads,\n    agregacion = tiempo_agregacion[3],\n    ordenamiento = tiempo_sort[3],\n    total = tiempo_agregacion[3] + tiempo_sort[3]\n  ))\n}\n\n# Comparar diferentes configuraciones\nconfiguraciones_threads &lt;- c(1, 2, 4, min(8, parallel::detectCores()))\nresultados_threads &lt;- list()\n\ncat(\"=== BENCHMARK DE THREADING ===\\n\")\n#&gt; === BENCHMARK DE THREADING ===\nfor(i in seq_along(configuraciones_threads)) {\n  n_threads &lt;- configuraciones_threads[i]\n  cat(\"Probando con\", n_threads, \"thread(s)... \")\n  \n  resultado &lt;- benchmark_threading(n_threads, 300000)  # Dataset más pequeño para rapidez\n  resultados_threads[[i]] &lt;- resultado\n  \n  cat(\"Agregación:\", round(resultado$agregacion, 3), \"s, \",\n      \"Ordenamiento:\", round(resultado$ordenamiento, 3), \"s, \",\n      \"Total:\", round(resultado$total, 3), \"s\\n\")\n}\n#&gt; Probando con 1 thread(s)... Agregación: 0 s,  Ordenamiento: 0.01 s,  Total: 0.01 s\n#&gt; Probando con 2 thread(s)... Agregación: 0.02 s,  Ordenamiento: 0.02 s,  Total: 0.04 s\n#&gt; Probando con 4 thread(s)... Agregación: 0.02 s,  Ordenamiento: 0.02 s,  Total: 0.04 s\n#&gt; Probando con 8 thread(s)... Agregación: 0 s,  Ordenamiento: 0.01 s,  Total: 0.01 s\n\n# Crear tabla de resultados\ntabla_threads &lt;- rbindlist(resultados_threads)\nprint(\"\\nComparación de performance por número de threads:\")\n#&gt; [1] \"\\nComparación de performance por número de threads:\"\nprint(tabla_threads)\n#&gt;    threads agregacion ordenamiento total\n#&gt;      &lt;num&gt;      &lt;num&gt;        &lt;num&gt; &lt;num&gt;\n#&gt; 1:       1       0.00         0.01  0.01\n#&gt; 2:       2       0.02         0.02  0.04\n#&gt; 3:       4       0.02         0.02  0.04\n#&gt; 4:       8       0.00         0.01  0.01\n\n# Calcular speedup relativo al baseline (1 thread)\nbaseline &lt;- tabla_threads[threads == 1, total]\ntabla_threads[, speedup := round(baseline / total, 2)]\nprint(\"\\nSpeedup relativo (vs 1 thread):\")\n#&gt; [1] \"\\nSpeedup relativo (vs 1 thread):\"\nprint(tabla_threads[, .(threads, total, speedup)])\n#&gt;    threads total speedup\n#&gt;      &lt;num&gt; &lt;num&gt;   &lt;num&gt;\n#&gt; 1:       1  0.01    1.00\n#&gt; 2:       2  0.04    0.25\n#&gt; 3:       4  0.04    0.25\n#&gt; 4:       8  0.01    1.00\n\n# Restaurar configuración óptima\nsetDTthreads(optimal_threads)",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimización de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#keys-e-índices-la-base-de-la-velocidad",
    "href": "cap04-performance.html#keys-e-índices-la-base-de-la-velocidad",
    "title": "\n9  Optimización de Performance\n",
    "section": "\n9.2 Keys e Índices: La Base de la Velocidad",
    "text": "9.2 Keys e Índices: La Base de la Velocidad\n\n9.2.1 1. Setkey: Ordenamiento Físico para Velocidad\n\n\n# Comparar performance con y sin keys\ndt_no_key &lt;- copy(big_dataset[sample(.N, 500000)])\ndt_with_key &lt;- copy(dt_no_key)\n\ncat(\"=== COMPARACIÓN SETKEY ===\\n\")\n#&gt; === COMPARACIÓN SETKEY ===\n\n# Tiempo para establecer key\ntiempo_setkey &lt;- system.time(setkey(dt_with_key, group_major, group_minor))\ncat(\"Tiempo para establecer key:\", round(tiempo_setkey[3], 3), \"segundos\\n\")\n#&gt; Tiempo para establecer key: 0.02 segundos\n\n# Comparar búsquedas simples\nvalores_busqueda &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\")\nsub_valores &lt;- c(\"a\", \"b\", \"c\")\n\ntiempo_sin_key &lt;- system.time({\n  result_no_key &lt;- dt_no_key[group_major %in% valores_busqueda & group_minor %in% sub_valores]\n})\n\ntiempo_con_key &lt;- system.time({\n  result_with_key &lt;- dt_with_key[.(valores_busqueda, sub_valores)]\n})\n\ncat(\"Búsqueda sin key:\", round(tiempo_sin_key[3], 4), \"segundos\\n\")\n#&gt; Búsqueda sin key: 0.02 segundos\ncat(\"Búsqueda con key:\", round(tiempo_con_key[3], 4), \"segundos\\n\")\n#&gt; Búsqueda con key: 0 segundos\ncat(\"Speedup:\", round(tiempo_sin_key[3] / tiempo_con_key[3], 1), \"x más rápido\\n\")\n#&gt; Speedup: Inf x más rápido\n\n# Verificar que ambos resultados son equivalentes\ncat(\"Resultados equivalentes:\", nrow(result_no_key) == nrow(result_with_key), \"\\n\")\n#&gt; Resultados equivalentes: FALSE\n\n\n9.2.2 2. Múltiples Keys para Diferentes Patrones de Consulta\n\n\n# Crear múltiples copias para diferentes estrategias de indexing\ndt_by_group &lt;- copy(big_dataset[sample(.N, 300000)])\ndt_by_time &lt;- copy(dt_by_group)\ndt_by_id &lt;- copy(dt_by_group)\n\n# Establecer diferentes keys según el patrón de uso\nsetkey(dt_by_group, group_major, group_minor)\nsetkey(dt_by_time, timestamp)\nsetkey(dt_by_id, id)\n\ncat(\"=== ESTRATEGIAS DE KEYS ===\\n\")\n#&gt; === ESTRATEGIAS DE KEYS ===\ncat(\"dt_by_group key:\", paste(key(dt_by_group), collapse = \", \"), \"\\n\")\n#&gt; dt_by_group key: group_major, group_minor\ncat(\"dt_by_time key:\", paste(key(dt_by_time), collapse = \", \"), \"\\n\")\n#&gt; dt_by_time key: timestamp\ncat(\"dt_by_id key:\", paste(key(dt_by_id), collapse = \", \"), \"\\n\\n\")\n#&gt; dt_by_id key: id\n\n# Consultas optimizadas según la key\ncat(\"Consultando por grupos...\\n\")\n#&gt; Consultando por grupos...\ntiempo_grupo &lt;- system.time({\n  result_grupo &lt;- dt_by_group[.(\"A\", c(\"a\", \"b\", \"c\"))]\n})\n\ncat(\"Consultando por tiempo...\\n\") \n#&gt; Consultando por tiempo...\ntiempo_temporal &lt;- system.time({\n  result_temporal &lt;- dt_by_time[timestamp &gt;= as.POSIXct(\"2024-01-01\") & \n                               timestamp &lt; as.POSIXct(\"2024-02-01\")]\n})\n\ncat(\"Consultando por IDs...\\n\")\n#&gt; Consultando por IDs...\nids_especificos &lt;- sample(1:1000000, 1000)\ntiempo_ids &lt;- system.time({\n  result_ids &lt;- dt_by_id[.(ids_especificos)]\n})\n\ncat(\"Tiempos de consulta optimizada:\\n\")\n#&gt; Tiempos de consulta optimizada:\ncat(\"• Por grupos:\", round(tiempo_grupo[3], 4), \"segundos\\n\")\n#&gt; • Por grupos: 0 segundos\ncat(\"• Por tiempo:\", round(tiempo_temporal[3], 4), \"segundos\\n\") \n#&gt; • Por tiempo: 0 segundos\ncat(\"• Por IDs:\", round(tiempo_ids[3], 4), \"segundos\\n\")\n#&gt; • Por IDs: 0 segundos\n\n\n9.2.3 3. Índices Secundarios con setindex()\n\n\n# Crear tabla con key principal e índices secundarios\ndt_indexed &lt;- copy(big_dataset[sample(.N, 400000)])\nsetkey(dt_indexed, group_major)  # Key principal\n\ncat(\"=== ÍNDICES SECUNDARIOS ===\\n\")\n#&gt; === ÍNDICES SECUNDARIOS ===\n\n# Crear índices secundarios para consultas frecuentes\ncat(\"Creando índices secundarios...\\n\")\n#&gt; Creando índices secundarios...\ntiempo_indices &lt;- system.time({\n  setindex(dt_indexed, category)\n  setindex(dt_indexed, status)\n  setindex(dt_indexed, region)\n  setindex(dt_indexed, timestamp)\n  setindex(dt_indexed, id, value_numeric)  # Índice compuesto\n})\n\ncat(\"Tiempo para crear índices:\", round(tiempo_indices[3], 3), \"segundos\\n\")\n#&gt; Tiempo para crear índices: 0.01 segundos\ncat(\"Índices creados:\", length(indices(dt_indexed)), \"\\n\")\n#&gt; Índices creados: 5\nprint(indices(dt_indexed))\n#&gt; [1] \"category\"          \"status\"            \"region\"           \n#&gt; [4] \"timestamp\"         \"id__value_numeric\"\n\n# Comparar consultas con y sin índices\ndt_sin_indices &lt;- copy(big_dataset[sample(.N, 400000)])\n\n# Consulta que puede usar índice\ncat(\"\\nComparando consultas por categoría:\\n\")\n#&gt; \n#&gt; Comparando consultas por categoría:\ntiempo_sin_indice &lt;- system.time({\n  result_sin_indice &lt;- dt_sin_indices[category == \"Cat_5\" & status == \"Active\"]\n})\n\ntiempo_con_indice &lt;- system.time({\n  result_con_indice &lt;- dt_indexed[category == \"Cat_5\" & status == \"Active\"]\n})\n\ncat(\"Sin índice:\", round(tiempo_sin_indice[3], 4), \"segundos\\n\")\n#&gt; Sin índice: 0 segundos\ncat(\"Con índice:\", round(tiempo_con_indice[3], 4), \"segundos\\n\")\n#&gt; Con índice: 0 segundos\ncat(\"Speedup:\", round(tiempo_sin_indice[3] / tiempo_con_indice[3], 1), \"x\\n\")\n#&gt; Speedup: NaN x",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimización de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#profiling-y-benchmarking-sistemático",
    "href": "cap04-performance.html#profiling-y-benchmarking-sistemático",
    "title": "\n9  Optimización de Performance\n",
    "section": "\n9.3 Profiling y Benchmarking Sistemático",
    "text": "9.3 Profiling y Benchmarking Sistemático\n\n9.3.1 1. Modo Verbose para Análisis Detallado\n\n\n# Activar modo verbose para operaciones específicas\nverbose_analysis &lt;- function(dt, operation_name, operation_func) {\n  cat(\"=== ANÁLISIS:\", operation_name, \"===\\n\")\n  \n  # Activar verbose temporalmente\n  old_verbose &lt;- getOption(\"datatable.verbose\")\n  options(datatable.verbose = TRUE)\n  \n  # Ejecutar operación\n  start_time &lt;- Sys.time()\n  result &lt;- operation_func(dt)\n  end_time &lt;- Sys.time()\n  \n  # Restaurar verbose\n  options(datatable.verbose = old_verbose)\n  \n  cat(\"Tiempo total:\", round(as.numeric(end_time - start_time), 4), \"segundos\\n\")\n  cat(\"Filas resultado:\", nrow(result), \"\\n\\n\")\n  \n  return(result)\n}\n\n# Ejemplo de análisis con verbose\ndt_sample &lt;- big_dataset[sample(.N, 100000)]\n\n# Operación compleja para analizar\nresultado_verbose &lt;- verbose_analysis(dt_sample, \"Agregación Compleja\", function(dt) {\n  dt[status %in% c(\"Active\", \"Completed\"), \n     .(avg_value = mean(value_numeric),\n       sum_amount = sum(amount),\n       count = .N,\n       median_amount = median(amount)), \n     by = .(group_major, category)]\n})\n#&gt; === ANÁLISIS: Agregación Compleja ===\n#&gt; Creando nuevo índice 'status'\n#&gt; Creación de índice status finalizó en ...&lt;forder.c&gt;: recibió 100000 filas y 10 columnas\n#&gt; forderReuseSorting: opt=-1, tomó 0.001s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Se optimizó la selección de subconjunto con índice 'status'\n#&gt; &lt;forder.c&gt;: recibió 2 filas y 1 columnas\n#&gt; forderReuseSorting: opt=-1, tomó 0.000s\n#&gt; forder tomó 0.000 seg\n#&gt; x ya está ordenado por estas columnas, no se requiere 'reorder'\n#&gt; i.status tiene el mismo tipo (character) que x.status. No se requiere coerción.\n#&gt; on= coincide con índice existente, usando índice\n#&gt; Inidiando bmerge ...\n#&gt; forderReuseSorting: usando key: __status\n#&gt; forderReuseSorting: opt=1, tomó 0.001s\n#&gt; bmerge: bucle bmerge_r tomó 0.000s\n#&gt; bmerge: tomó 0.001s\n#&gt; bmerge finalizado en 0.000s elapsed (0.000s cpu)\n#&gt; Construyendo irows para '!byjoin || nqbyjoin' ... 0.000s elapsed (0.000s cpu) \n#&gt; Reordenar 49856 filas luego de bmerge finalizó en ... forderReuseSorting: opt no posible: is.data.table(DT)=0, sortGroups=1, all1(ascArg)=1\n#&gt; &lt;forder.c&gt;: recibió un tipo de vector 'integer' de longitud 49856\n#&gt; forderReuseSorting: opt=0, tomó 0.001s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; cláusula 'i' presente y se detectaron las columnas usadas en by, sólo este subconjunto: [group_major, category]\n#&gt; Se detectó que j usa estas columnas: [value_numeric, amount]\n#&gt; Buscando grupos conn forderv ... forderReuseSorting: opt no posible: is.data.table(DT)=0, sortGroups=0, all1(ascArg)=1\n#&gt; &lt;forder.c&gt;: recibió 49856 filas y 2 columnas\n#&gt; forderReuseSorting: opt=0, tomó 0.000s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Buscando tamaño de grupos a partir de la posición (se puede omitir para ahorrar RAM) ... 0.000s elapsed (0.000s cpu) \n#&gt; Restaurando orden original ... forderReuseSorting: opt no posible: is.data.table(DT)=0, sortGroups=1, all1(ascArg)=1\n#&gt; &lt;forder.c&gt;: recibió un tipo de vector 'integer' de longitud 540\n#&gt; forderReuseSorting: opt=0, tomó 0.001s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Optimización de lapply activada, j sin cambios: 'list(mean(value_numeric), sum(amount), .N, median(amount))'\n#&gt; Optimización GForce de j: 'list(gmean(value_numeric), gsum(amount), .N, gmedian(amount))' (see ?GForce)\n#&gt; Generando grupos y ejecutando j en cada uno (GForce TRUE) ... gforce población inicial de grp tomó 0.000\n#&gt; asignación gforce high y low tomó 0.000\n#&gt; Este gmean tomó (narm=FALSE)... la recopilación tomó  0.000s\n#&gt; 0.000s\n#&gt; Este gsum (narm=FALSE) tomó... la recopilación tomó  0.000s\n#&gt; 0.000s\n#&gt; la evaluación de gforce tomó 0.001\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Tiempo total: 0.1081 segundos\n#&gt; Filas resultado: 540\n\nprint(head(resultado_verbose))\n#&gt;    group_major category avg_value sum_amount count median_amount\n#&gt;         &lt;char&gt;   &lt;char&gt;     &lt;num&gt;      &lt;num&gt; &lt;int&gt;         &lt;num&gt;\n#&gt; 1:           A    Cat_1 100.70722   28843.49    51        148.84\n#&gt; 2:        &lt;NA&gt;   Cat_14 101.44601  668919.82  1237        158.52\n#&gt; 3:           R   Cat_17  98.79088   21923.92    59         90.07\n#&gt; 4:        &lt;NA&gt;   Cat_16 100.60555  590698.94  1215        147.68\n#&gt; 5:           E    Cat_3  95.65443   34422.37    53        216.94\n#&gt; 6:        &lt;NA&gt;    Cat_7 101.14619  520769.40  1213        150.37\n\n\n9.3.2 2. Benchmarking Comparativo de Estrategias\n\n\n# Crear función de benchmark comprehensiva\nbenchmark_comprehensive &lt;- function(dt_size = 200000) {\n  dt_test &lt;- big_dataset[sample(.N, dt_size)]\n  \n  # Estrategia 1: Sin optimizaciones\n  strategy1 &lt;- function() {\n    dt_test[group_major %in% c(\"A\", \"B\", \"C\") & status == \"Active\",\n           .(mean_val = mean(value_numeric), \n             sum_amount = sum(amount),\n             count = .N),\n           by = .(group_minor, category)]\n  }\n  \n  # Estrategia 2: Con setkey optimizado\n  dt_keyed &lt;- copy(dt_test)\n  setkey(dt_keyed, group_major, group_minor)\n  strategy2 &lt;- function() {\n    dt_keyed[.(c(\"A\", \"B\", \"C\"))][status == \"Active\",\n            .(mean_val = mean(value_numeric),\n              sum_amount = sum(amount), \n              count = .N),\n            by = .(group_minor, category)]\n  }\n  \n  # Estrategia 3: Pre-filtrar luego agrupar\n  strategy3 &lt;- function() {\n    dt_filtered &lt;- dt_test[group_major %in% c(\"A\", \"B\", \"C\") & status == \"Active\"]\n    dt_filtered[, .(mean_val = mean(value_numeric),\n                   sum_amount = sum(amount),\n                   count = .N),\n               by = .(group_minor, category)]\n  }\n  \n  # Estrategia 4: Con índices secundarios\n  dt_indexed &lt;- copy(dt_test)\n  setindex(dt_indexed, group_major)\n  setindex(dt_indexed, status)\n  strategy4 &lt;- function() {\n    dt_indexed[group_major %in% c(\"A\", \"B\", \"C\") & status == \"Active\",\n              .(mean_val = mean(value_numeric),\n                sum_amount = sum(amount),\n                count = .N),\n              by = .(group_minor, category)]\n  }\n  \n  # Ejecutar benchmark\n  benchmark_result &lt;- microbenchmark(\n    \"Sin optimizar\" = strategy1(),\n    \"Con setkey\" = strategy2(),\n    \"Pre-filtrar\" = strategy3(), \n    \"Con índices\" = strategy4(),\n    times = 10\n  )\n  \n  return(benchmark_result)\n}\n\n# Ejecutar benchmark comprehensivo\ncat(\"=== BENCHMARK COMPREHENSIVO DE ESTRATEGIAS ===\\n\")\n#&gt; === BENCHMARK COMPREHENSIVO DE ESTRATEGIAS ===\nbenchmark_result &lt;- benchmark_comprehensive(150000)\nprint(benchmark_result)\n#&gt; Unit: milliseconds\n#&gt;           expr    min     lq    mean  median     uq    max neval\n#&gt;  Sin optimizar 2.1022 2.1491 2.28405 2.21155 2.3934 2.5935    10\n#&gt;     Con setkey 2.5918 2.7351 3.01076 2.95595 3.1528 3.8886    10\n#&gt;    Pre-filtrar 2.2044 2.4296 3.00480 2.75425 3.1098 4.5300    10\n#&gt;    Con índices 2.1676 2.3223 2.51195 2.41860 2.4670 3.7775    10\n\n# Crear visualización si ggplot2 está disponible\nif(require(ggplot2, quietly = TRUE)) {\n  plot_benchmark &lt;- autoplot(benchmark_result) +\n    labs(title = \"Comparación de Estrategias de Optimización\",\n         subtitle = \"Menor tiempo = mejor performance\",\n         y = \"Tiempo (milisegundos)\",\n         x = \"Estrategia\") +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  \n  print(plot_benchmark)\n}\n\n\n\n\n\n\n\n# Análisis de resultados\nsummary_benchmark &lt;- summary(benchmark_result)\nprint(\"\\nResumen de performance:\")\n#&gt; [1] \"\\nResumen de performance:\"\nprint(summary_benchmark)\n#&gt;            expr    min     lq    mean  median     uq    max neval\n#&gt; 1 Sin optimizar 2.1022 2.1491 2.28405 2.21155 2.3934 2.5935    10\n#&gt; 2    Con setkey 2.5918 2.7351 3.01076 2.95595 3.1528 3.8886    10\n#&gt; 3   Pre-filtrar 2.2044 2.4296 3.00480 2.75425 3.1098 4.5300    10\n#&gt; 4   Con índices 2.1676 2.3223 2.51195 2.41860 2.4670 3.7775    10\n\n# Calcular speedup relativo\nbaseline_median &lt;- summary_benchmark[summary_benchmark$expr == \"Sin optimizar\", \"median\"]\nsummary_benchmark$speedup &lt;- round(baseline_median / summary_benchmark$median, 2)\nprint(\"\\nSpeedup relativo (vs sin optimizar):\")\n#&gt; [1] \"\\nSpeedup relativo (vs sin optimizar):\"\nprint(summary_benchmark[, c(\"expr\", \"median\", \"speedup\")])\n#&gt;            expr  median speedup\n#&gt; 1 Sin optimizar 2.21155    1.00\n#&gt; 2    Con setkey 2.95595    0.75\n#&gt; 3   Pre-filtrar 2.75425    0.80\n#&gt; 4   Con índices 2.41860    0.91\n\n\n9.3.3 3. Memory Profiling Avanzado\n\n\n# Función para análisis detallado de memoria\nmemory_analysis &lt;- function(operation_name, operation_func, dt_input) {\n  cat(\"=== ANÁLISIS DE MEMORIA:\", operation_name, \"===\\n\")\n  \n  # Limpiar garbage collector\n  invisible(gc(verbose = FALSE))\n  \n  # Memoria antes\n  mem_before &lt;- as.numeric(object.size(dt_input))\n  \n  # Ejecutar operación y medir tiempo\n  start_time &lt;- Sys.time()\n  result &lt;- operation_func(dt_input)\n  end_time &lt;- Sys.time()\n  \n  # Memoria después\n  mem_after &lt;- as.numeric(object.size(dt_input))\n  mem_result &lt;- as.numeric(object.size(result))\n  \n  # Reportar resultados\n  cat(\"Tiempo de ejecución:\", round(as.numeric(end_time - start_time), 4), \"segundos\\n\")\n  cat(\"Memoria input:\", format(mem_before, units = \"auto\"), \"\\n\")\n  cat(\"Memoria después:\", format(mem_after, units = \"auto\"), \"\\n\")\n  cat(\"Memoria resultado:\", format(mem_result, units = \"auto\"), \"\\n\")\n  cat(\"Cambio en memoria input:\", format(mem_after - mem_before, units = \"auto\"), \"\\n\")\n  cat(\"Eficiencia memoria:\", round(mem_result / mem_before * 100, 1), \"% del input\\n\\n\")\n  \n  return(result)\n}\n\n# Comparar diferentes operaciones\ndt_mem_test &lt;- big_dataset[sample(.N, 100000)]\n\n# Operación 1: Modificación por referencia\nresult1 &lt;- memory_analysis(\"Modificación por referencia\", function(dt) {\n  dt[, new_computed_col := value_numeric * amount * 1.1]\n  return(dt)\n}, copy(dt_mem_test))\n#&gt; === ANÁLISIS DE MEMORIA: Modificación por referencia ===\n#&gt; Tiempo de ejecución: 7e-04 segundos\n#&gt; Memoria input: 7207216 \n#&gt; Memoria después: 8007424 \n#&gt; Memoria resultado: 8007424 \n#&gt; Cambio en memoria input: 800208 \n#&gt; Eficiencia memoria: 111.1 % del input\n\n# Operación 2: Crear nueva tabla\nresult2 &lt;- memory_analysis(\"Crear nueva tabla\", function(dt) {\n  dt[, .(id, group_major, value_numeric, amount, \n         new_computed_col = value_numeric * amount * 1.1)]\n}, dt_mem_test)\n#&gt; === ANÁLISIS DE MEMORIA: Crear nueva tabla ===\n#&gt; Tiempo de ejecución: 0.0012 segundos\n#&gt; Memoria input: 7207216 \n#&gt; Memoria después: 7207216 \n#&gt; Memoria resultado: 3603448 \n#&gt; Cambio en memoria input: 0 \n#&gt; Eficiencia memoria: 50 % del input\n\n# Operación 3: Agregación\nresult3 &lt;- memory_analysis(\"Agregación por grupos\", function(dt) {\n  dt[, .(mean_value = mean(value_numeric),\n         sum_amount = sum(amount),\n         count = .N), \n     by = .(group_major, group_minor)]\n}, dt_mem_test)\n#&gt; === ANÁLISIS DE MEMORIA: Agregación por grupos ===\n#&gt; Tiempo de ejecución: 0.003 segundos\n#&gt; Memoria input: 7207216 \n#&gt; Memoria después: 7207216 \n#&gt; Memoria resultado: 13712 \n#&gt; Cambio en memoria input: 0 \n#&gt; Eficiencia memoria: 0.2 % del input",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimización de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#optimización-de-operaciones-específicas",
    "href": "cap04-performance.html#optimización-de-operaciones-específicas",
    "title": "\n9  Optimización de Performance\n",
    "section": "\n9.4 Optimización de Operaciones Específicas",
    "text": "9.4 Optimización de Operaciones Específicas\n\n9.4.1 1. Joins a Gran Escala\n\n\n# Preparar datos para joins de diferentes tamaños\ndt_left_large &lt;- big_dataset[sample(.N, 200000)]\ndt_right_large &lt;- lookup_data[sample(.N, 100000)]\n\ncat(\"=== OPTIMIZACIÓN DE JOINS GRANDES ===\\n\")\n#&gt; === OPTIMIZACIÓN DE JOINS GRANDES ===\ncat(\"Tabla izquierda:\", nrow(dt_left_large), \"filas\\n\")\n#&gt; Tabla izquierda: 200000 filas\ncat(\"Tabla derecha:\", nrow(dt_right_large), \"filas\\n\\n\")\n#&gt; Tabla derecha: 100000 filas\n\n# Estrategia 1: Merge básico\ntiempo_merge &lt;- system.time({\n  result_merge &lt;- merge(dt_left_large, dt_right_large, by = \"id\", all.x = TRUE)\n})\n\n# Estrategia 2: Join con setkey\ndt_left_key &lt;- copy(dt_left_large)\ndt_right_key &lt;- copy(dt_right_large)\nsetkey(dt_left_key, id)\nsetkey(dt_right_key, id)\n\ntiempo_setkey_join &lt;- system.time({\n  result_setkey &lt;- dt_right_key[dt_left_key]\n})\n\n# Estrategia 3: Join con on= (sin modificar tablas originales)\ntiempo_on_join &lt;- system.time({\n  result_on &lt;- dt_left_large[dt_right_large, on = .(id)]\n})\n\n# Estrategia 4: Join filtrado (cuando sabemos que solo necesitamos subset)\nids_relevantes &lt;- intersect(dt_left_large$id, dt_right_large$id)[1:50000]\ntiempo_filtered_join &lt;- system.time({\n  dt_left_filtered &lt;- dt_left_large[id %in% ids_relevantes]\n  dt_right_filtered &lt;- dt_right_large[id %in% ids_relevantes]\n  result_filtered &lt;- merge(dt_left_filtered, dt_right_filtered, by = \"id\")\n})\n\n# Comparar resultados\ncat(\"Resultados de joins:\\n\")\n#&gt; Resultados de joins:\ncat(\"• Merge básico:\", round(tiempo_merge[3], 4), \"segundos,\", nrow(result_merge), \"filas\\n\")\n#&gt; • Merge básico: 0.03 segundos, 200000 filas\ncat(\"• Con setkey:\", round(tiempo_setkey_join[3], 4), \"segundos,\", nrow(result_setkey), \"filas\\n\")\n#&gt; • Con setkey: 0.02 segundos, 200000 filas\ncat(\"• Con on=:\", round(tiempo_on_join[3], 4), \"segundos,\", nrow(result_on), \"filas\\n\")\n#&gt; • Con on=: 0.01 segundos, 101800 filas\ncat(\"• Join filtrado:\", round(tiempo_filtered_join[3], 4), \"segundos,\", nrow(result_filtered), \"filas\\n\")\n#&gt; • Join filtrado: 0.01 segundos, 19881 filas\n\n# Mejor estrategia\ntiempos_join &lt;- c(tiempo_merge[3], tiempo_setkey_join[3], tiempo_on_join[3], tiempo_filtered_join[3])\nmejor_join &lt;- which.min(tiempos_join)\nestrategias_join &lt;- c(\"Merge básico\", \"Con setkey\", \"Con on=\", \"Join filtrado\")\ncat(\"\\nMejor estrategia:\", estrategias_join[mejor_join], \"\\n\")\n#&gt; \n#&gt; Mejor estrategia: Con on=\n\n\n9.4.2 2. Operaciones Temporales Optimizadas\n\n\n# Optimizar consultas en datos temporales\ndt_temporal &lt;- copy(temporal_dataset[sample(.N, 50000)])\n\ncat(\"=== OPTIMIZACIÓN DE CONSULTAS TEMPORALES ===\\n\")\n#&gt; === OPTIMIZACIÓN DE CONSULTAS TEMPORALES ===\n\n# Consulta 1: Rango de fechas sin optimizar\ntiempo_temporal_sin_key &lt;- system.time({\n  result_no_key &lt;- dt_temporal[timestamp &gt;= as.POSIXct(\"2024-06-01\") & \n                              timestamp &lt; as.POSIXct(\"2024-07-01\")]\n})\n\n# Consulta 2: Con key temporal\ndt_temporal_keyed &lt;- copy(dt_temporal)\nsetkey(dt_temporal_keyed, timestamp)\n\ntiempo_temporal_con_key &lt;- system.time({\n  inicio &lt;- as.POSIXct(\"2024-06-01\")\n  fin &lt;- as.POSIXct(\"2024-07-01\")\n  result_with_key &lt;- dt_temporal_keyed[timestamp %between% c(inicio, fin)]\n})\n\n# Consulta 3: Con rolling joins (para datos temporales complejos)\n# Simular eventos de referencia\neventos_ref &lt;- data.table(\n  event_time = seq(as.POSIXct(\"2024-06-01\"), as.POSIXct(\"2024-06-30\"), by = \"day\"),\n  event_type = sample(c(\"A\", \"B\", \"C\"), 30, replace = TRUE)\n)\nsetkey(eventos_ref, event_time)\n\ntiempo_rolling_join &lt;- system.time({\n  result_rolling &lt;- dt_temporal_keyed[eventos_ref, roll = TRUE]\n})\n\ncat(\"Resultados de consultas temporales:\\n\")\n#&gt; Resultados de consultas temporales:\ncat(\"• Sin key:\", round(tiempo_temporal_sin_key[3], 4), \"segundos,\", nrow(result_no_key), \"filas\\n\")\n#&gt; • Sin key: 0.02 segundos, 2039 filas\ncat(\"• Con key:\", round(tiempo_temporal_con_key[3], 4), \"segundos,\", nrow(result_with_key), \"filas\\n\")\n#&gt; • Con key: 0 segundos, 2039 filas\ncat(\"• Rolling join:\", round(tiempo_rolling_join[3], 4), \"segundos,\", nrow(result_rolling), \"filas\\n\")\n#&gt; • Rolling join: 0 segundos, 30 filas",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimización de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#casos-de-uso-de-optimización-extrema",
    "href": "cap04-performance.html#casos-de-uso-de-optimización-extrema",
    "title": "\n9  Optimización de Performance\n",
    "section": "\n9.5 Casos de Uso de Optimización Extrema",
    "text": "9.5 Casos de Uso de Optimización Extrema\n\n9.5.1 1. Pipeline de Análisis de Alto Rendimiento\n\n\n# Pipeline optimizado para análisis complejo\ncreate_optimized_pipeline &lt;- function(dt, sample_size = 100000) {\n  cat(\"=== PIPELINE DE ALTO RENDIMIENTO ===\\n\")\n  \n  # Paso 1: Muestreo estratificado eficiente\n  dt_sample &lt;- dt[, .SD[sample(min(.N, sample_size), sample_size)], by = region]\n  \n  # Paso 2: Establecer key óptima para operaciones posteriores\n  setkey(dt_sample, group_major, group_minor)\n  \n  # Paso 3: Cálculos intermedios optimizados (por referencia)\n  dt_sample[, `:=`(\n    value_normalized = scale(value_numeric)[,1],\n    amount_log = log1p(amount),  # log1p es más estable que log\n    efficiency_ratio = value_numeric / (amount + 1),\n    timestamp_hour = hour(timestamp)\n  )]\n  \n  # Paso 4: Agregaciones complejas usando .SD optimizado\n  result_aggregated &lt;- dt_sample[, \n    .(\n      # Estadísticas básicas\n      count = .N,\n      mean_value = mean(value_normalized, na.rm = TRUE),\n      median_amount = median(amount_log, na.rm = TRUE),\n      \n      # Estadísticas avanzadas\n      p95_efficiency = quantile(efficiency_ratio, 0.95, na.rm = TRUE),\n      cv_value = sd(value_normalized, na.rm = TRUE) / abs(mean(value_normalized, na.rm = TRUE)),\n      \n      # Análisis temporal\n      peak_hour = timestamp_hour[which.max(value_numeric)],\n      active_hours = uniqueN(timestamp_hour),\n      \n      # Diversidad\n      categories_used = uniqueN(category),\n      status_diversity = uniqueN(status)\n    ),\n    by = .(region, group_major),\n    .SDcols = c(\"value_normalized\", \"amount_log\", \"efficiency_ratio\", \n                \"timestamp_hour\", \"value_numeric\", \"category\", \"status\")\n  ]\n  \n  # Paso 5: Post-procesamiento optimizado\n  result_aggregated[, `:=`(\n    performance_score = round((mean_value + p95_efficiency) * log1p(count), 2),\n    complexity_index = categories_used * status_diversity * active_hours\n  )]\n  \n  # Paso 6: Ranking y clasificación final\n  result_aggregated[, rank_performance := frank(-performance_score), by = region]\n  result_aggregated[, tier := fcase(\n    rank_performance &lt;= 3, \"Tier_1\",\n    rank_performance &lt;= 10, \"Tier_2\", \n    rank_performance &lt;= 20, \"Tier_3\",\n    default = \"Tier_4\"\n  )]\n  \n  return(result_aggregated[order(-performance_score)])\n}\n\n# Ejecutar pipeline optimizado\ntiempo_pipeline &lt;- system.time({\n  resultado_pipeline &lt;- create_optimized_pipeline(big_dataset, 80000)\n})\n#&gt; === PIPELINE DE ALTO RENDIMIENTO ===\n\ncat(\"Tiempo total del pipeline:\", round(tiempo_pipeline[3], 3), \"segundos\\n\")\n#&gt; Tiempo total del pipeline: 0.22 segundos\ncat(\"Registros procesados: ~80,000 → \", nrow(resultado_pipeline), \"grupos finales\\n\")\n#&gt; Registros procesados: ~80,000 →  135 grupos finales\ncat(\"Reducción de datos:\", round((1 - nrow(resultado_pipeline)/80000) * 100, 1), \"%\\n\\n\")\n#&gt; Reducción de datos: 99.8 %\n\nprint(\"Top 10 grupos por performance:\")\n#&gt; [1] \"Top 10 grupos por performance:\"\nprint(resultado_pipeline[1:10, .(region, group_major, count, performance_score, tier)])\n#&gt;      region group_major count performance_score   tier\n#&gt;      &lt;char&gt;      &lt;char&gt; &lt;int&gt;             &lt;num&gt; &lt;char&gt;\n#&gt;  1:   North        &lt;NA&gt; 38443             79.25 Tier_1\n#&gt;  2:    East        &lt;NA&gt; 38482             78.27 Tier_1\n#&gt;  3:   South        &lt;NA&gt; 38511             77.88 Tier_1\n#&gt;  4:    West        &lt;NA&gt; 38478             77.56 Tier_1\n#&gt;  5: Central        &lt;NA&gt; 38371             76.97 Tier_1\n#&gt;  6: Central           N  1554             61.91 Tier_1\n#&gt;  7:    East           M  1647             61.90 Tier_1\n#&gt;  8:   North           Q  1641             61.34 Tier_1\n#&gt;  9:    West           G  1635             61.30 Tier_1\n#&gt; 10:   South           F  1590             61.00 Tier_1\n\n\n9.5.2 2. Sistema de Monitoreo de Performance en Tiempo Real\n\n\n# Sistema para monitorear performance de operaciones data.table\nperformance_monitor &lt;- function() {\n  # Crear registro de operaciones\n  operations_log &lt;- data.table(\n    operation_id = character(),\n    operation_type = character(),\n    dataset_size = integer(),\n    execution_time = numeric(),\n    memory_used = numeric(),\n    threads_used = integer(),\n    timestamp = .POSIXct(numeric())\n  )\n  \n  # Función para registrar operación\n  log_operation &lt;- function(op_type, dt_size, exec_time, mem_usage) {\n    new_entry &lt;- data.table(\n      operation_id = paste0(op_type, \"_\", format(Sys.time(), \"%H%M%S\")),\n      operation_type = op_type,\n      dataset_size = dt_size,\n      execution_time = exec_time,\n      memory_used = mem_usage,\n      threads_used = getDTthreads(),\n      timestamp = Sys.time()\n    )\n    operations_log &lt;&lt;- rbindlist(list(operations_log, new_entry), use.names = TRUE, fill = TRUE, ignore.attr = TRUE)\n  }\n  \n  # Función para analizar performance\n  analyze_performance &lt;- function() {\n    if(nrow(operations_log) == 0) {\n      cat(\"No hay operaciones registradas\\n\")\n      return(NULL)\n    }\n    \n    # Análisis por tipo de operación\n    performance_summary &lt;- operations_log[, .(\n      operations_count = .N,\n      avg_time = round(mean(execution_time), 4),\n      median_time = round(median(execution_time), 4),\n      max_time = round(max(execution_time), 4),\n      avg_memory = round(mean(memory_used), 0),\n      throughput_rows_per_sec = round(mean(dataset_size / execution_time), 0)\n    ), by = operation_type]\n    \n    return(performance_summary)\n  }\n  \n  return(list(log = log_operation, analyze = analyze_performance, get_log = function() operations_log))\n}\n\n# Inicializar sistema de monitoreo\nmonitor &lt;- performance_monitor()\n\n# Simular diferentes operaciones y monitorearlas\ndt_test &lt;- big_dataset[sample(.N, 50000)]\n\n# Operación 1: Agregación\ncat(\"Monitoreando operaciones:\\n\")\n#&gt; Monitoreando operaciones:\ntiempo_agg &lt;- system.time({\n  result_agg &lt;- dt_test[, .(mean_val = mean(value_numeric)), by = group_major]\n})\nmonitor$log(\"aggregation\", nrow(dt_test), tiempo_agg[3], object.size(result_agg))\n\n# Operación 2: Join\ntiempo_join &lt;- system.time({\n  result_join &lt;- dt_test[lookup_data[1:10000], on = .(id)]\n})\nmonitor$log(\"join\", nrow(dt_test), tiempo_join[3], object.size(result_join))\n\n# Operación 3: Sort\ntiempo_sort &lt;- system.time({\n  result_sort &lt;- dt_test[order(-value_numeric)]\n})\nmonitor$log(\"sort\", nrow(dt_test), tiempo_sort[3], object.size(result_sort))\n\n# Análisis de performance\ncat(\"\\n=== ANÁLISIS DE PERFORMANCE ===\\n\")\n#&gt; \n#&gt; === ANÁLISIS DE PERFORMANCE ===\nperformance_analysis &lt;- monitor$analyze()\nprint(performance_analysis)\n#&gt;    operation_type operations_count avg_time median_time max_time avg_memory\n#&gt;            &lt;char&gt;            &lt;int&gt;    &lt;num&gt;       &lt;num&gt;    &lt;num&gt;      &lt;num&gt;\n#&gt; 1:    aggregation                1     0.00        0.00     0.00       3256\n#&gt; 2:           join                1     0.28        0.28     0.28    1729416\n#&gt; 3:           sort                1     0.00        0.00     0.00    3607216\n#&gt;    throughput_rows_per_sec\n#&gt;                      &lt;num&gt;\n#&gt; 1:                     Inf\n#&gt; 2:                  178571\n#&gt; 3:                     Inf\n\n# Identificar operaciones problemáticas\nif(!is.null(performance_analysis)) {\n  problematic_ops &lt;- performance_analysis[avg_time &gt; median(avg_time) * 2]\n  if(nrow(problematic_ops) &gt; 0) {\n    cat(\"\\n⚠️ Operaciones con performance subóptima:\\n\")\n    print(problematic_ops)\n  } else {\n    cat(\"\\n✅ Todas las operaciones tienen performance aceptable\\n\")\n  }\n}\n#&gt; \n#&gt; ⚠️ Operaciones con performance subóptima:\n#&gt;    operation_type operations_count avg_time median_time max_time avg_memory\n#&gt;            &lt;char&gt;            &lt;int&gt;    &lt;num&gt;       &lt;num&gt;    &lt;num&gt;      &lt;num&gt;\n#&gt; 1:           join                1     0.28        0.28     0.28    1729416\n#&gt;    throughput_rows_per_sec\n#&gt;                      &lt;num&gt;\n#&gt; 1:                  178571",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimización de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#ejercicio-práctico-de-optimización",
    "href": "cap04-performance.html#ejercicio-práctico-de-optimización",
    "title": "\n9  Optimización de Performance\n",
    "section": "\n9.6 Ejercicio Práctico de Optimización",
    "text": "9.6 Ejercicio Práctico de Optimización\n\n\n\n\n\n\n🏋️ Ejercicio 15: Optimización Integral\n\n\n\nDado el siguiente código ineficiente, optimízalo usando todas las técnicas aprendidas:\n# Código INEFICIENTE para optimizar\nanalyze_data_slow &lt;- function(big_data, lookup) {\n  results &lt;- data.table()\n  \n  # Procesar cada región por separado\n  for(region in unique(big_data$region)) {\n    region_data &lt;- big_data[big_data$region == region, ]\n    \n    # Procesar cada grupo dentro de la región\n    for(group in unique(region_data$group_major)) {\n      group_data &lt;- region_data[region_data$group_major == group, ]\n      \n      # Cálculos por grupo\n      group_stats &lt;- data.frame(\n        region = region,\n        group = group,\n        count = nrow(group_data),\n        mean_value = mean(group_data$value_numeric),\n        sum_amount = sum(group_data$amount)\n      )\n      \n      # Join con lookup (ineficiente)\n      for(i in 1:nrow(group_stats)) {\n        matched_lookup &lt;- lookup[lookup$entity_type == \"Premium\", ]\n        if(nrow(matched_lookup) &gt; 0) {\n          group_stats$premium_factor[i] &lt;- mean(matched_lookup$weight_factor)\n        }\n      }\n      \n      results &lt;- rbind(results, group_stats)\n    }\n  }\n  \n  return(results)\n}\nOptimízalo para: 1. Eliminar todos los bucles 2. Usar operaciones vectorizadas 3. Implementar joins eficientes 4. Minimizar copias de memoria\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 15\n\n\n\n\n\n\n# Versión OPTIMIZADA\nanalyze_data_fast &lt;- function(big_data, lookup) {\n  \n  # Pre-calcular el premium_factor una sola vez\n  premium_factor &lt;- lookup[entity_type == \"Premium\", mean(weight_factor)]\n  \n  # Una sola operación vectorizada que reemplaza todos los bucles\n  result &lt;- big_data[, .(\n    count = .N,\n    mean_value = mean(value_numeric),\n    sum_amount = sum(amount),\n    premium_factor = premium_factor  # Usar valor pre-calculado\n  ), by = .(region, group = group_major)]\n  \n  return(result)\n}\n\n# Comparar performance\ndt_test_large &lt;- big_dataset[sample(.N, 20000)]  # Dataset más pequeño para el test\nlookup_test &lt;- lookup_data[sample(.N, 5000)]\n\ncat(\"=== COMPARACIÓN DE PERFORMANCE ===\\n\")\n#&gt; === COMPARACIÓN DE PERFORMANCE ===\n\n# Versión lenta (simulada de forma más rápida para el ejemplo)\ntiempo_lento &lt;- system.time({\n  # Simulamos la lógica ineficiente pero sin bucles extremos\n  result_slow &lt;- dt_test_large[, {\n    # Múltiples operaciones separadas (ineficiente)\n    temp_results &lt;- list()\n    for(i in seq_along(unique(group_major))) {\n      group_val &lt;- unique(group_major)[i]\n      group_subset &lt;- .SD[group_major == group_val]\n      temp_results[[i]] &lt;- data.table(\n        region = unique(region),\n        group = group_val,\n        count = nrow(group_subset),\n        mean_value = mean(group_subset$value_numeric),\n        sum_amount = sum(group_subset$amount),\n        premium_factor = lookup_test[entity_type == \"Premium\", mean(weight_factor)]\n      )\n    }\n    rbindlist(temp_results)\n  }, by = region]\n})\n\n# Versión optimizada\ntiempo_rapido &lt;- system.time({\n  result_fast &lt;- analyze_data_fast(dt_test_large, lookup_test)\n})\n\ncat(\"Método ineficiente (simulado):\", round(tiempo_lento[3], 4), \"segundos\\n\")\n#&gt; Método ineficiente (simulado): 0.11 segundos\ncat(\"Método optimizado:\", round(tiempo_rapido[3], 4), \"segundos\\n\")\n#&gt; Método optimizado: 0 segundos\ncat(\"Mejora de velocidad:\", round(tiempo_lento[3] / tiempo_rapido[3], 1), \"x más rápido\\n\")\n#&gt; Mejora de velocidad: Inf x más rápido\n\n# Verificar resultados equivalentes\ncat(\"Resultados similares:\", \n    nrow(result_slow) == nrow(result_fast), \n    all.equal(result_slow$count, result_fast$count), \"\\n\")\n#&gt; Resultados similares: TRUE Mean relative difference: 1.077508\n\nprint(\"\\nPrimeras filas del resultado optimizado:\")\n#&gt; [1] \"\\nPrimeras filas del resultado optimizado:\"\nprint(head(result_fast))\n#&gt;     region  group count mean_value sum_amount premium_factor\n#&gt;     &lt;char&gt; &lt;char&gt; &lt;int&gt;      &lt;num&gt;      &lt;num&gt;          &lt;num&gt;\n#&gt; 1: Central      G    94  108.12594   39703.33       1.252676\n#&gt; 2: Central   &lt;NA&gt;  1887   99.26696  886126.91       1.252676\n#&gt; 3:   South      E    82  102.41588   51290.98       1.252676\n#&gt; 4:    East      B    82   97.44042   26863.57       1.252676\n#&gt; 5:    West      J    92  100.79471   36067.56       1.252676\n#&gt; 6: Central      C    69   98.34540   25937.61       1.252676\n\ncat(\"\\n=== TÉCNICAS DE OPTIMIZACIÓN APLICADAS ===\\n\")\n#&gt; \n#&gt; === TÉCNICAS DE OPTIMIZACIÓN APLICADAS ===\ncat(\"1. ✅ Eliminación completa de bucles for\\n\")\n#&gt; 1. ✅ Eliminación completa de bucles for\ncat(\"2. ✅ Una sola operación by= vectorizada\\n\") \n#&gt; 2. ✅ Una sola operación by= vectorizada\ncat(\"3. ✅ Pre-cálculo de valores constantes\\n\")\n#&gt; 3. ✅ Pre-cálculo de valores constantes\ncat(\"4. ✅ Eliminación de rbind repetitivo\\n\")\n#&gt; 4. ✅ Eliminación de rbind repetitivo\ncat(\"5. ✅ Sintaxis data.table pura (sin data.frame)\\n\")\n#&gt; 5. ✅ Sintaxis data.table pura (sin data.frame)\ncat(\"6. ✅ Operaciones vectorizadas nativas\\n\")\n#&gt; 6. ✅ Operaciones vectorizadas nativas\ncat(\"7. ✅ Mínimo uso de memoria\\n\")\n#&gt; 7. ✅ Mínimo uso de memoria\n\n\n\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nThreading automático puede acelerar operaciones 2-10x en sistemas multi-core\n\nsetkey() es esencial para datasets &gt;100K filas con consultas repetitivas\n\nÍndices secundarios con setindex() permiten múltiples patrones de consulta eficientes\n\nBenchmarking sistemático revela cuellos de botella reales vs percibidos\n\nUna operación data.table vectorizada puede reemplazar docenas de bucles\n\nProfiling de memoria es crucial para datasets que se acercan a los límites de RAM\n\nLa optimización correcta puede resultar en mejoras de 10-100x en casos extremos\n\n\n\nEl dominio de estas técnicas de optimización te permite trabajar con datasets que de otra manera serían imposibles de procesar eficientemente. En el próximo capítulo exploraremos las mejores prácticas y patrones que complementan estas optimizaciones.\n[{“content”: “Reorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos”, “status”: “completed”, “id”: “1”}, {“content”: “Crear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1”, “status”: “completed”, “id”: “1-new”}, {“content”: “Reorganizar M0f3dulo 2: dividir en encadenamiento y joins”, “status”: “completed”, “id”: “2”}, {“content”: “Crear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3”, “status”: “completed”, “id”: “3-1”}, {“content”: “Crear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3”, “status”: “completed”, “id”: “3-2”}, {“content”: “Crear cap03-reshape.qmd para reshape del M0f3dulo 3”, “status”: “completed”, “id”: “3-3”}, {“content”: “Crear cap04-performance.qmd para optimización de performance del M0f3dulo 4”, “status”: “completed”, “id”: “4-1”}, {“content”: “Crear cap04-buenas-practicas.qmd para mejores pr0e1cticas del M0f3dulo 4”, “status”: “in_progress”, “id”: “4-2”}, {“content”: “Reorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones”, “status”: “pending”, “id”: “5”}]",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Optimización de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html",
    "href": "cap04-buenas-practicas.html",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "",
    "text": "10.1 Los Mandamientos de data.table",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-mandamientos",
    "href": "cap04-buenas-practicas.html#sec-mandamientos",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "",
    "text": "10.1.1 ✅ QUÉ HACER (Do’s)\n\n1. Usa := para Modificaciones Eficientes\n\nEl operador := es el corazón de la eficiencia en data.table. Modifica por referencia sin copiar toda la tabla.\n\n# ✅ CORRECTO: Modificación por referencia\nemployees_dt[, annual_bonus := salary * 0.1]\n\n# ✅ CORRECTO: Múltiples columnas a la vez\nemployees_dt[, `:=`(\n  salary_tier = fifelse(salary &gt; 100000, \"High\", \n                fifelse(salary &gt; 70000, \"Medium\", \"Low\")),\n  tenure_years = as.numeric(Sys.Date() - hire_date) / 365.25\n)]\n\n# ✅ CORRECTO: Modificación condicional\nemployees_dt[department == \"Engineering\", tech_bonus := salary * 0.05]\n\n# Mostrar resultado\nhead(employees_dt[, .(employee_id, department, salary, salary_tier, annual_bonus, tech_bonus)])\n#&gt;    employee_id  department salary salary_tier annual_bonus tech_bonus\n#&gt;          &lt;int&gt;      &lt;char&gt;  &lt;num&gt;      &lt;char&gt;        &lt;num&gt;      &lt;num&gt;\n#&gt; 1:           1 Engineering 128722        High      12872.2     6436.1\n#&gt; 2:           2     Finance 128148        High      12814.8         NA\n#&gt; 3:           3     Finance  50533         Low       5053.3         NA\n#&gt; 4:           4          HR  41787         Low       4178.7         NA\n#&gt; 5:           5       Sales  79771      Medium       7977.1         NA\n#&gt; 6:           6     Finance 138060        High      13806.0         NA\n\n\n# Comparar con método ineficiente\nemployees_copy &lt;- copy(employees_dt[1:1000])\n\n# ❌ INCORRECTO: Crear copias innecesarias\ntiming_inefficient &lt;- system.time({\n  employees_copy &lt;- employees_copy[, .(employee_id, department, salary, \n                                      new_column = salary * 1.1)]\n})\n\n# ✅ CORRECTO: Modificación por referencia\nemployees_ref &lt;- copy(employees_dt[1:1000])\ntiming_efficient &lt;- system.time({\n  employees_ref[, new_column := salary * 1.1]\n})\n\ncat(\"Método ineficiente:\", round(timing_inefficient[3], 4), \"segundos\\n\")\n#&gt; Método ineficiente: 0 segundos\ncat(\"Método eficiente:\", round(timing_efficient[3], 4), \"segundos\\n\")\n#&gt; Método eficiente: 0 segundos\ncat(\"Mejora:\", round(timing_inefficient[3] / timing_efficient[3], 1), \"x más rápido\\n\")\n#&gt; Mejora: NaN x más rápido\n\n2. Utiliza setkey() para Joins y Filtros Repetitivos\n\nCuando vas a hacer múltiples operaciones sobre las mismas columnas, setkey() paga con creces la inversión inicial.\n\n# Crear copias para comparar\ntrans_no_key &lt;- copy(transactions_dt[1:10000])\ntrans_with_key &lt;- copy(transactions_dt[1:10000])\n\n# Establecer key\nsetkey(trans_with_key, customer_id, transaction_date)\n\n# ✅ CORRECTO: Consultas rápidas con key\ncustomers_target &lt;- c(1, 50, 100, 500, 1000)\n\n# Sin key\ntime_no_key &lt;- system.time({\n  result1 &lt;- trans_no_key[customer_id %in% customers_target & \n                         transaction_date &gt;= as.Date(\"2024-01-01\")]\n})\n\n# Con key  \ntime_with_key &lt;- system.time({\n  # Usar sintaxis de key para máxima eficiencia\n  result2 &lt;- trans_with_key[.(customers_target, \n                             seq(as.Date(\"2024-01-01\"), as.Date(\"2024-12-31\"), by = \"day\"))]\n})\n\ncat(\"Sin key:\", round(time_no_key[3], 4), \"segundos\\n\")\n#&gt; Sin key: 0 segundos\ncat(\"Con key:\", round(time_with_key[3], 4), \"segundos\\n\")\n#&gt; Con key: 0.01 segundos\ncat(\"Speedup:\", round(time_no_key[3] / time_with_key[3], 1), \"x\\n\")\n#&gt; Speedup: 0 x\n\n3. Aprovecha .SD para Operaciones Múltiples\n\n.SD (Subset of Data) te permite aplicar funciones a múltiples columnas de manera elegante.\n\n# ✅ CORRECTO: Usar .SD para múltiples columnas\nnumeric_summary &lt;- employees_dt[, lapply(.SD, function(x) {\n  list(mean = mean(x, na.rm = TRUE),\n       median = median(x, na.rm = TRUE),\n       q95 = quantile(x, 0.95, na.rm = TRUE))\n}), .SDcols = is.numeric, by = department]\n\nprint(head(numeric_summary))\n#&gt;     department employee_id   salary performance_score manager_id annual_bonus\n#&gt;         &lt;char&gt;      &lt;list&gt;   &lt;list&gt;            &lt;list&gt;     &lt;list&gt;       &lt;list&gt;\n#&gt; 1: Engineering    25366.05 95310.06                 3   499.7326     9531.006\n#&gt; 2: Engineering       25715    95316                 3      499.5       9531.6\n#&gt; 3: Engineering       47551 144724.9                 4     950.95     14472.49\n#&gt; 4:     Finance    24716.19 94993.49           3.01034   503.8386     9499.349\n#&gt; 5:     Finance       24506    95204                 3        507       9520.4\n#&gt; 6:     Finance     47432.4 144319.8                 5        951     14431.98\n#&gt;    tenure_years tech_bonus\n#&gt;          &lt;list&gt;     &lt;list&gt;\n#&gt; 1:     5.614184   4765.503\n#&gt; 2:      5.61807     4765.8\n#&gt; 3:     10.11992   7236.245\n#&gt; 4:      5.66225        NaN\n#&gt; 5:     5.667351         NA\n#&gt; 6:      10.1848         NA\n\n# ✅ CORRECTO: .SD con transformaciones complejas\nemployees_standardized &lt;- employees_dt[, c(.SD[, .(employee_id, department)], \n                                          lapply(.SD, function(x) scale(x)[,1])), \n                                      .SDcols = is.numeric]\n\nprint(head(employees_standardized[, .(employee_id, department, salary, performance_score)]))\n#&gt;    employee_id  department    salary performance_score\n#&gt;          &lt;int&gt;      &lt;char&gt;     &lt;num&gt;             &lt;num&gt;\n#&gt; 1:           1 Engineering  1.061269      -0.002022701\n#&gt; 2:           2     Finance  1.043194      -0.002022701\n#&gt; 3:           3     Finance -1.400920      -0.002022701\n#&gt; 4:           4          HR -1.676334      -0.002022701\n#&gt; 5:           5       Sales -0.480209      -0.002022701\n#&gt; 6:           6     Finance  1.355325      -0.002022701\n\n4. Usa Vectorización en Lugar de Bucles\n\nLas operaciones vectorizadas son siempre más rápidas y más legibles.\n\n# ✅ CORRECTO: Operaciones vectorizadas\ntransactions_dt[, transaction_quarter := paste0(\"Q\", ceiling(month(transaction_date)/3), \n                                               \"_\", year(transaction_date))]\n\n# ✅ CORRECTO: Condicionales vectorizadas con fifelse\ntransactions_dt[, amount_category := fifelse(\n  amount &gt; 100, \"High\",\n  fifelse(amount &gt; 50, \"Medium\", \"Low\")\n)]\n\n# ✅ CORRECTO: Uso de %between% para rangos\nemployees_dt[, mid_career := salary %between% c(60000, 120000)]\n\n# Mostrar resultados\nprint(head(transactions_dt[, .(transaction_id, amount, amount_category, transaction_quarter)]))\n#&gt;    transaction_id amount amount_category transaction_quarter\n#&gt;             &lt;int&gt;  &lt;num&gt;          &lt;char&gt;              &lt;char&gt;\n#&gt; 1:              1  19.01             Low             Q3_2024\n#&gt; 2:              2  28.39             Low             Q4_2024\n#&gt; 3:              3  41.68             Low             Q4_2023\n#&gt; 4:              4  10.01             Low             Q3_2023\n#&gt; 5:              5  29.42             Low             Q1_2023\n#&gt; 6:              6  38.53             Low             Q3_2023\nprint(head(employees_dt[, .(employee_id, salary, mid_career)]))\n#&gt;    employee_id salary mid_career\n#&gt;          &lt;int&gt;  &lt;num&gt;     &lt;lgcl&gt;\n#&gt; 1:           1 128722      FALSE\n#&gt; 2:           2 128148      FALSE\n#&gt; 3:           3  50533      FALSE\n#&gt; 4:           4  41787      FALSE\n#&gt; 5:           5  79771       TRUE\n#&gt; 6:           6 138060      FALSE\n\n5. Utiliza Encadenamiento para Operaciones Complejas\n\nEl encadenamiento DT[...][...] es más eficiente que variables intermedias.\n\n# ✅ CORRECTO: Encadenamiento eficiente\nhigh_performers &lt;- employees_dt[\n  performance_score &gt;= 4 & tenure_years &gt;= 2\n][\n  , .(avg_salary = mean(salary), \n      count = .N,\n      avg_tenure = mean(tenure_years)), \n  by = department\n][\n  order(-avg_salary)\n]\n\nprint(high_performers)\n#&gt;     department avg_salary count avg_tenure\n#&gt;         &lt;char&gt;      &lt;num&gt; &lt;int&gt;      &lt;num&gt;\n#&gt; 1:       Sales   95508.85  1735   6.269524\n#&gt; 2:   Marketing   95241.65  1680   6.293222\n#&gt; 3:     Finance   95124.27  1766   6.333967\n#&gt; 4: Engineering   94705.74  1697   6.231506\n#&gt; 5:          HR   94161.02  1647   6.256346\n\n# ✅ CORRECTO: Encadenamiento con modificaciones\ntop_departments &lt;- transactions_dt[\n  transaction_date &gt;= as.Date(\"2024-01-01\")\n][\n  , total_revenue := sum(amount), by = store_location\n][\n  total_revenue &gt; 10000\n][\n  order(-total_revenue)\n]\n\nprint(head(top_departments[, .(store_location, total_revenue)]))\n#&gt;    store_location total_revenue\n#&gt;            &lt;char&gt;         &lt;num&gt;\n#&gt; 1:        Store_P      132929.2\n#&gt; 2:        Store_P      132929.2\n#&gt; 3:        Store_P      132929.2\n#&gt; 4:        Store_P      132929.2\n#&gt; 5:        Store_P      132929.2\n#&gt; 6:        Store_P      132929.2\n\n\n10.1.2 ❌ QUÉ NO HACER (Don’ts)\n\n1. No Uses Bucles for con data.table\n\nLos bucles explícitos destruyen todas las optimizaciones de data.table.\n\n# Crear dataset pequeño para la demostración\nsample_trans &lt;- transactions_dt[sample(.N, 1000)]\n\n# ❌ INCORRECTO: Bucle ineficiente\ncalculate_inefficient &lt;- function(dt) {\n  result &lt;- copy(dt)\n  for(i in 1:nrow(result)) {\n    result[i, profit_margin := amount[i] * 0.2]\n  }\n  return(result)\n}\n\n# ✅ CORRECTO: Operación vectorizada\ncalculate_efficient &lt;- function(dt) {\n  result &lt;- copy(dt)\n  result[, profit_margin := amount * 0.2]\n  return(result)\n}\n\n# Comparar tiempos\ntime_inefficient &lt;- system.time(result_bad &lt;- calculate_inefficient(sample_trans))\ntime_efficient &lt;- system.time(result_good &lt;- calculate_efficient(sample_trans))\n\ncat(\"Método con bucle:\", round(time_inefficient[3], 4), \"segundos\\n\")\n#&gt; Método con bucle: 0.11 segundos\ncat(\"Método vectorizado:\", round(time_efficient[3], 4), \"segundos\\n\")\n#&gt; Método vectorizado: 0 segundos\ncat(\"Mejora:\", round(time_inefficient[3] / time_efficient[3], 1), \"x más rápido\\n\")\n#&gt; Mejora: Inf x más rápido\n\n# Verificar que los resultados son idénticos\ncat(\"Resultados idénticos:\", identical(result_bad$profit_margin, result_good$profit_margin), \"\\n\")\n#&gt; Resultados idénticos: FALSE\n\n2. No Mezcles dplyr con data.table sin Cuidado\n\nMixing paradigmas puede causar copias inesperadas y pérdida de performance.\n\n# ❌ PROBLEMÁTICO: Puede forzar copias y perder optimizaciones\nlibrary(dplyr)\nemployees_dt %&gt;% \n  mutate(new_salary = salary * 1.1) %&gt;% \n  filter(department == \"Engineering\") %&gt;%\n  arrange(desc(salary))\n\n# ✅ CORRECTO: Sintaxis data.table pura\nemployees_dt[, new_salary := salary * 1.1][\n  department == \"Engineering\"\n][order(-salary)]\n\n# ✅ ALTERNATIVA: dtplyr para sintaxis dplyr + performance data.table\nlibrary(dtplyr)\nemployees_dt %&gt;% \n  lazy_dt() %&gt;%\n  mutate(new_salary = salary * 1.1) %&gt;% \n  filter(department == \"Engineering\") %&gt;%\n  arrange(desc(salary)) %&gt;%\n  as.data.table()\n\n3. No Ignores la Gestión de Memoria\n\nCrear copias innecesarias puede agotar la memoria rápidamente.\n\n# Demostrar el problema con copias\ndemo_dt &lt;- employees_dt[1:1000]\n\n# ❌ INCORRECTO: Crear múltiples copias\nmeasure_memory_waste &lt;- function() {\n  copy1 &lt;- copy(demo_dt)\n  copy2 &lt;- copy(demo_dt)\n  copy3 &lt;- copy(demo_dt)\n  \n  # Modificaciones que podrían haberse hecho por referencia\n  copy1[, bonus1 := salary * 0.1]\n  copy2[, bonus2 := salary * 0.15]\n  copy3[, bonus3 := salary * 0.2]\n  \n  return(list(copy1, copy2, copy3))\n}\n\n# ✅ CORRECTO: Trabajar con referencias\nmeasure_memory_efficient &lt;- function() {\n  working_dt &lt;- demo_dt  # Solo una referencia\n  \n  # Todas las modificaciones por referencia\n  working_dt[, `:=`(\n    bonus1 = salary * 0.1,\n    bonus2 = salary * 0.15, \n    bonus3 = salary * 0.2\n  )]\n  \n  return(working_dt)\n}\n\n# Nota: En este ejemplo, usamos copias pequeñas para demostrar el concepto\n# sin consumir mucha memoria en el tutorial\nmemory_waste &lt;- object.size(measure_memory_waste())\nmemory_efficient &lt;- object.size(measure_memory_efficient())\n\ncat(\"Enfoque con múltiples copias:\", format(memory_waste, units = \"KB\"), \"\\n\")\n#&gt; Enfoque con múltiples copias: 258.9 Kb\ncat(\"Enfoque eficiente:\", format(memory_efficient, units = \"KB\"), \"\\n\")\n#&gt; Enfoque eficiente: 102.2 Kb\n\n4. No Uses rbind() Repetitivo\n\nConstruir tablas fila por fila es extremadamente ineficiente.\n\n# ❌ INCORRECTO: rbind repetitivo (simulado para evitar demora)\nbuild_table_bad &lt;- function(n) {\n  result &lt;- data.table()\n  # Simulamos solo algunas iteraciones para el ejemplo\n  for(i in 1:min(n, 50)) {  # Limitamos a 50 para el ejemplo\n    new_row &lt;- data.table(\n      id = i, \n      value = rnorm(1),\n      category = sample(LETTERS[1:3], 1)\n    )\n    result &lt;- rbind(result, new_row)\n  }\n  return(result)\n}\n\n# ✅ CORRECTO: Crear toda la tabla de una vez\nbuild_table_good &lt;- function(n) {\n  data.table(\n    id = 1:n,\n    value = rnorm(n),\n    category = sample(LETTERS[1:3], n, replace = TRUE)\n  )\n}\n\n# Comparar tiempos\nn_rows &lt;- 50  # Pequeño para el ejemplo\ntime_bad &lt;- system.time(table_bad &lt;- build_table_bad(n_rows))\ntime_good &lt;- system.time(table_good &lt;- build_table_good(n_rows))\n\ncat(\"Método rbind repetitivo:\", round(time_bad[3], 4), \"segundos\\n\")\n#&gt; Método rbind repetitivo: 0 segundos\ncat(\"Método eficiente:\", round(time_good[3], 4), \"segundos\\n\")\n#&gt; Método eficiente: 0 segundos\ncat(\"Diferencia:\", round(time_bad[3] / time_good[3], 1), \"x más lento\\n\")\n#&gt; Diferencia: NaN x más lento\n\n# Para tablas grandes, la diferencia sería dramática\ncat(\"\\nNota: Para 10,000 filas, el método rbind puede ser 100-1000x más lento\\n\")\n#&gt; \n#&gt; Nota: Para 10,000 filas, el método rbind puede ser 100-1000x más lento",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-patrones",
    "href": "cap04-buenas-practicas.html#sec-patrones",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "\n10.2 Patrones de Código Idiomático",
    "text": "10.2 Patrones de Código Idiomático\n\n10.2.1 1. Análisis Exploratorio de Datos\n\n\n# Patrón: Resumen rápido de todas las variables numéricas\neda_summary &lt;- employees_dt[, lapply(.SD, function(x) {\n  if(is.numeric(x)) {\n    list(\n      count = sum(!is.na(x)),\n      mean = round(mean(x, na.rm = TRUE), 2),\n      median = round(median(x, na.rm = TRUE), 2),\n      min = min(x, na.rm = TRUE),\n      max = max(x, na.rm = TRUE),\n      missing = sum(is.na(x))\n    )\n  }\n}), .SDcols = is.numeric]\n\nprint(eda_summary)\n#&gt;    employee_id   salary performance_score manager_id annual_bonus tenure_years\n#&gt;         &lt;list&gt;   &lt;list&gt;            &lt;list&gt;     &lt;list&gt;       &lt;list&gt;       &lt;list&gt;\n#&gt; 1:       50000    50000             50000      49022        50000        50000\n#&gt; 2:     25000.5 95020.46                 3     500.86      9502.05         5.64\n#&gt; 3:     25000.5  94991.5                 3        501      9499.15         5.65\n#&gt; 4:           1    40013                 1          1       4001.3    0.6351814\n#&gt; 5:       50000   149999                 5       1000      14999.9     10.63381\n#&gt; 6:           0        0                 0        978            0            0\n#&gt;    tech_bonus\n#&gt;        &lt;list&gt;\n#&gt; 1:      10095\n#&gt; 2:     4765.5\n#&gt; 3:     4765.8\n#&gt; 4:    2000.65\n#&gt; 5:     7499.9\n#&gt; 6:      39905\n\n# Patrón: Distribución de variables categóricas\ncategorical_summary &lt;- employees_dt[, .(\n  count = .N,\n  avg_salary = round(mean(salary), 0),\n  median_performance = median(as.numeric(performance_score))\n), by = .(department, remote_work)][order(department, -avg_salary)]\n\nprint(categorical_summary)\n#&gt;      department remote_work count avg_salary median_performance\n#&gt;          &lt;char&gt;      &lt;lgcl&gt; &lt;int&gt;      &lt;num&gt;              &lt;num&gt;\n#&gt;  1: Engineering       FALSE  7016      95520                  3\n#&gt;  2: Engineering        TRUE  3079      94832                  3\n#&gt;  3:     Finance        TRUE  2952      95463                  3\n#&gt;  4:     Finance       FALSE  6913      94793                  3\n#&gt;  5:          HR        TRUE  2993      94883                  3\n#&gt;  6:          HR       FALSE  6990      94690                  3\n#&gt;  7:   Marketing       FALSE  7034      95350                  3\n#&gt;  8:   Marketing        TRUE  3016      93386                  3\n#&gt;  9:       Sales        TRUE  2971      95904                  3\n#&gt; 10:       Sales       FALSE  7036      95028                  3\n\n\n10.2.2 2. Limpieza y Validación de Datos\n\n\n# Patrón: Identificar y manejar outliers\nidentify_outliers &lt;- function(dt, column) {\n  Q1 &lt;- quantile(dt[[column]], 0.25, na.rm = TRUE)\n  Q3 &lt;- quantile(dt[[column]], 0.75, na.rm = TRUE)\n  IQR &lt;- Q3 - Q1\n  lower_bound &lt;- Q1 - 1.5 * IQR\n  upper_bound &lt;- Q3 + 1.5 * IQR\n  \n  dt[, paste0(column, \"_outlier\") := get(column) &lt; lower_bound | get(column) &gt; upper_bound]\n  \n  return(dt[get(paste0(column, \"_outlier\")) == TRUE])\n}\n\n# Identificar outliers en salarios\nsalary_outliers &lt;- identify_outliers(copy(employees_dt), \"salary\")\ncat(\"Outliers en salarios encontrados:\", nrow(salary_outliers), \"\\n\")\n#&gt; Outliers en salarios encontrados: 0\nprint(head(salary_outliers[, .(employee_id, department, salary)]))\n#&gt; data.table vacía (0 filas y 3 columnas): employee_id,department,salary\n\n# Patrón: Validación de integridad de datos\ndata_quality_check &lt;- employees_dt[, .(\n  total_records = .N,\n  missing_salary = sum(is.na(salary)),\n  invalid_performance = sum(performance_score &lt; 1 | performance_score &gt; 5, na.rm = TRUE),\n  future_hire_dates = sum(hire_date &gt; Sys.Date(), na.rm = TRUE),\n  negative_salaries = sum(salary &lt; 0, na.rm = TRUE)\n)]\n\nprint(data_quality_check)\n#&gt;    total_records missing_salary invalid_performance future_hire_dates\n#&gt;            &lt;int&gt;          &lt;int&gt;               &lt;int&gt;             &lt;int&gt;\n#&gt; 1:         50000              0                   0                 0\n#&gt;    negative_salaries\n#&gt;                &lt;int&gt;\n#&gt; 1:                 0\n\n\n10.2.3 3. Análisis de Series Temporales\n\n\n# Patrón: Agregaciones temporales con rolling windows\n# Crear datos temporales\ndaily_sales &lt;- transactions_dt[, .(\n  daily_revenue = sum(amount),\n  transaction_count = .N\n), by = transaction_date][order(transaction_date)]\n\n# Rolling average de 7 días\ndaily_sales[, `:=`(\n  revenue_7day_avg = frollmean(daily_revenue, 7, align = \"right\"),\n  revenue_7day_sum = frollsum(daily_revenue, 7, align = \"right\"),\n  growth_rate = (daily_revenue / data.table::shift(daily_revenue, 1) - 1) * 100\n)]\n\nprint(head(daily_sales[!is.na(revenue_7day_avg)], 10))\n#&gt;     transaction_date daily_revenue transaction_count revenue_7day_avg\n#&gt;               &lt;Date&gt;         &lt;num&gt;             &lt;int&gt;            &lt;num&gt;\n#&gt;  1:       2023-01-07       7600.28               161         6830.914\n#&gt;  2:       2023-01-08       6939.91               144         6860.439\n#&gt;  3:       2023-01-09       8018.96               140         6919.359\n#&gt;  4:       2023-01-10       6010.28               130         6963.241\n#&gt;  5:       2023-01-11       8311.52               152         7188.080\n#&gt;  6:       2023-01-12       7070.97               148         7351.023\n#&gt;  7:       2023-01-13       6851.72               125         7257.663\n#&gt;  8:       2023-01-14       7485.59               137         7241.279\n#&gt;  9:       2023-01-15       7499.29               140         7321.190\n#&gt; 10:       2023-01-16       6335.47               120         7080.691\n#&gt;     revenue_7day_sum growth_rate\n#&gt;                &lt;num&gt;       &lt;num&gt;\n#&gt;  1:         47816.40   1.2663153\n#&gt;  2:         48023.07  -8.6887588\n#&gt;  3:         48435.51  15.5484725\n#&gt;  4:         48742.69 -25.0491336\n#&gt;  5:         50316.56  38.2883992\n#&gt;  6:         51457.16 -14.9256694\n#&gt;  7:         50803.64  -3.1007061\n#&gt;  8:         50688.95   9.2512537\n#&gt;  9:         51248.33   0.1830183\n#&gt; 10:         49564.84 -15.5190691\n\n# Patrón: Análisis de tendencias por período\nmonthly_trends &lt;- transactions_dt[, .(\n  total_revenue = sum(amount),\n  avg_transaction = round(mean(amount), 2),\n  transaction_count = .N\n), by = .(year = year(transaction_date), month = month(transaction_date))][\n  order(year, month)\n][, `:=`(\n  revenue_growth = (total_revenue / data.table::shift(total_revenue, 1) - 1) * 100,\n  period = paste0(year, \"-\", sprintf(\"%02d\", month))\n)]\n\nprint(head(monthly_trends, 12))\n#&gt;      year month total_revenue avg_transaction transaction_count revenue_growth\n#&gt;     &lt;int&gt; &lt;int&gt;         &lt;num&gt;           &lt;num&gt;             &lt;int&gt;          &lt;num&gt;\n#&gt;  1:  2023     1      219815.3           51.12              4300             NA\n#&gt;  2:  2023     2      199300.1           51.70              3855      -9.332936\n#&gt;  3:  2023     3      218209.1           50.59              4313       9.487719\n#&gt;  4:  2023     4      200160.0           49.56              4039      -8.271484\n#&gt;  5:  2023     5      214969.5           50.27              4276       7.398852\n#&gt; ---                                                                           \n#&gt;  8:  2023     8      214542.1           51.12              4197       4.867881\n#&gt;  9:  2023     9      209143.9           51.16              4088      -2.516172\n#&gt; 10:  2023    10      214762.0           50.66              4239       2.686223\n#&gt; 11:  2023    11      194004.0           47.25              4106      -9.665572\n#&gt; 12:  2023    12      213822.5           49.96              4280      10.215517\n#&gt;      period\n#&gt;      &lt;char&gt;\n#&gt;  1: 2023-01\n#&gt;  2: 2023-02\n#&gt;  3: 2023-03\n#&gt;  4: 2023-04\n#&gt;  5: 2023-05\n#&gt; ---        \n#&gt;  8: 2023-08\n#&gt;  9: 2023-09\n#&gt; 10: 2023-10\n#&gt; 11: 2023-11\n#&gt; 12: 2023-12\n\n\n10.2.4 4. Análisis de Cohortes\n\n\n# Patrón: Análisis de cohorte de empleados por año de contratación\ncohort_analysis &lt;- employees_dt[, hire_year := year(hire_date)][, .(\n  cohort_size = .N,\n  avg_current_salary = round(mean(salary), 0),\n  avg_performance = round(mean(performance_score), 2),\n  retention_rate = round(.N / employees_dt[year(hire_date) == hire_year, .N] * 100, 1)\n), by = hire_year][order(hire_year)]\n\nprint(cohort_analysis)\n#&gt;     hire_year cohort_size avg_current_salary avg_performance retention_rate\n#&gt;         &lt;int&gt;       &lt;int&gt;              &lt;num&gt;           &lt;num&gt;          &lt;num&gt;\n#&gt;  1:      2015        5054              94757            2.98           10.1\n#&gt;  2:      2016        5018              95581            2.99           10.0\n#&gt;  3:      2017        5061              94834            2.99           10.1\n#&gt;  4:      2018        4906              94943            3.00            9.8\n#&gt;  5:      2019        5010              95127            3.00           10.0\n#&gt;  6:      2020        5086              94636            3.00           10.2\n#&gt;  7:      2021        4927              95138            3.02            9.9\n#&gt;  8:      2022        4929              94619            3.02            9.9\n#&gt;  9:      2023        4975              95381            3.00           10.0\n#&gt; 10:      2024        5034              95193            3.02           10.1\n\n# Patrón: Segmentación de clientes por comportamiento\ncustomer_segmentation &lt;- transactions_dt[, .(\n  total_spent = sum(amount),\n  transaction_frequency = .N,\n  avg_transaction = round(mean(amount), 2),\n  days_active = as.numeric(max(transaction_date) - min(transaction_date)) + 1,\n  favorite_category = names(sort(table(product_category), decreasing = TRUE))[1]\n), by = customer_id][, `:=`(\n  spending_tier = cut(total_spent, \n                     breaks = quantile(total_spent, c(0, 0.33, 0.66, 1)), \n                     labels = c(\"Low\", \"Medium\", \"High\"),\n                     include.lowest = TRUE),\n  frequency_tier = cut(transaction_frequency,\n                      breaks = quantile(transaction_frequency, c(0, 0.5, 1)),\n                      labels = c(\"Occasional\", \"Frequent\"),\n                      include.lowest = TRUE)\n)]\n\n# Resumen de segmentación\nsegment_summary &lt;- customer_segmentation[, .(\n  customers = .N,\n  avg_total_spent = round(mean(total_spent), 2),\n  avg_frequency = round(mean(transaction_frequency), 1)\n), by = .(spending_tier, frequency_tier)]\n\nprint(segment_summary)\n#&gt;    spending_tier frequency_tier customers avg_total_spent avg_frequency\n#&gt;           &lt;fctr&gt;         &lt;fctr&gt;     &lt;int&gt;           &lt;num&gt;         &lt;num&gt;\n#&gt; 1:           Low     Occasional      2984          264.30           7.0\n#&gt; 2:        Medium     Occasional      1958          460.58           8.6\n#&gt; 3:           Low       Frequent       316          321.93          11.6\n#&gt; 4:          High       Frequent      2525          770.54          13.5\n#&gt; 5:          High     Occasional       875          679.31           9.1\n#&gt; 6:        Medium       Frequent      1341          485.92          12.3",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-debugging",
    "href": "cap04-buenas-practicas.html#sec-debugging",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "\n10.3 Debugging y Troubleshooting",
    "text": "10.3 Debugging y Troubleshooting\n\n10.3.1 1. Herramientas de Diagnóstico\n\n\n# Función para inspeccionar comprehensivamente un data.table\ninspect_dt &lt;- function(dt, name = \"data.table\") {\n  cat(\"=== Inspección de\", name, \"===\\n\")\n  cat(\"Dimensiones:\", nrow(dt), \"x\", ncol(dt), \"\\n\")\n  cat(\"Memoria:\", format(object.size(dt), units = \"MB\"), \"\\n\")\n  cat(\"Key:\", ifelse(is.null(key(dt)), \"Ninguna\", paste(key(dt), collapse = \", \")), \"\\n\")\n  cat(\"Índices:\", length(indices(dt)), \"\\n\")\n  if(length(indices(dt)) &gt; 0) {\n    cat(\"Índices disponibles:\\n\")\n    for(idx in indices(dt)) {\n      cat(\"  -\", paste(idx, collapse = \", \"), \"\\n\")\n    }\n  }\n  cat(\"Clases de columnas:\\n\")\n  col_classes &lt;- sapply(dt, function(x) paste(class(x), collapse = \", \"))\n  for(i in seq_along(col_classes)) {\n    cat(\"  \", names(col_classes)[i], \":\", col_classes[i], \"\\n\")\n  }\n  cat(\"Valores faltantes por columna:\\n\")\n  missing_counts &lt;- dt[, lapply(.SD, function(x) sum(is.na(x)))]\n  for(i in seq_along(missing_counts)) {\n    cat(\"  \", names(missing_counts)[i], \":\", missing_counts[[i]], \"\\n\")\n  }\n  cat(\"\\n\")\n}\n\n# Inspeccionar nuestros datasets principales\ninspect_dt(employees_dt[1:1000], \"employees_dt (muestra)\")\n#&gt; === Inspección de employees_dt (muestra) ===\n#&gt; Dimensiones: 1000 x 13 \n#&gt; Memoria: 0.1 Mb \n#&gt; Key: Ninguna \n#&gt; Índices: 0 \n#&gt; Clases de columnas:\n#&gt;    employee_id : integer \n#&gt;    department : character \n#&gt;    salary : numeric \n#&gt;    hire_date : Date \n#&gt;    performance_score : integer \n#&gt;    remote_work : logical \n#&gt;    manager_id : integer \n#&gt;    annual_bonus : numeric \n#&gt;    salary_tier : character \n#&gt;    tenure_years : numeric \n#&gt;    tech_bonus : numeric \n#&gt;    mid_career : logical \n#&gt;    hire_year : integer \n#&gt; Valores faltantes por columna:\n#&gt;    employee_id : 0 \n#&gt;    department : 0 \n#&gt;    salary : 0 \n#&gt;    hire_date : 0 \n#&gt;    performance_score : 0 \n#&gt;    remote_work : 0 \n#&gt;    manager_id : 25 \n#&gt;    annual_bonus : 0 \n#&gt;    salary_tier : 0 \n#&gt;    tenure_years : 0 \n#&gt;    tech_bonus : 805 \n#&gt;    mid_career : 0 \n#&gt;    hire_year : 0\n\n\n10.3.2 2. Debugging de Operaciones Complejas\n\n\n# Función para debuggear operaciones paso a paso\ndebug_complex_operation &lt;- function(dt, verbose = TRUE) {\n  if(verbose) cat(\"Paso 1: Filtrado inicial\\n\")\n  step1 &lt;- dt[salary &gt; 70000 & !is.na(performance_score)]\n  if(verbose) cat(\"  Filas después del filtro:\", nrow(step1), \"\\n\")\n  \n  if(verbose) cat(\"Paso 2: Cálculos por grupo\\n\")\n  step2 &lt;- step1[, .(\n    avg_salary = mean(salary),\n    avg_performance = mean(performance_score),\n    count = .N,\n    salary_std = sd(salary)\n  ), by = department]\n  if(verbose) cat(\"  Grupos creados:\", nrow(step2), \"\\n\")\n  \n  if(verbose) cat(\"Paso 3: Filtrado post-agregación\\n\")\n  step3 &lt;- step2[count &gt;= 10]  # Solo departamentos con suficientes empleados\n  if(verbose) cat(\"  Grupos finales:\", nrow(step3), \"\\n\")\n  \n  if(verbose) cat(\"Paso 4: Ordenamiento final\\n\")\n  result &lt;- step3[order(-avg_salary)]\n  \n  return(result)\n}\n\n# Ejecutar con debugging\nresult_debug &lt;- debug_complex_operation(employees_dt, verbose = TRUE)\n#&gt; Paso 1: Filtrado inicial\n#&gt;   Filas después del filtro: 36411 \n#&gt; Paso 2: Cálculos por grupo\n#&gt;   Grupos creados: 5 \n#&gt; Paso 3: Filtrado post-agregación\n#&gt;   Grupos finales: 5 \n#&gt; Paso 4: Ordenamiento final\nprint(result_debug)\n#&gt;     department avg_salary avg_performance count salary_std\n#&gt;         &lt;char&gt;      &lt;num&gt;           &lt;num&gt; &lt;int&gt;      &lt;num&gt;\n#&gt; 1: Engineering   110479.1        2.988536  7327   23043.35\n#&gt; 2:       Sales   110280.8        3.002877  7300   23149.18\n#&gt; 3:     Finance   109922.3        3.013630  7190   22984.42\n#&gt; 4:   Marketing   109620.3        2.989902  7328   23162.78\n#&gt; 5:          HR   109554.0        3.007982  7266   23207.83\n\n\n10.3.3 3. Validación y Testing\n\n\n# Función para validar resultados de operaciones\nvalidate_operation &lt;- function(original_dt, result_dt, operation_name) {\n  cat(\"=== Validación de\", operation_name, \"===\\n\")\n  \n  # Verificar que no se perdieron datos inesperadamente\n  if(\"by\" %in% names(attributes(result_dt))) {\n    cat(\"Operación de agregación detectada\\n\")\n  } else {\n    rows_ratio &lt;- nrow(result_dt) / nrow(original_dt)\n    cat(\"Ratio de filas resultado/original:\", round(rows_ratio, 3), \"\\n\")\n    if(rows_ratio &gt; 1) {\n      cat(\"⚠️ ADVERTENCIA: El resultado tiene más filas que el original\\n\")\n    }\n  }\n  \n  # Verificar valores faltantes\n  original_na &lt;- original_dt[, lapply(.SD, function(x) sum(is.na(x)))]\n  result_na &lt;- result_dt[, lapply(.SD, function(x) sum(is.na(x)))]\n  \n  cat(\"NAs en original:\", sum(unlist(original_na)), \"\\n\")\n  cat(\"NAs en resultado:\", sum(unlist(result_na)), \"\\n\")\n  \n  # Verificar tipos de datos\n  original_types &lt;- sapply(original_dt, class)\n  result_types &lt;- sapply(result_dt, class)\n  \n  common_cols &lt;- intersect(names(original_types), names(result_types))\n  type_changes &lt;- sapply(common_cols, function(col) {\n    !identical(original_types[[col]], result_types[[col]])\n  })\n  \n  if(any(type_changes)) {\n    cat(\"⚠️ ADVERTENCIA: Cambios de tipo detectados en columnas:\", \n        paste(names(type_changes)[type_changes], collapse = \", \"), \"\\n\")\n  } else {\n    cat(\"✅ Tipos de datos preservados correctamente\\n\")\n  }\n  \n  cat(\"\\n\")\n}\n\n# Ejemplo de validación\nsample_employees &lt;- employees_dt[1:1000]\nfiltered_result &lt;- sample_employees[salary &gt; 80000]\nvalidate_operation(sample_employees, filtered_result, \"filtrado por salario\")\n#&gt; === Validación de filtrado por salario ===\n#&gt; Ratio de filas resultado/original: 0.629 \n#&gt; NAs en original: 830 \n#&gt; NAs en resultado: 515 \n#&gt; ✅ Tipos de datos preservados correctamente\n\naggregated_result &lt;- sample_employees[, .(avg_salary = mean(salary)), by = department]\nvalidate_operation(sample_employees, aggregated_result, \"agregación por departamento\")\n#&gt; === Validación de agregación por departamento ===\n#&gt; Ratio de filas resultado/original: 0.005 \n#&gt; NAs en original: 830 \n#&gt; NAs en resultado: 0 \n#&gt; ✅ Tipos de datos preservados correctamente",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-estilo",
    "href": "cap04-buenas-practicas.html#sec-estilo",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "\n10.4 Estilo de Código y Convenciones",
    "text": "10.4 Estilo de Código y Convenciones\n\n10.4.1 1. Naming Conventions\n\n\n# ✅ CORRECTO: Nombres descriptivos\ncustomer_lifetime_value &lt;- transactions_dt[, .(\n  total_revenue = sum(amount),\n  avg_order_value = mean(amount),\n  transaction_count = .N\n), by = customer_id]\n\n# ✅ CORRECTO: Consistencia en naming\ndt_sales_daily &lt;- transactions_dt[, .(daily_revenue = sum(amount)), by = transaction_date]\ndt_sales_monthly &lt;- transactions_dt[, .(monthly_revenue = sum(amount)), \n                                   by = .(year = year(transaction_date), \n                                          month = month(transaction_date))]\n\n# ✅ CORRECTO: Prefijos para variables temporales\ntmp_high_value_customers &lt;- customer_lifetime_value[total_revenue &gt; 1000]\ntemp_analysis_result &lt;- tmp_high_value_customers[, .N, by = .(revenue_tier = cut(total_revenue, 3))]\n\n\n10.4.2 2. Formateo y Organización\n\n\n# ✅ CORRECTO: Formateo claro para operaciones complejas\ncomplex_analysis &lt;- employees_dt[\n  # Filtros principales\n  salary &gt; 50000 & \n  !is.na(performance_score) & \n  tenure_years &gt;= 1,\n  \n  # Cálculos\n  .(\n    employee_count = .N,\n    avg_salary = round(mean(salary), 0),\n    median_salary = round(median(salary), 0),\n    salary_range = max(salary) - min(salary),\n    top_performer_ratio = sum(performance_score &gt;= 4) / .N,\n    remote_work_ratio = sum(remote_work, na.rm = TRUE) / .N\n  ),\n  \n  # Agrupación\n  by = .(\n    department,\n    salary_tier = cut(salary, \n                     breaks = c(0, 60000, 90000, Inf), \n                     labels = c(\"Entry\", \"Mid\", \"Senior\"))\n  )\n][\n  # Post-procesamiento\n  employee_count &gt;= 5  # Solo grupos con suficientes empleados\n][\n  # Ordenamiento\n  order(department, -avg_salary)\n]\n\nprint(head(complex_analysis))\n#&gt;     department salary_tier employee_count avg_salary median_salary salary_range\n#&gt;         &lt;char&gt;      &lt;fctr&gt;          &lt;int&gt;      &lt;num&gt;         &lt;num&gt;        &lt;num&gt;\n#&gt; 1: Engineering      Senior           5365     120083        120133        59994\n#&gt; 2: Engineering         Mid           2598      74729         74684        29969\n#&gt; 3: Engineering       Entry            909      54998         55010         9979\n#&gt; 4:     Finance      Senior           5219     119710        119357        59994\n#&gt; 5:     Finance         Mid           2529      74926         74889        29994\n#&gt; 6:     Finance       Entry            891      54939         54765         9961\n#&gt;    top_performer_ratio remote_work_ratio\n#&gt;                  &lt;num&gt;             &lt;num&gt;\n#&gt; 1:           0.1906803         0.2999068\n#&gt; 2:           0.1989992         0.2998460\n#&gt; 3:           0.2057206         0.3190319\n#&gt; 4:           0.2040621         0.3035064\n#&gt; 5:           0.2119415         0.3013049\n#&gt; 6:           0.1818182         0.2962963\n\n\n10.4.3 3. Documentación y Comentarios\n\n\n# Función bien documentada para análisis de retención\nanalyze_employee_retention &lt;- function(employees_dt, analysis_date = Sys.Date()) {\n  #' Analiza patrones de retención de empleados\n  #' \n  #' @param employees_dt data.table con datos de empleados\n  #' @param analysis_date Fecha de referencia para el análisis\n  #' @return data.table con métricas de retención por departamento\n  \n  # Calcular métricas base\n  employees_dt[, `:=`(\n    tenure_years = as.numeric(analysis_date - hire_date) / 365.25,\n    is_long_tenure = tenure_years &gt;= 3\n  )]\n  \n  # Análisis de retención por departamento\n  retention_analysis &lt;- employees_dt[\n    !is.na(tenure_years),\n    .(\n      total_employees = .N,\n      avg_tenure = round(mean(tenure_years), 2),\n      retention_3_year = sum(is_long_tenure) / .N,\n      avg_salary_retained = mean(salary[is_long_tenure]),\n      avg_salary_new = mean(salary[!is_long_tenure])\n    ),\n    by = department\n  ][\n    order(-retention_3_year)\n  ]\n  \n  return(retention_analysis)\n}\n\n# Uso de la función\nretention_results &lt;- analyze_employee_retention(employees_dt)\nprint(retention_results)\n#&gt;     department total_employees avg_tenure retention_3_year avg_salary_retained\n#&gt;         &lt;char&gt;           &lt;int&gt;      &lt;num&gt;            &lt;num&gt;               &lt;num&gt;\n#&gt; 1:     Finance            9865       5.66        0.7690826            94881.15\n#&gt; 2:          HR            9983       5.64        0.7667034            94739.93\n#&gt; 3:   Marketing           10050       5.69        0.7658706            94678.32\n#&gt; 4: Engineering           10095       5.61        0.7626548            95438.25\n#&gt; 5:       Sales           10007       5.62        0.7553712            95281.11\n#&gt;    avg_salary_new\n#&gt;             &lt;num&gt;\n#&gt; 1:       95367.65\n#&gt; 2:       94774.08\n#&gt; 3:       95029.48\n#&gt; 4:       94898.17\n#&gt; 5:       95308.60",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-testing",
    "href": "cap04-buenas-practicas.html#sec-testing",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "\n10.5 Testing y Validación",
    "text": "10.5 Testing y Validación\n\n10.5.1 1. Unit Tests para Funciones data.table\n\n\n# Función simple para testing\ncalculate_employee_bonus &lt;- function(salary, performance_score, department) {\n  base_bonus &lt;- salary * 0.1\n  performance_multiplier &lt;- performance_score / 3\n  department_bonus &lt;- fifelse(department == \"Sales\", salary * 0.05, 0)\n  \n  return(base_bonus * performance_multiplier + department_bonus)\n}\n\n# Tests básicos\ntest_bonus_calculation &lt;- function() {\n  # Test 1: Cálculo básico\n  test_salary &lt;- 100000\n  test_performance &lt;- 3\n  test_dept &lt;- \"Engineering\"\n  \n  expected_bonus &lt;- (100000 * 0.1) * (3/3) + 0  # 10000\n  actual_bonus &lt;- calculate_employee_bonus(test_salary, test_performance, test_dept)\n  \n  cat(\"Test 1 - Cálculo básico:\", \n      ifelse(abs(actual_bonus - expected_bonus) &lt; 0.01, \"✅ PASS\", \"❌ FAIL\"), \"\\n\")\n  \n  # Test 2: Bonus de ventas\n  test_dept_sales &lt;- \"Sales\"\n  expected_bonus_sales &lt;- (100000 * 0.1) * (3/3) + (100000 * 0.05)  # 15000\n  actual_bonus_sales &lt;- calculate_employee_bonus(test_salary, test_performance, test_dept_sales)\n  \n  cat(\"Test 2 - Bonus de ventas:\", \n      ifelse(abs(actual_bonus_sales - expected_bonus_sales) &lt; 0.01, \"✅ PASS\", \"❌ FAIL\"), \"\\n\")\n  \n  # Test 3: Performance alto\n  test_performance_high &lt;- 5\n  expected_bonus_high &lt;- (100000 * 0.1) * (5/3) + 0  # 16666.67\n  actual_bonus_high &lt;- calculate_employee_bonus(test_salary, test_performance_high, test_dept)\n  \n  cat(\"Test 3 - Performance alto:\", \n      ifelse(abs(actual_bonus_high - expected_bonus_high) &lt; 1, \"✅ PASS\", \"❌ FAIL\"), \"\\n\")\n}\n\n# Ejecutar tests\ntest_bonus_calculation()\n#&gt; Test 1 - Cálculo básico: ✅ PASS \n#&gt; Test 2 - Bonus de ventas: ✅ PASS \n#&gt; Test 3 - Performance alto: ✅ PASS\n\n# Aplicar a datos reales\nemployees_dt[, calculated_bonus := calculate_employee_bonus(salary, performance_score, department)]\nprint(head(employees_dt[, .(employee_id, department, salary, performance_score, calculated_bonus)]))\n#&gt;    employee_id  department salary performance_score calculated_bonus\n#&gt;          &lt;int&gt;      &lt;char&gt;  &lt;num&gt;             &lt;int&gt;            &lt;num&gt;\n#&gt; 1:           1 Engineering 128722                 3         12872.20\n#&gt; 2:           2     Finance 128148                 3         12814.80\n#&gt; 3:           3     Finance  50533                 3          5053.30\n#&gt; 4:           4          HR  41787                 3          4178.70\n#&gt; 5:           5       Sales  79771                 3         11965.65\n#&gt; 6:           6     Finance 138060                 3         13806.00\n\n\n10.5.2 2. Validation de Integridad de Datos\n\n\n# Suite completa de validación\nvalidate_data_integrity &lt;- function(dt, table_name = \"data.table\") {\n  cat(\"=== Validación de Integridad:\", table_name, \"===\\n\")\n  \n  validation_results &lt;- list()\n  \n  # 1. Verificar duplicados en ID\n  if(\"employee_id\" %in% names(dt)) {\n    duplicate_ids &lt;- dt[, .N, by = employee_id][N &gt; 1]\n    validation_results$duplicate_ids &lt;- nrow(duplicate_ids)\n    cat(\"IDs duplicados:\", nrow(duplicate_ids), \n        ifelse(nrow(duplicate_ids) == 0, \"✅\", \"❌\"), \"\\n\")\n  }\n  \n  # 2. Verificar rangos válidos\n  if(\"salary\" %in% names(dt)) {\n    invalid_salaries &lt;- dt[salary &lt; 0 | salary &gt; 1000000, .N]\n    validation_results$invalid_salaries &lt;- invalid_salaries\n    cat(\"Salarios inválidos:\", invalid_salaries, \n        ifelse(invalid_salaries == 0, \"✅\", \"❌\"), \"\\n\")\n  }\n  \n  if(\"performance_score\" %in% names(dt)) {\n    invalid_performance &lt;- dt[performance_score &lt; 1 | performance_score &gt; 5, .N]\n    validation_results$invalid_performance &lt;- invalid_performance\n    cat(\"Scores de performance inválidos:\", invalid_performance,\n        ifelse(invalid_performance == 0, \"✅\", \"❌\"), \"\\n\")\n  }\n  \n  # 3. Verificar fechas\n  if(\"hire_date\" %in% names(dt)) {\n    future_dates &lt;- dt[hire_date &gt; Sys.Date(), .N]\n    very_old_dates &lt;- dt[hire_date &lt; as.Date(\"1950-01-01\"), .N]\n    validation_results$future_dates &lt;- future_dates\n    validation_results$very_old_dates &lt;- very_old_dates\n    cat(\"Fechas futuras:\", future_dates, ifelse(future_dates == 0, \"✅\", \"❌\"), \"\\n\")\n    cat(\"Fechas muy antiguas:\", very_old_dates, ifelse(very_old_dates == 0, \"✅\", \"❌\"), \"\\n\")\n  }\n  \n  # 4. Verificar consistencia referencial\n  if(all(c(\"manager_id\", \"employee_id\") %in% names(dt))) {\n    orphan_managers &lt;- dt[!is.na(manager_id) & !manager_id %in% employee_id, .N]\n    validation_results$orphan_managers &lt;- orphan_managers\n    cat(\"Managers inexistentes:\", orphan_managers, \n        ifelse(orphan_managers == 0, \"✅\", \"❌\"), \"\\n\")\n  }\n  \n  # Resumen\n  total_issues &lt;- sum(unlist(validation_results))\n  cat(\"\\nResumen: Total de issues encontrados:\", total_issues, \n      ifelse(total_issues == 0, \"✅ Datos válidos\", \"❌ Requiere atención\"), \"\\n\\n\")\n  \n  return(validation_results)\n}\n\n# Ejecutar validación\nintegrity_results &lt;- validate_data_integrity(employees_dt, \"employees_dt\")\n#&gt; === Validación de Integridad: employees_dt ===\n#&gt; IDs duplicados: 0 ✅ \n#&gt; Salarios inválidos: 0 ✅ \n#&gt; Scores de performance inválidos: 0 ✅ \n#&gt; Fechas futuras: 0 ✅ \n#&gt; Fechas muy antiguas: 0 ✅ \n#&gt; Managers inexistentes: 0 ✅ \n#&gt; \n#&gt; Resumen: Total de issues encontrados: 0 ✅ Datos válidos",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-ejercicio-refactoring",
    "href": "cap04-buenas-practicas.html#sec-ejercicio-refactoring",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "\n10.6 Ejercicio Final: Refactoring de Código",
    "text": "10.6 Ejercicio Final: Refactoring de Código\n\n\n\n\n\n\n🛠️ Ejercicio 9: Refactoring Completo\n\n\n\nToma el siguiente código mal escrito y refactorízalo aplicando todas las buenas prácticas:\n# CÓDIGO MALO para refactorizar\nbad_analysis &lt;- function(data) {\n  result &lt;- data.frame()\n  \n  for(dept in unique(data$department)) {\n    dept_data &lt;- data[data$department == dept, ]\n    \n    for(year in 2020:2024) {\n      year_data &lt;- dept_data[as.numeric(format(dept_data$hire_date, \"%Y\")) == year, ]\n      \n      if(nrow(year_data) &gt; 0) {\n        avg_sal &lt;- mean(year_data$salary)\n        count &lt;- nrow(year_data)\n        high_performers &lt;- nrow(year_data[year_data$performance_score &gt;= 4, ])\n        \n        new_row &lt;- data.frame(\n          department = dept,\n          hire_year = year,\n          avg_salary = avg_sal,\n          employee_count = count,\n          high_performer_count = high_performers,\n          high_performer_rate = high_performers / count\n        )\n        \n        result &lt;- rbind(result, new_row)\n      }\n    }\n  }\n  \n  return(result)\n}\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 9\n\n\n\n\n\n\n# CÓDIGO REFACTORIZADO aplicando buenas prácticas\ngood_analysis &lt;- function(employees_dt) {\n  #' Analiza empleados por departamento y año de contratación\n  #' @param employees_dt data.table con datos de empleados\n  #' @return data.table con análisis agregado\n  \n  # Validación de entrada\n  required_cols &lt;- c(\"department\", \"hire_date\", \"salary\", \"performance_score\")\n  if(!all(required_cols %in% names(employees_dt))) {\n    stop(\"Faltan columnas requeridas: \", \n         paste(setdiff(required_cols, names(employees_dt)), collapse = \", \"))\n  }\n  \n  # Una sola operación vectorizada que reemplaza todos los bucles\n  result &lt;- employees_dt[\n    # Filtro para años de interés\n    year(hire_date) %between% c(2020, 2024),\n    \n    # Cálculos agregados\n    .(\n      avg_salary = round(mean(salary, na.rm = TRUE), 0),\n      employee_count = .N,\n      high_performer_count = sum(performance_score &gt;= 4, na.rm = TRUE),\n      median_salary = median(salary, na.rm = TRUE),\n      salary_std = round(sd(salary, na.rm = TRUE), 0)\n    ),\n    \n    # Agrupación\n    by = .(department, hire_year = year(hire_date))\n  ][\n    # Cálculos derivados\n    , high_performer_rate := round(high_performer_count / employee_count, 3)\n  ][\n    # Filtrar grupos pequeños\n    employee_count &gt;= 3\n  ][\n    # Ordenamiento lógico\n    order(department, hire_year)\n  ]\n  \n  return(result)\n}\n\n# Comparar rendimiento\nsample_employees &lt;- employees_dt[sample(.N, 5000)]\n\n# Tiempo del método refactorizado\ntiempo_bueno &lt;- system.time({\n  resultado_bueno &lt;- good_analysis(sample_employees)\n})\n\ncat(\"Método refactorizado:\", round(tiempo_bueno[3], 4), \"segundos\\n\")\n#&gt; Método refactorizado: 0 segundos\ncat(\"Filas resultado:\", nrow(resultado_bueno), \"\\n\")\n#&gt; Filas resultado: 25\n\nprint(head(resultado_bueno))\n#&gt;     department hire_year avg_salary employee_count high_performer_count\n#&gt;         &lt;char&gt;     &lt;int&gt;      &lt;num&gt;          &lt;int&gt;                &lt;int&gt;\n#&gt; 1: Engineering      2020      95376            102                   21\n#&gt; 2: Engineering      2021      92345             87                   24\n#&gt; 3: Engineering      2022      98022            104                   23\n#&gt; 4: Engineering      2023      87590            110                   17\n#&gt; 5: Engineering      2024      91134             95                   13\n#&gt; 6:     Finance      2020      95926            110                   16\n#&gt;    median_salary salary_std high_performer_rate\n#&gt;            &lt;num&gt;      &lt;num&gt;               &lt;num&gt;\n#&gt; 1:       94355.5      30045               0.206\n#&gt; 2:       86740.0      35390               0.276\n#&gt; 3:      102976.5      31567               0.221\n#&gt; 4:       86547.0      33963               0.155\n#&gt; 5:       90209.0      32451               0.137\n#&gt; 6:       97021.0      29789               0.145\n\n# Verificación adicional: completeness\ncat(\"\\nVerificación de completeness:\\n\")\n#&gt; \n#&gt; Verificación de completeness:\ncat(\"Departamentos únicos en original:\", uniqueN(sample_employees$department), \"\\n\")\n#&gt; Departamentos únicos en original: 5\ncat(\"Departamentos únicos en resultado:\", uniqueN(resultado_bueno$department), \"\\n\")\n#&gt; Departamentos únicos en resultado: 5\ncat(\"Años únicos en resultado:\", paste(sort(unique(resultado_bueno$hire_year)), collapse = \", \"), \"\\n\")\n#&gt; Años únicos en resultado: 2020, 2021, 2022, 2023, 2024\n\nMejoras aplicadas en el refactoring:\n\n\nEliminación total de bucles: Una sola operación by vectorizada\n\nSin rbind repetitivo: El resultado se construye eficientemente\n\nValidación de entrada: Verificación de columnas requeridas\n\nOperaciones vectorizadas: mean(), sum(), .N son nativamente rápidas\n\nSintaxis data.table pura: Sin conversiones a/desde data.frame\n\nFiltros inteligentes: Eliminación de grupos pequeños\n\nCálculos derivados: Usando := para eficiencia\n\nDocumentación: Función bien documentada\n\nManejo de NAs: Parámetro na.rm = TRUE donde corresponde\n\nOrdenamiento lógico: Resultado ordenado para mejor interpretación",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#próximo-capítulo-integración-con-el-ecosistema",
    "href": "cap04-buenas-practicas.html#próximo-capítulo-integración-con-el-ecosistema",
    "title": "10  Buenas Prácticas y Código Idiomático",
    "section": "\n10.7 Próximo Capítulo: Integración con el Ecosistema",
    "text": "10.7 Próximo Capítulo: Integración con el Ecosistema\nEn el siguiente y último capítulo exploraremos: - Integración con ggplot2 para visualización de datos - Workflows con shiny para aplicaciones interactivas\n- Interoperabilidad con tidymodels para machine learning - Conexión con bases de datos y sistemas Big Data - dtplyr: El puente entre data.table y tidyverse\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nEl operador := es fundamental para código eficiente en data.table\n\nLos bucles explícitos destruyen todas las optimizaciones - usa vectorización\n\nsetkey() es crucial para datasets grandes y operaciones repetitivas\n\nLa gestión de memoria puede marcar la diferencia entre código viable e inviable\n\nValidación y testing previenen errores costosos en análisis de datos\n\nEl estilo consistente hace el código mantenible y colaborativo\n\nUna operación data.table bien diseñada puede reemplazar cientos de líneas de código tradicional\n\n\n\nHas dominado las buenas prácticas de data.table. En el próximo capítulo veremos cómo integrar todo este poder con el ecosistema R para crear soluciones completas de análisis de datos.",
    "crumbs": [
      "**Módulo 4**: Optimización y Buenas Prácticas",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Buenas Prácticas y Código Idiomático</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html",
    "href": "cap05-visualizacion.html",
    "title": "11  Visualización de Datos con data.table",
    "section": "",
    "text": "11.1 Integración con ggplot2: Gráficos Estáticos Profesionales",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Visualización de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#integración-con-ggplot2-gráficos-estáticos-profesionales",
    "href": "cap05-visualizacion.html#integración-con-ggplot2-gráficos-estáticos-profesionales",
    "title": "11  Visualización de Datos con data.table",
    "section": "",
    "text": "11.1.1 1. El Workflow Fundamental: data.table → ggplot2\n\nLa filosofía es clara: hacer toda la manipulación pesada de datos con data.table y pasar el resultado final limpio a ggplot2.\n\n# PASO 1: Preparación con data.table (rápido y eficiente)\nventas_mensuales &lt;- ventas_detalladas[,\n  .(\n    revenue_total = sum(revenue),\n    unidades_vendidas = sum(cantidad),\n    ticket_promedio = round(mean(revenue), 2),\n    num_transacciones = .N,\n    satisfaccion_media = round(mean(satisfaccion_cliente), 2)\n  ),\n  by = .(año, mes)\n][, `:=`(\n  fecha_mes = as.Date(paste(año, mes, \"01\", sep = \"-\")),\n  crecimiento = (revenue_total / data.table::shift(revenue_total, 1) - 1) * 100\n)]\n\n# PASO 2: Visualización con ggplot2 (hermoso y profesional)\np1 &lt;- ggplot(ventas_mensuales, aes(x = fecha_mes, y = revenue_total)) +\n  geom_line(color = \"#2E8B57\", size = 1.3, alpha = 0.8) +\n  geom_point(color = \"#2E8B57\", size = 3, alpha = 0.9) +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"#FF6B35\", alpha = 0.3) +\n  scale_y_continuous(\n    labels = dollar_format(prefix = \"$\", suffix = \"K\", scale = 1e-3),\n    expand = expansion(mult = c(0.02, 0.1))\n  ) +\n  scale_x_date(\n    date_labels = \"%b %Y\", \n    date_breaks = \"3 months\",\n    expand = expansion(mult = c(0.02, 0.02))\n  ) +\n  labs(\n    title = \"Evolución del Revenue Mensual\",\n    subtitle = \"Tendencia de ventas con línea de regresión suavizada\",\n    x = NULL,\n    y = \"Revenue Total\",\n    caption = \"Datos procesados con data.table | Visualización: ggplot2\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 16, face = \"bold\", hjust = 0),\n    plot.subtitle = element_text(color = \"gray40\", size = 12, hjust = 0),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.minor = element_blank(),\n    plot.caption = element_text(color = \"gray50\", size = 9)\n  )\n\nprint(p1)\n\n\n\n\n\n\n\n\n11.1.2 2. Gráficos Multidimensionales Avanzados\n\n\n# Análisis complejo con múltiples dimensiones\nanalisis_completo &lt;- ventas_detalladas[,\n  .(\n    revenue_total = sum(revenue),\n    margen_promedio = round(mean(1 - descuento), 3),\n    satisfaccion_media = round(mean(satisfaccion_cliente), 2),\n    variacion_precios = sd(precio_final) / mean(precio_final),\n    dias_activos = uniqueN(fecha)\n  ),\n  by = .(region, producto, año)\n][, `:=`(\n  revenue_per_dia = revenue_total / dias_activos,\n  categoria_revenue = cut(revenue_total, \n                         breaks = quantile(revenue_total, c(0, 0.33, 0.66, 1)),\n                         labels = c(\"Bajo\", \"Medio\", \"Alto\"),\n                         include.lowest = TRUE)\n)]\n\n# Gráfico de burbujas multivariable\np2 &lt;- ggplot(analisis_completo, \n             aes(x = margen_promedio, y = satisfaccion_media)) +\n  geom_point(aes(size = revenue_total, color = region, shape = factor(año)), \n             alpha = 0.7, stroke = 1) +\n  geom_text(aes(label = producto), \n            vjust = -1.2, hjust = 0.5, size = 2.5, color = \"gray30\") +\n  scale_size_continuous(\n    name = \"Revenue Total\", \n    labels = dollar_format(prefix = \"$\", suffix = \"K\", scale = 1e-3),\n    range = c(3, 15),\n    guide = guide_legend(override.aes = list(alpha = 1))\n  ) +\n  scale_color_brewer(\n    name = \"Región\", \n    type = \"qual\", \n    palette = \"Set2\"\n  ) +\n  scale_shape_manual(\n    name = \"Año\",\n    values = c(16, 17),\n    guide = guide_legend(override.aes = list(size = 5))\n  ) +\n  scale_x_continuous(\n    labels = percent_format(),\n    expand = expansion(mult = c(0.05, 0.05))\n  ) +\n  labs(\n    title = \"Análisis Multidimensional: Performance por Región y Producto\",\n    subtitle = \"Margen vs Satisfacción vs Revenue | Tamaño = Revenue, Color = Región, Forma = Año\",\n    x = \"Margen Promedio\",\n    y = \"Satisfacción Media del Cliente\",\n    caption = \"Cada punto representa una combinación región-producto-año\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 15, face = \"bold\"),\n    plot.subtitle = element_text(color = \"gray40\", size = 11),\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\",\n    panel.grid.minor = element_blank()\n  ) +\n  guides(\n    color = guide_legend(title.position = \"top\", title.hjust = 0.5),\n    size = guide_legend(title.position = \"top\", title.hjust = 0.5),\n    shape = guide_legend(title.position = \"top\", title.hjust = 0.5)\n  )\n\nprint(p2)\n\n\n\n\n\n\n\n\n11.1.3 3. Series Temporales con Múltiples Métricas\n\n\n# Preparar datos para series temporales múltiples\nseries_temporales &lt;- datos_temporales[,\n  .(\n    cpu_promedio = round(mean(cpu_usage), 1),\n    memory_promedio = round(mean(memory_usage), 1),\n    response_time_p95 = round(quantile(response_time, 0.95), 0),\n    error_total = sum(error_count),\n    load_promedio = round(mean(load_score), 1)\n  ),\n  by = .(fecha, hora)\n][, timestamp := as.POSIXct(paste(fecha, sprintf(\"%02d:00:00\", hora)))]\n\n# Transformar a formato largo para ggplot\nseries_largo &lt;- melt(series_temporales, \n                    id.vars = c(\"timestamp\", \"fecha\", \"hora\"),\n                    measure.vars = c(\"cpu_promedio\", \"memory_promedio\", \"load_promedio\"),\n                    variable.name = \"metrica\",\n                    value.name = \"valor\")\n\n# Mapear nombres más descriptivos\nseries_largo[, metrica_clean := fcase(\n  metrica == \"cpu_promedio\", \"CPU Usage (%)\",\n  metrica == \"memory_promedio\", \"Memory Usage (%)\",\n  metrica == \"load_promedio\", \"Load Score\",\n  default = as.character(metrica)\n)]\n\n# Gráfico de series temporales múltiples\np3 &lt;- ggplot(series_largo[fecha &gt;= as.Date(\"2024-01-01\") & fecha &lt;= as.Date(\"2024-01-07\")], \n             aes(x = timestamp, y = valor, color = metrica_clean)) +\n  geom_line(size = 0.8, alpha = 0.8) +\n  geom_smooth(method = \"loess\", se = FALSE, size = 1.2, alpha = 0.9) +\n  scale_color_viridis_d(name = \"Métrica\", option = \"plasma\", end = 0.8) +\n  scale_x_datetime(\n    date_labels = \"%d %b\\n%H:%M\",\n    date_breaks = \"12 hours\"\n  ) +\n  scale_y_continuous(\n    expand = expansion(mult = c(0.02, 0.1))\n  ) +\n  labs(\n    title = \"Monitoreo de Sistema - Primera Semana de Enero 2024\",\n    subtitle = \"Tendencias de CPU, Memoria y Load Score con líneas de regresión suavizada\",\n    x = \"Timestamp\",\n    y = \"Valor\",\n    caption = \"Datos agregados por hora | Líneas suavizadas con método LOESS\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 14, face = \"bold\"),\n    plot.subtitle = element_text(color = \"gray40\", size = 11),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"bottom\",\n    panel.grid.minor.x = element_blank(),\n    strip.text = element_text(size = 10, face = \"bold\")\n  ) +\n  facet_wrap(~ metrica_clean, scales = \"free_y\", ncol = 1)\n\nprint(p3)\n\n\n\n\n\n\n\n\n11.1.4 4. Heatmaps y Visualizaciones de Correlación\n\n\n# Preparar matriz de correlación usando data.table\ncorrelacion_por_region &lt;- ventas_detalladas[,\n  .(\n    precio_promedio = mean(precio_final),\n    revenue_promedio = mean(revenue),\n    satisfaccion_promedio = mean(satisfaccion_cliente),\n    descuento_promedio = mean(descuento),\n    cantidad_promedio = mean(cantidad)\n  ),\n  by = .(region, producto)\n]\n\n# Crear heatmap de performance por región-producto\nheatmap_data &lt;- correlacion_por_region[, .(\n  region, producto,\n  revenue_normalizado = scale(revenue_promedio)[,1],\n  satisfaccion_normalizada = scale(satisfaccion_promedio)[,1],\n  eficiencia = (scale(revenue_promedio)[,1] + scale(satisfaccion_promedio)[,1]) / 2\n)]\n\np4 &lt;- ggplot(heatmap_data, aes(x = region, y = producto, fill = eficiencia)) +\n  geom_tile(color = \"white\", size = 0.3) +\n  geom_text(aes(label = round(eficiencia, 2)), \n            color = ifelse(heatmap_data$eficiencia &gt; 0, \"white\", \"black\"),\n            size = 3.5, fontface = \"bold\") +\n  scale_fill_gradient2(\n    name = \"Índice de\\nEficiencia\",\n    low = \"#d73027\", mid = \"#f7f7f7\", high = \"#1a9850\",\n    midpoint = 0,\n    guide = guide_colorbar(title.position = \"top\", title.hjust = 0.5)\n  ) +\n  labs(\n    title = \"Mapa de Calor: Eficiencia por Región y Producto\",\n    subtitle = \"Índice combinado de Revenue y Satisfacción del Cliente (valores estandarizados)\",\n    x = \"Región\",\n    y = \"Producto\",\n    caption = \"Verde = Alta eficiencia, Rojo = Baja eficiencia\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 14, face = \"bold\"),\n    plot.subtitle = element_text(color = \"gray40\", size = 11),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 10),\n    legend.position = \"right\",\n    panel.grid = element_blank()\n  )\n\nprint(p4)",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Visualización de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#gráficos-interactivos-con-plotly",
    "href": "cap05-visualizacion.html#gráficos-interactivos-con-plotly",
    "title": "11  Visualización de Datos con data.table",
    "section": "\n11.2 Gráficos Interactivos con Plotly",
    "text": "11.2 Gráficos Interactivos con Plotly\n\n11.2.1 1. Conversión de ggplot2 a Plotly\n\n\n# Crear gráfico base con ggplot2\ndatos_interactivos &lt;- ventas_detalladas[,\n  .(\n    revenue_diario = sum(revenue),\n    unidades = sum(cantidad),\n    transacciones = .N,\n    satisfaccion_avg = round(mean(satisfaccion_cliente), 2),\n    productos_unicos = uniqueN(producto)\n  ),\n  by = .(fecha, region)\n]\n\n# Gráfico base para conversión\ngrafico_base &lt;- ggplot(datos_interactivos[fecha &gt;= as.Date(\"2024-01-01\") & fecha &lt;= as.Date(\"2024-03-31\")], \n                       aes(x = fecha, y = revenue_diario, color = region)) +\n  geom_line(alpha = 0.8, size = 1) +\n  geom_point(aes(size = transacciones, \n                text = paste(\"Fecha:\", fecha,\n                           \"&lt;br&gt;Región:\", region,\n                           \"&lt;br&gt;Revenue:\", scales::dollar(revenue_diario),\n                           \"&lt;br&gt;Transacciones:\", transacciones,\n                           \"&lt;br&gt;Satisfacción:\", satisfaccion_avg)),\n             alpha = 0.7) +\n  scale_color_brewer(type = \"qual\", palette = \"Set2\") +\n  scale_size_continuous(range = c(2, 8)) +\n  labs(\n    title = \"Revenue Diario por Región (Interactivo)\",\n    x = \"Fecha\",\n    y = \"Revenue Diario\",\n    color = \"Región\",\n    size = \"Transacciones\"\n  ) +\n  theme_minimal() %&gt;% suppressWarnings()\n\n# Convertir a plotly\nif(requireNamespace(\"plotly\", quietly = TRUE)) {\n  grafico_interactivo &lt;- plotly::ggplotly(grafico_base, tooltip = \"text\") %&gt;%\n    plotly::layout(\n      title = list(text = \"Revenue Diario por Región&lt;br&gt;&lt;sub&gt;Hover para detalles | Click en leyenda para filtrar&lt;/sub&gt;\"),\n      hovermode = \"closest\"\n    )\n  \n  grafico_interactivo\n} else {\n  grafico_base\n  cat(\"💡 Instala 'plotly' para ver la versión interactiva: install.packages('plotly')\\n\")\n}\n\n\n11.2.2 2. Gráficos 3D y Superficies\n\n\nif(requireNamespace(\"plotly\", quietly = TRUE)) {\n  # Preparar datos para superficie 3D\n  superficie_data &lt;- ventas_detalladas[año == 2024,\n    .(\n      revenue_total = sum(revenue),\n      satisfaccion_media = mean(satisfaccion_cliente),\n      margen_promedio = mean(1 - descuento)\n    ),\n    by = .(mes, region)\n  ]\n  \n  # Crear matriz para la superficie\n  matriz_revenue &lt;- dcast(superficie_data, mes ~ region, value.var = \"revenue_total\", fill = 0)\n  matriz_vals &lt;- as.matrix(matriz_revenue[, -1])\n  \n  # Gráfico 3D\n  p3d &lt;- plotly::plot_ly(\n    z = matriz_vals,\n    x = colnames(matriz_vals),\n    y = matriz_revenue$mes,\n    type = \"surface\",\n    colorscale = \"Viridis\"\n  ) %&gt;%\n    plotly::layout(\n      title = \"Superficie 3D: Revenue por Mes y Región\",\n      scene = list(\n        xaxis = list(title = \"Región\"),\n        yaxis = list(title = \"Mes\"),\n        zaxis = list(title = \"Revenue\")\n      )\n    )\n  \n  p3d\n} else {\n  cat(\"💡 Instala 'plotly' para ver gráficos 3D interactivos\\n\")\n}",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Visualización de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#tablas-interactivas-con-dt",
    "href": "cap05-visualizacion.html#tablas-interactivas-con-dt",
    "title": "11  Visualización de Datos con data.table",
    "section": "\n11.3 Tablas Interactivas con DT",
    "text": "11.3 Tablas Interactivas con DT\n\n11.3.1 1. Dashboard de Datos con DT\n\n\n# Preparar datos comprehensivos para tabla\ntabla_comprehensiva &lt;- ventas_detalladas[,\n  .(\n    Revenue_Total = round(sum(revenue), 2),\n    Unidades_Vendidas = sum(cantidad),\n    Num_Transacciones = .N,\n    Ticket_Promedio = round(mean(revenue), 2),\n    Satisfaccion_Media = round(mean(satisfaccion_cliente), 2),\n    Descuento_Promedio = round(mean(descuento) * 100, 1),\n    Precio_Promedio = round(mean(precio_final), 2),\n    Revenue_por_Transaccion = round(sum(revenue) / .N, 2)\n  ),\n  by = .(Región = region, Producto = producto, Año = año)\n][, `:=`(\n  Ranking_Revenue = frank(-Revenue_Total),\n  Eficiencia = round((Satisfaccion_Media * Revenue_Total) / 1000, 2)\n)][order(-Revenue_Total)]\n\n# Crear tabla interactiva avanzada\ntabla_interactiva &lt;- DT::datatable(\n  tabla_comprehensiva,\n  caption = \"Dashboard Interactivo de Ventas - Análisis Completo\",\n  options = list(\n    pageLength = 15,\n    scrollX = TRUE,\n    scrollY = \"400px\",\n    dom = 'Bfrtip',\n    buttons = list(\n      list(extend = 'copy', text = 'Copiar'),\n      list(extend = 'csv', text = 'Descargar CSV'),\n      list(extend = 'excel', text = 'Descargar Excel'),\n      list(extend = 'pdf', text = 'Descargar PDF')\n    ),\n    columnDefs = list(\n      list(className = 'dt-center', targets = c(3, 4, 5, 6, 7, 8, 9, 10)),\n      list(width = '100px', targets = c(0, 1, 2))\n    ),\n    initComplete = DT::JS(\n      \"function(settings, json) {\",\n      \"$(this.api().table().header()).css({'background-color': '#2E8B57', 'color': '#fff'});\",\n      \"}\"\n    )\n  ),\n  extensions = c('Buttons', 'Scroller'),\n  rownames = FALSE,\n  class = 'cell-border stripe hover'\n) %&gt;%\n  DT::formatCurrency(c(\"Revenue_Total\", \"Ticket_Promedio\", \"Precio_Promedio\", \"Revenue_por_Transaccion\"), \n                     currency = \"$\", digits = 2) %&gt;%\n  DT::formatRound(c(\"Satisfaccion_Media\", \"Eficiencia\"), digits = 2) %&gt;%\n  DT::formatPercentage(\"Descuento_Promedio\", digits = 1) %&gt;%\n  DT::formatStyle(\n    \"Eficiencia\",\n    background = DT::styleColorBar(range(tabla_comprehensiva$Eficiencia), \"#4CAF50\"),\n    backgroundSize = \"100% 90%\",\n    backgroundRepeat = \"no-repeat\",\n    backgroundPosition = \"center\"\n  ) %&gt;%\n  DT::formatStyle(\n    \"Satisfaccion_Media\",\n    backgroundColor = DT::styleInterval(\n      cuts = c(3, 4),\n      values = c(\"#ffebee\", \"#e8f5e8\", \"#c8e6c9\")\n    )\n  ) %&gt;%\n  DT::formatStyle(\n    \"Ranking_Revenue\",\n    color = DT::styleInterval(\n      cuts = c(5, 10),\n      values = c(\"#d32f2f\", \"#ff9800\", \"#4caf50\")\n    ),\n    fontWeight = \"bold\"\n  )\n\ntabla_interactiva\n\n\n11.3.2 2. Tablas con Gráficos Embebidos (Sparklines)\n\n\n# Preparar datos para sparklines (tendencias mensuales)\ntendencias_mensuales &lt;- ventas_detalladas[,\n  .(revenue_mensual = sum(revenue)),\n  by = .(region, producto, año, mes)\n][order(region, producto, año, mes)]\n\n# Crear sparklines para cada combinación región-producto\nsparkline_data &lt;- tendencias_mensuales[,\n  .(\n    Revenue_Total = sum(revenue_mensual),\n    Meses_Activos = .N,\n    Revenue_Promedio = round(mean(revenue_mensual), 2),\n    Tendencia = list(revenue_mensual),\n    Max_Mes = max(revenue_mensual),\n    Min_Mes = min(revenue_mensual)\n  ),\n  by = .(Región = region, Producto = producto)\n][order(-Revenue_Total)]\n\n# Crear función para sparklines\ncrear_sparkline &lt;- function(values) {\n  paste0('&lt;span class=\"sparkline\"&gt;', paste(values, collapse = ','), '&lt;/span&gt;')\n}\n\n# Aplicar sparklines\nsparkline_data[, Tendencia_Visual := sapply(Tendencia, crear_sparkline)]\n\n# Tabla con sparklines\ntabla_sparklines &lt;- DT::datatable(\n  sparkline_data[, .(Región, Producto, Revenue_Total, Revenue_Promedio, \n                    Max_Mes, Min_Mes, Tendencia_Visual)],\n  caption = \"Análisis de Tendencias con Sparklines\",\n  options = list(\n    pageLength = 10,\n    scrollX = TRUE,\n    columnDefs = list(\n      list(className = 'dt-center', targets = c(2, 3, 4, 5, 6))\n    ),\n    fnDrawCallback = DT::JS(\n      'function(){\n        $(\".sparkline\").sparkline(\"html\", {\n          type: \"line\",\n          width: \"100px\",\n          height: \"30px\",\n          lineColor: \"#2E8B57\",\n          fillColor: \"#e8f5e8\",\n          spotColor: \"#FF6B35\",\n          minSpotColor: \"#FF6B35\",\n          maxSpotColor: \"#FF6B35\"\n        });\n      }'\n    )\n  ),\n  escape = FALSE,\n  rownames = FALSE\n) %&gt;%\n  DT::formatCurrency(c(\"Revenue_Total\", \"Revenue_Promedio\", \"Max_Mes\", \"Min_Mes\"), \n                     currency = \"$\", digits = 0)\n\n# Note: Para que las sparklines funcionen completamente, se necesita incluir la librería jQuery Sparklines\ncat(\"💡 Para sparklines completas, incluye: &lt;script src='https://cdn.jsdelivr.net/gh/garethflowers/jquery-sparkline/jquery.sparkline.min.js'&gt;&lt;/script&gt;\\n\")\n\ntabla_sparklines",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Visualización de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#dashboards-integrados-combinando-todo",
    "href": "cap05-visualizacion.html#dashboards-integrados-combinando-todo",
    "title": "11  Visualización de Datos con data.table",
    "section": "\n11.4 Dashboards Integrados: Combinando Todo",
    "text": "11.4 Dashboards Integrados: Combinando Todo\n\n11.4.1 1. Dashboard Ejecutivo Completo\n\n\n# Preparar datos para dashboard ejecutivo\nresumen_ejecutivo &lt;- ventas_detalladas[,\n  .(\n    revenue_total = sum(revenue),\n    unidades_total = sum(cantidad),\n    transacciones_total = .N,\n    satisfaccion_promedio = round(mean(satisfaccion_cliente), 2)\n  )\n]\n\nkpis_por_region &lt;- ventas_detalladas[,\n  .(\n    Revenue = sum(revenue),\n    Unidades = sum(cantidad),\n    Transacciones = .N,\n    Satisfacción = round(mean(satisfaccion_cliente), 2),\n    Ticket_Promedio = round(mean(revenue), 2)\n  ),\n  by = region\n][order(-Revenue)]\n\ntendencia_mensual &lt;- ventas_detalladas[,\n  .(revenue = sum(revenue)),\n  by = .(año, mes)\n][, fecha := as.Date(paste(año, mes, \"01\", sep = \"-\"))]\n\ntop_productos &lt;- ventas_detalladas[,\n  .(revenue = sum(revenue), satisfaccion = round(mean(satisfaccion_cliente), 2)),\n  by = producto\n][order(-revenue)]\n\n# Layout del dashboard usando grid.arrange\nlibrary(gridExtra)\n\n# Gráfico 1: KPIs por región\ng1 &lt;- ggplot(kpis_por_region, aes(x = reorder(region, Revenue), y = Revenue)) +\n  geom_col(fill = \"#2E8B57\", alpha = 0.8) +\n  geom_text(aes(label = scales::dollar(Revenue, scale = 1e-3, suffix = \"K\")), \n            hjust = -0.1, color = \"#2E8B57\", fontface = \"bold\") +\n  coord_flip() +\n  labs(title = \"Revenue por Región\", x = NULL, y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#2E8B57\"))\n\n# Gráfico 2: Tendencia temporal\ng2 &lt;- ggplot(tendencia_mensual, aes(x = fecha, y = revenue)) +\n  geom_line(color = \"#2E8B57\", size = 1.2) +\n  geom_point(color = \"#2E8B57\", size = 2) +\n  scale_y_continuous(labels = scales::dollar_format(scale = 1e-3, suffix = \"K\")) +\n  labs(title = \"Tendencia Mensual\", x = NULL, y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#2E8B57\"))\n\n# Gráfico 3: Top productos\ng3 &lt;- ggplot(top_productos, aes(x = reorder(producto, revenue), y = revenue)) +\n  geom_col(fill = \"#FF6B35\", alpha = 0.8) +\n  coord_flip() +\n  labs(title = \"Top Productos\", x = NULL, y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#FF6B35\"))\n\n# Gráfico 4: Satisfacción vs Revenue\ng4 &lt;- ggplot(top_productos, aes(x = satisfaccion, y = revenue)) +\n  geom_point(size = 4, color = \"#8E44AD\", alpha = 0.7) +\n  geom_text(aes(label = producto), vjust = -0.5, size = 3) +\n  labs(title = \"Satisfacción vs Revenue\", x = \"Satisfacción\", y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#8E44AD\"))\n\n# Combinar todos los gráficos\ngrid.arrange(\n  g1, g2, g3, g4,\n  ncol = 2, nrow = 2,\n  top = grid::textGrob(\"DASHBOARD EJECUTIVO DE VENTAS\", \n                      gp = grid::gpar(fontsize = 20, fontface = \"bold\", col = \"#2E8B57\"))\n)\n\n\n\n\n\n\n\n# Mostrar métricas clave\ncat(\"\\n📊 MÉTRICAS CLAVE DEL PERÍODO:\\n\")\n#&gt; \n#&gt; 📊 MÉTRICAS CLAVE DEL PERÍODO:\ncat(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\")\n#&gt; ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\ncat(\"💰 Revenue Total:\", scales::dollar(resumen_ejecutivo$revenue_total), \"\\n\")\n#&gt; 💰 Revenue Total: $907,171\ncat(\"📦 Unidades Vendidas:\", scales::comma(resumen_ejecutivo$unidades_total), \"\\n\")\n#&gt; 📦 Unidades Vendidas: 1,534\ncat(\"🛒 Total Transacciones:\", scales::comma(resumen_ejecutivo$transacciones_total), \"\\n\")\n#&gt; 🛒 Total Transacciones: 731\ncat(\"⭐ Satisfacción Promedio:\", resumen_ejecutivo$satisfaccion_promedio, \"/5\\n\")\n#&gt; ⭐ Satisfacción Promedio: 3.7 /5\ncat(\"🎯 Ticket Promedio:\", scales::dollar(resumen_ejecutivo$revenue_total / resumen_ejecutivo$transacciones_total), \"\\n\")\n#&gt; 🎯 Ticket Promedio: $1,241.00\n\n\n11.4.2 2. Tabla de Métricas Interactiva Final\n\n\n# Crear tabla final con todas las métricas\nmetricas_finales &lt;- ventas_detalladas[,\n  .(\n    Revenue = round(sum(revenue), 2),\n    Unidades = sum(cantidad),\n    Transacciones = .N,\n    Días_Activos = uniqueN(fecha),\n    Satisfacción = round(mean(satisfaccion_cliente), 2),\n    Descuento_Avg = round(mean(descuento) * 100, 1),\n    Revenue_per_Día = round(sum(revenue) / uniqueN(fecha), 2)\n  ),\n  by = .(Región = region, Producto = producto, Año = año)\n][, `:=`(\n  Performance_Score = round((Revenue / 1000) * Satisfacción * (1 - Descuento_Avg/100), 2),\n  Ranking = frank(-Revenue, ties.method = \"min\")\n)][order(-Performance_Score)]\n\n# Tabla final con formato avanzado\ntabla_final &lt;- DT::datatable(\n  metricas_finales,\n  caption = \"MÉTRICAS INTEGRALES DE PERFORMANCE | Dashboard Interactivo Final\",\n  options = list(\n    pageLength = 20,\n    scrollX = TRUE,\n    scrollY = \"500px\",\n    dom = 'Bfrtip',\n    buttons = list(\n      list(extend = 'copy', text = '📋 Copiar'),\n      list(extend = 'csv', text = '📊 CSV'),\n      list(extend = 'excel', text = '📈 Excel'),\n      list(extend = 'print', text = '🖨️ Imprimir')\n    ),\n    columnDefs = list(\n      list(className = 'dt-center', targets = c(3:10)),\n      list(orderSequence = c('desc', 'asc'), targets = c(3, 9, 10))\n    ),\n    initComplete = DT::JS(\n      \"function(settings, json) {\",\n      \"$(this.api().table().header()).css({\",\n      \"'background': 'linear-gradient(90deg, #2E8B57, #3CB371)',\",\n      \"'color': '#fff',\",\n      \"'text-align': 'center',\",\n      \"'font-weight': 'bold'\",\n      \"});\",\n      \"}\"\n    )\n  ),\n  extensions = c('Buttons', 'Scroller'),\n  rownames = FALSE,\n  class = 'cell-border stripe hover compact'\n) %&gt;%\n  DT::formatCurrency(c(\"Revenue\", \"Revenue_per_Día\"), currency = \"$\", digits = 0) %&gt;%\n  DT::formatRound(c(\"Satisfacción\", \"Performance_Score\"), digits = 2) %&gt;%\n  DT::formatPercentage(\"Descuento_Avg\", digits = 1) %&gt;%\n  DT::formatStyle(\n    \"Performance_Score\",\n    background = DT::styleColorBar(range(metricas_finales$Performance_Score), \"#2E8B57\"),\n    backgroundSize = \"100% 90%\",\n    backgroundRepeat = \"no-repeat\",\n    backgroundPosition = \"center\",\n    color = \"white\",\n    fontWeight = \"bold\"\n  ) %&gt;%\n  DT::formatStyle(\n    \"Ranking\",\n    backgroundColor = DT::styleInterval(\n      cuts = c(3, 7, 15),\n      values = c(\"#FFD700\", \"#C0C0C0\", \"#CD7F32\", \"#f5f5f5\")  # Oro, Plata, Bronce, Normal\n    ),\n    fontWeight = \"bold\",\n    textAlign = \"center\"\n  ) %&gt;%\n  DT::formatStyle(\n    \"Satisfacción\",\n    color = DT::styleInterval(\n      cuts = c(3.5, 4.5),\n      values = c(\"#e74c3c\", \"#f39c12\", \"#27ae60\")\n    ),\n    fontWeight = \"bold\"\n  )\n\ntabla_final",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Visualización de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#próximo-capítulo-aplicaciones-del-mundo-real",
    "href": "cap05-visualizacion.html#próximo-capítulo-aplicaciones-del-mundo-real",
    "title": "11  Visualización de Datos con data.table",
    "section": "\n11.5 Próximo Capítulo: Aplicaciones del Mundo Real",
    "text": "11.5 Próximo Capítulo: Aplicaciones del Mundo Real\nEn el siguiente capítulo exploraremos: - Aplicaciones Shiny para dashboards dinámicos - Integración con tidymodels para machine learning - Conexión con bases de datos y herramientas Big Data - Casos de uso industriales reales\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\ndata.table + ggplot2 = Combinación perfecta para análisis visual profesional\n\nPlotly añade interactividad sin sacrificar la estética de ggplot2\n\nDT transforma tablas estáticas en dashboards interactivos potentes\n\nEl workflow óptimo: Procesar con data.table → Visualizar con ggplot2/plotly/DT\n\nSparklines y formato avanzado elevan las tablas a herramientas de análisis\n\nLos dashboards integrados combinan múltiples visualizaciones para insights completos\n\n\n\nHas dominado la visualización de datos con data.table. En el próximo capítulo veremos cómo construir aplicaciones completas del mundo real.",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Visualización de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html",
    "href": "cap05-aplicaciones.html",
    "title": "12  Aplicaciones del Mundo Real",
    "section": "",
    "text": "12.1 Aplicaciones Shiny Escalables con data.table",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#aplicaciones-shiny-escalables-con-data.table",
    "href": "cap05-aplicaciones.html#aplicaciones-shiny-escalables-con-data.table",
    "title": "12  Aplicaciones del Mundo Real",
    "section": "",
    "text": "12.1.1 1. Arquitectura de App Shiny Profesional\n\n\n# Estructura modular para apps grandes\nlibrary(shiny)\nlibrary(shinydashboard)\nlibrary(data.table)\nlibrary(DT)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# === MÓDULO: Data Processing ===\n# Todas las operaciones data.table en funciones separadas\nprocess_customer_data &lt;- function(clientes_dt, filters = list()) {\n  # Aplicar filtros dinámicamente\n  result &lt;- clientes_dt\n  \n  if(!is.null(filters$region) && filters$region != \"Todos\") {\n    result &lt;- result[region == filters$region]\n  }\n  \n  if(!is.null(filters$edad_min)) {\n    result &lt;- result[edad &gt;= filters$edad_min]\n  }\n  \n  if(!is.null(filters$fecha_desde)) {\n    # Aquí se aplicarían filtros de fecha si tuviéramos esos datos\n  }\n  \n  return(result)\n}\n\ncalculate_customer_metrics &lt;- function(clientes_dt) {\n  clientes_dt[,\n    .(\n      total_clientes = .N,\n      edad_promedio = round(mean(edad), 1),\n      ingresos_promedio = round(mean(ingresos), 0),\n      satisfaccion_promedio = round(mean(satisfaccion), 2),\n      churn_rate = round(mean(churn_flag) * 100, 1),\n      valor_promedio = round(mean(valor_cliente), 2),\n      engagement_promedio = round(mean(engagement_score), 2)\n    ),\n    by = .(region, categoria_ingresos)\n  ]\n}\n\n# === UI: Dashboard Layout ===\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Customer Analytics - Powered by data.table\"),\n  \n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Overview\", tabName = \"overview\", icon = icon(\"dashboard\")),\n      menuItem(\"Clientes\", tabName = \"clientes\", icon = icon(\"users\")),\n      menuItem(\"Segmentación\", tabName = \"segmentacion\", icon = icon(\"chart-pie\")),\n      menuItem(\"Predicciones\", tabName = \"predicciones\", icon = icon(\"brain\")),\n      menuItem(\"Datos Raw\", tabName = \"datos\", icon = icon(\"table\"))\n    )\n  ),\n  \n  dashboardBody(\n    tags$head(\n      tags$style(HTML(\"\n        .content-wrapper, .right-side {\n          background-color: #f4f4f4;\n        }\n        .main-header .navbar {\n          background-color: #2E8B57 !important;\n        }\n      \"))\n    ),\n    \n    tabItems(\n      # Tab Overview\n      tabItem(tabName = \"overview\",\n        fluidRow(\n          valueBoxOutput(\"total_clientes\"),\n          valueBoxOutput(\"churn_rate\"),\n          valueBoxOutput(\"valor_promedio\")\n        ),\n        fluidRow(\n          box(\n            title = \"Filtros Globales\", status = \"primary\", solidHeader = TRUE,\n            width = 3,\n            selectInput(\"region_filter\", \"Región:\",\n                       choices = c(\"Todos\", unique(datos_clientes$region)),\n                       selected = \"Todos\"),\n            sliderInput(\"edad_range\", \"Rango de Edad:\",\n                       min = 18, max = 80, value = c(18, 80)),\n            actionButton(\"aplicar_filtros\", \"Aplicar Filtros\", \n                        class = \"btn-primary\")\n          ),\n          box(\n            title = \"Revenue por Región\", status = \"success\", solidHeader = TRUE,\n            width = 9,\n            plotlyOutput(\"revenue_plot\", height = \"400px\")\n          )\n        )\n      ),\n      \n      # Tab Clientes\n      tabItem(tabName = \"clientes\",\n        fluidRow(\n          box(\n            title = \"Análisis de Clientes\", status = \"primary\", solidHeader = TRUE,\n            width = 12,\n            DT::dataTableOutput(\"clientes_table\")\n          )\n        )\n      ),\n      \n      # Tab Segmentación\n      tabItem(tabName = \"segmentacion\",\n        fluidRow(\n          box(\n            title = \"Segmentación por Valor\", status = \"warning\", solidHeader = TRUE,\n            width = 6,\n            plotOutput(\"segmentacion_plot\")\n          ),\n          box(\n            title = \"Matriz de Retención\", status = \"info\", solidHeader = TRUE,\n            width = 6,\n            plotOutput(\"matriz_retencion\")\n          )\n        )\n      )\n    )\n  )\n)\n\n# === SERVER: Lógica Reactiva ===\nserver &lt;- function(input, output, session) {\n  \n  # Datos reactivos - aquí brilla data.table\n  datos_filtrados &lt;- reactive({\n    input$aplicar_filtros  # Dependencia del botón\n    \n    isolate({\n      filtros &lt;- list(\n        region = input$region_filter,\n        edad_min = input$edad_range[1],\n        edad_max = input$edad_range[2]\n      )\n      \n      result &lt;- datos_clientes[\n        edad &gt;= filtros$edad_min & edad &lt;= filtros$edad_max\n      ]\n      \n      if(filtros$region != \"Todos\") {\n        result &lt;- result[region == filtros$region]\n      }\n      \n      return(result)\n    })\n  })\n  \n  # ValueBoxes\n  output$total_clientes &lt;- renderValueBox({\n    valueBox(\n      value = comma(nrow(datos_filtrados())),\n      subtitle = \"Total Clientes\",\n      icon = icon(\"users\"),\n      color = \"blue\"\n    )\n  })\n  \n  output$churn_rate &lt;- renderValueBox({\n    rate &lt;- round(mean(datos_filtrados()$churn_flag) * 100, 1)\n    valueBox(\n      value = paste0(rate, \"%\"),\n      subtitle = \"Tasa de Churn\",\n      icon = icon(\"exclamation-triangle\"),\n      color = if(rate &gt; 15) \"red\" else if(rate &gt; 10) \"yellow\" else \"green\"\n    )\n  })\n  \n  output$valor_promedio &lt;- renderValueBox({\n    valor &lt;- round(mean(datos_filtrados()$valor_cliente), 2)\n    valueBox(\n      value = dollar(valor),\n      subtitle = \"Valor Promedio\",\n      icon = icon(\"dollar-sign\"),\n      color = \"green\"\n    )\n  })\n  \n  # Gráfico principal\n  output$revenue_plot &lt;- renderPlotly({\n    # Cálculo super rápido con data.table\n    plot_data &lt;- datos_filtrados()[,\n      .(\n        valor_total = sum(valor_cliente),\n        clientes = .N,\n        satisfaccion_avg = round(mean(satisfaccion), 2)\n      ),\n      by = region\n    ]\n    \n    p &lt;- ggplot(plot_data, aes(x = reorder(region, valor_total), y = valor_total)) +\n      geom_col(aes(fill = satisfaccion_avg), alpha = 0.8) +\n      geom_text(aes(label = dollar(valor_total, scale = 1e-3, suffix = \"K\")), \n               hjust = -0.1) +\n      scale_fill_viridis_c(name = \"Satisfacción\\nPromedio\") +\n      coord_flip() +\n      labs(title = \"Valor Total por Región\", x = \"Región\", y = \"Valor Total\") +\n      theme_minimal()\n    \n    ggplotly(p)\n  })\n  \n  # Tabla de clientes\n  output$clientes_table &lt;- DT::renderDataTable({\n    tabla_data &lt;- datos_filtrados()[,\n      .(\n        cliente_id, edad, region, \n        ingresos = dollar(ingresos),\n        valor_cliente = round(valor_cliente, 2),\n        satisfaccion,\n        engagement_score = round(engagement_score, 2),\n        riesgo_churn = ifelse(riesgo_churn == 1, \"Alto\", \"Bajo\"),\n        es_vip = ifelse(cliente_vip == 1, \"Sí\", \"No\")\n      )\n    ]\n    \n    DT::datatable(\n      tabla_data,\n      options = list(pageLength = 25, scrollX = TRUE),\n      rownames = FALSE\n    ) %&gt;%\n      DT::formatStyle(\n        \"riesgo_churn\",\n        backgroundColor = DT::styleEqual(\"Alto\", \"#ffebee\")\n      ) %&gt;%\n      DT::formatStyle(\n        \"es_vip\",\n        backgroundColor = DT::styleEqual(\"Sí\", \"#e8f5e8\")\n      )\n  })\n}\n\n# Lanzar la app\n# shinyApp(ui = ui, server = server)\n\n\n12.1.2 2. Optimización de Performance en Shiny\n\n\n# === TÉCNICAS DE OPTIMIZACIÓN ===\n\n# 1. Pre-procesar datos pesados al inicio\nonSessionStart &lt;- function(session) {\n  # Cálculos que no cambian frecuentemente\n  session$userData$metricas_estaticas &lt;- datos_clientes[,\n    .(\n      clientes_por_region = .N,\n      valor_total = sum(valor_cliente),\n      edad_promedio = mean(edad)\n    ),\n    by = region\n  ]\n  \n  # Índices para búsquedas rápidas\n  setkey(session$userData$clientes_dt, cliente_id)\n  setindex(session$userData$clientes_dt, region, categoria_ingresos)\n}\n\n# 2. Usar reactive values para cache inteligente\nserver &lt;- function(input, output, session) {\n  # Cache de cálculos costosos\n  cache_metricas &lt;- reactiveValues()\n  \n  # Solo recalcular cuando cambien inputs relevantes\n  observe({\n    key &lt;- paste(input$region_filter, input$edad_range[1], input$edad_range[2], sep = \"_\")\n    \n    if(is.null(cache_metricas[[key]])) {\n      cache_metricas[[key]] &lt;- calculate_customer_metrics(\n        datos_clientes[\n          region %in% input$region_filter & \n          edad %between% input$edad_range\n        ]\n      )\n    }\n  })\n  \n  # 3. Renderizado condicional\n  output$tabla_grande &lt;- DT::renderDataTable({\n    # Solo renderizar si la pestaña está visible\n    req(input$tabs == \"datos_detallados\")\n    \n    # data.table operation ultrarrápida\n    datos_tabla &lt;- datos_filtrados()[,\n      .(cliente_id, region, valor_cliente, churn_flag)\n    ][order(-valor_cliente)]\n    \n    DT::datatable(datos_tabla, options = list(pageLength = 50))\n  })\n}\n\n# 4. Módulos para escalabilidad\ncustomerMetricsUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  tagList(\n    valueBoxOutput(ns(\"total_value\")),\n    plotOutput(ns(\"distribution_plot\"))\n  )\n}\n\ncustomerMetricsServer &lt;- function(id, data) {\n  moduleServer(id, function(input, output, session) {\n    output$total_value &lt;- renderValueBox({\n      # Cálculo modular con data.table\n      total &lt;- data()[, sum(valor_cliente)]\n      valueBox(\n        value = dollar(total, scale = 1e-6, suffix = \"M\"),\n        subtitle = \"Valor Total\",\n        icon = icon(\"chart-line\"),\n        color = \"green\"\n      )\n    })\n  })\n}",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#integración-con-tidymodels-machine-learning-robusto",
    "href": "cap05-aplicaciones.html#integración-con-tidymodels-machine-learning-robusto",
    "title": "12  Aplicaciones del Mundo Real",
    "section": "\n12.2 Integración con tidymodels: Machine Learning Robusto",
    "text": "12.2 Integración con tidymodels: Machine Learning Robusto\n\n12.2.1 1. Workflow Completo: data.table → tidymodels → data.table\n\n\n# PASO 1: Feature Engineering con data.table (ultrarrápido)\npreparar_datos_ml &lt;- function(clientes_dt, transacciones_dt) {\n  # Calcular métricas de transacciones por cliente\n  metricas_transaccionales &lt;- transacciones_dt[, monto_final := monto * (1 - descuento_aplicado)][\n    fecha_transaccion &gt;= Sys.Date() - 365,  # Último año\n    .(\n      transacciones_año = .N,\n      monto_total_año = sum(monto_final),\n      monto_promedio = round(mean(monto_final), 2),\n      categorias_compradas = uniqueN(producto_categoria),\n      canal_principal = names(sort(table(canal), decreasing = TRUE))[1],\n      frecuencia_compra_dias = as.numeric(max(fecha_transaccion) - min(fecha_transaccion)) / .N,\n      usa_descuentos = mean(descuento_aplicado &gt; 0),\n      tasa_devolucion = mean(es_devolucion)\n    ),\n    by = cliente_id\n  ]\n  \n  # Unir con datos de clientes\n  datos_completos &lt;- clientes_dt[metricas_transaccionales, on = .(cliente_id)]\n  \n  # Feature engineering adicional\n  datos_completos[, `:=`(\n    # Variables de interacción\n    ingresos_edad_ratio = ingresos / edad,\n    valor_por_producto = valor_cliente / num_productos,\n    engagement_per_month = engagement_score / pmax(antiguedad_meses, 1),\n    \n    # Variables categóricas optimizadas\n    segmento_valor = cut(valor_cliente, \n                        breaks = quantile(valor_cliente, c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE),\n                        labels = c(\"Bajo\", \"Medio-Bajo\", \"Medio-Alto\", \"Alto\"),\n                        include.lowest = TRUE),\n    \n    # Variables binarias\n    cliente_frecuente = as.numeric(transacciones_año &gt; quantile(transacciones_año, 0.75, na.rm = TRUE)),\n    multicanal = as.numeric(categorias_compradas &gt;= 3),\n    \n    # Target variable limpia\n    churn = factor(ifelse(churn_flag == 1, \"Si\", \"No\"), levels = c(\"No\", \"Si\"))\n  )]\n  \n  # Remover casos con NAs en variables críticas\n  datos_limpios &lt;- datos_completos[\n    !is.na(transacciones_año) & \n    !is.na(monto_total_año) & \n    !is.na(churn)\n  ]\n  \n  return(datos_limpios)\n}\n\n# Ejecutar preparación\ndatos_ml &lt;- preparar_datos_ml(datos_clientes, transacciones_detalle)\n\ncat(\"Datos preparados para ML:\\n\")\n#&gt; Datos preparados para ML:\ncat(\"- Filas:\", nrow(datos_ml), \"\\n\")\n#&gt; - Filas: 5938\ncat(\"- Columnas:\", ncol(datos_ml), \"\\n\")\n#&gt; - Columnas: 33\ncat(\"- Distribución de churn:\\n\")\n#&gt; - Distribución de churn:\nprint(datos_ml[, .N, by = churn])\n#&gt;     churn     N\n#&gt;    &lt;fctr&gt; &lt;int&gt;\n#&gt; 1:     Si   707\n#&gt; 2:     No  5231\n\n\n12.2.2 2. Modelado con tidymodels (Ejemplo Conceptual)\n\n\n# Ejemplo de workflow completo con tidymodels\nlibrary(tidymodels)\nlibrary(themis)  # Para balanceo de clases\n\n# PASO 2: Convertir a tibble para tidymodels\ndatos_tibble &lt;- as_tibble(datos_ml)\n\n# PASO 3: Split de datos\nset.seed(123)\ndata_split &lt;- initial_split(\n  datos_tibble, \n  prop = 0.8, \n  strata = churn\n)\n\ntrain_data &lt;- training(data_split)\ntest_data &lt;- testing(data_split)\n\n# PASO 4: Receta de preprocesamiento\nreceta_churn &lt;- recipe(churn ~ ., data = train_data) %&gt;%\n  # Remover variables no predictivas\n  step_rm(cliente_id, churn_flag) %&gt;%\n  \n  # Imputación de NAs\n  step_impute_median(all_numeric_predictors()) %&gt;%\n  step_impute_mode(all_nominal_predictors()) %&gt;%\n  \n  # Feature engineering\n  step_log(ingresos, valor_cliente, offset = 1) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  \n  # Variables dummy\n  step_dummy(all_nominal_predictors()) %&gt;%\n  \n  # Balanceo de clases\n  step_downsample(churn, under_ratio = 2) %&gt;%\n  \n  # Remover variables con varianza cero\n  step_zv(all_predictors()) %&gt;%\n  \n  # Correlación alta\n  step_corr(all_numeric_predictors(), threshold = 0.9)\n\n# PASO 5: Modelos\nmodelo_rf &lt;- rand_forest(\n  trees = tune(),\n  mtry = tune(),\n  min_n = tune()\n) %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"randomForest\")\n\nmodelo_xgb &lt;- boost_tree(\n  trees = tune(),\n  tree_depth = tune(),\n  learn_rate = tune(),\n  min_n = tune()\n) %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"xgboost\")\n\n# PASO 6: Workflows\nworkflow_rf &lt;- workflow() %&gt;%\n  add_recipe(receta_churn) %&gt;%\n  add_model(modelo_rf)\n\nworkflow_xgb &lt;- workflow() %&gt;%\n  add_recipe(receta_churn) %&gt;%\n  add_model(modelo_xgb)\n\n# PASO 7: Cross-validation y tuning\ncv_folds &lt;- vfold_cv(train_data, v = 5, strata = churn)\n\n# Tuning Random Forest\ntune_rf &lt;- workflow_rf %&gt;%\n  tune_grid(\n    resamples = cv_folds,\n    grid = 20,\n    metrics = metric_set(roc_auc, precision, recall, f_meas)\n  )\n\n# PASO 8: Mejor modelo\nbest_rf &lt;- select_best(tune_rf, metric = \"roc_auc\")\nfinal_workflow_rf &lt;- finalize_workflow(workflow_rf, best_rf)\n\n# PASO 9: Fit final y predicciones\nmodelo_final &lt;- fit(final_workflow_rf, train_data)\npredicciones &lt;- predict(modelo_final, test_data, type = \"prob\")\n\n# Métricas de evaluación\nmetricas_modelo &lt;- test_data %&gt;%\n  cbind(predicciones) %&gt;%\n  mutate(pred = factor(fifelse(.pred_Si &gt;= 0.5, 1, 0), levels = c(0, 1), labels = c(\"No\", \"Si\"))) %&gt;% \n  metrics(truth = churn, pred)\n\nprint(metricas_modelo)\n\n\n12.2.3 3. Post-procesamiento y Análisis con data.table\n\n\n# Simular predicciones para el ejemplo (en producción vendrían del modelo)\nset.seed(789)\npredicciones_simuladas &lt;- data.table(\n  cliente_id = datos_ml[sample(.N, 2000), cliente_id],\n  prob_churn = runif(2000, 0, 1),\n  pred_churn = sample(c(\"Si\", \"No\"), 2000, replace = TRUE, prob = c(0.15, 0.85)),\n  confidence_score = runif(2000, 0.6, 0.95)\n)\n\n# ANÁLISIS DE RESULTADOS con data.table\n# Unir predicciones con datos originales\nresultados_ml &lt;- datos_ml[predicciones_simuladas, on = .(cliente_id)]\n\n# Análisis de segmentos de riesgo\nanalisis_riesgo &lt;- resultados_ml[,\n  .(\n    clientes_total = .N,\n    churn_predicho = sum(pred_churn == \"Si\"),\n    prob_churn_media = round(mean(prob_churn), 3),\n    valor_en_riesgo = sum(valor_cliente[pred_churn == \"Si\"]),\n    revenue_en_riesgo = sum(monto_total_año[pred_churn == \"Si\"], na.rm = TRUE),\n    ingresos_promedio = round(mean(ingresos), 0),\n    engagement_promedio = round(mean(engagement_score), 2)\n  ),\n  by = .(region, categoria_ingresos)\n][order(-valor_en_riesgo)]\n\ncat(\"=== ANÁLISIS DE RIESGO DE CHURN POR SEGMENTO ===\\n\")\n#&gt; === ANÁLISIS DE RIESGO DE CHURN POR SEGMENTO ===\nprint(analisis_riesgo)\n#&gt;     region categoria_ingresos clientes_total churn_predicho prob_churn_media\n#&gt;     &lt;char&gt;             &lt;fctr&gt;          &lt;int&gt;          &lt;int&gt;            &lt;num&gt;\n#&gt;  1: Centro               Alto            115             27            0.496\n#&gt;  2:  Norte               Alto            149             22            0.474\n#&gt;  3:   Este               Alto            149             26            0.476\n#&gt;  4:    Sur               Alto            136             15            0.472\n#&gt;  5: Centro              Medio            132             23            0.480\n#&gt; ---                                                                         \n#&gt; 11:  Oeste              Medio            123             20            0.477\n#&gt; 12: Centro               Bajo            141             19            0.477\n#&gt; 13:    Sur               Bajo            118             25            0.501\n#&gt; 14:   Este               Bajo            142             17            0.531\n#&gt; 15:  Oeste               Bajo            133             22            0.523\n#&gt;     valor_en_riesgo revenue_en_riesgo ingresos_promedio engagement_promedio\n#&gt;               &lt;num&gt;             &lt;num&gt;             &lt;num&gt;               &lt;num&gt;\n#&gt;  1:       3971.9904          4357.158            101231                7.74\n#&gt;  2:       3448.6127          3115.558            101081                7.56\n#&gt;  3:       2752.8342          2759.645            103060                7.62\n#&gt;  4:       1918.1725          1584.725             93285                7.55\n#&gt;  5:       1900.4059          2514.022             48193                7.54\n#&gt; ---                                                                        \n#&gt; 11:       1159.6149          2632.164             49278                7.63\n#&gt; 12:        912.9440          3273.967             27460                7.72\n#&gt; 13:        879.7883          3768.650             26754                7.62\n#&gt; 14:        812.1611          1624.176             27489                7.43\n#&gt; 15:        794.0182          2108.543             27076                7.72\n\n# Identificar clientes de alta prioridad para retención\nclientes_retencion &lt;- resultados_ml[\n  pred_churn == \"Si\" & \n  prob_churn &gt; 0.7 & \n  valor_cliente &gt; quantile(resultados_ml$valor_cliente, 0.7, na.rm = TRUE),\n  .(\n    cliente_id, region, edad, ingresos, valor_cliente,\n    prob_churn = round(prob_churn, 3),\n    transacciones_año, monto_total_año,\n    satisfaccion, engagement_score,\n    accion_recomendada = fcase(\n      satisfaccion &lt; 3, \"Mejora_Servicio\",\n      engagement_score &lt; 5, \"Aumentar_Engagement\", \n      monto_total_año &lt; 1000, \"Incentivo_Compra\",\n      default = \"Programa_Lealtad\"\n    )\n  )\n][order(-valor_cliente)]\n\ncat(\"\\n=== TOP 10 CLIENTES PARA RETENCIÓN INMEDIATA ===\\n\")\n#&gt; \n#&gt; === TOP 10 CLIENTES PARA RETENCIÓN INMEDIATA ===\nprint(head(clientes_retencion, 10))\n#&gt;     cliente_id region  edad ingresos valor_cliente prob_churn transacciones_año\n#&gt;          &lt;int&gt; &lt;char&gt; &lt;num&gt;    &lt;num&gt;         &lt;num&gt;      &lt;num&gt;             &lt;int&gt;\n#&gt;  1:         69 Centro    49   312277      761.9559      0.899                 1\n#&gt;  2:       9176 Centro    22    70610      406.0075      0.888                 2\n#&gt;  3:       6866    Sur    49    61726      274.0634      0.967                 1\n#&gt;  4:       3461    Sur    23   138172      269.4354      0.998                 2\n#&gt;  5:       8123  Oeste    49   140832      266.1725      0.705                 1\n#&gt;  6:       3497  Norte    39   102743      240.4186      0.849                 1\n#&gt;  7:       2847   Este    41    82017      216.5249      0.890                 2\n#&gt;  8:       2896   Este    21    83534      197.9756      0.836                 2\n#&gt;  9:       4247  Oeste    35    68037      175.5355      0.709                 1\n#&gt; 10:       9463  Norte    20    46169      164.3616      0.843                 2\n#&gt;     monto_total_año satisfaccion engagement_score accion_recomendada\n#&gt;               &lt;num&gt;        &lt;num&gt;            &lt;num&gt;             &lt;char&gt;\n#&gt;  1:        11.56000          3.1             10.0   Incentivo_Compra\n#&gt;  2:       292.31936          3.5             10.0   Incentivo_Compra\n#&gt;  3:        55.99000          3.1             10.0   Incentivo_Compra\n#&gt;  4:       190.29448          4.3              9.3   Incentivo_Compra\n#&gt;  5:        42.78000          1.0              8.0    Mejora_Servicio\n#&gt;  6:       103.06000          2.4              6.8    Mejora_Servicio\n#&gt;  7:       169.53063          3.1             10.0   Incentivo_Compra\n#&gt;  8:        73.40943          4.7             10.0   Incentivo_Compra\n#&gt;  9:        49.41055          2.5              4.5    Mejora_Servicio\n#&gt; 10:       148.34431          2.3             10.0    Mejora_Servicio\n\n# Análisis de efectividad del modelo por segmento\nif(nrow(resultados_ml[!is.na(churn_flag)]) &gt; 0) {\n  efectividad_modelo &lt;- resultados_ml[!is.na(churn_flag),\n    .(\n      precision = sum(pred_churn == \"Si\" & churn == \"Si\") / sum(pred_churn == \"Si\"),\n      recall = sum(pred_churn == \"Si\" & churn == \"Si\") / sum(churn == \"Si\"),\n      accuracy = mean(pred_churn == churn),\n      clientes_evaluados = .N\n    ),\n    by = .(region, categoria_edad)\n  ][clientes_evaluados &gt;= 10]  # Solo segmentos con suficientes datos\n  \n  cat(\"\\n=== EFECTIVIDAD DEL MODELO POR SEGMENTO ===\\n\")\n  print(head(efectividad_modelo[order(-accuracy)]))\n}\n#&gt; \n#&gt; === EFECTIVIDAD DEL MODELO POR SEGMENTO ===\n#&gt;    region categoria_edad  precision     recall  accuracy clientes_evaluados\n#&gt;    &lt;char&gt;         &lt;fctr&gt;      &lt;num&gt;      &lt;num&gt;     &lt;num&gt;              &lt;int&gt;\n#&gt; 1:  Oeste         Senior 0.20000000 0.25000000 0.8478261                 46\n#&gt; 2:   Este         Adulto 0.22222222 0.33333333 0.8225806                124\n#&gt; 3:   Este          Joven 0.13333333 0.22222222 0.8148148                108\n#&gt; 4:  Norte         Adulto 0.19047619 0.30769231 0.8000000                130\n#&gt; 5:  Oeste         Adulto 0.08333333 0.07142857 0.7837838                111\n#&gt; 6:  Norte          Joven 0.07142857 0.09090909 0.7676768                 99",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#dtplyr-el-puente-entre-data.table-y-tidyverse",
    "href": "cap05-aplicaciones.html#dtplyr-el-puente-entre-data.table-y-tidyverse",
    "title": "12  Aplicaciones del Mundo Real",
    "section": "\n12.3 dtplyr: El Puente Entre data.table y tidyverse",
    "text": "12.3 dtplyr: El Puente Entre data.table y tidyverse\n\n12.3.1 1. Introducción y Casos de Uso\n\n\nif(requireNamespace(\"dtplyr\", quietly = TRUE) && requireNamespace(\"dplyr\", quietly = TRUE)) {\n  library(dtplyr)\n  library(dplyr, warn.conflicts = FALSE)\n  \n  # Convertir data.table a lazy_dt\n  clientes_lazy &lt;- lazy_dt(datos_clientes)\n  \n  # Workflow con sintaxis dplyr que se traduce a data.table\n  analisis_dtplyr &lt;- clientes_lazy %&gt;%\n    filter(edad &gt;= 25, edad &lt;= 65) %&gt;%\n    mutate(\n      categoria_valor = case_when(\n        valor_cliente &gt;= quantile(valor_cliente, 0.8) ~ \"Premium\",\n        valor_cliente &gt;= quantile(valor_cliente, 0.5) ~ \"Standard\",\n        TRUE ~ \"Basic\"\n      ),\n      riesgo_total = riesgo_churn + (5 - satisfaccion) / 5\n    ) %&gt;%\n    group_by(region, categoria_valor) %&gt;%\n    summarise(\n      clientes = n(),\n      valor_promedio = round(mean(valor_cliente), 2),\n      engagement_promedio = round(mean(engagement_score), 2),\n      churn_rate = round(mean(churn_flag) * 100, 1),\n      riesgo_promedio = round(mean(riesgo_total), 2),\n      .groups = 'drop'\n    ) %&gt;%\n    arrange(desc(valor_promedio)) %&gt;%\n    as.data.table()  # Convertir de vuelta a data.table\n  \n  print(\"Resultado del análisis con dtplyr:\")\n  print(head(analisis_dtplyr, 10))\n  \n  # Ver el código data.table generado\n  cat(\"\\n=== CÓDIGO DATA.TABLE GENERADO POR DTPLYR ===\\n\")\n  codigo_generado &lt;- clientes_lazy %&gt;%\n    filter(edad &gt;= 25, edad &lt;= 65) %&gt;%\n    group_by(region) %&gt;%\n    summarise(valor_promedio = mean(valor_cliente), .groups = 'drop') %&gt;%\n    show_query()\n  \n} else {\n  cat(\"💡 Para usar dtplyr, instala los paquetes:\\n\")\n  cat(\"install.packages(c('dtplyr', 'dplyr'))\\n\")\n}\n#&gt; 💡 Para usar dtplyr, instala los paquetes:\n#&gt; install.packages(c('dtplyr', 'dplyr'))\n\n\n12.3.2 2. Comparación de Performance: dtplyr vs dplyr puro\n\n\nif(requireNamespace(\"dtplyr\", quietly = TRUE) && requireNamespace(\"dplyr\", quietly = TRUE)) {\n  library(microbenchmark)\n  \n  # Crear dataset más grande para benchmark\n  datos_benchmark &lt;- rbindlist(replicate(5, datos_clientes, simplify = FALSE))\n  \n  # Operación compleja para comparar\n  operacion_compleja &lt;- function(data, metodo) {\n    if(metodo == \"dplyr\") {\n      # dplyr puro sobre data.frame\n      as.data.frame(data) %&gt;%\n        filter(edad &gt;= 30, satisfaccion &gt;= 3) %&gt;%\n        group_by(region, categoria_ingresos) %&gt;%\n        summarise(\n          clientes = n(),\n          valor_total = sum(valor_cliente),\n          engagement_avg = mean(engagement_score),\n          .groups = 'drop'\n        ) %&gt;%\n        arrange(desc(valor_total))\n    } else if(metodo == \"dtplyr\") {\n      # dtplyr (sintaxis dplyr + motor data.table)\n      lazy_dt(data) %&gt;%\n        filter(edad &gt;= 30, satisfaccion &gt;= 3) %&gt;%\n        group_by(region, categoria_ingresos) %&gt;%\n        summarise(\n          clientes = n(),\n          valor_total = sum(valor_cliente),\n          engagement_avg = mean(engagement_score),\n          .groups = 'drop'\n        ) %&gt;%\n        arrange(desc(valor_total)) %&gt;%\n        as.data.table()\n    } else {\n      # data.table puro\n      data[\n        edad &gt;= 30 & satisfaccion &gt;= 3,\n        .(\n          clientes = .N,\n          valor_total = sum(valor_cliente),\n          engagement_avg = mean(engagement_score)\n        ),\n        by = .(region, categoria_ingresos)\n      ][order(-valor_total)]\n    }\n  }\n  \n  # Benchmark\n  benchmark_results &lt;- microbenchmark(\n    dplyr_puro = operacion_compleja(datos_benchmark, \"dplyr\"),\n    dtplyr = operacion_compleja(datos_benchmark, \"dtplyr\"),\n    data_table = operacion_compleja(datos_benchmark, \"data.table\"),\n    times = 10\n  )\n  \n  cat(\"=== BENCHMARK DE PERFORMANCE ===\\n\")\n  print(benchmark_results)\n  \n  # Calcular speedup\n  medias &lt;- aggregate(time ~ expr, data = benchmark_results, FUN = mean)\n  medias$speedup &lt;- medias$time[medias$expr == \"dplyr_puro\"] / medias$time\n  \n  cat(\"\\n=== SPEEDUP RELATIVO (vs dplyr puro) ===\\n\")\n  print(medias[, c(\"expr\", \"speedup\")])\n  \n} else {\n  cat(\"Benchmark requiere dtplyr y dplyr instalados\\n\")\n}\n#&gt; Benchmark requiere dtplyr y dplyr instalados",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#conexión-con-bases-de-datos-y-big-data",
    "href": "cap05-aplicaciones.html#conexión-con-bases-de-datos-y-big-data",
    "title": "12  Aplicaciones del Mundo Real",
    "section": "\n12.4 Conexión con Bases de Datos y Big Data",
    "text": "12.4 Conexión con Bases de Datos y Big Data\n\n12.4.1 1. Lectura/Escritura Eficiente con fread/fwrite\n\n\n# === FREAD: Lectura ultrarrápida ===\n# Crear archivo de ejemplo grande\narchivo_test &lt;- tempfile(fileext = \".csv\")\n\n# Generar datos sintéticos para el ejemplo\ndatos_grandes &lt;- data.table(\n  id = 1:100000,\n  timestamp = seq(as.POSIXct(\"2024-01-01\"), by = \"min\", length.out = 100000),\n  sensor_value = round(rnorm(100000, 50, 15), 2),\n  location = sample(c(\"Factory_A\", \"Factory_B\", \"Factory_C\"), 100000, replace = TRUE),\n  quality_score = round(runif(100000, 0.8, 1.0), 3),\n  batch_id = sample(1:1000, 100000, replace = TRUE)\n)\n\n# Escribir archivo\ncat(\"Escribiendo archivo de prueba...\\n\")\n#&gt; Escribiendo archivo de prueba...\ntiempo_write &lt;- system.time({\n  fwrite(datos_grandes, archivo_test, \n         nThread = getDTthreads(),\n         showProgress = FALSE)\n})\n\n# Información del archivo\ninfo_archivo &lt;- file.info(archivo_test)\ncat(\"Archivo creado:\", round(info_archivo$size / 1024^2, 2), \"MB\\n\")\n#&gt; Archivo creado: 4.06 MB\ncat(\"Tiempo de escritura:\", round(tiempo_write[3], 3), \"segundos\\n\")\n#&gt; Tiempo de escritura: 0.01 segundos\n\n# Lectura con diferentes configuraciones\ncat(\"\\n=== COMPARACIÓN DE MÉTODOS DE LECTURA ===\\n\")\n#&gt; \n#&gt; === COMPARACIÓN DE MÉTODOS DE LECTURA ===\n\n# 1. fread básico\ntiempo_fread_basico &lt;- system.time({\n  datos_fread &lt;- fread(archivo_test, showProgress = FALSE)\n})\n\n# 2. fread optimizado\ntiempo_fread_opt &lt;- system.time({\n  datos_fread_opt &lt;- fread(\n    archivo_test,\n    nThread = getDTthreads(),\n    select = c(\"id\", \"timestamp\", \"sensor_value\", \"location\"),  # Solo columnas necesarias\n    colClasses = list(character = \"location\", numeric = c(\"sensor_value\")),\n    showProgress = FALSE\n  )\n})\n\n# 3. read.csv para comparación\ntiempo_base_r &lt;- system.time({\n  datos_base &lt;- read.csv(archivo_test, stringsAsFactors = FALSE)\n})\n\ncat(\"fread básico:\", round(tiempo_fread_basico[3], 3), \"segundos\\n\")\n#&gt; fread básico: 0.006 segundos\ncat(\"fread optimizado:\", round(tiempo_fread_opt[3], 3), \"segundos\\n\")\n#&gt; fread optimizado: 0.004 segundos\ncat(\"read.csv (base R):\", round(tiempo_base_r[3], 3), \"segundos\\n\")\n#&gt; read.csv (base R): 0.098 segundos\ncat(\"Speedup fread vs base R:\", round(tiempo_base_r[3] / tiempo_fread_basico[3], 1), \"x\\n\")\n#&gt; Speedup fread vs base R: 16.3 x\n\n# Verificar que los datos son idénticos\ncat(\"Datos idénticos:\", identical(datos_fread$id, datos_fread_opt$id), \"\\n\")\n#&gt; Datos idénticos: TRUE\n\n# Limpiar\nunlink(archivo_test)\n\n\n12.4.2 2. Integración con Bases de Datos\n\n\n# Ejemplo de integración con bases de datos\nlibrary(DBI)\nlibrary(RSQLite)  # o RPostgreSQL, RMySQL, etc.\n\n# === SETUP DE CONEXIÓN ===\n# Crear base de datos SQLite para el ejemplo\ncon &lt;- dbConnect(RSQLite::SQLite(), \":memory:\")\n\n# Escribir data.table a la base de datos\ndbWriteTable(con, \"clientes\", datos_clientes)\ndbWriteTable(con, \"transacciones\", transacciones_detalle)\n\n# === WORKFLOW HÍBRIDO: SQL + data.table ===\n\n# 1. Query inicial en SQL (aprovechar índices de DB)\nquery_sql &lt;- \"\n  SELECT c.cliente_id, c.region, c.edad, c.ingresos,\n         t.monto, t.fecha_transaccion, t.producto_categoria\n  FROM clientes c\n  JOIN transacciones t ON c.cliente_id = t.cliente_id\n  WHERE c.edad &gt;= 25 AND c.edad &lt;= 65\n    AND t.fecha_transaccion &gt;= '2024-01-01'\n\"\n\n# 2. Traer datos a data.table\ndatos_query &lt;- as.data.table(dbGetQuery(con, query_sql))\n\n# 3. Análisis complejo con data.table (más rápido que SQL)\nanalisis_hibrido &lt;- datos_query[,\n  .(\n    transacciones_total = .N,\n    monto_total = sum(monto),\n    monto_promedio = round(mean(monto), 2),\n    categorias_distintas = uniqueN(producto_categoria),\n    primera_compra = min(fecha_transaccion),\n    ultima_compra = max(fecha_transaccion)\n  ),\n  by = .(cliente_id, region)\n][, `:=`(\n  dias_activo = as.numeric(as.Date(ultima_compra) - as.Date(primera_compra)) + 1,\n  frecuencia_compra = transacciones_total / pmax(as.numeric(as.Date(ultima_compra) - as.Date(primera_compra)) + 1, 1)\n)][order(-monto_total)]\n\n# 4. Escribir resultados de vuelta a DB (opcional)\ndbWriteTable(con, \"analisis_clientes\", analisis_hibrido, overwrite = TRUE)\n\n# 5. Verificación\nresumen_db &lt;- dbGetQuery(con, \"SELECT COUNT(*) as clientes_analizados FROM analisis_clientes\")\ncat(\"Clientes analizados en DB:\", resumen_db$clientes_analizados, \"\\n\")\n\n# Cerrar conexión\ndbDisconnect(con)\n\n# === MEJORES PRÁCTICAS ===\n# 1. Usar SQL para filtros iniciales y joins simples\n# 2. Traer datos a data.table para análisis complejos\n# 3. Aprovechar índices de DB para WHERE y JOIN\n# 4. Usar data.table para agregaciones complejas y feature engineering\n# 5. Escribir resultados finales de vuelta a DB si es necesario\n\n\n12.4.3 3. Integración con Apache Arrow/Parquet\n\n\n# Ejemplo de integración con ecosistema Arrow\nlibrary(arrow)\n\n# === ESCRITURA A PARQUET ===\n# Parquet es ultra-eficiente para datasets grandes\narchivo_parquet &lt;- tempfile(fileext = \".parquet\")\n\n# Escribir data.table a Parquet\nwrite_parquet(datos_clientes, archivo_parquet)\n\n# === LECTURA DESDE PARQUET ===\n# Leer directo a data.table\ndatos_parquet &lt;- read_parquet(archivo_parquet, as_data_frame = TRUE)\nsetDT(datos_parquet)  # Asegurar que es data.table\n\n# === DATASETS PARTICIONADOS ===\n# Para datasets muy grandes, usar particiones\ndirectorio_particionado &lt;- file.path(tempdir(), \"partitioned_data\")\ndir.create(directorio_particionado, showWarnings = FALSE, recursive = TRUE)\n\n# Particionar por región - método más robusto\nfor(region_name in unique(datos_clientes$region)) {\n  region_data &lt;- datos_clientes[region == region_name]\n  archivo_region &lt;- file.path(directorio_particionado, paste0(\"region_\", region_name, \".parquet\"))\n  write_parquet(region_data, archivo_region)\n}\n\n# Verificar que los archivos se crearon correctamente\narchivos_parquet &lt;- list.files(directorio_particionado, pattern = \"\\\\.parquet$\", full.names = TRUE)\ncat(\"Archivos Parquet creados:\", length(archivos_parquet), \"\\n\")\n\n# Leer dataset particionado solo si hay archivos válidos\nif(length(archivos_parquet) &gt; 0) {\n  dataset &lt;- open_dataset(directorio_particionado)\n} else {\n  stop(\"No se pudieron crear archivos Parquet válidos\")\n}\n\n# Query con pushdown de predicados (muy eficiente)\ntryCatch({\n  resultado_arrow &lt;- dataset %&gt;%\n    filter(edad &gt;= 30, satisfaccion &gt;= 4) %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n      clientes = n(),\n      valor_promedio = mean(valor_cliente),\n      ingresos_promedio = mean(ingresos)\n    ) %&gt;%\n    collect() %&gt;%  # Traer a memoria\n    as.data.table()  # Convertir a data.table\n  \n  print(resultado_arrow)\n}, error = function(e) {\n  cat(\"Error en consulta Arrow:\", conditionMessage(e), \"\\n\")\n  cat(\"Usando método alternativo con data.table directo...\\n\")\n  \n  # Fallback: usar data.table directamente\n  resultado_arrow &lt;- datos_clientes[edad &gt;= 30 & satisfaccion &gt;= 4, .(\n    clientes = .N,\n    valor_promedio = mean(valor_cliente),\n    ingresos_promedio = mean(ingresos)\n  ), by = region]\n  \n  print(resultado_arrow)\n})\n\n# === VENTAJAS DEL WORKFLOW ARROW + DATA.TABLE ===\n# 1. Parquet es extremadamente eficiente en espacio\n# 2. Pushdown de predicados reduce transferencia de datos\n# 3. Compatibilidad con otros lenguajes (Python, Spark)\n# 4. data.table para análisis final en R",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#casos-de-uso-industriales-reales",
    "href": "cap05-aplicaciones.html#casos-de-uso-industriales-reales",
    "title": "12  Aplicaciones del Mundo Real",
    "section": "\n12.5 Casos de Uso Industriales Reales",
    "text": "12.5 Casos de Uso Industriales Reales\n\n12.5.1 1. Sistema de Monitoreo IoT en Tiempo Real\n\n\n# === ANÁLISIS DE SENSORES IOT ===\n# Simular análisis en tiempo real de sensores\n\n# Función para procesar batch de datos de sensores\nprocesar_batch_sensores &lt;- function(datos_sensores, ventana_horas = 1) {\n  # Análisis de anomalías en tiempo real\n  datos_sensores[,\n    `:=`(\n      temp_anomaly = abs(temperatura - mean(temperatura)) &gt; 2 * sd(temperatura),\n      humidity_anomaly = abs(humedad - mean(humedad)) &gt; 2 * sd(humedad),\n      battery_critical = nivel_bateria &lt; 15\n    ),\n    by = .(sensor_id, fecha)\n  ]\n  \n  # Resumen por sensor y hora\n  resumen_sensores &lt;- datos_sensores[,\n    .(\n      temp_promedio = round(mean(temperatura), 2),\n      temp_min = min(temperatura),\n      temp_max = max(temperatura),\n      humedad_promedio = round(mean(humedad), 1),\n      presion_promedio = round(mean(presion), 1),\n      movimientos_detectados = sum(movimiento_detectado),\n      anomalias_temp = sum(temp_anomaly),\n      anomalias_humedad = sum(humidity_anomaly),\n      alertas_bateria = sum(battery_critical),\n      lecturas_total = .N,\n      uptime_pct = round((1 - sum(is.na(temperatura)) / .N) * 100, 1)\n    ),\n    by = .(sensor_id, fecha, hora)\n  ][, `:=`(\n    estado_sensor = fcase(\n      alertas_bateria &gt; 0, \"CRÍTICO\",\n      anomalias_temp + anomalias_humedad &gt; 5, \"ADVERTENCIA\",\n      uptime_pct &lt; 95, \"DEGRADADO\",\n      default = \"NORMAL\"\n    ),\n    score_salud = pmin(100, uptime_pct - (anomalias_temp + anomalias_humedad) * 5 - alertas_bateria * 20)\n  )]\n  \n  return(resumen_sensores)\n}\n\n# Procesar datos de sensores\nanalisis_sensores &lt;- procesar_batch_sensores(sensores_iot)\n\n# Dashboard de alertas críticas\nalertas_criticas &lt;- analisis_sensores[\n  estado_sensor %in% c(\"CRÍTICO\", \"ADVERTENCIA\"),\n  .(\n    sensor_id, fecha, hora,\n    estado_sensor, score_salud,\n    anomalias_temp, anomalias_humedad, alertas_bateria,\n    accion_requerida = fcase(\n      alertas_bateria &gt; 0, \"Cambiar_Batería\",\n      anomalias_temp &gt; 3, \"Revisar_Sensor_Temperatura\",\n      anomalias_humedad &gt; 3, \"Revisar_Sensor_Humedad\",\n      default = \"Inspección_General\"\n    )\n  )\n][order(fecha, hora, -score_salud)]\n\ncat(\"=== ALERTAS CRÍTICAS DEL SISTEMA IOT ===\\n\")\n#&gt; === ALERTAS CRÍTICAS DEL SISTEMA IOT ===\nprint(head(alertas_criticas, 15))\n#&gt;     sensor_id      fecha  hora estado_sensor score_salud anomalias_temp\n#&gt;        &lt;char&gt;     &lt;Date&gt; &lt;int&gt;        &lt;char&gt;       &lt;num&gt;          &lt;int&gt;\n#&gt; 1: SENSOR_091 2024-01-22    20       CRÍTICO          80              0\n#&gt; 2: SENSOR_078 2024-01-24     4       CRÍTICO          80              0\n#&gt; 3: SENSOR_030 2024-01-26    19       CRÍTICO          80              0\n#&gt; 4: SENSOR_032 2024-01-31     7       CRÍTICO          80              0\n#&gt;    anomalias_humedad alertas_bateria accion_requerida\n#&gt;                &lt;int&gt;           &lt;int&gt;           &lt;char&gt;\n#&gt; 1:                 0               1  Cambiar_Batería\n#&gt; 2:                 0               1  Cambiar_Batería\n#&gt; 3:                 0               1  Cambiar_Batería\n#&gt; 4:                 0               1  Cambiar_Batería\n\n# Estadísticas de salud del sistema\nsalud_sistema &lt;- analisis_sensores[,\n  .(\n    sensores_activos = uniqueN(sensor_id),\n    sensores_criticos = uniqueN(sensor_id[estado_sensor == \"CRÍTICO\"]),\n    sensores_degradados = uniqueN(sensor_id[estado_sensor %in% c(\"ADVERTENCIA\", \"DEGRADADO\")]),\n    score_salud_promedio = round(mean(score_salud), 1),\n    anomalias_totales = sum(anomalias_temp + anomalias_humedad),\n    uptime_sistema = round(mean(uptime_pct), 1)\n  ),\n  by = .(fecha)\n]\n\ncat(\"\\n=== SALUD GENERAL DEL SISTEMA ===\\n\")\n#&gt; \n#&gt; === SALUD GENERAL DEL SISTEMA ===\nprint(head(salud_sistema))\n#&gt;         fecha sensores_activos sensores_criticos sensores_degradados\n#&gt;        &lt;Date&gt;            &lt;int&gt;             &lt;int&gt;               &lt;int&gt;\n#&gt; 1: 2023-12-31               12                 0                   0\n#&gt; 2: 2024-01-01              100                 0                   0\n#&gt; 3: 2024-01-02              100                 0                   0\n#&gt; 4: 2024-01-03              100                 0                   0\n#&gt; 5: 2024-01-04              100                 0                   0\n#&gt; 6: 2024-01-05              100                 0                   0\n#&gt;    score_salud_promedio anomalias_totales uptime_sistema\n#&gt;                   &lt;num&gt;             &lt;int&gt;          &lt;num&gt;\n#&gt; 1:                   NA                NA            100\n#&gt; 2:                  100                 0            100\n#&gt; 3:                  100                 0            100\n#&gt; 4:                  100                 0            100\n#&gt; 5:                  100                 0            100\n#&gt; 6:                  100                 0            100\n\n\n12.5.2 2. Sistema de Recomendaciones E-commerce\n\n\n# === MOTOR DE RECOMENDACIONES ===\n# Sistema basado en comportamiento de compra\n\n# Función para calcular similaridad entre clientes\ncalcular_recomendaciones &lt;- function(transacciones_dt, cliente_target, top_n = 5) {\n  \n  # Matriz de compras por cliente-categoría\n  matriz_compras &lt;- transacciones_dt[,\n    .(\n      total_comprado = sum(monto_final),\n      frecuencia = .N\n    ),\n    by = .(cliente_id, producto_categoria)\n  ]\n  \n  # Perfil del cliente target\n  perfil_target &lt;- matriz_compras[cliente_id == cliente_target]\n  \n  if(nrow(perfil_target) == 0) {\n    return(data.table(mensaje = \"Cliente no encontrado\"))\n  }\n  \n  # Encontrar clientes similares\n  clientes_similares &lt;- matriz_compras[\n    producto_categoria %in% perfil_target$producto_categoria & \n    cliente_id != cliente_target,\n    .(\n      overlap_categorias = .N,\n      valor_similar = sum(total_comprado)\n    ),\n    by = cliente_id\n  ][overlap_categorias &gt;= 2][order(-overlap_categorias, -valor_similar)]\n  \n  # Recomendaciones basadas en clientes similares\n  if(nrow(clientes_similares) &gt; 0) {\n    recomendaciones &lt;- matriz_compras[\n      cliente_id %in% head(clientes_similares$cliente_id, 20) &\n      !producto_categoria %in% perfil_target$producto_categoria,\n      .(\n        score_recomendacion = sum(total_comprado),\n        clientes_que_compran = .N,\n        frecuencia_promedio = round(mean(frecuencia), 1)\n      ),\n      by = producto_categoria\n    ][clientes_que_compran &gt;= 3][order(-score_recomendacion)][1:top_n]\n    \n    return(recomendaciones)\n  } else {\n    return(data.table(mensaje = \"No hay suficientes datos para recomendaciones\"))\n  }\n}\n\n# Función para análisis de mercado\nanalizar_tendencias_mercado &lt;- function(transacciones_dt, periodo_dias = 30) {\n  fecha_corte &lt;- max(transacciones_dt$fecha_transaccion) - periodo_dias\n  \n  tendencias &lt;- transacciones_dt[\n    fecha_transaccion &gt;= fecha_corte,\n    .(\n      ventas_recientes = sum(monto_final),\n      transacciones_recientes = .N,\n      clientes_unicos = uniqueN(cliente_id),\n      ticket_promedio = round(mean(monto_final), 2),\n      crecimiento_semanal = .N / (periodo_dias / 7)\n    ),\n    by = producto_categoria\n  ][order(-ventas_recientes)]\n  \n  # Calcular métricas adicionales\n  tendencias[, `:=`(\n    penetracion_mercado = round((clientes_unicos / uniqueN(transacciones_dt$cliente_id)) * 100, 1),\n    velocidad_venta = round(transacciones_recientes / periodo_dias, 2),\n    categoria_trend = fcase(\n      crecimiento_semanal &gt; quantile(crecimiento_semanal, 0.75), \"📈 CRECIENTE\",\n      crecimiento_semanal &lt; quantile(crecimiento_semanal, 0.25), \"📉 DECLINANTE\",\n      default = \"➡️ ESTABLE\"\n    )\n  )]\n  \n  return(tendencias)\n}\n\n# Ejecutar análisis de recomendaciones\ncliente_ejemplo &lt;- datos_clientes[sample(.N, 1), cliente_id]\nrecomendaciones &lt;- calcular_recomendaciones(transacciones_detalle, cliente_ejemplo)\n\ncat(\"=== RECOMENDACIONES PARA CLIENTE\", cliente_ejemplo, \"===\\n\")\n#&gt; === RECOMENDACIONES PARA CLIENTE 3450 ===\nprint(recomendaciones)\n#&gt;    producto_categoria score_recomendacion clientes_que_compran\n#&gt;                &lt;char&gt;               &lt;num&gt;                &lt;int&gt;\n#&gt; 1:        Electronics            2412.048                   16\n#&gt; 2:              Books            1472.585                   10\n#&gt; 3:             Beauty            1152.812                   15\n#&gt; 4:               &lt;NA&gt;                  NA                   NA\n#&gt; 5:               &lt;NA&gt;                  NA                   NA\n#&gt;    frecuencia_promedio\n#&gt;                  &lt;num&gt;\n#&gt; 1:                 1.4\n#&gt; 2:                 1.5\n#&gt; 3:                 1.2\n#&gt; 4:                  NA\n#&gt; 5:                  NA\n\n# Análisis de tendencias de mercado\ntendencias_mercado &lt;- analizar_tendencias_mercado(transacciones_detalle, 60)\n\ncat(\"\\n=== TENDENCIAS DE MERCADO (últimos 60 días) ===\\n\")\n#&gt; \n#&gt; === TENDENCIAS DE MERCADO (últimos 60 días) ===\nprint(tendencias_mercado)\n#&gt;    producto_categoria ventas_recientes transacciones_recientes clientes_unicos\n#&gt;                &lt;char&gt;            &lt;num&gt;                   &lt;int&gt;           &lt;int&gt;\n#&gt; 1:             Sports         59738.74                     728             696\n#&gt; 2:              Books         57747.86                     673             658\n#&gt; 3:               Home         57641.77                     700             678\n#&gt; 4:           Clothing         55649.79                     723             699\n#&gt; 5:             Beauty         55388.89                     680             662\n#&gt; 6:        Electronics         52302.97                     689             663\n#&gt;    ticket_promedio crecimiento_semanal penetracion_mercado velocidad_venta\n#&gt;              &lt;num&gt;               &lt;num&gt;               &lt;num&gt;           &lt;num&gt;\n#&gt; 1:           82.06            84.93333                 7.0           12.13\n#&gt; 2:           85.81            78.51667                 6.6           11.22\n#&gt; 3:           82.35            81.66667                 6.8           11.67\n#&gt; 4:           76.97            84.35000                 7.0           12.05\n#&gt; 5:           81.45            79.33333                 6.7           11.33\n#&gt; 6:           75.91            80.38333                 6.7           11.48\n#&gt;    categoria_trend\n#&gt;             &lt;char&gt;\n#&gt; 1:    📈 CRECIENTE\n#&gt; 2:   📉 DECLINANTE\n#&gt; 3:       ➡️ ESTABLE\n#&gt; 4:    📈 CRECIENTE\n#&gt; 5:   📉 DECLINANTE\n#&gt; 6:       ➡️ ESTABLE\n\n# Análisis de cohorstes de clientes\nanalisis_cohortes &lt;- transacciones_detalle[,\n  .(\n    primera_compra = min(fecha_transaccion),\n    ultima_compra = max(fecha_transaccion),\n    valor_total = sum(monto_final),\n    frecuencia_compra = .N\n  ),\n  by = cliente_id\n][, `:=`(\n  cohorte_mes = format(primera_compra, \"%Y-%m\"),\n  dias_como_cliente = as.numeric(ultima_compra - primera_compra) + 1\n)][, `:=`(\n  valor_por_dia = round(valor_total / pmax(dias_como_cliente, 1), 2)\n)][,\n  .(\n    clientes_cohorte = .N,\n    valor_promedio_cohorte = round(mean(valor_total), 2),\n    dias_retencion_promedio = round(mean(dias_como_cliente), 1),\n    valor_por_dia_promedio = round(mean(valor_por_dia), 2)\n  ),\n  by = cohorte_mes\n][order(cohorte_mes)]\n\ncat(\"\\n=== ANÁLISIS DE COHORTES POR MES ===\\n\")\n#&gt; \n#&gt; === ANÁLISIS DE COHORTES POR MES ===\nprint(head(analisis_cohortes, 12))\n#&gt;     cohorte_mes clientes_cohorte valor_promedio_cohorte dias_retencion_promedio\n#&gt;          &lt;char&gt;            &lt;int&gt;                  &lt;num&gt;                   &lt;num&gt;\n#&gt;  1:     2023-01             1919                 480.73                   576.0\n#&gt;  2:     2023-02             1419                 468.32                   540.2\n#&gt;  3:     2023-03             1254                 449.64                   513.0\n#&gt;  4:     2023-04             1018                 434.10                   479.9\n#&gt;  5:     2023-05              797                 418.61                   458.0\n#&gt;  6:     2023-06              640                 400.50                   418.7\n#&gt;  7:     2023-07              573                 373.78                   393.7\n#&gt;  8:     2023-08              451                 354.58                   356.5\n#&gt;  9:     2023-09              366                 342.35                   336.0\n#&gt; 10:     2023-10              310                 326.32                   289.0\n#&gt; 11:     2023-11              218                 323.99                   274.6\n#&gt; 12:     2023-12              192                 277.01                   260.5\n#&gt;     valor_por_dia_promedio\n#&gt;                      &lt;num&gt;\n#&gt;  1:                   1.71\n#&gt;  2:                   1.81\n#&gt;  3:                   2.11\n#&gt;  4:                   2.59\n#&gt;  5:                   2.89\n#&gt;  6:                   2.14\n#&gt;  7:                   4.20\n#&gt;  8:                   3.89\n#&gt;  9:                   5.20\n#&gt; 10:                   7.84\n#&gt; 11:                   6.48\n#&gt; 12:                   5.16",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#ejercicio-final-aplicación-completa-de-producción",
    "href": "cap05-aplicaciones.html#ejercicio-final-aplicación-completa-de-producción",
    "title": "12  Aplicaciones del Mundo Real",
    "section": "\n12.6 Ejercicio Final: Aplicación Completa de Producción",
    "text": "12.6 Ejercicio Final: Aplicación Completa de Producción\n\n\n\n\n\n\n🏋️ Ejercicio 10: Sistema de Analytics Empresarial\n\n\n\nDiseña un sistema completo que integre:\n\n\nPipeline de datos con data.table\n\nDashboard Shiny interactivo\n\nModelo predictivo con tidymodels\nAlertas automáticas\nReportes ejecutivos\n\nUsa los datasets de clientes, transacciones y sensores como base.\n\n\n\n\n\n\n\n\n💡 Solución del Ejercicio 10\n\n\n\n\n\n\n# === PIPELINE DE DATOS UNIFICADO ===\ncrear_pipeline_analytics &lt;- function() {\n  \n  # 1. CONSOLIDACIÓN DE DATOS\n  pipeline_data &lt;- list()\n  \n  # Métricas de clientes\n  pipeline_data$clientes_kpis &lt;- datos_clientes[,\n    .(\n      clientes_total = .N,\n      valor_total = sum(valor_cliente),\n      churn_rate = round(mean(churn_flag) * 100, 1),\n      satisfaccion_promedio = round(mean(satisfaccion), 2),\n      engagement_promedio = round(mean(engagement_score), 2)\n    ),\n    by = .(region, categoria_ingresos)\n  ]\n  \n  # Métricas de transacciones\n  pipeline_data$transacciones_kpis &lt;- transacciones_detalle[\n    fecha_transaccion &gt;= Sys.Date() - 90,  # Últimos 90 días\n    .(\n      revenue_total = sum(monto_final),\n      transacciones_total = .N,\n      ticket_promedio = round(mean(monto_final), 2),\n      clientes_activos = uniqueN(cliente_id),\n      productos_vendidos = sum(1 - es_devolucion)\n    ),\n    by = .(mes = month(fecha_transaccion), producto_categoria)\n  ]\n  \n  # Estado de sensores IoT\n  pipeline_data$sensores_status &lt;- sensores_iot[\n    fecha &gt;= Sys.Date() - 7,  # Última semana\n    .(\n      sensores_activos = uniqueN(sensor_id),\n      alertas_criticas = sum(alerta_temperatura + alerta_bateria + alerta_humedad),\n      uptime_promedio = round(mean(1 - is.na(temperatura)) * 100, 1),\n      score_salud = round(mean(100 - alerta_temperatura * 20 - alerta_bateria * 30), 1)\n    ),\n    by = fecha\n  ]\n  \n  # 2. ALERTAS AUTOMÁTICAS\n  alertas &lt;- list()\n  \n  # Alerta de churn elevado\n  alertas$churn_critico &lt;- pipeline_data$clientes_kpis[\n    churn_rate &gt; 15,\n    .(region, categoria_ingresos, churn_rate, valor_total)\n  ]\n  \n  # Alerta de caída de revenue\n  alertas$revenue_bajo &lt;- pipeline_data$transacciones_kpis[,\n    .(revenue_cambio = (revenue_total / shift(revenue_total, 1) - 1) * 100),\n    by = producto_categoria\n  ][revenue_cambio &lt; -10 & !is.na(revenue_cambio)]\n  \n  # Alerta de sensores críticos\n  alertas$sensores_criticos &lt;- pipeline_data$sensores_status[\n    score_salud &lt; 80 | alertas_criticas &gt; 10\n  ]\n  \n  # 3. DASHBOARD SUMMARY\n  dashboard_summary &lt;- list(\n    kpis_generales = list(\n      clientes_total = sum(pipeline_data$clientes_kpis$clientes_total),\n      revenue_total = sum(pipeline_data$transacciones_kpis$revenue_total),\n      churn_promedio = round(weighted.mean(pipeline_data$clientes_kpis$churn_rate, \n                                          pipeline_data$clientes_kpis$clientes_total), 1),\n      alertas_activas = length(alertas$churn_critico) + nrow(alertas$revenue_bajo) + nrow(alertas$sensores_criticos)\n    ),\n    alertas_activas = alertas,\n    datos_pipeline = pipeline_data\n  )\n  \n  return(dashboard_summary)\n}\n\n# Ejecutar pipeline\nsistema_analytics &lt;- crear_pipeline_analytics()\n\n# === REPORTE EJECUTIVO AUTOMÁTICO ===\ngenerar_reporte_ejecutivo &lt;- function(analytics_data) {\n  cat(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\")\n  cat(\"                    📊 REPORTE EJECUTIVO EMPRESARIAL                     \\n\")\n  cat(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\\n\")\n  \n  kpis &lt;- analytics_data$kpis_generales\n  alertas &lt;- analytics_data$alertas_activas\n  \n  # KPIs principales\n  cat(\"📈 INDICADORES CLAVE DE RENDIMIENTO:\\n\")\n  cat(\"   • Total de Clientes:\", scales::comma(kpis$clientes_total), \"\\n\")\n  cat(\"   • Revenue Total:\", scales::dollar(kpis$revenue_total), \"\\n\")\n  cat(\"   • Tasa de Churn Promedio:\", kpis$churn_promedio, \"%\\n\")\n  cat(\"   • Alertas Activas:\", kpis$alertas_activas, \"\\n\\n\")\n  \n  # Estado de alertas\n  cat(\"🚨 ESTADO DE ALERTAS:\\n\")\n  cat(\"   • Regiones con Churn Crítico:\", nrow(alertas$churn_critico), \"\\n\")\n  cat(\"   • Productos con Revenue Bajo:\", nrow(alertas$revenue_bajo), \"\\n\")\n  cat(\"   • Sensores en Estado Crítico:\", nrow(alertas$sensores_criticos), \"\\n\\n\")\n  \n  # Recomendaciones automáticas\n  cat(\"💡 RECOMENDACIONES AUTOMÁTICAS:\\n\")\n  if(nrow(alertas$churn_critico) &gt; 0) {\n    cat(\"   • ACCIÓN INMEDIATA: Implementar programa de retención en regiones críticas\\n\")\n  }\n  if(nrow(alertas$revenue_bajo) &gt; 0) {\n    cat(\"   • ANÁLISIS REQUERIDO: Investigar caída de ventas en productos específicos\\n\")\n  }\n  if(nrow(alertas$sensores_criticos) &gt; 0) {\n    cat(\"   • MANTENIMIENTO: Revisar sensores con bajo score de salud\\n\")\n  }\n  if(kpis$alertas_activas == 0) {\n    cat(\"   • ✅ SISTEMA SALUDABLE: Todos los indicadores dentro de rangos normales\\n\")\n  }\n  \n  cat(\"\\n━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\")\n  cat(\"Reporte generado automáticamente:\", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\"), \"\\n\")\n  cat(\"━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\\n\")\n}\n\n# Generar reporte\ngenerar_reporte_ejecutivo(sistema_analytics)\n#&gt; ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n#&gt;                     📊 REPORTE EJECUTIVO EMPRESARIAL                     \n#&gt; ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n#&gt; \n#&gt; 📈 INDICADORES CLAVE DE RENDIMIENTO:\n#&gt;    • Total de Clientes: 10,000 \n#&gt;    • Revenue Total: $0 \n#&gt;    • Tasa de Churn Promedio: 12.1 %\n#&gt;    • Alertas Activas: 4 \n#&gt; \n#&gt; 🚨 ESTADO DE ALERTAS:\n#&gt;    • Regiones con Churn Crítico: 0 \n#&gt;    • Productos con Revenue Bajo: 0 \n#&gt;    • Sensores en Estado Crítico: 0 \n#&gt; \n#&gt; 💡 RECOMENDACIONES AUTOMÁTICAS:\n#&gt; \n#&gt; ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n#&gt; Reporte generado automáticamente: 2025-08-21 01:32:29 \n#&gt; ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\n\n# === MÉTRICAS DETALLADAS ===\ncat(\"\\n📊 DETALLE DE ALERTAS CRÍTICAS:\\n\\n\")\n#&gt; \n#&gt; 📊 DETALLE DE ALERTAS CRÍTICAS:\n\nif(nrow(sistema_analytics$alertas_activas$churn_critico) &gt; 0) {\n  cat(\"🔴 CHURN CRÍTICO POR REGIÓN:\\n\")\n  print(sistema_analytics$alertas_activas$churn_critico)\n  cat(\"\\n\")\n}\n\nif(nrow(sistema_analytics$alertas_activas$revenue_bajo) &gt; 0) {\n  cat(\"📉 PRODUCTOS CON REVENUE BAJO:\\n\")\n  print(head(sistema_analytics$alertas_activas$revenue_bajo))\n  cat(\"\\n\")\n}\n\nif(nrow(sistema_analytics$alertas_activas$sensores_criticos) &gt; 0) {\n  cat(\"⚠️ SENSORES EN ESTADO CRÍTICO:\\n\")\n  print(head(sistema_analytics$alertas_activas$sensores_criticos))\n}\n\nComponentes del Sistema Completo:\n\n\nPipeline de Datos: Consolidación automática de múltiples fuentes\n\nSistema de Alertas: Detección automática de anomalías\n\nDashboard KPIs: Métricas en tiempo real\n\nReporte Ejecutivo: Generación automática de insights\n\nRecomendaciones: Acciones basadas en datos\n\nEscalabilidad: Modular y extensible\n\n\n\n\n\n\n\n\n\n\n\n🎯 Puntos Clave de Este Capítulo\n\n\n\n\n\nShiny + data.table = Aplicaciones web ultrarrápidas y responsivas\n\ntidymodels se integra perfectamente con data.table para ML robusto\n\ndtplyr facilita la transición desde dplyr manteniendo performance\n\nfread/fwrite son las herramientas más rápidas de R para I/O\n\nBases de datos + data.table = Workflow híbrido óptimo\n\nCasos reales demuestran la versatilidad industrial de data.table\n\nSistemas completos integran múltiples componentes de forma modular\n\n\n\nHas completado tu formación integral en aplicaciones del mundo real con data.table. Ahora tienes las herramientas para construir sistemas completos de analytics empresarial de nivel industrial.",
    "crumbs": [
      "**Módulo 5**: Integración con el Ecosistema R",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusiones y Próximos Pasos",
    "section": "",
    "text": "Tu Transformación: De Principiante a Experto\n¡Felicitaciones! Has completado un viaje transformador en el mundo de data.table. Reflexionemos sobre lo que has logrado:",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#tu-transformación-de-principiante-a-experto",
    "href": "conclusion.html#tu-transformación-de-principiante-a-experto",
    "title": "Conclusiones y Próximos Pasos",
    "section": "",
    "text": "Antes de este tutorial:\n\nQuizás conocías data.frame básico o dplyr\n\nLas operaciones con datos grandes te tomaban minutos u horas\nEl código de manipulación de datos era verbose y difícil de mantener\nAhora dominas:\n\n\nFundamentos Sólidos\nTécnicas Avanzadas\nPerformance & Optimización\nIntegración Ecosistema\n\n\n\n\n✅ Sintaxis DT[i, j, by]: El corazón de data.table\n✅ Modificación por referencia: Poder de := sin copias de memoria\n✅ Símbolos especiales: .N, .SD, .I, .GRP como herramientas avanzadas\n✅ Encadenamiento: Operaciones fluidas y legibles\n\n\n\n\n✅ Rolling joins: Para análisis temporal y series financieras\n✅ Non-equi joins: Uniones basadas en rangos e inequidades\n✅ Reshape avanzado: melt() y dcast() para transformaciones complejas\n✅ Window functions: Análisis temporal sofisticado\n\n\n\n\n✅ Keys e índices: Aceleración dramática en datasets grandes\n✅ Threading: Aprovechar múltiples núcleos automáticamente\n✅ Benchmarking: Medir y optimizar código sistemáticamente\n✅ Best practices: Do’s y Don’ts para código profesional\n\n\n\n\n✅ ggplot2: Visualizaciones profesionales\n✅ Shiny: Dashboards reactivos ultra-rápidos\n✅ tidymodels: Machine learning workflows\n✅ dtplyr: Lo mejor de ambos mundos",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#el-impacto-real-en-tu-trabajo",
    "href": "conclusion.html#el-impacto-real-en-tu-trabajo",
    "title": "Conclusiones y Próximos Pasos",
    "section": "El Impacto Real en tu Trabajo",
    "text": "El Impacto Real en tu Trabajo\nAntes vs. Después: Un Ejemplo Concreto\n\n# ANTES: Código típico de R base/dplyr (simulado)\ncodigo_antes &lt;- '\n# Múltiples pasos, copias de memoria, código verbose\ndf_filtered &lt;- df[df$category %in% c(\"A\", \"B\") & df$year == 2024, ]\ndf_summary &lt;- aggregate(value ~ region + product, df_filtered, mean)\ndf_ranked &lt;- df_summary[order(-df_summary$value), ]\ndf_top10 &lt;- head(df_ranked, 10)\n'\n\n# AHORA: Tu código data.table experto\nset.seed(123)\ndatos_demo &lt;- data.table(\n  category = sample(c(\"A\", \"B\", \"C\"), 1000, replace = TRUE),\n  year = sample(2022:2024, 1000, replace = TRUE),\n  region = sample(c(\"Norte\", \"Sur\", \"Este\", \"Oeste\"), 1000, replace = TRUE),\n  product = sample(c(\"P1\", \"P2\", \"P3\", \"P4\"), 1000, replace = TRUE),\n  value = round(rnorm(1000, 100, 20), 2)\n)\n\n# Una línea elegante y eficiente\nresultado_experto &lt;- datos_demo[\n  category %in% c(\"A\", \"B\") & year == 2024,\n  .(avg_value = mean(value)), \n  by = .(region, product)\n][order(-avg_value)][1:10]\n\nprint(resultado_experto)\n#&gt;     region product avg_value\n#&gt;     &lt;char&gt;  &lt;char&gt;     &lt;num&gt;\n#&gt;  1:    Sur      P2  113.6217\n#&gt;  2:  Oeste      P2  109.0908\n#&gt;  3:  Norte      P1  106.2233\n#&gt;  4:  Oeste      P3  103.4631\n#&gt;  5:   Este      P4  102.4247\n#&gt;  6:   Este      P1  102.0107\n#&gt;  7:  Norte      P3  101.4153\n#&gt;  8:  Norte      P2  101.2600\n#&gt;  9:    Sur      P1  101.0940\n#&gt; 10:    Sur      P3  100.8458\n\nBeneficios Cuantificables\n\n# Simulación de mejoras típicas al adoptar data.table\nmejoras &lt;- data.table(\n  Aspecto = c(\n    \"Velocidad de procesamiento\",\n    \"Uso de memoria\", \n    \"Líneas de código\",\n    \"Tiempo de desarrollo\",\n    \"Mantenibilidad\"\n  ),\n  Antes = c(\"10 min\", \"2 GB\", \"50 líneas\", \"2 horas\", \"Difícil\"),\n  Despues = c(\"30 seg\", \"500 MB\", \"10 líneas\", \"30 min\", \"Fácil\"),\n  Mejora = c(\"20x más rápido\", \"75% menos memoria\", \"80% menos código\", \n             \"4x más rápido\", \"Significativamente mejor\")\n)\n\nkable(mejoras, caption = \"Impacto típico de adoptar data.table\")\n\n\nImpacto típico de adoptar data.table\n\n\n\n\n\n\n\nAspecto\nAntes\nDespues\nMejora\n\n\n\nVelocidad de procesamiento\n10 min\n30 seg\n20x más rápido\n\n\nUso de memoria\n2 GB\n500 MB\n75% menos memoria\n\n\nLíneas de código\n50 líneas\n10 líneas\n80% menos código\n\n\nTiempo de desarrollo\n2 horas\n30 min\n4x más rápido\n\n\nMantenibilidad\nDifícil\nFácil\nSignificativamente mejor",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#recursos-para-continuar-aprendiendo",
    "href": "conclusion.html#recursos-para-continuar-aprendiendo",
    "title": "Conclusiones y Próximos Pasos",
    "section": "Recursos para Continuar Aprendiendo",
    "text": "Recursos para Continuar Aprendiendo\n1. Documentación y Referencias Oficiales\n\n\n📚 Viñetas oficiales: browseVignettes(\"data.table\") en R\n\n📖 Manual completo: CRAN data.table PDF\n\n\n🌐 Wiki del proyecto: data.table Wiki\n\n\n💡 Articles collection: Community Articles\n\n2. Comunidad y Soporte\n\n\n💬 Stack Overflow: Tag [data.table] - comunidad muy activa\n\n🐛 GitHub Issues: Reportar bugs y pedir features\n\n\n📧 Mailing list: datatable-help@lists.r-forge.r-project.org\n\n\n🐦 Twitter: Sigue @rdatatable para actualizaciones\n3. Recursos de Aprendizaje Avanzado\n\n\n\n\n\n\n📚 Lecturas Recomendadas\n\n\n\n\n\nAdvanced R - Para entender R a profundidad\n\nR for Data Science - Contexto del ecosistema\n\nData.table in Action - Casos de uso reales\n\nPerformance comparisons - Benchmarks detallados\n\n\n\n4. Datasets para Practicar\n\n# Datasets grandes para practicar\nlibrary(data.table)\n\n# 1. NYC Taxi Data (varios GB)\n# Descarga desde: https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n\n# 2. Flight data\ninstall.packages(\"nycflights13\")\nlibrary(nycflights13)\nflights_dt &lt;- as.data.table(flights)\n\n# 3. Datos financieros\ninstall.packages(\"quantmod\")\nlibrary(quantmod)\n# getSymbols() para datos de acciones\n\n# 4. Generar datos sintéticos grandes\nbig_practice_data &lt;- data.table(\n  id = 1:10000000,  # 10 millones de filas\n  group = sample(LETTERS, 10000000, replace = TRUE),\n  value = rnorm(10000000),\n  date = sample(seq(as.Date(\"2020-01-01\"), Sys.Date(), by = \"day\"), 10000000, replace = TRUE)\n)",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#desafíos-de-certificación",
    "href": "conclusion.html#desafíos-de-certificación",
    "title": "Conclusiones y Próximos Pasos",
    "section": "Desafíos de Certificación",
    "text": "Desafíos de Certificación\nPara consolidar tu aprendizaje, aquí tienes desafíos progresivos:\n🥉 Nivel Bronce: Fundamentos\n\n\n\n\n\n\nDesafío 1: Operaciones Básicas\n\n\n\nDado un data.table con columnas [id, category, value, date]:\n\nFiltra las filas donde value &gt; 100\n\nCalcula la suma de value por category\n\nAñade una columna con el ranking de value dentro de cada category\n\nOrdena por category y -value\n\n\n\n\n🥈 Nivel Plata: Intermedio\n\n\n\n\n\n\nDesafío 2: Joins y Reshape\n\n\n\n\n\nUne dos data.tables usando setkey() para máxima eficiencia\n\nConvierte datos de formato ancho a largo usando melt()\n\n\nCalcula medias móviles de 7 días para una serie temporal\n\nCrea una función que automatice este pipeline\n\n\n\n🥇 Nivel Oro: Avanzado\n\n\n\n\n\n\nDesafío 3: Optimización y Rolling Joins\n\n\n\n\n\nImplementa un rolling join para calcular precios de cierre más recientes\n\nOptimiza una función que toma &gt;10 segundos usando keys e índices\n\nCrea una non-equi join para categorizar observaciones por rangos\n\nBenchmarks tu solución vs. alternativas de R base/dplyr\n\n\n\n💎 Nivel Diamante: Experto\n\n\n\n\n\n\nDesafío 4: Aplicación Completa\n\n\n\nCrea una aplicación Shiny que: 1. Procese datasets &gt;1GB usando data.table 2. Visualice resultados con ggplot2 3. Permita interactividad en tiempo real 4. Integre un modelo predictivo simple 5. Exporte resultados en múltiples formatos",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#contribuir-al-ecosistema-data.table",
    "href": "conclusion.html#contribuir-al-ecosistema-data.table",
    "title": "Conclusiones y Próximos Pasos",
    "section": "Contribuir al Ecosistema data.table",
    "text": "Contribuir al Ecosistema data.table\nFormas de Contribuir\n\n\n🐛 Reportar bugs: Con ejemplos reproducibles mínimos\n\n💡 Sugerir mejoras: Features que necesitas en tu trabajo\n\n📝 Documentación: Mejorar ejemplos y explicaciones\n\n🧪 Testing: Probar versiones de desarrollo\n\n📚 Tutoriales: Crear contenido para la comunidad\nCódigo de Ejemplo Reproducible\n\n# Template para reportar issues\nlibrary(data.table)\n\n# Datos mínimos que reproducen el problema\ndt &lt;- data.table(x = 1:3, y = c(\"a\", \"b\", \"c\"))\n\n# Código que causa el problema\n# dt[...] # Tu código aquí\n\n# Resultado esperado vs. resultado actual\n# Esperado: ...\n# Actual: ...\n\n# Información del sistema\nsessionInfo()",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#el-futuro-de-data.table",
    "href": "conclusion.html#el-futuro-de-data.table",
    "title": "Conclusiones y Próximos Pasos",
    "section": "El Futuro de data.table",
    "text": "El Futuro de data.table\nDesarrollos Recientes y Futuros\n\n\n🚀 Performance mejorado: Optimizaciones continuas en el core C\n\n🔗 Mejor integración: Con Arrow, DuckDB, y herramientas Big Data\n\n📊 Nuevas funcionalidades: Window functions expandidas, más joins especiales\n\n🌐 Ecosistema creciente: Más paquetes construidos sobre data.table\nTendencias en Data Science donde data.table Brilla\n\n\nBig Data local: Procesamiento de TB en laptops\n\nReal-time analytics: Shiny apps ultra-responsivas\n\nFinancial modeling: Rolling joins para series temporales\n\nIoT data processing: Análisis de sensores en tiempo real",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#reflexión-final-tu-nueva-superheroa",
    "href": "conclusion.html#reflexión-final-tu-nueva-superheroa",
    "title": "Conclusiones y Próximos Pasos",
    "section": "Reflexión Final: Tu Nueva Superheroa",
    "text": "Reflexión Final: Tu Nueva Superheroa\n\n# Tu evolución como data scientist\nevolucion &lt;- data.table(\n  Etapa = c(\"Inicio del tutorial\", \"Después del tutorial\"),\n  Herramientas = c(\"R base, dplyr básico\", \"data.table experto + ecosistema\"),\n  Performance = c(\"Datasets pequeños\", \"Big Data sin problemas\"),\n  Productividad = c(\"Horas por análisis\", \"Minutos por análisis\"),\n  Confianza = c(\"Principiante\", \"Experto certificado\")\n)\n\nprint(evolucion)\n#&gt;                   Etapa                    Herramientas            Performance\n#&gt;                  &lt;char&gt;                          &lt;char&gt;                 &lt;char&gt;\n#&gt; 1:  Inicio del tutorial            R base, dplyr básico      Datasets pequeños\n#&gt; 2: Después del tutorial data.table experto + ecosistema Big Data sin problemas\n#&gt;           Productividad           Confianza\n#&gt;                  &lt;char&gt;              &lt;char&gt;\n#&gt; 1:   Horas por análisis        Principiante\n#&gt; 2: Minutos por análisis Experto certificado\n\n# Tu nuevo toolkit mental\ncat(\"\\n🧰 TU TOOLKIT MENTAL ACTUAL:\\n\")\n#&gt; \n#&gt; 🧰 TU TOOLKIT MENTAL ACTUAL:\ncat(\"   • DT[i, j, by] - Sintaxis universal\\n\")\n#&gt;    • DT[i, j, by] - Sintaxis universal\ncat(\"   • := para modificaciones eficientes\\n\") \n#&gt;    • := para modificaciones eficientes\ncat(\"   • setkey() para performance\\n\")\n#&gt;    • setkey() para performance\ncat(\"   • Rolling joins para temporal data\\n\")\n#&gt;    • Rolling joins para temporal data\ncat(\"   • .SD/.SDcols para operaciones complejas\\n\")\n#&gt;    • .SD/.SDcols para operaciones complejas\ncat(\"   • Integración perfecta con ggplot2/shiny\\n\")\n#&gt;    • Integración perfecta con ggplot2/shiny\n\n\n\n\n\n\n\n\n🎯 Tu Certificado de Maestría\n\n\n\nCERTIFICAMOS QUE:\nHas completado exitosamente el Tutorial Completo de data.table y ahora posees:\n✅ Conocimiento fundamental de la sintaxis DT[i, j, by]\n✅ Dominio de técnicas avanzadas como rolling joins y reshape\n✅ Habilidades de optimización para Big Data\n✅ Capacidad de integración con el ecosistema R\n✅ Experiencia práctica con ejercicios del mundo real\nEstás oficialmente preparado/a para: - Manejar datasets de cualquier tamaño con confianza - Escribir código data.table eficiente y mantenible - Integrar data.table en workflows profesionales - Mentorear a otros en el uso de esta poderosa herramienta\n\n¡Bienvenido/a al selecto grupo de expertos en data.table! 🎉",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#agradecimientos",
    "href": "conclusion.html#agradecimientos",
    "title": "Conclusiones y Próximos Pasos",
    "section": "Agradecimientos",
    "text": "Agradecimientos\nEste tutorial fue posible gracias a:\n\n\nMatt Dowle y el equipo de desarrollo de data.table\n\n\nLa comunidad R que mantiene el ecosistema vibrante\n\nLos contribuidores que reportan bugs y mejoran la documentación\n\nTú, por completar este viaje de aprendizaje\n\n\n\n\n\n\n\n\n🚀 Próximo Paso: ¡Úsalo en el Mundo Real!\n\n\n\nNo dejes que este conocimiento se oxide. Tu próxima misión:\n\n\nIdentifica un proyecto actual donde puedas aplicar data.table\n\n\nRefactoriza código existente para aprovechar la velocidad de data.table\n\n\nComparte tu experiencia con colegas y la comunidad\n\nMantente actualizado con las nuevas versiones y características\n\nEl mundo de los datos te espera. ¡Ve y conquístalo con data.table! 💪\n\n\n\n¡Gracias por acompañarnos en este viaje! Tu adventure con data.table apenas comienza… 🌟\n\nTutorial generado el 20 de agosto de 2025 con R R version 4.4.2 (2024-10-31 ucrt) y data.table 1.17.0",
    "crumbs": [
      "Conclusiones y Próximos Pasos"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Referencias Académicas y Técnicas\nEste tutorial se basa en la documentación oficial de data.table, artículos de la comunidad, y años de experiencia práctica con la herramienta. A continuación se presentan las referencias clave consultadas.",
    "crumbs": [
      "Referencias"
    ]
  },
  {
    "objectID": "references.html#enlaces-útiles-adicionales",
    "href": "references.html#enlaces-útiles-adicionales",
    "title": "Referencias",
    "section": "Enlaces Útiles Adicionales",
    "text": "Enlaces Útiles Adicionales\n\nDocumentación Oficial\n\ndata.table en CRAN: https://cran.r-project.org/package=data.table\nViñetas del paquete: Ejecuta browseVignettes(\"data.table\") en R\nAyuda integrada: ?data.table, ?setkey, ?merge.data.table en R\n\n\n\nComunidad y Soporte\n\nStack Overflow: Preguntas etiquetadas con data.table\nGitHub del proyecto: https://github.com/Rdatatable/data.table\nReddit r/rstats: Comunidad activa de usuarios de R\n\n\n\nRecursos de Aprendizaje\n\nR for Data Science: https://r4ds.hadley.nz/\nAdvanced R: https://adv-r.hadley.nz/\nR-bloggers: https://www.r-bloggers.com/\n\n\n\nComparaciones y Benchmarks\n\nVincent Arel-Bundock: Comparaciones detalladas de performance\nH2O.ai benchmarks: https://h2oai.github.io/db-benchmark/\nThe Raft blog: Artículos técnicos de la comunidad data.table\n\n\n\nDatasets para Práctica\n\nNYC Open Data: https://opendata.cityofnewyork.us/\nKaggle Datasets: https://www.kaggle.com/datasets\nUCI ML Repository: https://archive.ics.uci.edu/ml/index.php\n\n\n\n\n\n\n\n\nNota sobre las Referencias\n\n\n\nEste tutorial está diseñado para ser un recurso educativo comprehensivo. Las técnicas y ejemplos presentados están basados en las mejores prácticas de la comunidad data.table y han sido verificados contra la documentación oficial más reciente.\nPara mantenerte actualizado con los cambios en data.table, recomendamos seguir el repositorio oficial en GitHub y las notas de nuevas versiones.\n\n\n\nÚltima actualización el r format(Sys.Date(), \"%d de %B de %Y\") con R r R.version.string y data.table r packageVersion(\"data.table\")",
    "crumbs": [
      "Referencias"
    ]
  }
]