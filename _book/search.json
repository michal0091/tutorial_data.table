[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Domina data.table en R",
    "section": "",
    "text": "Prefacio",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#por-qu√©-data.table",
    "href": "index.html#por-qu√©-data.table",
    "title": "Domina data.table en R",
    "section": "¬øPor qu√© data.table?",
    "text": "¬øPor qu√© data.table?\nEn el ecosistema de R, cuando hablamos de manipulaci√≥n eficiente de datos, data.table es el rey indiscutible. No es solo una mejora incremental sobre data.frame - es una reimaginaci√≥n completa de c√≥mo deber√≠an funcionar las operaciones con datos.\nLos Tres Pilares de data.table\n\n\n\nüöÄ Velocidad\nüß† Memoria\n‚úçÔ∏è Sintaxis\n\n\n\ndata.table est√° escrito en C y optimizado hasta el √∫ltimo detalle. Para datasets grandes, la diferencia puede ser de segundos vs.¬†horas.\n\n\nSu caracter√≠stica de modificaci√≥n por referencia significa que no crea copias innecesarias de tus datos. Un dataset de 1GB sigue siendo 1GB, no 3GB.\n\n\nLa sintaxis DT[i, j, by] es consistente y poderosa. Una vez que la dominas, puedes expresar operaciones complejas de forma incre√≠blemente concisa.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#para-qui√©n-es-este-tutorial",
    "href": "index.html#para-qui√©n-es-este-tutorial",
    "title": "Domina data.table en R",
    "section": "¬øPara qui√©n es este tutorial?",
    "text": "¬øPara qui√©n es este tutorial?\nEste tutorial est√° dise√±ado para:\n\n\nUsuarios de R base que quieren acelerar dram√°ticamente su flujo de trabajo\n\nUsuarios de dplyr que necesitan manejar datasets m√°s grandes\n\nCient√≠ficos de datos que trabajan con millones de filas y necesitan eficiencia\n\nAnalistas que quieren una herramienta m√°s potente para manipulaci√≥n de datos",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#lo-que-aprender√°s",
    "href": "index.html#lo-que-aprender√°s",
    "title": "Domina data.table en R",
    "section": "Lo que aprender√°s",
    "text": "Lo que aprender√°s\nAl final de este tutorial, ser√°s capaz de:\n\n\n\n\n\n\nHabilidades que dominar√°s üéØ\n\n\n\n\n\n\n‚úÖ Sintaxis fundamental: Dominar DT[i, j, by] como un experto\n‚úÖ Manipulaci√≥n avanzada: Joins, reshape, y operaciones complejas\n‚úÖ Optimizaci√≥n: Escribir c√≥digo data.table que vuela\n‚úÖ Integraci√≥n: Combinar data.table con ggplot2, shiny, y m√°s\n‚úÖ Buenas pr√°cticas: Evitar errores comunes y escribir c√≥digo mantenible",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#estructura-del-tutorial",
    "href": "index.html#estructura-del-tutorial",
    "title": "Domina data.table en R",
    "section": "Estructura del Tutorial",
    "text": "Estructura del Tutorial\n\nM√≥dulo 1: Fundamentos y Sintaxis Esencial\nEmpezaremos desde cero: qu√© es un data.table, c√≥mo se diferencia de un data.frame, y c√≥mo dominar la sintaxis DT[i, j, by].\n\nM√≥dulo 2: Manipulaci√≥n de Datos Intermedia\nEncadenamiento de operaciones, joins b√°sicos, y t√©cnicas que te har√°n m√°s productivo.\n\nM√≥dulo 3: T√©cnicas Avanzadas y Funciones Especiales\nLos s√≠mbolos especiales (.SD, .N, etc.), joins avanzados, y reshape de datos.\n\nM√≥dulo 4: Optimizaci√≥n y Buenas Pr√°cticas\nC√≥mo escribir c√≥digo data.table realmente r√°pido y evitar errores comunes.\n\nM√≥dulo 5: Integraci√≥n con el Ecosistema R\nUsar data.table con ggplot2, shiny, tidymodels, y otros paquetes populares.",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#requisitos-previos",
    "href": "index.html#requisitos-previos",
    "title": "Domina data.table en R",
    "section": "Requisitos Previos",
    "text": "Requisitos Previos\nConocimientos Necesarios\n\n\nR b√°sico: Vectores, listas, funciones b√°sicas\n\ndata.frame b√°sico: Indexaci√≥n con [filas, columnas]\n\n\nExperiencia recomendada: Haber trabajado con datos reales en R\nSoftware Requerido\n\n# Instalaci√≥n de paquetes necesarios\ninstall.packages(c(\"data.table\", \"ggplot2\", \"DT\"))\n\n# Verificar versiones\npackageVersion(\"data.table\")  # &gt;= 1.14.0 recomendado",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#convenciones-de-este-tutorial",
    "href": "index.html#convenciones-de-este-tutorial",
    "title": "Domina data.table en R",
    "section": "Convenciones de este Tutorial",
    "text": "Convenciones de este Tutorial\nIconos y Callouts\n\n\n\n\n\n\nüí° Consejo\n\n\n\nConsejos pr√°cticos y mejores pr√°cticas.\n\n\n\n\n\n\n\n\n‚ö†Ô∏è Cuidado\n\n\n\nErrores comunes y c√≥mo evitarlos.\n\n\n\n\n\n\n\n\nüìù Nota\n\n\n\nInformaci√≥n adicional y contexto.\n\n\n\n\n\n\n\n\n‚ùó Importante\n\n\n\nConceptos clave que debes recordar.\n\n\nC√≥digo y Ejercicios\nLos ejercicios pr√°cticos aparecer√°n en cajas especiales y tendr√°n sus soluciones explicadas paso a paso. Recomendamos encarecidamente que intentes resolver cada ejercicio antes de ver la soluci√≥n.\n\n# Los bloques de c√≥digo incluir√°n explicaciones detalladas\nlibrary(data.table)\n\n# Ejemplo simple: crear un data.table\ndt_ejemplo &lt;- data.table(\n  id = 1:5,\n  valor = c(10, 20, 30, 40, 50),\n  categoria = c(\"A\", \"B\", \"A\", \"C\", \"B\")\n)\n\nprint(dt_ejemplo)\n#&gt;       id valor categoria\n#&gt;    &lt;int&gt; &lt;num&gt;    &lt;char&gt;\n#&gt; 1:     1    10         A\n#&gt; 2:     2    20         B\n#&gt; 3:     3    30         A\n#&gt; 4:     4    40         C\n#&gt; 5:     5    50         B",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#obtener-ayuda",
    "href": "index.html#obtener-ayuda",
    "title": "Domina data.table en R",
    "section": "Obtener Ayuda",
    "text": "Obtener Ayuda\nSi tienes preguntas durante tu aprendizaje:\n\n\nDocumentaci√≥n oficial: ?data.table en R\n\nVi√±etas: browseVignettes(\"data.table\")\n\n\nStack Overflow: Tag [data.table]\n\n\nGitHub: Rdatatable/data.table",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "index.html#contribuciones-y-feedback",
    "href": "index.html#contribuciones-y-feedback",
    "title": "Domina data.table en R",
    "section": "Contribuciones y Feedback",
    "text": "Contribuciones y Feedback\nEste tutorial es un proyecto vivo. Si encuentras errores, tienes sugerencias de mejora, o quieres contribuir con ejemplos adicionales, ¬°tu participaci√≥n es bienvenida!\n\n\n\n\n\n\n\nüéØ ¬øListo para comenzar?\n\n\n\nEn el pr√≥ximo cap√≠tulo configuraremos nuestro entorno y crearemos nuestro primer data.table. ¬°El viaje hacia la maestr√≠a en manipulaci√≥n de datos comienza ahora!\n\n\n\nInformaci√≥n del Sistema:\n\n#&gt; üìÖ Generado: 20 de agosto de 2025\n#&gt; üîß Versi√≥n de R: R version 4.4.2 (2024-10-31 ucrt)\n#&gt; üì¶ Versi√≥n de data.table: 1.17.0\n#&gt; üì¶ Versi√≥n de Quarto: 1.7.32",
    "crumbs": [
      "Prefacio"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "",
    "text": "1.1 La Historia de data.table\ndata.table naci√≥ en 2006 de la frustraci√≥n de Matt Dowle con la velocidad de operaciones sobre data.frame para datasets grandes. Su visi√≥n era simple pero revolucionaria: ¬øpor qu√© conformarse con segundos cuando puedes tener milisegundos?\nHoy, m√°s de 15 a√±os despu√©s, data.table es la referencia mundial para manipulaci√≥n de datos de alta performance en R, usado por empresas como Facebook, Netflix, y miles de cient√≠ficos de datos alrededor del mundo.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#qu√©-hace-a-data.table-especial",
    "href": "intro.html#qu√©-hace-a-data.table-especial",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "\n1.2 ¬øQu√© hace a data.table especial?",
    "text": "1.2 ¬øQu√© hace a data.table especial?\n\n1.2.1 1. Es un data.frame mejorado üîß\nUn data.table es un data.frame. Esto significa:\n\n# Creamos un data.table\ndt &lt;- data.table(x = 1:3, y = c(\"A\", \"B\", \"C\"))\n\n# Verificamos su herencia\nclass(dt)\n#&gt; [1] \"data.table\" \"data.frame\"\nis.data.frame(dt)\n#&gt; [1] TRUE\n\nEsta compatibilidad es crucial: puedes usar un data.table en cualquier lugar que espere un data.frame sin problemas.\n\n1.2.2 2. Modificaci√≥n por referencia üß†\nLa caracter√≠stica m√°s distintiva de data.table es su capacidad de modificar objetos por referencia, sin crear copias.\n\n# R base: crea una copia completa\ndf &lt;- data.frame(x = 1:1000000, y = rnorm(1000000))\ndf$z &lt;- df$x + df$y  # ¬°Copia completa en memoria!\n\n# data.table: modificaci√≥n in-place\ndt &lt;- data.table(x = 1:1000000, y = rnorm(1000000))\ndt[, z := x + y]     # ¬°Sin copias! Modificaci√≥n directa\n\n\n\n\n\n\n\nüí° Implicaciones de la Modificaci√≥n por Referencia\n\n\n\n\n\nVentaja: Velocidad extrema y uso eficiente de memoria\n\nCuidado: Los cambios son permanentes, no hay ‚Äúdeshacer‚Äù autom√°tico\n\nSoluci√≥n: Usa copy() cuando necesites preservar el original\n\n\n\n\n1.2.3 3. Sintaxis consistente y potente ‚úçÔ∏è\nTodo en data.table se reduce a una estructura simple pero poderosa:\n\n# La estructura universal de data.table\nDT[i, j, by]\n\n# i = filas (WHERE)    - \"¬øQu√© filas me interesan?\"\n# j = columnas (WHAT)  - \"¬øQu√© quiero hacer?\"  \n# by = grupos (BY)     - \"¬øAgrupado por qu√©?\"",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#comparaci√≥n-data.table-vs.-dplyr-vs.-r-base",
    "href": "intro.html#comparaci√≥n-data.table-vs.-dplyr-vs.-r-base",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "\n1.3 Comparaci√≥n: data.table vs.¬†dplyr vs.¬†R base",
    "text": "1.3 Comparaci√≥n: data.table vs.¬†dplyr vs.¬†R base\nVeamos c√≥mo se comparan las tres principales formas de manipular datos en R:\n\n1.3.1 Tarea: Calcular la media de valor por categoria\n\n\n\nR Base\ndplyr\ndata.table\n\n\n\n\n# R base: verbose y lento\nresultado_base &lt;- aggregate(valor ~ categoria, data = datos, FUN = mean)\nhead(resultado_base)\n#&gt;   categoria    valor\n#&gt; 1         A 100.0053\n#&gt; 2         B 100.0914\n#&gt; 3         C 100.1848\n#&gt; 4         D 100.0232\n#&gt; 5         E 100.0879\n\n\n\n\n# dplyr: legible pero m√°s lento para datos grandes\nresultado_dplyr &lt;- datos %&gt;%\n  group_by(categoria) %&gt;%\n  summarise(media_valor = mean(valor), .groups = 'drop')\n\nhead(resultado_dplyr)\n#&gt; # A tibble: 5 √ó 2\n#&gt;   categoria media_valor\n#&gt;   &lt;chr&gt;           &lt;dbl&gt;\n#&gt; 1 A                100.\n#&gt; 2 B                100.\n#&gt; 3 C                100.\n#&gt; 4 D                100.\n#&gt; 5 E                100.\n\n\n\n\n# data.table: conciso y ultra r√°pido\nresultado_dt &lt;- datos_dt[, .(media_valor = mean(valor)), by = categoria]\nhead(resultado_dt)\n#&gt;    categoria media_valor\n#&gt;       &lt;char&gt;       &lt;num&gt;\n#&gt; 1:         C    100.1848\n#&gt; 2:         B    100.0914\n#&gt; 3:         D    100.0232\n#&gt; 4:         A    100.0053\n#&gt; 5:         E    100.0879\n\n\n\n\n\n1.3.2 Comparaci√≥n de Rendimiento\n\n# Comparamos velocidad (solo con muestra para el ejemplo)\nif(nrow(datos) &gt; 10000) {\n  muestra &lt;- slice_sample(datos, n = 10000)\n  muestra_dt &lt;- as.data.table(muestra)\n  \n  benchmark_resultado &lt;- microbenchmark(\n    \"R Base\" = aggregate(valor ~ categoria, data = muestra, FUN = mean),\n    \"dplyr\" = muestra %&gt;% group_by(categoria) %&gt;% summarise(media = mean(valor), .groups = 'drop'),\n    \"data.table\" = muestra_dt[, .(media = mean(valor)), by = categoria],\n    times = 50\n  )\n  \n  print(benchmark_resultado)\n}\n#&gt; Unit: milliseconds\n#&gt;        expr    min     lq     mean  median     uq    max neval\n#&gt;      R Base 1.2766 1.4461 1.870040 1.82790 2.0006 5.7968    50\n#&gt;       dplyr 1.0564 1.1938 1.330138 1.27525 1.4306 2.0359    50\n#&gt;  data.table 1.2652 1.3448 1.474080 1.46270 1.5597 1.9502    50\n\n\n\n\n\n\n\nüìä Interpretando los Resultados\n\n\n\nEn datasets grandes (millones de filas), data.table puede ser 10-100x m√°s r√°pido que R base y 2-10x m√°s r√°pido que dplyr. La diferencia se amplifica con operaciones m√°s complejas.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#tu-primer-data.table",
    "href": "intro.html#tu-primer-data.table",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "\n1.4 Tu Primer data.table\n",
    "text": "1.4 Tu Primer data.table\n\n\n1.4.1 Creaci√≥n B√°sica\nExisten varias formas de crear un data.table:\n\n# 1. Desde cero\nmi_dt &lt;- data.table(\n  nombre = c(\"Ana\", \"Juan\", \"Mar√≠a\", \"Carlos\"),\n  edad = c(25, 30, 28, 35),\n  ciudad = c(\"Madrid\", \"Barcelona\", \"Sevilla\", \"Valencia\"),\n  salario = c(35000, 42000, 38000, 50000)\n)\n\nprint(mi_dt)\n#&gt;    nombre  edad    ciudad salario\n#&gt;    &lt;char&gt; &lt;num&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:    Ana    25    Madrid   35000\n#&gt; 2:   Juan    30 Barcelona   42000\n#&gt; 3:  Mar√≠a    28   Sevilla   38000\n#&gt; 4: Carlos    35  Valencia   50000\n\n\n# 2. Convirtiendo un data.frame existente\niris_dt &lt;- as.data.table(iris)\nprint(head(iris_dt))\n#&gt;    Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n#&gt;           &lt;num&gt;       &lt;num&gt;        &lt;num&gt;       &lt;num&gt;  &lt;fctr&gt;\n#&gt; 1:          5.1         3.5          1.4         0.2  setosa\n#&gt; 2:          4.9         3.0          1.4         0.2  setosa\n#&gt; 3:          4.7         3.2          1.3         0.2  setosa\n#&gt; 4:          4.6         3.1          1.5         0.2  setosa\n#&gt; 5:          5.0         3.6          1.4         0.2  setosa\n#&gt; 6:          5.4         3.9          1.7         0.4  setosa\n\n\n# 3. Leyendo un archivo (s√∫per r√°pido)\ndatos_csv &lt;- fread(\"mi_archivo.csv\")\n\n\n1.4.2 Explorando tu data.table\n\n\n# Informaci√≥n b√°sica\ndim(iris_dt)         # Dimensiones\n#&gt; [1] 150   5\nnames(iris_dt)       # Nombres de columnas\n#&gt; [1] \"Sepal.Length\" \"Sepal.Width\"  \"Petal.Length\" \"Petal.Width\"  \"Species\"\nstr(iris_dt)         # Estructura\n#&gt; Classes 'data.table' and 'data.frame':   150 obs. of  5 variables:\n#&gt;  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...\n#&gt;  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...\n#&gt;  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...\n#&gt;  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...\n#&gt;  $ Species     : Factor w/ 3 levels \"setosa\",\"versicolor\",..: 1 1 1 1 1 1 1 1 1 1 ...\n#&gt;  - attr(*, \".internal.selfref\")=&lt;externalptr&gt;\n\n\n# Estad√≠sticas r√°pidas por grupo\niris_dt[, .N, by = Species]  # Conteo por especie\n#&gt;       Species     N\n#&gt;        &lt;fctr&gt; &lt;int&gt;\n#&gt; 1:     setosa    50\n#&gt; 2: versicolor    50\n#&gt; 3:  virginica    50",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#configuraci√≥n-del-entorno",
    "href": "intro.html#configuraci√≥n-del-entorno",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "\n1.5 Configuraci√≥n del Entorno",
    "text": "1.5 Configuraci√≥n del Entorno\nPara aprovechar al m√°ximo data.table, configuremos nuestro entorno:\n\n# 1. Configurar n√∫mero de threads (para aprovechar m√∫ltiples n√∫cleos)\nsetDTthreads(0)  # 0 = usar todos los n√∫cleos disponibles\ngetDTthreads()   # Verificar configuraci√≥n\n#&gt; [1] 16\n\n# 2. Opciones de visualizaci√≥n\noptions(datatable.print.nrows = 10)     # Mostrar 10 filas\noptions(datatable.print.class = TRUE)   # Mostrar clases de columnas\n\n# 3. Modo verboso para aprendizaje (opcional)\n# options(datatable.verbose = TRUE)  # Descomenta para debug\n\n\n\n\n\n\n\nüöÄ Consejo de Performance\n\n\n\nsetDTthreads(0) utiliza todos los n√∫cleos de CPU disponibles. En m√°quinas con muchos n√∫cleos, esto puede acelerar operaciones hasta 4-8x. Para laptops o uso interactivo, considera setDTthreads(2) para mantener el sistema responsive.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#anatom√≠a-de-la-sintaxis-dti-j-by",
    "href": "intro.html#anatom√≠a-de-la-sintaxis-dti-j-by",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "\n1.6 Anatom√≠a de la Sintaxis DT[i, j, by]\n",
    "text": "1.6 Anatom√≠a de la Sintaxis DT[i, j, by]\n\nLa sintaxis de data.table puede parecer intimidante al principio, pero es incre√≠blemente l√≥gica:\n\n# Ejemplo con nuestros datos de empleados\nprint(mi_dt)\n#&gt;    nombre  edad    ciudad salario\n#&gt;    &lt;char&gt; &lt;num&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:    Ana    25    Madrid   35000\n#&gt; 2:   Juan    30 Barcelona   42000\n#&gt; 3:  Mar√≠a    28   Sevilla   38000\n#&gt; 4: Carlos    35  Valencia   50000\n\n# i: ¬øQU√â FILAS? (filtrado)\nmi_dt[edad &gt; 28]\n#&gt;    nombre  edad    ciudad salario\n#&gt;    &lt;char&gt; &lt;num&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:   Juan    30 Barcelona   42000\n#&gt; 2: Carlos    35  Valencia   50000\n\n# j: ¬øQU√â HACER? (selecci√≥n/c√°lculo)\nmi_dt[, .(nombre, salario)]\n#&gt;    nombre salario\n#&gt;    &lt;char&gt;   &lt;num&gt;\n#&gt; 1:    Ana   35000\n#&gt; 2:   Juan   42000\n#&gt; 3:  Mar√≠a   38000\n#&gt; 4: Carlos   50000\n\n# by: ¬øAGRUPADO POR QU√â? (agrupaci√≥n)\nmi_dt[, mean(salario), by = ciudad]\n#&gt;       ciudad    V1\n#&gt;       &lt;char&gt; &lt;num&gt;\n#&gt; 1:    Madrid 35000\n#&gt; 2: Barcelona 42000\n#&gt; 3:   Sevilla 38000\n#&gt; 4:  Valencia 50000",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#ejercicio-pr√°ctico-tu-primera-experiencia",
    "href": "intro.html#ejercicio-pr√°ctico-tu-primera-experiencia",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "\n1.7 Ejercicio Pr√°ctico: Tu Primera Experiencia",
    "text": "1.7 Ejercicio Pr√°ctico: Tu Primera Experiencia\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 1: Explorando los datos de iris\n\n\n\nUsando el data.table iris_dt que creamos:\n\n\nFiltra las filas donde Sepal.Length &gt; 6.0\n\n\nCalcula la media de Petal.Width para cada Species\n\n\nSelecciona solo las columnas que empiecen con ‚ÄúPetal‚Äù\n\n¬°Intenta resolver cada parte antes de ver la soluci√≥n!\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 1\n\n\n\n\n\n\n# 1. Filtrar filas\niris_grandes &lt;- iris_dt[Sepal.Length &gt; 6.0]\nprint(nrow(iris_grandes))\n#&gt; [1] 61\n\n# 2. Media de Petal.Width por Species\nmedias_petal &lt;- iris_dt[, .(media_petal_width = mean(Petal.Width)), by = Species]\nprint(medias_petal)\n#&gt;       Species media_petal_width\n#&gt;        &lt;fctr&gt;             &lt;num&gt;\n#&gt; 1:     setosa             0.246\n#&gt; 2: versicolor             1.326\n#&gt; 3:  virginica             2.026\n\n# 3. Seleccionar columnas que empiecen con \"Petal\"\ncolumnas_petal &lt;- iris_dt[, .SD, .SDcols = patterns(\"^Petal\")]\nprint(head(columnas_petal))\n#&gt;    Petal.Length Petal.Width\n#&gt;           &lt;num&gt;       &lt;num&gt;\n#&gt; 1:          1.4         0.2\n#&gt; 2:          1.4         0.2\n#&gt; 3:          1.3         0.2\n#&gt; 4:          1.5         0.2\n#&gt; 5:          1.4         0.2\n#&gt; 6:          1.7         0.4\n\nExplicaci√≥n: - [Sepal.Length &gt; 6.0] filtra filas por condici√≥n l√≥gica - .(media_petal_width = mean(Petal.Width)) crea una nueva columna calculada - patterns(\"^Petal\") usa regex para seleccionar columnas din√°micamente",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "intro.html#pr√≥ximos-pasos",
    "href": "intro.html#pr√≥ximos-pasos",
    "title": "\n1¬† Introducci√≥n a data.table\n",
    "section": "\n1.8 Pr√≥ximos Pasos",
    "text": "1.8 Pr√≥ximos Pasos\nHas dado tus primeros pasos en el mundo de data.table. En el siguiente cap√≠tulo profundizaremos en cada componente de la sintaxis DT[i, j, by] y descubrir√°s el verdadero poder de esta herramienta.\n\n1.8.1 Lo que viene\nEn el Cap√≠tulo 1 exploraremos: - Filtrado avanzado de filas (i) - Selecci√≥n y transformaci√≥n de columnas (j) - Agrupaciones poderosas (by) - S√≠mbolos especiales como .N, .SD, etc.\n\n\n\n\n\n\n\nüéØ Recuerda\n\n\n\ndata.table no es solo una herramienta m√°s r√°pida - es una forma diferente de pensar sobre la manipulaci√≥n de datos. La inversi√≥n inicial en aprender su sintaxis te pagar√° dividendos durante toda tu carrera como analista de datos.",
    "crumbs": [
      "<span class='chapter-number'>1</span>¬† <span class='chapter-title'>Introducci√≥n a `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html",
    "href": "cap01-sintaxis.html",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "",
    "text": "2.1 La Sintaxis DT[i, j, by]: El Coraz√≥n de data.table\nTodo en data.table gira alrededor de esta estructura simple pero poderosa. Piensa en ella como una pregunta en tres partes que le haces a tus datos:\n# La estructura universal\nDT[i,           j,              by]\n   ‚Üì            ‚Üì               ‚Üì\n ¬øD√≥nde?    ¬øQu√© hacer?    ¬øAgrupado por?\n(filtros)   (seleccionar/   (variables de\n           transformar)      agrupaci√≥n)\nCada componente es opcional, lo que hace la sintaxis extremadamente flexible.",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#el-componente-i-selecci√≥n-y-filtrado-de-filas",
    "href": "cap01-sintaxis.html#el-componente-i-selecci√≥n-y-filtrado-de-filas",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.2 El Componente i: Selecci√≥n y Filtrado de Filas",
    "text": "2.2 El Componente i: Selecci√≥n y Filtrado de Filas\n\n2.2.1 1. Filtrado B√°sico por Condiciones\n\n\n# Empleados con salario &gt; 45000\nempleados[salario &gt; 45000]\n#&gt;       id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     4 Carlos           IT   50000        8    2015-09-20\n#&gt; 2:     6  Pedro           IT   55000       10    2013-04-12\n#&gt; 3:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt; 4:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt; 5:    12  Diego         RRHH   52000        8    2016-01-25\n\n\n# M√∫ltiples condiciones: IT con m√°s de 5 a√±os de experiencia\nempleados[departamento == \"IT\" & a√±os_exp &gt; 5]\n#&gt;       id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     4 Carlos           IT   50000        8    2015-09-20\n#&gt; 2:     5  Luc√≠a           IT   45000        6    2018-11-05\n#&gt; 3:     6  Pedro           IT   55000       10    2013-04-12\n\n\n# Usando %in% para m√∫ltiples valores\nempleados[departamento %in% c(\"Ventas\", \"Marketing\")]\n#&gt;       id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     1    Ana       Ventas   35000        2    2022-01-15\n#&gt; 2:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; 3:     3  Mar√≠a       Ventas   38000        3    2021-07-01\n#&gt; 4:     7 Isabel    Marketing   40000        4    2020-02-28\n#&gt; 5:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt; 6:     9 Carmen    Marketing   41000        3    2021-10-03\n\n\n2.2.2 2. Filtrado por Posici√≥n\n\n\n# Primeras 3 filas\nempleados[1:3]\n#&gt;       id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:     1    Ana       Ventas   35000        2    2022-01-15\n#&gt; 2:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; 3:     3  Mar√≠a       Ventas   38000        3    2021-07-01\n\n# √öltima fila usando .N (n√∫mero total de filas)\nempleados[.N]\n#&gt;       id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:    12  Diego         RRHH   52000        8    2016-01-25\n\n# √öltimas 3 filas\nempleados[(.N-2):.N]\n#&gt;       id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt; 1:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt; 2:    11  Laura         RRHH   44000        5    2019-06-18\n#&gt; 3:    12  Diego         RRHH   52000        8    2016-01-25\n\n\n2.2.3 3. Filtrado por Orden\n\n\n# Ordenar por salario (ascendente)\nempleados[order(salario)]\n#&gt;        id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;     &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt;  1:     1    Ana       Ventas   35000        2    2022-01-15\n#&gt;  2:     3  Mar√≠a       Ventas   38000        3    2021-07-01\n#&gt;  3:     7 Isabel    Marketing   40000        4    2020-02-28\n#&gt;  4:     9 Carmen    Marketing   41000        3    2021-10-03\n#&gt;  5:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; ---                                                         \n#&gt;  8:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt;  9:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt; 10:     4 Carlos           IT   50000        8    2015-09-20\n#&gt; 11:    12  Diego         RRHH   52000        8    2016-01-25\n#&gt; 12:     6  Pedro           IT   55000       10    2013-04-12\n\n# Ordenar por salario descendente\nempleados[order(-salario)]\n#&gt;        id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;     &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt;  1:     6  Pedro           IT   55000       10    2013-04-12\n#&gt;  2:    12  Diego         RRHH   52000        8    2016-01-25\n#&gt;  3:     4 Carlos           IT   50000        8    2015-09-20\n#&gt;  4:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt;  5:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt; ---                                                         \n#&gt;  8:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt;  9:     9 Carmen    Marketing   41000        3    2021-10-03\n#&gt; 10:     7 Isabel    Marketing   40000        4    2020-02-28\n#&gt; 11:     3  Mar√≠a       Ventas   38000        3    2021-07-01\n#&gt; 12:     1    Ana       Ventas   35000        2    2022-01-15\n\n# Ordenar por m√∫ltiples columnas\nempleados[order(departamento, -salario)]\n#&gt;        id nombre departamento salario a√±os_exp fecha_ingreso\n#&gt;     &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;\n#&gt;  1:     6  Pedro           IT   55000       10    2013-04-12\n#&gt;  2:     4 Carlos           IT   50000        8    2015-09-20\n#&gt;  3:     5  Luc√≠a           IT   45000        6    2018-11-05\n#&gt;  4:     8 Miguel    Marketing   47000        7    2017-08-15\n#&gt;  5:     9 Carmen    Marketing   41000        3    2021-10-03\n#&gt; ---                                                         \n#&gt;  8:    10  Jorge         RRHH   48000        9    2014-12-01\n#&gt;  9:    11  Laura         RRHH   44000        5    2019-06-18\n#&gt; 10:     2   Juan       Ventas   42000        5    2019-03-10\n#&gt; 11:     3  Mar√≠a       Ventas   38000        3    2021-07-01\n#&gt; 12:     1    Ana       Ventas   35000        2    2022-01-15\n\n\n\n\n\n\n\nüí° Consejo: Filtrado Eficiente\n\n\n\ndata.table optimiza autom√°ticamente muchas operaciones de filtrado. Para datasets enormes, considera usar setkey() para acelerar filtros repetitivos (lo veremos en cap√≠tulos posteriores).",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#el-componente-j-el-poder-de-la-transformaci√≥n",
    "href": "cap01-sintaxis.html#el-componente-j-el-poder-de-la-transformaci√≥n",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.3 El Componente j: El Poder de la Transformaci√≥n",
    "text": "2.3 El Componente j: El Poder de la Transformaci√≥n\n\n2.3.1 1. Selecci√≥n Simple de Columnas\n\n\n# Seleccionar una columna (devuelve vector)\nempleados[, salario]\n#&gt;  [1] 35000 42000 38000 50000 45000 55000 40000 47000 41000 48000 44000 52000\n\n# Seleccionar una columna (devolver data.table)\nempleados[, .(salario)]\n#&gt;     salario\n#&gt;       &lt;num&gt;\n#&gt;  1:   35000\n#&gt;  2:   42000\n#&gt;  3:   38000\n#&gt;  4:   50000\n#&gt;  5:   45000\n#&gt; ---        \n#&gt;  8:   47000\n#&gt;  9:   41000\n#&gt; 10:   48000\n#&gt; 11:   44000\n#&gt; 12:   52000\n\n# M√∫ltiples columnas\nempleados[, .(nombre, salario, departamento)]\n#&gt;     nombre salario departamento\n#&gt;     &lt;char&gt;   &lt;num&gt;       &lt;char&gt;\n#&gt;  1:    Ana   35000       Ventas\n#&gt;  2:   Juan   42000       Ventas\n#&gt;  3:  Mar√≠a   38000       Ventas\n#&gt;  4: Carlos   50000           IT\n#&gt;  5:  Luc√≠a   45000           IT\n#&gt; ---                            \n#&gt;  8: Miguel   47000    Marketing\n#&gt;  9: Carmen   41000    Marketing\n#&gt; 10:  Jorge   48000         RRHH\n#&gt; 11:  Laura   44000         RRHH\n#&gt; 12:  Diego   52000         RRHH\n\n\n2.3.2 2. Creaci√≥n de Nuevas Columnas\n\n\n# Crear columna calculada\nempleados[, .(nombre, salario, salario_anual = salario * 12)]\n#&gt;     nombre salario salario_anual\n#&gt;     &lt;char&gt;   &lt;num&gt;         &lt;num&gt;\n#&gt;  1:    Ana   35000        420000\n#&gt;  2:   Juan   42000        504000\n#&gt;  3:  Mar√≠a   38000        456000\n#&gt;  4: Carlos   50000        600000\n#&gt;  5:  Luc√≠a   45000        540000\n#&gt; ---                             \n#&gt;  8: Miguel   47000        564000\n#&gt;  9: Carmen   41000        492000\n#&gt; 10:  Jorge   48000        576000\n#&gt; 11:  Laura   44000        528000\n#&gt; 12:  Diego   52000        624000\n\n# M√∫ltiples c√°lculos\nempleados[, .(\n  nombre,\n  salario_mensual = salario,\n  salario_anual = salario * 12,\n  salario_por_a√±o_exp = round(salario / a√±os_exp, 0)\n)]\n#&gt;     nombre salario_mensual salario_anual salario_por_a√±o_exp\n#&gt;     &lt;char&gt;           &lt;num&gt;         &lt;num&gt;               &lt;num&gt;\n#&gt;  1:    Ana           35000        420000               17500\n#&gt;  2:   Juan           42000        504000                8400\n#&gt;  3:  Mar√≠a           38000        456000               12667\n#&gt;  4: Carlos           50000        600000                6250\n#&gt;  5:  Luc√≠a           45000        540000                7500\n#&gt; ---                                                         \n#&gt;  8: Miguel           47000        564000                6714\n#&gt;  9: Carmen           41000        492000               13667\n#&gt; 10:  Jorge           48000        576000                5333\n#&gt; 11:  Laura           44000        528000                8800\n#&gt; 12:  Diego           52000        624000                6500\n\n\n2.3.3 3. Funciones de Agregaci√≥n\n\n\n# Estad√≠sticas b√°sicas\nempleados[, .(\n  salario_promedio = mean(salario),\n  salario_mediana = median(salario),\n  salario_max = max(salario),\n  salario_min = min(salario),\n  total_empleados = .N\n)]\n#&gt;    salario_promedio salario_mediana salario_max salario_min total_empleados\n#&gt;               &lt;num&gt;           &lt;num&gt;       &lt;num&gt;       &lt;num&gt;           &lt;int&gt;\n#&gt; 1:            44750           44500       55000       35000              12\n\n\n2.3.4 4. El S√≠mbolo Especial .N\n\n.N es una variable especial que representa el n√∫mero de filas en el grupo actual:\n\n# Contar total de filas\nempleados[, .N]\n#&gt; [1] 12\n\n# Contar empleados por departamento\nempleados[, .N, by = departamento]\n#&gt;    departamento     N\n#&gt;          &lt;char&gt; &lt;int&gt;\n#&gt; 1:       Ventas     3\n#&gt; 2:           IT     3\n#&gt; 3:    Marketing     3\n#&gt; 4:         RRHH     3\n\n# Usar .N en c√°lculos\nempleados[, .(\n  empleados_total = .N,\n  salario_promedio = mean(salario)\n)]\n#&gt;    empleados_total salario_promedio\n#&gt;              &lt;int&gt;            &lt;num&gt;\n#&gt; 1:              12            44750",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#el-componente-by-agrupaciones-poderosas",
    "href": "cap01-sintaxis.html#el-componente-by-agrupaciones-poderosas",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.4 El Componente by: Agrupaciones Poderosas",
    "text": "2.4 El Componente by: Agrupaciones Poderosas\n\n2.4.1 1. Agrupaci√≥n Simple\n\n\n# Estad√≠sticas por departamento\nempleados[, .(\n  empleados = .N,\n  salario_promedio = round(mean(salario), 0),\n  salario_total = sum(salario)\n), by = departamento]\n#&gt;    departamento empleados salario_promedio salario_total\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;         &lt;num&gt;\n#&gt; 1:       Ventas         3            38333        115000\n#&gt; 2:           IT         3            50000        150000\n#&gt; 3:    Marketing         3            42667        128000\n#&gt; 4:         RRHH         3            48000        144000\n\n\n2.4.2 2. Agrupaci√≥n por M√∫ltiples Variables\n\n\n# Crear categor√≠as de experiencia para el ejemplo\nempleados[, categoria_exp := ifelse(a√±os_exp &lt;= 5, \"Junior\", \"Senior\")]\n\n# Agrupar por departamento y categor√≠a de experiencia\nempleados[, .(\n  empleados = .N,\n  salario_promedio = round(mean(salario), 0)\n), by = .(departamento, categoria_exp)]\n#&gt;    departamento categoria_exp empleados salario_promedio\n#&gt;          &lt;char&gt;        &lt;char&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt; 1:       Ventas        Junior         3            38333\n#&gt; 2:           IT        Senior         3            50000\n#&gt; 3:    Marketing        Junior         2            40500\n#&gt; 4:    Marketing        Senior         1            47000\n#&gt; 5:         RRHH        Senior         2            50000\n#&gt; 6:         RRHH        Junior         1            44000\n\n\n2.4.3 3. Agrupaci√≥n con Expresiones\n\n\n# Agrupar por rangos de salario calculados sobre la marcha\nempleados[, .(\n  empleados = .N,\n  salario_promedio = round(mean(salario), 0)\n), by = .(rango_salario = ifelse(salario &gt; 45000, \"Alto\", \"Medio-Bajo\"))]\n#&gt;    rango_salario empleados salario_promedio\n#&gt;           &lt;char&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt; 1:    Medio-Bajo         7            40714\n#&gt; 2:          Alto         5            50400",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#combinando-los-tres-componentes",
    "href": "cap01-sintaxis.html#combinando-los-tres-componentes",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.5 Combinando los Tres Componentes",
    "text": "2.5 Combinando los Tres Componentes\nLa verdadera potencia surge cuando combinas i, j, y by:\n\n# Filtrar empleados con &gt; 4 a√±os exp, calcular stats por departamento\nempleados[a√±os_exp &gt; 4, .(\n  empleados_experimentados = .N,\n  salario_promedio = round(mean(salario), 0),\n  a√±os_exp_promedio = round(mean(a√±os_exp), 1)\n), by = departamento]\n#&gt;    departamento empleados_experimentados salario_promedio a√±os_exp_promedio\n#&gt;          &lt;char&gt;                    &lt;int&gt;            &lt;num&gt;             &lt;num&gt;\n#&gt; 1:       Ventas                        1            42000               5.0\n#&gt; 2:           IT                        3            50000               8.0\n#&gt; 3:    Marketing                        1            47000               7.0\n#&gt; 4:         RRHH                        3            48000               7.3",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#ejercicios-pr√°cticos",
    "href": "cap01-sintaxis.html#ejercicios-pr√°cticos",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.6 Ejercicios Pr√°cticos",
    "text": "2.6 Ejercicios Pr√°cticos\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 1: Dominar la Sintaxis B√°sica\n\n\n\nUsando el dataset empleados, resuelve:\n\n\nFiltrado: Empleados de ‚ÄúVentas‚Äù o ‚ÄúIT‚Äù con salario &gt; 40000\n\nAgregaci√≥n: Por cada departamento, calcula: empleados totales, salario promedio, y a√±os de experiencia m√°ximo\n\nCombinado: Encuentra empleados con m√°s a√±os de experiencia que el promedio de su departamento\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 1\n\n\n\n\n\n\n# 1. Filtrado avanzado\nempleados_filtrados &lt;- empleados[\n  departamento %in% c(\"Ventas\", \"IT\") & salario &gt; 40000\n]\nprint(empleados_filtrados)\n#&gt;       id nombre departamento salario a√±os_exp fecha_ingreso categoria_exp\n#&gt;    &lt;int&gt; &lt;char&gt;       &lt;char&gt;   &lt;num&gt;    &lt;num&gt;        &lt;Date&gt;        &lt;char&gt;\n#&gt; 1:     2   Juan       Ventas   42000        5    2019-03-10        Junior\n#&gt; 2:     4 Carlos           IT   50000        8    2015-09-20        Senior\n#&gt; 3:     5  Luc√≠a           IT   45000        6    2018-11-05        Senior\n#&gt; 4:     6  Pedro           IT   55000       10    2013-04-12        Senior\n\n# 2. Agregaci√≥n por departamento\nstats_dept &lt;- empleados[, .(\n  total_empleados = .N,\n  salario_promedio = round(mean(salario), 0),\n  a√±os_exp_maximo = max(a√±os_exp)\n), by = departamento]\nprint(stats_dept)\n#&gt;    departamento total_empleados salario_promedio a√±os_exp_maximo\n#&gt;          &lt;char&gt;           &lt;int&gt;            &lt;num&gt;           &lt;num&gt;\n#&gt; 1:       Ventas               3            38333               5\n#&gt; 2:           IT               3            50000              10\n#&gt; 3:    Marketing               3            42667               7\n#&gt; 4:         RRHH               3            48000               9\n\n# 3. Empleados por encima del promedio de experiencia en su departamento\nempleados_promedio_exp &lt;- empleados[, exp_promedio_dept := mean(a√±os_exp), by = departamento][\n  a√±os_exp &gt; exp_promedio_dept, \n  .(nombre, departamento, a√±os_exp, exp_promedio_dept)\n]\nprint(empleados_promedio_exp)\n#&gt;    nombre departamento a√±os_exp exp_promedio_dept\n#&gt;    &lt;char&gt;       &lt;char&gt;    &lt;num&gt;             &lt;num&gt;\n#&gt; 1:   Juan       Ventas        5          3.333333\n#&gt; 2:  Pedro           IT       10          8.000000\n#&gt; 3: Miguel    Marketing        7          4.666667\n#&gt; 4:  Jorge         RRHH        9          7.333333\n#&gt; 5:  Diego         RRHH        8          7.333333",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#patrones-comunes-y-mejores-pr√°cticas",
    "href": "cap01-sintaxis.html#patrones-comunes-y-mejores-pr√°cticas",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.7 Patrones Comunes y Mejores Pr√°cticas",
    "text": "2.7 Patrones Comunes y Mejores Pr√°cticas\n\n2.7.1 1. Piensa en SQL\n\nSi conoces SQL, data.table te resultar√° familiar:\n\n# SQL: SELECT departamento, AVG(salario) FROM empleados WHERE salario &gt; 40000 GROUP BY departamento\n# data.table:\nempleados[salario &gt; 40000, .(salario_promedio = mean(salario)), by = departamento]\n\n\n2.7.2 2. Usa .() para M√∫ltiples Columnas\n\n.() es tu amigo para selecciones y c√°lculos m√∫ltiples:\n\n# ‚úÖ Correcto: m√∫ltiples columnas con nombres descriptivos\nempleados[, .(\n  empleado = nombre,\n  dept = departamento,\n  sueldo = salario,\n  experiencia = a√±os_exp\n)]\n#&gt;     empleado      dept sueldo experiencia\n#&gt;       &lt;char&gt;    &lt;char&gt;  &lt;num&gt;       &lt;num&gt;\n#&gt;  1:      Ana    Ventas  35000           2\n#&gt;  2:     Juan    Ventas  42000           5\n#&gt;  3:    Mar√≠a    Ventas  38000           3\n#&gt;  4:   Carlos        IT  50000           8\n#&gt;  5:    Luc√≠a        IT  45000           6\n#&gt; ---                                      \n#&gt;  8:   Miguel Marketing  47000           7\n#&gt;  9:   Carmen Marketing  41000           3\n#&gt; 10:    Jorge      RRHH  48000           9\n#&gt; 11:    Laura      RRHH  44000           5\n#&gt; 12:    Diego      RRHH  52000           8\n\n\n2.7.3 3. Combina Operaciones de Forma Legible\n\n\n# Ejemplo complejo pero legible\nanalisis_empleados &lt;- empleados[\n  a√±os_exp &gt; 3,                     # i: filtrar por experiencia\n  .(                                # j: calcular m√©tricas\n    empleados = .N,\n    salario_promedio = round(mean(salario), 0),\n    experiencia_total = sum(a√±os_exp),\n    salario_max = max(salario)\n  ),\n  by = departamento                 # by: agrupar por departamento\n][order(-salario_promedio)]         # ordenar por salario desc\n\nprint(analisis_empleados)\n#&gt;    departamento empleados salario_promedio experiencia_total salario_max\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;             &lt;num&gt;       &lt;num&gt;\n#&gt; 1:           IT         3            50000                24       55000\n#&gt; 2:         RRHH         3            48000                22       52000\n#&gt; 3:    Marketing         2            43500                11       47000\n#&gt; 4:       Ventas         1            42000                 5       42000",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#comparaci√≥n-de-performance",
    "href": "cap01-sintaxis.html#comparaci√≥n-de-performance",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.8 Comparaci√≥n de Performance",
    "text": "2.8 Comparaci√≥n de Performance\nVeamos c√≥mo la sintaxis data.table se compara con alternativas:\n\n# Preparar datos para comparaci√≥n\nlibrary(microbenchmark)\nventas_sample &lt;- ventas[sample(.N, 10000)]  # Muestra para benchmark\n\n# Comparar diferentes aproximaciones\nbenchmark_sintaxis &lt;- microbenchmark(\n  \"data.table\" = ventas_sample[precio &gt; 100, .(avg_precio = mean(precio)), by = categoria],\n  \"base R\" = aggregate(precio ~ categoria, ventas_sample[ventas_sample$precio &gt; 100, ], mean),\n  times = 20\n)\n\nprint(benchmark_sintaxis)\n#&gt; Unit: milliseconds\n#&gt;        expr    min      lq     mean  median      uq    max neval\n#&gt;  data.table 1.2198 1.46930 1.548200 1.50395 1.67785 1.9922    20\n#&gt;      base R 2.3412 2.55975 3.170085 3.20035 3.53505 4.9892    20",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-sintaxis.html#pr√≥ximo-cap√≠tulo-s√≠mbolos-especiales",
    "href": "cap01-sintaxis.html#pr√≥ximo-cap√≠tulo-s√≠mbolos-especiales",
    "title": "\n2¬† La Sintaxis DT[i, j, by]\n",
    "section": "\n2.9 Pr√≥ximo Cap√≠tulo: S√≠mbolos Especiales",
    "text": "2.9 Pr√≥ximo Cap√≠tulo: S√≠mbolos Especiales\nEn el siguiente cap√≠tulo profundizaremos en: - .SD: El subset de datos por grupo - .SDcols: Control granular de columnas - .I y .GRP: √çndices y identificadores de grupo - Casos de uso avanzados de estos s√≠mbolos\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nDT[i, j, by] es la sintaxis universal - dom√≠nala y dominar√°s data.table\n\n\ni filtra filas - usa condiciones l√≥gicas, posiciones, u ordenamiento\n\nj selecciona/calcula - usa .() para m√∫ltiples columnas con nombres\n\nby agrupa datos - puede usar m√∫ltiples variables o expresiones\n\n.N cuenta filas - funciona en contexto general o por grupo\n\nCombina libremente - la flexibilidad es el superpoder de data.table\n\n\n\n\nCon estos fundamentos s√≥lidos de la sintaxis DT[i, j, by], est√°s listo para explorar los s√≠mbolos especiales que hacen de data.table una herramienta verdaderamente poderosa.",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>2</span>¬† <span class='chapter-title'>La Sintaxis `DT[i, j, by]`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html",
    "href": "cap01-simbolos.html",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "",
    "text": "3.1 El S√≠mbolo .SD: Subset of Data\n.SD es quiz√°s el s√≠mbolo m√°s poderoso de data.table. Contiene todas las columnas del grupo actual (excepto las variables de agrupaci√≥n) como un data.table en s√≠ mismo.",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#el-s√≠mbolo-.sd-subset-of-data",
    "href": "cap01-simbolos.html#el-s√≠mbolo-.sd-subset-of-data",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "",
    "text": "3.1.1 1. Conceptos Fundamentales de .SD\n\n\n# Veamos qu√© contiene .SD\nempleados_avanzado[, {\n  cat(\"Grupo:\", unique(departamento), \"\\n\")\n  cat(\"Columnas en .SD:\", names(.SD), \"\\n\")\n  cat(\"Filas en .SD:\", nrow(.SD), \"\\n\\n\")\n  # Devolver algo para que funcione el data.table\n  .N\n}, by = departamento]\n#&gt; Grupo: Ventas \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus a√±os_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: IT \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus a√±os_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: Marketing \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus a√±os_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: RRHH \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus a√±os_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4 \n#&gt; \n#&gt; Grupo: Finanzas \n#&gt; Columnas en .SD: id nombre nivel salario_base bonus a√±os_exp certificaciones proyectos_completados rating_performance fecha_ingreso activo salario_total experiencia_categoria productividad valor_empleado \n#&gt; Filas en .SD: 4\n#&gt;    departamento    V1\n#&gt;          &lt;char&gt; &lt;int&gt;\n#&gt; 1:       Ventas     4\n#&gt; 2:           IT     4\n#&gt; 3:    Marketing     4\n#&gt; 4:         RRHH     4\n#&gt; 5:     Finanzas     4\n\n\n# Ejemplo pr√°ctico: estad√≠sticas de salario por departamento\nstats_salarios &lt;- empleados_avanzado[, {\n  list(\n    empleados = .N,\n    salario_promedio = round(mean(.SD$salario_total), 0),\n    salario_mediana = round(median(.SD$salario_total), 0),\n    salario_max = max(.SD$salario_total),\n    salario_min = min(.SD$salario_total),\n    rango_salario = max(.SD$salario_total) - min(.SD$salario_total)\n  )\n}, by = departamento]\n\nprint(stats_salarios)\n#&gt;    departamento empleados salario_promedio salario_mediana salario_max\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;           &lt;num&gt;       &lt;num&gt;\n#&gt; 1:       Ventas         4            52175           52750       70200\n#&gt; 2:           IT         4            52200           53350       63300\n#&gt; 3:    Marketing         4            55900           57200       60200\n#&gt; 4:         RRHH         4            51550           54100       60600\n#&gt; 5:     Finanzas         4            57875           56600       71800\n#&gt;    salario_min rango_salario\n#&gt;          &lt;num&gt;         &lt;num&gt;\n#&gt; 1:       33000         37200\n#&gt; 2:       38800         24500\n#&gt; 3:       49000         11200\n#&gt; 4:       37400         23200\n#&gt; 5:       46500         25300\n\n\n3.1.2 2. Aplicar Funciones con lapply(.SD, ...)\n\nEl verdadero poder de .SD surge cuando lo combinas con lapply() para aplicar funciones a m√∫ltiples columnas:\n\n# Aplicar mean() a todas las columnas num√©ricas por departamento\nmedias_por_dept &lt;- empleados_avanzado[, \n  lapply(.SD, mean, na.rm = TRUE), \n  by = departamento,\n  .SDcols = is.numeric  # Solo columnas num√©ricas\n]\n\nprint(medias_por_dept)\n#&gt;    departamento    id salario_base bonus a√±os_exp certificaciones\n#&gt;          &lt;char&gt; &lt;num&gt;        &lt;num&gt; &lt;num&gt;    &lt;num&gt;           &lt;num&gt;\n#&gt; 1:       Ventas   2.5        47475  4700    11.75            2.75\n#&gt; 2:           IT   6.5        45625  6575    11.25            1.00\n#&gt; 3:    Marketing  10.5        49075  6825     3.00            4.75\n#&gt; 4:         RRHH  14.5        44575  6975     9.25            3.25\n#&gt; 5:     Finanzas  18.5        51050  6825     4.75            1.75\n#&gt;    proyectos_completados rating_performance salario_total productividad\n#&gt;                    &lt;num&gt;              &lt;num&gt;         &lt;num&gt;         &lt;num&gt;\n#&gt; 1:                 11.25              3.850         52175        1.1900\n#&gt; 2:                 35.00              4.150         52200        3.1975\n#&gt; 3:                 43.75              4.425         55900       24.6075\n#&gt; 4:                 32.50              4.625         51550       11.7425\n#&gt; 5:                 38.00              3.675         57875       11.3625\n#&gt;    valor_empleado\n#&gt;             &lt;num&gt;\n#&gt; 1:       2443.035\n#&gt; 2:       2415.500\n#&gt; 3:        727.840\n#&gt; 4:       2051.960\n#&gt; 5:       1157.883\n\n\n# M√∫ltiples estad√≠sticas por grupo usando funciones personalizadas\nestadisticas_avanzadas &lt;- empleados_avanzado[, \n  lapply(.SD, function(x) {\n    if(is.numeric(x)) {\n      list(\n        media = round(mean(x, na.rm = TRUE), 2),\n        mediana = round(median(x, na.rm = TRUE), 2),\n        desv_std = round(sd(x, na.rm = TRUE), 2),\n        cv = round(sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE), 3)\n      )\n    } else {\n      list(valores_unicos = length(unique(x)))\n    }\n  }),\n  by = departamento,\n  .SDcols = c(\"salario_total\", \"a√±os_exp\", \"rating_performance\")\n]\n\nprint(estadisticas_avanzadas)\n#&gt;     departamento salario_total a√±os_exp rating_performance\n#&gt;           &lt;char&gt;        &lt;list&gt;   &lt;list&gt;             &lt;list&gt;\n#&gt;  1:       Ventas         52175    11.75               3.85\n#&gt;  2:       Ventas         52750       12                3.7\n#&gt;  3:       Ventas      17803.44     2.99                0.7\n#&gt;  4:       Ventas         0.341    0.254              0.181\n#&gt;  5:           IT         52200    11.25               4.15\n#&gt; ---                                                       \n#&gt; 16:         RRHH         0.194     0.62              0.065\n#&gt; 17:     Finanzas         57875     4.75               3.67\n#&gt; 18:     Finanzas         56600      4.5               3.55\n#&gt; 19:     Finanzas      13198.07      2.5               0.45\n#&gt; 20:     Finanzas         0.228    0.526              0.122\n\n\n3.1.3 3. Transformaciones Complejas con .SD\n\n\n# Normalizar columnas dentro de cada departamento (Z-score)\nempleados_normalizados &lt;- empleados_avanzado[,\n  c(.SD[, 1:2], lapply(.SD[, -(1:2)], function(x) {\n    if(is.numeric(x) && length(unique(x)) &gt; 1) {\n      round((x - mean(x)) / sd(x), 3)\n    } else {\n      x\n    }\n  })),\n  by = departamento\n][order(departamento, id)]\n\n# Mostrar solo algunas columnas para claridad\nprint(empleados_normalizados[, .(departamento, nombre, salario_total, a√±os_exp, rating_performance)])\n#&gt;     departamento     nombre salario_total a√±os_exp rating_performance\n#&gt;           &lt;char&gt;     &lt;char&gt;         &lt;num&gt;    &lt;num&gt;              &lt;num&gt;\n#&gt;  1:     Finanzas Empleado_Q        -0.862   -0.300             -0.833\n#&gt;  2:     Finanzas Empleado_R         0.654    0.100              0.056\n#&gt;  3:     Finanzas Empleado_S         1.055    1.300              1.389\n#&gt;  4:     Finanzas Empleado_T        -0.847   -1.100             -0.611\n#&gt;  5:           IT Empleado_E         0.742   -1.306             -0.691\n#&gt; ---                                                                  \n#&gt; 16:         RRHH Empleado_P        -1.416    0.479             -1.088\n#&gt; 17:       Ventas Empleado_A         1.012   -1.256              0.072\n#&gt; 18:       Ventas Empleado_B        -0.605   -0.251             -0.503\n#&gt; 19:       Ventas Empleado_C        -1.077    0.419             -0.935\n#&gt; 20:       Ventas Empleado_D         0.670    1.088              1.366",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#control-de-columnas-con-.sdcols",
    "href": "cap01-simbolos.html#control-de-columnas-con-.sdcols",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "\n3.2 Control de Columnas con .SDcols\n",
    "text": "3.2 Control de Columnas con .SDcols\n\n.SDcols te permite especificar exactamente qu√© columnas debe incluir .SD.\n\n3.2.1 1. Formas de Especificar .SDcols\n\n\n# Por nombres de columna\npor_nombres &lt;- empleados_avanzado[,\n  lapply(.SD, mean),\n  by = departamento,\n  .SDcols = c(\"salario_total\", \"a√±os_exp\", \"rating_performance\")\n]\n\n# Por patrones\npor_patrones &lt;- empleados_avanzado[,\n  lapply(.SD, max),\n  by = departamento,\n  .SDcols = patterns(\"salario|rating\")\n]\n\n# Por tipo de datos\npor_tipo &lt;- empleados_avanzado[,\n  lapply(.SD, function(x) length(unique(x))),\n  by = departamento,\n  .SDcols = is.character\n]\n\nprint(\"Por nombres:\")\n#&gt; [1] \"Por nombres:\"\nprint(por_nombres)\n#&gt;    departamento salario_total a√±os_exp rating_performance\n#&gt;          &lt;char&gt;         &lt;num&gt;    &lt;num&gt;              &lt;num&gt;\n#&gt; 1:       Ventas         52175    11.75              3.850\n#&gt; 2:           IT         52200    11.25              4.150\n#&gt; 3:    Marketing         55900     3.00              4.425\n#&gt; 4:         RRHH         51550     9.25              4.625\n#&gt; 5:     Finanzas         57875     4.75              3.675\nprint(\"\\nPor patrones:\")\n#&gt; [1] \"\\nPor patrones:\"\nprint(por_patrones)\n#&gt;    departamento salario_base rating_performance salario_total\n#&gt;          &lt;char&gt;        &lt;num&gt;              &lt;num&gt;         &lt;num&gt;\n#&gt; 1:       Ventas        65000                4.8         70200\n#&gt; 2:           IT        58600                4.8         63300\n#&gt; 3:    Marketing        55400                5.0         60200\n#&gt; 4:         RRHH        53300                5.0         60600\n#&gt; 5:     Finanzas        68500                4.3         71800\nprint(\"\\nPor tipo (character):\")\n#&gt; [1] \"\\nPor tipo (character):\"\nprint(por_tipo)\n#&gt;    departamento nombre departamento nivel\n#&gt;          &lt;char&gt;  &lt;int&gt;        &lt;int&gt; &lt;int&gt;\n#&gt; 1:       Ventas      4            1     4\n#&gt; 2:           IT      4            1     4\n#&gt; 3:    Marketing      4            1     4\n#&gt; 4:         RRHH      4            1     4\n#&gt; 5:     Finanzas      4            1     4\n\n\n3.2.2 2. Casos de Uso Avanzados de .SDcols\n\n\n# An√°lisis de correlaciones por departamento\ncorrelaciones_dept &lt;- empleados_avanzado[activo == TRUE,  # Solo empleados activos\n{\n  # Seleccionar solo columnas num√©ricas con variabilidad\n  cols_numericas &lt;- sapply(.SD, function(x) is.numeric(x) && var(x, na.rm = TRUE) &gt; 0)\n  nombres_cols_validas &lt;- names(cols_numericas)[cols_numericas]\n  \n  if(length(nombres_cols_validas) &gt;= 2) {\n    cor_matrix &lt;- cor(.SD[, nombres_cols_validas, with = FALSE])\n    # Extraer correlaci√≥n espec√≠fica: salario vs rating (si ambas existen)\n    if(\"salario_total\" %in% nombres_cols_validas && \"rating_performance\" %in% nombres_cols_validas) {\n      correlacion_sal_rating &lt;- round(cor_matrix[\"salario_total\", \"rating_performance\"], 3)\n    } else {\n      correlacion_sal_rating &lt;- NA\n    }\n    list(\n      correlacion_salario_rating = correlacion_sal_rating,\n      num_variables = length(nombres_cols_validas)\n    )\n  } else {\n    list(correlacion_salario_rating = NA, num_variables = length(nombres_cols_validas))\n  }\n},\nby = departamento,\n.SDcols = is.numeric\n]\n\nprint(correlaciones_dept)\n#&gt;    departamento correlacion_salario_rating num_variables\n#&gt;          &lt;char&gt;                      &lt;num&gt;         &lt;int&gt;\n#&gt; 1:       Ventas                      0.586            10\n#&gt; 2:           IT                     -0.399            10\n#&gt; 3:    Marketing                      0.033            10\n#&gt; 4:         RRHH                      0.845            10\n#&gt; 5:     Finanzas                      0.912            10\n\n\n# Selecci√≥n din√°mica de columnas basada en criterios\ncolumnas_con_variacion &lt;- empleados_avanzado[, \n  sapply(.SD, function(x) if(is.numeric(x)) var(x, na.rm = TRUE) &gt; 1000 else FALSE),\n  .SDcols = is.numeric\n]\n\nprint(\"Columnas con alta variaci√≥n:\")\n#&gt; [1] \"Columnas con alta variaci√≥n:\"\nprint(names(columnas_con_variacion)[columnas_con_variacion])\n#&gt; [1] \"salario_base\"   \"bonus\"          \"salario_total\"  \"valor_empleado\"\n\n# Usar esas columnas para an√°lisis\nanalisis_alta_variacion &lt;- empleados_avanzado[,\n  lapply(.SD, function(x) c(min = min(x), max = max(x), rango = max(x) - min(x))),\n  .SDcols = names(columnas_con_variacion)[columnas_con_variacion]\n]\n\nprint(analisis_alta_variacion)\n#&gt;    salario_base bonus salario_total valor_empleado\n#&gt;           &lt;num&gt; &lt;num&gt;         &lt;num&gt;          &lt;num&gt;\n#&gt; 1:        30600  2400         33000          301.0\n#&gt; 2:        68500 12300         71800         4615.2\n#&gt; 3:        37900  9900         38800         4314.2",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#el-s√≠mbolo-.i-√≠ndices-de-fila",
    "href": "cap01-simbolos.html#el-s√≠mbolo-.i-√≠ndices-de-fila",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "\n3.3 El S√≠mbolo .I: √çndices de Fila",
    "text": "3.3 El S√≠mbolo .I: √çndices de Fila\n.I contiene los √≠ndices (n√∫meros de fila) de las observaciones del grupo actual en el data.table original.\n\n3.3.1 1. Usos B√°sicos de .I\n\n\n# Encontrar el √≠ndice del empleado con mayor salario por departamento\nindices_top_salario &lt;- empleados_avanzado[,\n  .I[which.max(salario_total)],\n  by = departamento\n]\n\nprint(\"√çndices de empleados con mayor salario:\")\n#&gt; [1] \"√çndices de empleados con mayor salario:\"\nprint(indices_top_salario)\n#&gt;    departamento    V1\n#&gt;          &lt;char&gt; &lt;int&gt;\n#&gt; 1:       Ventas     1\n#&gt; 2:           IT     7\n#&gt; 3:    Marketing     9\n#&gt; 4:         RRHH    14\n#&gt; 5:     Finanzas    19\n\n# Usar esos √≠ndices para extraer las filas completas\ntop_empleados_por_dept &lt;- empleados_avanzado[indices_top_salario$V1]\nprint(\"\\nEmpleados con mayor salario por departamento:\")\n#&gt; [1] \"\\nEmpleados con mayor salario por departamento:\"\nprint(top_empleados_por_dept[, .(departamento, nombre, salario_total)])\n#&gt;    departamento     nombre salario_total\n#&gt;          &lt;char&gt;     &lt;char&gt;         &lt;num&gt;\n#&gt; 1:       Ventas Empleado_A         70200\n#&gt; 2:           IT Empleado_G         63300\n#&gt; 3:    Marketing Empleado_I         60200\n#&gt; 4:         RRHH Empleado_N         60600\n#&gt; 5:     Finanzas Empleado_S         71800\n\n\n3.3.2 2. Casos de Uso Avanzados con .I\n\n\n# Top N empleados por departamento\ntop_2_por_dept &lt;- empleados_avanzado[,\n  .I[order(-salario_total)][1:min(2, .N)],  # Top 2 o todos si hay menos de 2\n  by = departamento\n]\n\nempleados_top2 &lt;- empleados_avanzado[top_2_por_dept$V1]\nprint(\"Top 2 empleados por departamento:\")\n#&gt; [1] \"Top 2 empleados por departamento:\"\nprint(empleados_top2[, .(departamento, nombre, salario_total)][order(departamento, -salario_total)])\n#&gt;     departamento     nombre salario_total\n#&gt;           &lt;char&gt;     &lt;char&gt;         &lt;num&gt;\n#&gt;  1:     Finanzas Empleado_S         71800\n#&gt;  2:     Finanzas Empleado_R         66500\n#&gt;  3:           IT Empleado_G         63300\n#&gt;  4:           IT Empleado_E         61000\n#&gt;  5:    Marketing Empleado_I         60200\n#&gt;  6:    Marketing Empleado_L         59600\n#&gt;  7:         RRHH Empleado_N         60600\n#&gt;  8:         RRHH Empleado_O         55600\n#&gt;  9:       Ventas Empleado_A         70200\n#&gt; 10:       Ventas Empleado_D         64100\n\n\n# Muestreo estratificado usando .I\nset.seed(123)\nmuestra_estratificada &lt;- empleados_avanzado[,\n  .I[sample(.N, size = min(2, .N))],  # 2 empleados por departamento\n  by = departamento\n]\n\nempleados_muestra &lt;- empleados_avanzado[muestra_estratificada$V1]\nprint(\"Muestra estratificada:\")\n#&gt; [1] \"Muestra estratificada:\"\nprint(empleados_muestra[, .(departamento, nombre, a√±os_exp)])\n#&gt;     departamento     nombre a√±os_exp\n#&gt;           &lt;char&gt;     &lt;char&gt;    &lt;int&gt;\n#&gt;  1:       Ventas Empleado_C       13\n#&gt;  2:       Ventas Empleado_D       15\n#&gt;  3:           IT Empleado_G       12\n#&gt;  4:           IT Empleado_F       11\n#&gt;  5:    Marketing Empleado_K        2\n#&gt;  6:    Marketing Empleado_J        7\n#&gt;  7:         RRHH Empleado_N        1\n#&gt;  8:         RRHH Empleado_P       12\n#&gt;  9:     Finanzas Empleado_S        8\n#&gt; 10:     Finanzas Empleado_Q        4",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#el-s√≠mbolo-.grp-identificador-de-grupo",
    "href": "cap01-simbolos.html#el-s√≠mbolo-.grp-identificador-de-grupo",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "\n3.4 El S√≠mbolo .GRP: Identificador de Grupo",
    "text": "3.4 El S√≠mbolo .GRP: Identificador de Grupo\n.GRP es un contador que asigna un n√∫mero √∫nico e incremental a cada grupo.\n\n3.4.1 1. Usos de .GRP\n\n\n# Asignar ID √∫nico a cada departamento\nempleados_con_grupo &lt;- empleados_avanzado[,\n  .(nombre, departamento, grupo_id = .GRP, empleados_en_grupo = .N),\n  by = departamento\n]\n\nprint(empleados_con_grupo)\n#&gt;     departamento     nombre departamento grupo_id empleados_en_grupo\n#&gt;           &lt;char&gt;     &lt;char&gt;       &lt;char&gt;    &lt;int&gt;              &lt;int&gt;\n#&gt;  1:       Ventas Empleado_A       Ventas        1                  4\n#&gt;  2:       Ventas Empleado_B       Ventas        1                  4\n#&gt;  3:       Ventas Empleado_C       Ventas        1                  4\n#&gt;  4:       Ventas Empleado_D       Ventas        1                  4\n#&gt;  5:           IT Empleado_E           IT        2                  4\n#&gt;  6:           IT Empleado_F           IT        2                  4\n#&gt;  7:           IT Empleado_G           IT        2                  4\n#&gt;  8:           IT Empleado_H           IT        2                  4\n#&gt;  9:    Marketing Empleado_I    Marketing        3                  4\n#&gt; 10:    Marketing Empleado_J    Marketing        3                  4\n#&gt; 11:    Marketing Empleado_K    Marketing        3                  4\n#&gt; 12:    Marketing Empleado_L    Marketing        3                  4\n#&gt; 13:         RRHH Empleado_M         RRHH        4                  4\n#&gt; 14:         RRHH Empleado_N         RRHH        4                  4\n#&gt; 15:         RRHH Empleado_O         RRHH        4                  4\n#&gt; 16:         RRHH Empleado_P         RRHH        4                  4\n#&gt; 17:     Finanzas Empleado_Q     Finanzas        5                  4\n#&gt; 18:     Finanzas Empleado_R     Finanzas        5                  4\n#&gt; 19:     Finanzas Empleado_S     Finanzas        5                  4\n#&gt; 20:     Finanzas Empleado_T     Finanzas        5                  4\n#&gt;     departamento     nombre departamento grupo_id empleados_en_grupo\n\n\n# An√°lisis de transacciones por grupo de cliente\nanalisis_grupos &lt;- transacciones[,\n  .(\n    grupo_cliente = .GRP,\n    num_transacciones = .N,\n    monto_promedio = round(mean(monto_final), 2),\n    primera_compra = min(fecha),\n    ultima_compra = max(fecha)\n  ),\n  by = tipo_cliente\n]\n\nprint(analisis_grupos)\n#&gt;    tipo_cliente grupo_cliente num_transacciones monto_promedio primera_compra\n#&gt;          &lt;char&gt;         &lt;int&gt;             &lt;int&gt;          &lt;num&gt;         &lt;Date&gt;\n#&gt; 1:        Basic             1               502         223.58     2023-01-01\n#&gt; 2:      Regular             2               297         207.99     2023-01-02\n#&gt; 3:      Premium             3               201         219.04     2023-01-02\n#&gt;    ultima_compra\n#&gt;           &lt;Date&gt;\n#&gt; 1:    2023-12-31\n#&gt; 2:    2023-12-31\n#&gt; 3:    2023-12-30",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#combinando-s√≠mbolos-casos-de-uso-profesionales",
    "href": "cap01-simbolos.html#combinando-s√≠mbolos-casos-de-uso-profesionales",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "\n3.5 Combinando S√≠mbolos: Casos de Uso Profesionales",
    "text": "3.5 Combinando S√≠mbolos: Casos de Uso Profesionales\n\n3.5.1 1. An√°lisis de Cohortes\n\n\n# An√°lisis de cohortes de empleados por a√±o de ingreso\nlibrary(lubridate)\n\nanalisis_cohortes &lt;- empleados_avanzado[,\n  .(\n    cohorte_id = .GRP,\n    a√±o_ingreso = year(min(fecha_ingreso)),\n    empleados_iniciales = .N,\n    salario_inicial_promedio = round(mean(salario_base), 0),\n    retencion_actual = round(mean(activo) * 100, 1),\n    performance_promedio = round(mean(rating_performance), 2),\n    # Usando .SD para m√©tricas adicionales\n    experiencia_rango = paste0(min(.SD$a√±os_exp), \"-\", max(.SD$a√±os_exp), \" a√±os\")\n  ),\n  by = .(a√±o_cohorte = year(fecha_ingreso)),\n  .SDcols = \"a√±os_exp\"\n][order(a√±o_cohorte)]\n\nprint(analisis_cohortes)\n#&gt;    a√±o_cohorte cohorte_id a√±o_ingreso empleados_iniciales\n#&gt;          &lt;num&gt;      &lt;int&gt;       &lt;num&gt;               &lt;int&gt;\n#&gt; 1:        2015          1        2015                   1\n#&gt; 2:        2016          7        2016                   4\n#&gt; 3:        2017          8        2017                   2\n#&gt; 4:        2018          3        2018                   3\n#&gt; 5:        2019          6        2019                   1\n#&gt; 6:        2021          2        2021                   3\n#&gt; 7:        2022          5        2022                   3\n#&gt; 8:        2023          4        2023                   3\n#&gt;    salario_inicial_promedio retencion_actual performance_promedio\n#&gt;                       &lt;num&gt;            &lt;num&gt;                &lt;num&gt;\n#&gt; 1:                    65000            100.0                 3.90\n#&gt; 2:                    50875            100.0                 4.30\n#&gt; 3:                    50550            100.0                 4.10\n#&gt; 4:                    36267             66.7                 4.00\n#&gt; 5:                    58600            100.0                 4.30\n#&gt; 6:                    43533            100.0                 4.40\n#&gt; 7:                    51567            100.0                 3.60\n#&gt; 8:                    42967            100.0                 4.43\n#&gt;    experiencia_rango\n#&gt;               &lt;char&gt;\n#&gt; 1:          8-8 a√±os\n#&gt; 2:         1-14 a√±os\n#&gt; 3:          2-2 a√±os\n#&gt; 4:         7-13 a√±os\n#&gt; 5:        12-12 a√±os\n#&gt; 6:         1-11 a√±os\n#&gt; 7:         4-10 a√±os\n#&gt; 8:        11-15 a√±os\n\n\n3.5.2 2. Detecci√≥n de Outliers por Grupo\n\n\n# Detectar outliers en salario dentro de cada departamento\noutliers_salario &lt;- empleados_avanzado[,\n{\n  Q1 &lt;- quantile(salario_total, 0.25)\n  Q3 &lt;- quantile(salario_total, 0.75)\n  IQR &lt;- Q3 - Q1\n  limite_inferior &lt;- Q1 - 1.5 * IQR\n  limite_superior &lt;- Q3 + 1.5 * IQR\n  \n  outliers_indices &lt;- .I[salario_total &lt; limite_inferior | salario_total &gt; limite_superior]\n  \n  list(\n    departamento = unique(departamento),\n    num_outliers = length(outliers_indices),\n    outliers_ids = if(length(outliers_indices) &gt; 0) list(outliers_indices) else list(integer(0)),\n    limite_inf = round(limite_inferior, 0),\n    limite_sup = round(limite_superior, 0)\n  )\n},\nby = departamento\n]\n\nprint(outliers_salario)\n#&gt;    departamento departamento num_outliers outliers_ids limite_inf limite_sup\n#&gt;          &lt;char&gt;       &lt;char&gt;        &lt;int&gt;       &lt;list&gt;      &lt;num&gt;      &lt;num&gt;\n#&gt; 1:       Ventas       Ventas            0                    -188     105112\n#&gt; 2:           IT           IT            0                   17575      87975\n#&gt; 3:    Marketing    Marketing            0                   43750      69350\n#&gt; 4:         RRHH         RRHH            0                   36725      68925\n#&gt; 5:     Finanzas     Finanzas            0                   14888      99588\n\n# Extraer los outliers reales\noutliers_reales &lt;- unique(unlist(outliers_salario$outliers_ids))\nif(length(outliers_reales) &gt; 0) {\n  empleados_outliers &lt;- empleados_avanzado[outliers_reales]\n  print(\"\\nEmpleados con salarios outliers:\")\n  print(empleados_outliers[, .(nombre, departamento, salario_total)])\n}\n\n\n3.5.3 3. Ventana M√≥vil con .SD\n\n\n# An√°lisis de ventana m√≥vil en transacciones\n# Primero ordenamos por fecha\ntransacciones_ordenadas &lt;- transacciones[order(fecha)]\n\n# Crear grupos por mes para simular ventana temporal\nventana_movil &lt;- transacciones_ordenadas[,\n{\n  # Para cada mes, calcular m√©tricas usando .SD\n  current_data &lt;- .SD\n  list(\n    mes = unique(mes),\n    transacciones_mes = .N,\n    monto_total = sum(monto_final),\n    ticket_promedio = round(mean(monto_final), 2),\n    # Diversidad de productos\n    productos_unicos = uniqueN(producto_id),\n    # An√°lisis de canales usando .SD\n    canal_dominante = names(sort(table(.SD$canal), decreasing = TRUE))[1],\n    concentracion_clientes = round(1 - (uniqueN(cliente_id) / .N), 3)  # √çndice de concentraci√≥n\n  )\n},\nby = .(a√±o = year(fecha), mes),\n.SDcols = c(\"monto_final\", \"producto_id\", \"canal\", \"cliente_id\")\n][order(a√±o, mes)]\n\nprint(ventana_movil)\n#&gt;       a√±o   mes   mes transacciones_mes monto_total ticket_promedio\n#&gt;     &lt;num&gt; &lt;int&gt; &lt;int&gt;             &lt;int&gt;       &lt;num&gt;           &lt;num&gt;\n#&gt;  1:  2023     1     1                86    17489.98          203.37\n#&gt;  2:  2023     2     2                86    18022.41          209.56\n#&gt;  3:  2023     3     3                73    14743.75          201.97\n#&gt;  4:  2023     4     4                87    18146.44          208.58\n#&gt;  5:  2023     5     5                86    17393.11          202.25\n#&gt;  6:  2023     6     6                82    19097.84          232.90\n#&gt;  7:  2023     7     7                79    17723.32          224.35\n#&gt;  8:  2023     8     8                87    18408.98          211.60\n#&gt;  9:  2023     9     9                72    17707.42          245.94\n#&gt; 10:  2023    10    10                88    19787.56          224.86\n#&gt; 11:  2023    11    11                84    18717.37          222.83\n#&gt; 12:  2023    12    12                90    20800.00          231.11\n#&gt;     productos_unicos canal_dominante concentracion_clientes\n#&gt;                &lt;int&gt;          &lt;char&gt;                  &lt;num&gt;\n#&gt;  1:               10          Online                  0.337\n#&gt;  2:               10          Online                  0.326\n#&gt;  3:               10          Online                  0.315\n#&gt;  4:               10          Online                  0.253\n#&gt;  5:               10          Online                  0.395\n#&gt;  6:               10          Online                  0.293\n#&gt;  7:               10          Online                  0.342\n#&gt;  8:               10          Online                  0.322\n#&gt;  9:               10          Online                  0.375\n#&gt; 10:               10          Online                  0.273\n#&gt; 11:               10          Online                  0.274\n#&gt; 12:               10          Online                  0.267",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#ejercicios-pr√°cticos",
    "href": "cap01-simbolos.html#ejercicios-pr√°cticos",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "\n3.6 Ejercicios Pr√°cticos",
    "text": "3.6 Ejercicios Pr√°cticos\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 5: An√°lisis Multidimensional con S√≠mbolos Especiales\n\n\n\nUsando el dataset transacciones, crea un an√°lisis que utilice todos los s√≠mbolos especiales:\n\n\nCon .SD: Calcula estad√≠sticas de monto por categor√≠a y canal\n\nCon .SDcols: Analiza solo columnas que contengan ‚Äúmonto‚Äù o ‚Äúdescuento‚Äù\n\nCon .I: Encuentra las 3 mejores transacciones por categor√≠a\n\nCon .GRP: Asigna IDs √∫nicos a combinaciones categor√≠a-canal\n\nAn√°lisis combinado: Crea un reporte complejo que use m√∫ltiples s√≠mbolos\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 5\n\n\n\n\n\n\n# 1. Estad√≠sticas con .SD por categor√≠a y canal\nestadisticas_SD &lt;- transacciones[,\n  lapply(.SD, function(x) {\n    if(is.numeric(x)) {\n      list(\n        promedio = round(mean(x, na.rm = TRUE), 2),\n        mediana = round(median(x, na.rm = TRUE), 2),\n        desv_std = round(sd(x, na.rm = TRUE), 2)\n      )\n    } else {\n      list(valores_unicos = length(unique(x)))\n    }\n  }),\n  by = .(categoria, canal),\n  .SDcols = c(\"monto\", \"monto_final\", \"descuento\")\n]\n\nprint(\"1. Estad√≠sticas por categor√≠a y canal:\")\n#&gt; [1] \"1. Estad√≠sticas por categor√≠a y canal:\"\nprint(head(estadisticas_SD, 8))\n#&gt;      categoria  canal  monto monto_final descuento\n#&gt;         &lt;char&gt; &lt;char&gt; &lt;list&gt;      &lt;list&gt;    &lt;list&gt;\n#&gt; 1:      Sports Online 262.85      224.49      0.15\n#&gt; 2:      Sports Online 251.83      219.81      0.15\n#&gt; 3:      Sports Online    133      116.98      0.09\n#&gt; 4: Electronics Mobile  236.1      198.43      0.15\n#&gt; 5: Electronics Mobile 191.67      152.54      0.14\n#&gt; 6: Electronics Mobile 157.27      130.66      0.09\n#&gt; 7:       Books Mobile 248.05      210.83      0.16\n#&gt; 8:       Books Mobile 244.29       208.4      0.17\n\n# 2. An√°lisis con .SDcols espec√≠ficas\nanalisis_montos &lt;- transacciones[,\n  lapply(.SD, function(x) c(\n    min = min(x),\n    max = max(x),\n    rango = max(x) - min(x),\n    coef_var = sd(x) / mean(x)\n  )),\n  by = categoria,\n  .SDcols = patterns(\"monto|descuento\")\n]\n\nprint(\"\\n2. An√°lisis de montos y descuentos:\")\n#&gt; [1] \"\\n2. An√°lisis de montos y descuentos:\"\nprint(analisis_montos)\n#&gt;       categoria       monto descuento monto_final\n#&gt;          &lt;char&gt;       &lt;num&gt;     &lt;num&gt;       &lt;num&gt;\n#&gt;  1:      Sports  13.6900000 0.0000000  11.4996000\n#&gt;  2:      Sports 498.1800000 0.3000000 465.4980000\n#&gt;  3:      Sports 484.4900000 0.3000000 453.9984000\n#&gt;  4:      Sports   0.5180114 0.5658237   0.5377436\n#&gt;  5: Electronics  12.2600000 0.0000000  10.4796000\n#&gt;  6: Electronics 498.4300000 0.3000000 481.5900000\n#&gt;  7: Electronics 486.1700000 0.3000000 471.1104000\n#&gt;  8: Electronics   0.5828812 0.5806229   0.5883679\n#&gt;  9:       Books  10.7900000 0.0000000   8.7010000\n#&gt; 10:       Books 499.6700000 0.3000000 480.2000000\n#&gt; 11:       Books 488.8800000 0.3000000 471.4990000\n#&gt; 12:       Books   0.5671143 0.6141504   0.5912270\n#&gt; 13:    Clothing  10.1700000 0.0000000   9.2547000\n#&gt; 14:    Clothing 497.7800000 0.3000000 489.6243000\n#&gt; 15:    Clothing 487.6100000 0.3000000 480.3696000\n#&gt; 16:    Clothing   0.5622603 0.5388315   0.5733788\n\n# 3. Top 3 transacciones por categor√≠a usando .I\nindices_top3 &lt;- transacciones[,\n  .I[order(-monto_final)][1:min(3, .N)],\n  by = categoria\n]\n\ntop3_transacciones &lt;- transacciones[indices_top3$V1]\nprint(\"\\n3. Top 3 transacciones por categor√≠a:\")\n#&gt; [1] \"\\n3. Top 3 transacciones por categor√≠a:\"\nprint(top3_transacciones[, .(categoria, transaction_id, monto_final, producto_id)][order(categoria, -monto_final)])\n#&gt;       categoria transaction_id monto_final producto_id\n#&gt;          &lt;char&gt;          &lt;int&gt;       &lt;num&gt;      &lt;char&gt;\n#&gt;  1:       Books            235    480.2000           D\n#&gt;  2:       Books            826    479.8431           C\n#&gt;  3:       Books            545    475.1424           F\n#&gt;  4:    Clothing            304    489.6243           E\n#&gt;  5:    Clothing            718    486.0300           I\n#&gt;  6:    Clothing            917    473.1660           B\n#&gt;  7: Electronics            788    481.5900           J\n#&gt;  8: Electronics            225    477.9190           E\n#&gt;  9: Electronics            636    476.8132           C\n#&gt; 10:      Sports            148    465.4980           E\n#&gt; 11:      Sports            776    465.4642           H\n#&gt; 12:      Sports             73    462.3894           C\n\n# 4. IDs √∫nicos con .GRP\ngrupos_categoria_canal &lt;- transacciones[,\n  .(\n    grupo_id = .GRP,\n    transacciones = .N,\n    monto_promedio = round(mean(monto_final), 2)\n  ),\n  by = .(categoria, canal)\n][order(grupo_id)]\n\nprint(\"\\n4. IDs de grupos categor√≠a-canal:\")\n#&gt; [1] \"\\n4. IDs de grupos categor√≠a-canal:\"\nprint(grupos_categoria_canal)\n#&gt;       categoria  canal grupo_id transacciones monto_promedio\n#&gt;          &lt;char&gt; &lt;char&gt;    &lt;int&gt;         &lt;int&gt;          &lt;num&gt;\n#&gt;  1:      Sports Online        1           125         224.49\n#&gt;  2: Electronics Mobile        2            49         198.43\n#&gt;  3:       Books Mobile        3            47         210.83\n#&gt;  4: Electronics Online        4           125         228.96\n#&gt;  5: Electronics  Store        5            77         196.52\n#&gt;  6:    Clothing Online        6           121         215.08\n#&gt;  7:       Books  Store        7            77         223.28\n#&gt;  8:       Books Online        8           129         222.99\n#&gt;  9:    Clothing  Store        9            85         200.10\n#&gt; 10:      Sports Mobile       10            48         237.55\n#&gt; 11:      Sports  Store       11            76         222.88\n#&gt; 12:    Clothing Mobile       12            41         225.89\n\n# 5. An√°lisis combinado ultra-avanzado\nanalisis_completo &lt;- transacciones[,\n{\n  # Usar todos los s√≠mbolos en un an√°lisis complejo\n  grupo_id &lt;- .GRP\n  num_trans &lt;- .N\n  \n  # Estad√≠sticas b√°sicas con .SD\n  stats_basicas &lt;- lapply(.SD[, .(monto_final, descuento)], function(x) {\n    c(media = mean(x), mediana = median(x))\n  })\n  \n  # Top performer con .I\n  top_transaction_idx &lt;- .I[which.max(monto_final)]\n  \n  # An√°lisis de clientes\n  clientes_unicos &lt;- uniqueN(cliente_id)\n  cliente_top &lt;- cliente_id[which.max(monto_final)]\n  \n  list(\n    grupo_id = grupo_id,\n    categoria = unique(categoria),\n    canal = unique(canal),\n    num_transacciones = num_trans,\n    monto_promedio = round(stats_basicas$monto_final[\"media\"], 2),\n    monto_mediana = round(stats_basicas$monto_final[\"mediana\"], 2),\n    descuento_promedio = round(stats_basicas$descuento[\"media\"], 3),\n    clientes_unicos = clientes_unicos,\n    concentracion = round(1 - (clientes_unicos / num_trans), 3),\n    top_transaction_id = transacciones[top_transaction_idx, transaction_id],\n    top_cliente_id = cliente_top,\n    diversidad_productos = uniqueN(producto_id)\n  )\n},\nby = .(categoria, canal),\n.SDcols = c(\"monto_final\", \"descuento\", \"cliente_id\", \"producto_id\")\n][order(-monto_promedio)]\n\nprint(\"\\n5. An√°lisis completo combinando todos los s√≠mbolos:\")\n#&gt; [1] \"\\n5. An√°lisis completo combinando todos los s√≠mbolos:\"\nprint(analisis_completo)\n#&gt;       categoria  canal grupo_id   categoria  canal num_transacciones\n#&gt;          &lt;char&gt; &lt;char&gt;    &lt;int&gt;      &lt;char&gt; &lt;char&gt;             &lt;int&gt;\n#&gt;  1:      Sports Mobile       10      Sports Mobile                48\n#&gt;  2: Electronics Online        4 Electronics Online               125\n#&gt;  3:    Clothing Mobile       12    Clothing Mobile                41\n#&gt;  4:      Sports Online        1      Sports Online               125\n#&gt;  5:       Books  Store        7       Books  Store                77\n#&gt;  6:       Books Online        8       Books Online               129\n#&gt;  7:      Sports  Store       11      Sports  Store                76\n#&gt;  8:    Clothing Online        6    Clothing Online               121\n#&gt;  9:       Books Mobile        3       Books Mobile                47\n#&gt; 10:    Clothing  Store        9    Clothing  Store                85\n#&gt; 11: Electronics Mobile        2 Electronics Mobile                49\n#&gt; 12: Electronics  Store        5 Electronics  Store                77\n#&gt;     monto_promedio monto_mediana descuento_promedio clientes_unicos\n#&gt;              &lt;num&gt;         &lt;num&gt;              &lt;num&gt;           &lt;int&gt;\n#&gt;  1:         237.55        272.55              0.166              39\n#&gt;  2:         228.96        235.17              0.155              77\n#&gt;  3:         225.89        244.68              0.149              34\n#&gt;  4:         224.49        219.81              0.150              76\n#&gt;  5:         223.28        214.69              0.133              54\n#&gt;  6:         222.99        205.71              0.142              69\n#&gt;  7:         222.88        227.40              0.158              52\n#&gt;  8:         215.08        216.92              0.160              66\n#&gt;  9:         210.83        208.40              0.164              35\n#&gt; 10:         200.10        176.29              0.155              57\n#&gt; 11:         198.43        152.54              0.153              33\n#&gt; 12:         196.52        185.82              0.139              58\n#&gt;     concentracion top_transaction_id top_cliente_id diversidad_productos\n#&gt;             &lt;num&gt;              &lt;int&gt;          &lt;int&gt;                &lt;int&gt;\n#&gt;  1:         0.188                776             88                   10\n#&gt;  2:         0.384                 74             74                   10\n#&gt;  3:         0.171                780             76                   10\n#&gt;  4:         0.392                148             53                   10\n#&gt;  5:         0.299                242             57                   10\n#&gt;  6:         0.465                235             99                   10\n#&gt;  7:         0.316                 73             54                   10\n#&gt;  8:         0.455                304             41                   10\n#&gt;  9:         0.255                545             88                   10\n#&gt; 10:         0.329                718             50                   10\n#&gt; 11:         0.327                636             98                   10\n#&gt; 12:         0.247                788             52                   10\n\n# Mostrar tabla final formateada para PDF\nknitr::kable(\n  analisis_completo,\n  caption = \"An√°lisis Completo por Categor√≠a y Canal\",\n  digits = 2,\n  format.args = list(big.mark = \",\")\n)\n\n\nAn√°lisis Completo por Categor√≠a y Canal\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncategoria\ncanal\ngrupo_id\ncategoria\ncanal\nnum_transacciones\nmonto_promedio\nmonto_mediana\ndescuento_promedio\nclientes_unicos\nconcentracion\ntop_transaction_id\ntop_cliente_id\ndiversidad_productos\n\n\n\nSports\nMobile\n10\nSports\nMobile\n48\n237.55\n272.55\n0.17\n39\n0.19\n776\n88\n10\n\n\nElectronics\nOnline\n4\nElectronics\nOnline\n125\n228.96\n235.17\n0.16\n77\n0.38\n74\n74\n10\n\n\nClothing\nMobile\n12\nClothing\nMobile\n41\n225.89\n244.68\n0.15\n34\n0.17\n780\n76\n10\n\n\nSports\nOnline\n1\nSports\nOnline\n125\n224.49\n219.81\n0.15\n76\n0.39\n148\n53\n10\n\n\nBooks\nStore\n7\nBooks\nStore\n77\n223.28\n214.69\n0.13\n54\n0.30\n242\n57\n10\n\n\nBooks\nOnline\n8\nBooks\nOnline\n129\n222.99\n205.71\n0.14\n69\n0.47\n235\n99\n10\n\n\nSports\nStore\n11\nSports\nStore\n76\n222.88\n227.40\n0.16\n52\n0.32\n73\n54\n10\n\n\nClothing\nOnline\n6\nClothing\nOnline\n121\n215.08\n216.92\n0.16\n66\n0.46\n304\n41\n10\n\n\nBooks\nMobile\n3\nBooks\nMobile\n47\n210.83\n208.40\n0.16\n35\n0.26\n545\n88\n10\n\n\nClothing\nStore\n9\nClothing\nStore\n85\n200.10\n176.29\n0.16\n57\n0.33\n718\n50\n10\n\n\nElectronics\nMobile\n2\nElectronics\nMobile\n49\n198.43\n152.54\n0.15\n33\n0.33\n636\n98\n10\n\n\nElectronics\nStore\n5\nElectronics\nStore\n77\n196.52\n185.82\n0.14\n58\n0.25\n788\n52\n10",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap01-simbolos.html#patrones-avanzados-y-mejores-pr√°cticas",
    "href": "cap01-simbolos.html#patrones-avanzados-y-mejores-pr√°cticas",
    "title": "\n3¬† S√≠mbolos Especiales en data.table\n",
    "section": "\n3.7 Patrones Avanzados y Mejores Pr√°cticas",
    "text": "3.7 Patrones Avanzados y Mejores Pr√°cticas\n\n3.7.1 1. Funciones Personalizadas con .SD\n\n\n# Crear funci√≥n personalizada para an√°lisis estad√≠stico\nanalisis_estadistico &lt;- function(dt, by_vars, numeric_cols) {\n  dt[,\n    lapply(.SD, function(x) {\n      if(is.numeric(x) && length(unique(x)) &gt; 1) {\n        list(\n          n = length(x),\n          media = round(mean(x, na.rm = TRUE), 2),\n          mediana = round(median(x, na.rm = TRUE), 2),\n          q25 = round(quantile(x, 0.25, na.rm = TRUE), 2),\n          q75 = round(quantile(x, 0.75, na.rm = TRUE), 2),\n          desv_std = round(sd(x, na.rm = TRUE), 2),\n          cv = round(sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE), 3),\n          asimetria = round((mean(x) - median(x)) / sd(x), 3)\n        )\n      } else {\n        list(valores_unicos = length(unique(x)))\n      }\n    }),\n    by = by_vars,\n    .SDcols = numeric_cols\n  ]\n}\n\n# Aplicar la funci√≥n\nresultado_personalizado &lt;- analisis_estadistico(\n  empleados_avanzado,\n  by_vars = \"departamento\",\n  numeric_cols = c(\"salario_total\", \"a√±os_exp\", \"rating_performance\")\n)\n\nprint(resultado_personalizado)\n#&gt;     departamento salario_total a√±os_exp rating_performance\n#&gt;           &lt;char&gt;        &lt;list&gt;   &lt;list&gt;             &lt;list&gt;\n#&gt;  1:       Ventas             4        4                  4\n#&gt;  2:       Ventas         52175    11.75               3.85\n#&gt;  3:       Ventas         52750       12                3.7\n#&gt;  4:       Ventas         39300    10.25               3.42\n#&gt;  5:       Ventas         65625     13.5               4.12\n#&gt;  6:       Ventas      17803.44     2.99                0.7\n#&gt;  7:       Ventas         0.341    0.254              0.181\n#&gt;  8:       Ventas        -0.032   -0.084              0.216\n#&gt;  9:           IT             4        4                  4\n#&gt; 10:           IT         52200    11.25               4.15\n#&gt; 11:           IT         53350     11.5               4.05\n#&gt; 12:           IT         43975    10.75               3.77\n#&gt; 13:           IT         61575       12               4.42\n#&gt; 14:           IT      11866.76     0.96               0.51\n#&gt; 15:           IT         0.227    0.085              0.122\n#&gt; 16:           IT        -0.097   -0.261              0.197\n#&gt; 17:    Marketing             4        4                  4\n#&gt; 18:    Marketing         55900        3               4.42\n#&gt; 19:    Marketing         57200        2               4.45\n#&gt; 20:    Marketing         53350     1.75               4.25\n#&gt; 21:    Marketing         59750     3.25               4.62\n#&gt; 22:    Marketing       5196.15     2.71               0.49\n#&gt; 23:    Marketing         0.093    0.903              0.111\n#&gt; 24:    Marketing         -0.25    0.369             -0.051\n#&gt; 25:         RRHH             4        4                  4\n#&gt; 26:         RRHH         51550     9.25               4.62\n#&gt; 27:         RRHH         54100       11                4.6\n#&gt; 28:         RRHH         48800     7.75               4.45\n#&gt; 29:         RRHH         56850     12.5               4.78\n#&gt; 30:         RRHH       9993.83     5.74                0.3\n#&gt; 31:         RRHH         0.194     0.62              0.065\n#&gt; 32:         RRHH        -0.255   -0.305              0.084\n#&gt; 33:     Finanzas             4        4                  4\n#&gt; 34:     Finanzas         57875     4.75               3.67\n#&gt; 35:     Finanzas         56600      4.5               3.55\n#&gt; 36:     Finanzas         46650      3.5               3.38\n#&gt; 37:     Finanzas         67825     5.75               3.85\n#&gt; 38:     Finanzas      13198.07      2.5               0.45\n#&gt; 39:     Finanzas         0.228    0.526              0.122\n#&gt; 40:     Finanzas         0.097      0.1              0.278\n#&gt;     departamento salario_total a√±os_exp rating_performance\n\n\n3.7.2 2. Optimizaci√≥n de Performance\n\n\n# ‚úÖ HACER: Usar .SDcols para limitar columnas\n# M√°s eficiente\nempleados[, lapply(.SD, mean), by = dept, .SDcols = c(\"sal\", \"exp\")]\n\n# ‚ùå NO HACER: Procesar todas las columnas innecesariamente\n# Menos eficiente\nempleados[, lapply(.SD, mean), by = dept]\n\n# ‚úÖ HACER: Combinar operaciones en una sola expresi√≥n\n# M√°s eficiente\nempleados[, {\n  list(\n    media_sal = mean(salario),\n    max_exp = max(a√±os_exp),\n    grupo_id = .GRP\n  )\n}, by = dept]\n\n# ‚ùå NO HACER: M√∫ltiples pasadas por los datos\n# Menos eficiente\nmedia_sal &lt;- empleados[, mean(salario), by = dept]\nmax_exp &lt;- empleados[, max(a√±os_exp), by = dept]\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\n.SD es un mini-data.table con los datos del grupo actual - √∫salo con lapply() para operaciones m√∫ltiples\n\n.SDcols controla qu√© columnas incluye .SD - esencial para performance y precisi√≥n\n\n.I te da los √≠ndices reales - perfecto para top-N, muestreo y filtrado avanzado\n\n.GRP asigna IDs √∫nicos a grupos - √∫til para tracking y an√°lisis de cohortes\n\nCombinar s√≠mbolos permite an√°lisis complejos en una sola expresi√≥n\n\nPerformance: Limita .SDcols y combina operaciones para m√°xima eficiencia\n\n\n\nCon el dominio de estos s√≠mbolos especiales, tienes las herramientas para realizar an√°lisis de datos sofisticados y eficientes. En el pr√≥ximo m√≥dulo exploraremos t√©cnicas de manipulaci√≥n intermedia como encadenamiento y joins.\n[{‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1-new‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 2: dividir en encadenamiento y joins‚Äù, ‚Äústatus‚Äù: ‚Äúin_progress‚Äù, ‚Äúid‚Äù: ‚Äú2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 3: dividir en joins avanzados, funciones especiales y reshape‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú3‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú4‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú5‚Äù}]",
    "crumbs": [
      "**M√≥dulo 1**: Fundamentos y Sintaxis Esencial",
      "<span class='chapter-number'>3</span>¬† <span class='chapter-title'>S√≠mbolos Especiales en `data.table`</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html",
    "href": "cap02-encadenamiento.html",
    "title": "\n4¬† Encadenamiento de Operaciones (Chaining)\n",
    "section": "",
    "text": "4.1 Conceptos Fundamentales del Encadenamiento\nEl encadenamiento en data.table permite ejecutar m√∫ltiples operaciones secuenciales en una sola expresi√≥n usando la sintaxis DT[...][...][...]. Cada conjunto de corchetes opera sobre el resultado del anterior.",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#conceptos-fundamentales-del-encadenamiento",
    "href": "cap02-encadenamiento.html#conceptos-fundamentales-del-encadenamiento",
    "title": "\n4¬† Encadenamiento de Operaciones (Chaining)\n",
    "section": "",
    "text": "4.1.1 1. Encadenamiento B√°sico\n\n\n# Operaciones separadas (tradicional)\npaso1 &lt;- empleados[salario &gt; 45000]  # Filtrar\npaso2 &lt;- paso1[, .(empleados = .N, salario_promedio = mean(salario)), by = departamento]  # Agrupar\nresultado_separado &lt;- paso2[order(-salario_promedio)]  # Ordenar\n\n# Misma operaci√≥n encadenada\nresultado_encadenado &lt;- empleados[\n  salario &gt; 45000\n][\n  , .(empleados = .N, salario_promedio = round(mean(salario), 0)), by = departamento\n][\n  order(-salario_promedio)\n]\n\nprint(\"Resultado con encadenamiento:\")\n#&gt; [1] \"Resultado con encadenamiento:\"\nprint(resultado_encadenado)\n#&gt;    departamento empleados salario_promedio\n#&gt;          &lt;char&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt; 1:       Ventas         3            74700\n#&gt; 2:         RRHH         3            68933\n#&gt; 3:     Finanzas         3            63533\n#&gt; 4:    Marketing         4            61750\n#&gt; 5:           IT         3            61633\n\n\n4.1.2 2. Ventajas del Encadenamiento\n\n\n# Ejemplo que muestra las ventajas\nanalisis_productividad &lt;- empleados[\n  activo == TRUE & a√±os_exp &gt;= 3     # Solo empleados activos con experiencia\n][\n  , productividad_ajustada := pmin(productividad, 5)  # Ajustar outliers\n][\n  , .(\n    empleados = .N,\n    productividad_media = round(mean(productividad_ajustada), 2),\n    salario_total_grupo = sum(salario_total),\n    proyectos_totales = sum(proyectos)\n  ), by = .(departamento, nivel)\n][\n  productividad_media &gt; 1.5          # Solo grupos productivos\n][\n  order(departamento, -productividad_media)\n][\n  , ranking := 1:.N                  # Agregar ranking\n]\n\nprint(analisis_productividad)\n#&gt;    departamento   nivel empleados productividad_media salario_total_grupo\n#&gt;          &lt;char&gt;  &lt;char&gt;     &lt;int&gt;               &lt;num&gt;               &lt;num&gt;\n#&gt; 1:     Finanzas  Junior         1                5.00               79000\n#&gt; 2:           IT  Senior         1                5.00               63700\n#&gt; 3:           IT Manager         1                4.00               50300\n#&gt; 4:    Marketing    Lead         1                2.08               64000\n#&gt; 5:    Marketing Manager         1                1.60               78200\n#&gt; 6:         RRHH  Junior         1                3.00               82500\n#&gt; 7:       Ventas  Junior         1                2.09               89300\n#&gt;    proyectos_totales ranking\n#&gt;                &lt;int&gt;   &lt;int&gt;\n#&gt; 1:                19       1\n#&gt; 2:                22       2\n#&gt; 3:                24       3\n#&gt; 4:                25       4\n#&gt; 5:                 8       5\n#&gt; 6:                12       6\n#&gt; 7:                23       7\n\n\n\n\n\n\n\nüí° ¬øPor qu√© encadenar?\n\n\n\n\n\nMenos variables temporales - No necesitas almacenar resultados intermedios\n\nC√≥digo m√°s compacto - M√∫ltiples operaciones en una expresi√≥n\n\nMejor rendimiento - Menos copias en memoria\n\nFlujo l√≥gico claro - Lee de arriba abajo como una receta",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#comparaci√≥n-con-dplyr-pipes",
    "href": "cap02-encadenamiento.html#comparaci√≥n-con-dplyr-pipes",
    "title": "\n4¬† Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.2 Comparaci√≥n con dplyr Pipes",
    "text": "4.2 Comparaci√≥n con dplyr Pipes\nComparemos las dos aproximaciones principales para operaciones secuenciales:\n\n4.2.1 1. Sintaxis Lado a Lado\n\n\n\ndata.table (Chaining)\ndplyr (Pipes)\n\n\n\n\n# Pipeline complejo con data.table\npipeline_dt &lt;- ventas[\n  a√±o == 2024 & valor_neto &gt; 1000    # Filtrar ventas importantes de 2024\n][\n  , .(\n    ventas_totales = sum(valor_neto),\n    unidades_totales = sum(cantidad),\n    transacciones = .N,\n    ticket_promedio = round(mean(valor_neto), 2)\n  ), by = .(region, producto)\n][\n  ventas_totales &gt; 10000             # Solo combinaciones significativas\n][\n  order(region, -ventas_totales)\n][\n  , rank_en_region := rank(-ventas_totales), by = region\n][\n  rank_en_region &lt;= 3                # Top 3 productos por regi√≥n\n]\n\nprint(head(pipeline_dt, 12))\n#&gt;     region   producto ventas_totales unidades_totales transacciones\n#&gt;     &lt;char&gt;     &lt;char&gt;          &lt;num&gt;            &lt;int&gt;         &lt;int&gt;\n#&gt;  1: Centro Accesorios      1050344.8             1151           199\n#&gt;  2: Centro Smartphone      1023300.8             1023           171\n#&gt;  3: Centro     Tablet       874227.4              916           162\n#&gt;  4:   Este Smartphone       989853.6             1048           182\n#&gt;  5:   Este     Laptop       941461.4              984           164\n#&gt; ---                                                                \n#&gt;  8:  Norte Accesorios       922333.3             1026           168\n#&gt;  9:  Norte     Tablet       909612.5              953           172\n#&gt; 10:  Oeste     Laptop      1161534.8             1270           203\n#&gt; 11:  Oeste Smartphone       993922.4             1104           178\n#&gt; 12:  Oeste Accesorios       950027.6             1048           183\n#&gt;     ticket_promedio rank_en_region\n#&gt;               &lt;num&gt;          &lt;num&gt;\n#&gt;  1:         5278.11              1\n#&gt;  2:         5984.22              2\n#&gt;  3:         5396.47              3\n#&gt;  4:         5438.76              1\n#&gt;  5:         5740.62              2\n#&gt; ---                               \n#&gt;  8:         5490.08              2\n#&gt;  9:         5288.44              3\n#&gt; 10:         5721.85              1\n#&gt; 11:         5583.83              2\n#&gt; 12:         5191.41              3\n\n\n\n\n# Mismo pipeline con dplyr\npipeline_dplyr &lt;- ventas %&gt;%\n  filter(a√±o == 2024, valor_neto &gt; 1000) %&gt;%\n  group_by(region, producto) %&gt;%\n  summarise(\n    ventas_totales = sum(valor_neto),\n    unidades_totales = sum(cantidad),\n    transacciones = n(),\n    ticket_promedio = round(mean(valor_neto), 2),\n    .groups = 'drop'\n  ) %&gt;%\n  filter(ventas_totales &gt; 10000) %&gt;%\n  arrange(region, desc(ventas_totales)) %&gt;%\n  group_by(region) %&gt;%\n  mutate(rank_en_region = rank(desc(ventas_totales))) %&gt;%\n  filter(rank_en_region &lt;= 3) %&gt;%\n  ungroup()\n\nprint(head(as.data.table(pipeline_dplyr), 12))\n#&gt;     region   producto ventas_totales unidades_totales transacciones\n#&gt;     &lt;char&gt;     &lt;char&gt;          &lt;num&gt;            &lt;int&gt;         &lt;int&gt;\n#&gt;  1: Centro Accesorios      1050344.8             1151           199\n#&gt;  2: Centro Smartphone      1023300.8             1023           171\n#&gt;  3: Centro     Tablet       874227.4              916           162\n#&gt;  4:   Este Smartphone       989853.6             1048           182\n#&gt;  5:   Este     Laptop       941461.4              984           164\n#&gt; ---                                                                \n#&gt;  8:  Norte Accesorios       922333.3             1026           168\n#&gt;  9:  Norte     Tablet       909612.5              953           172\n#&gt; 10:  Oeste     Laptop      1161534.8             1270           203\n#&gt; 11:  Oeste Smartphone       993922.4             1104           178\n#&gt; 12:  Oeste Accesorios       950027.6             1048           183\n#&gt;     ticket_promedio rank_en_region\n#&gt;               &lt;num&gt;          &lt;num&gt;\n#&gt;  1:         5278.11              1\n#&gt;  2:         5984.22              2\n#&gt;  3:         5396.47              3\n#&gt;  4:         5438.76              1\n#&gt;  5:         5740.62              2\n#&gt; ---                               \n#&gt;  8:         5490.08              2\n#&gt;  9:         5288.44              3\n#&gt; 10:         5721.85              1\n#&gt; 11:         5583.83              2\n#&gt; 12:         5191.41              3\n\n\n\n\n\n4.2.2 2. Benchmark de Performance\n\n\n# Crear dataset m√°s grande para benchmark significativo\nset.seed(123)\nventas_grandes &lt;- data.table(\n  id = 1:100000,\n  categoria = sample(LETTERS[1:5], 100000, replace = TRUE),\n  valor = runif(100000, 10, 1000),\n  fecha = sample(seq(as.Date(\"2023-01-01\"), as.Date(\"2024-12-31\"), by = \"day\"), 100000, replace = TRUE)\n)\nventas_grandes[, a√±o := year(fecha)]\n\n# Benchmark\nbenchmark_pipes &lt;- microbenchmark(\n  \"data.table_chain\" = ventas_grandes[a√±o == 2024][, .(suma = sum(valor)), by = categoria][order(-suma)],\n  \"dplyr_pipes\" = ventas_grandes %&gt;% filter(a√±o == 2024) %&gt;% group_by(categoria) %&gt;% summarise(suma = sum(valor), .groups = 'drop') %&gt;% arrange(desc(suma)),\n  times = 20\n)\n\nprint(benchmark_pipes)\n#&gt; Unit: milliseconds\n#&gt;              expr    min      lq     mean  median      uq    max neval\n#&gt;  data.table_chain 2.6527 2.80095 3.096565 2.98645 3.06400 4.7616    20\n#&gt;       dplyr_pipes 2.6597 2.92150 3.697215 3.43110 4.01295 6.8438    20",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#patrones-avanzados-de-encadenamiento",
    "href": "cap02-encadenamiento.html#patrones-avanzados-de-encadenamiento",
    "title": "\n4¬† Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.3 Patrones Avanzados de Encadenamiento",
    "text": "4.3 Patrones Avanzados de Encadenamiento\n\n4.3.1 1. Encadenamiento con Modificaci√≥n por Referencia\n\n\n# Combinar := con encadenamiento para an√°lisis iterativo\nempleados_analisis &lt;- copy(empleados)[\n  , salario_z := scale(salario_total)[,1], by = departamento  # Z-score por depto\n][\n  , categoria_performance := cut(salario_z, breaks = c(-Inf, -1, 1, Inf), \n                                labels = c(\"Bajo\", \"Medio\", \"Alto\"))\n][\n  , .(\n    empleados = .N,\n    salario_promedio = round(mean(salario_total), 0),\n    performance_dist = paste(table(categoria_performance), collapse = \"/\")\n  ), by = .(departamento, categoria_performance)\n][\n  order(departamento, categoria_performance)\n]\n\nprint(empleados_analisis)\n#&gt;     departamento categoria_performance empleados salario_promedio\n#&gt;           &lt;char&gt;                &lt;fctr&gt;     &lt;int&gt;            &lt;num&gt;\n#&gt;  1:     Finanzas                  Bajo         1            39000\n#&gt;  2:     Finanzas                 Medio         3            71167\n#&gt;  3:           IT                  Bajo         1            50300\n#&gt;  4:           IT                 Medio         2            63500\n#&gt;  5:           IT                  Alto         1            72700\n#&gt;  6:    Marketing                  Bajo         1            64000\n#&gt;  7:    Marketing                 Medio         3            75167\n#&gt;  8:         RRHH                 Medio         3            62933\n#&gt;  9:         RRHH                  Alto         1            89500\n#&gt; 10:       Ventas                  Bajo         1            59100\n#&gt; 11:       Ventas                 Medio         3            84667\n#&gt;     performance_dist\n#&gt;               &lt;char&gt;\n#&gt;  1:            1/0/0\n#&gt;  2:            0/1/0\n#&gt;  3:            1/0/0\n#&gt;  4:            0/1/0\n#&gt;  5:            0/0/1\n#&gt;  6:            1/0/0\n#&gt;  7:            0/1/0\n#&gt;  8:            0/1/0\n#&gt;  9:            0/0/1\n#&gt; 10:            1/0/0\n#&gt; 11:            0/1/0\n\n\n4.3.2 2. Encadenamiento con Validaciones\n\n\n# Pipeline con validaciones integradas\npipeline_validado &lt;- ventas[\n  !is.na(valor_neto) & valor_neto &gt; 0     # Validar datos b√°sicos\n][\n  , .N, by = a√±o                           # Verificar distribuci√≥n temporal\n][\n  , {\n    cat(\"Distribuci√≥n por a√±o:\\n\")\n    print(.SD)\n    if(min(N) &lt; 100) warning(\"Pocos datos en algunos a√±os\")\n    .SD\n  }\n][\n  # Continuar con el an√°lisis principal\n  , .(a√±os_con_datos = .N, transacciones_totales = sum(N))\n]\n#&gt; Distribuci√≥n por a√±o:\n#&gt;      a√±o     N\n#&gt;    &lt;int&gt; &lt;int&gt;\n#&gt; 1:  2023  4962\n#&gt; 2:  2024  5038\n\nprint(pipeline_validado)\n#&gt;    a√±os_con_datos transacciones_totales\n#&gt;             &lt;int&gt;                 &lt;int&gt;\n#&gt; 1:              2                 10000\n\n\n4.3.3 3. Encadenamiento con An√°lisis Exploratorio\n\n\n# Pipeline de an√°lisis exploratorio\neda_pipeline &lt;- ventas[\n  sample(.N, 5000)                    # Muestra para EDA r√°pido\n][\n  , .(\n    valores_unicos = uniqueN(cliente_id),\n    valor_promedio = round(mean(valor_neto), 2),\n    valor_mediana = round(median(valor_neto), 2),\n    outliers_superiores = sum(valor_neto &gt; quantile(valor_neto, 0.95))\n  ), by = .(region, categoria)\n][\n  , coef_variacion := round((valor_promedio - valor_mediana) / valor_promedio, 3)\n][\n  order(-valores_unicos)\n][\n  , {\n    cat(\"Top regiones-categor√≠as por diversidad de clientes:\\n\")\n    print(.SD[1:5])\n    .SD\n  }\n]\n#&gt; Top regiones-categor√≠as por diversidad de clientes:\n#&gt;    region categoria valores_unicos valor_promedio valor_mediana\n#&gt;    &lt;char&gt;    &lt;char&gt;          &lt;int&gt;          &lt;num&gt;         &lt;num&gt;\n#&gt; 1:  Oeste Servicios            259        4661.32       3620.13\n#&gt; 2:  Norte  Hardware            255        4513.11       3287.83\n#&gt; 3:  Oeste  Hardware            249        4866.92       3741.86\n#&gt; 4:   Este  Software            247        4632.75       3713.56\n#&gt; 5: Centro  Software            246        4679.73       3562.80\n#&gt;    outliers_superiores coef_variacion\n#&gt;                  &lt;int&gt;          &lt;num&gt;\n#&gt; 1:                  19          0.223\n#&gt; 2:                  18          0.271\n#&gt; 3:                  18          0.231\n#&gt; 4:                  18          0.198\n#&gt; 5:                  17          0.239\n\n\n4.3.4 4. Encadenamiento con Funciones Personalizadas\n\n\n# Definir funci√≥n auxiliar\ncalcular_metricas_avanzadas &lt;- function(valores) {\n  list(\n    media = round(mean(valores), 2),\n    percentil_95 = round(quantile(valores, 0.95), 2),\n    coef_asimetria = round((mean(valores) - median(valores)) / sd(valores), 3),\n    outliers_count = sum(valores &gt; (mean(valores) + 2 * sd(valores)))\n  )\n}\n\n# Pipeline con funci√≥n personalizada\nmetricas_avanzadas &lt;- ventas[\n  a√±o == 2024 & !is.na(valor_neto)\n][\n  , calcular_metricas_avanzadas(valor_neto), by = .(region, trimestre)\n][\n  outliers_count &gt; 5                 # Solo regiones/trimestres con anomal√≠as\n][\n  order(region, trimestre)\n]\n\nprint(metricas_avanzadas)\n#&gt;     region trimestre   media percentil_95 coef_asimetria outliers_count\n#&gt;     &lt;char&gt;     &lt;int&gt;   &lt;num&gt;        &lt;num&gt;          &lt;num&gt;          &lt;int&gt;\n#&gt;  1: Centro         1 4512.27     12113.24          0.276             14\n#&gt;  2: Centro         2 4379.47     12860.78          0.303             13\n#&gt;  3: Centro         3 4586.36     12705.74          0.346             16\n#&gt;  4: Centro         4 5031.66     13807.56          0.272             18\n#&gt;  5:   Este         1 4647.60     12434.10          0.265             14\n#&gt; ---                                                                    \n#&gt; 16:  Oeste         4 4629.18     13104.52          0.269             17\n#&gt; 17:    Sur         1 5657.17     14089.79          0.278             13\n#&gt; 18:    Sur         2 4854.70     12187.45          0.212             11\n#&gt; 19:    Sur         3 5142.59     13569.57          0.337              9\n#&gt; 20:    Sur         4 4893.29     12974.33          0.307             13",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#t√©cnicas-de-debugging-en-encadenamientos",
    "href": "cap02-encadenamiento.html#t√©cnicas-de-debugging-en-encadenamientos",
    "title": "\n4¬† Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.4 T√©cnicas de Debugging en Encadenamientos",
    "text": "4.4 T√©cnicas de Debugging en Encadenamientos\n\n4.4.1 1. Inspecci√≥n Intermedia\n\n\n# T√©cnica: usar {} para inspeccionar pasos intermedios\ndebug_pipeline &lt;- empleados[\n  salario_total &gt; 50000\n][\n  , {\n    cat(\"Despu√©s del filtro:\", .N, \"filas\\n\")\n    .SD\n  }\n][\n  , .(empleados = .N, salario_avg = mean(salario_total)), by = departamento\n][\n  , {\n    cat(\"Despu√©s de agrupar:\", nrow(.SD), \"grupos\\n\")\n    print(.SD)\n    .SD\n  }\n][\n  order(-salario_avg)\n]\n#&gt; Despu√©s del filtro: 19 filas\n#&gt; Despu√©s de agrupar: 5 grupos\n#&gt;    departamento empleados salario_avg\n#&gt;          &lt;char&gt;     &lt;int&gt;       &lt;num&gt;\n#&gt; 1:       Ventas         4    78275.00\n#&gt; 2:           IT         4    62500.00\n#&gt; 3:    Marketing         4    72375.00\n#&gt; 4:         RRHH         4    69575.00\n#&gt; 5:     Finanzas         3    71166.67\n\n\n4.4.2 2. Validaciones en Cadena\n\n\n# Pipeline robusto con validaciones\npipeline_robusto &lt;- ventas[\n  a√±o %in% 2023:2024                      # A√±os v√°lidos\n][\n  , if(.N == 0) stop(\"No hay datos despu√©s del filtro de a√±os\") else .SD\n][\n  !is.na(valor_neto) & valor_neto &gt; 0     # Valores v√°lidos\n][\n  , if(.N &lt; 1000) warning(\"Pocos datos para an√°lisis confiable\") else .SD\n][\n  , .(ventas = sum(valor_neto), transacciones = .N), by = .(a√±o, region)\n][\n  ventas &gt; 0                              # Verificar resultados l√≥gicos\n]\n\nprint(pipeline_robusto)\n#&gt;       a√±o region  ventas transacciones\n#&gt;     &lt;int&gt; &lt;char&gt;   &lt;num&gt;         &lt;int&gt;\n#&gt;  1:  2023    Sur 4770068           958\n#&gt;  2:  2024 Centro 4669677          1005\n#&gt;  3:  2024  Norte 4571534           985\n#&gt;  4:  2024   Este 4589704           979\n#&gt;  5:  2023 Centro 4841287           986\n#&gt;  6:  2023   Este 4799598           993\n#&gt;  7:  2024    Sur 5136588           996\n#&gt;  8:  2024  Oeste 5059483          1073\n#&gt;  9:  2023  Norte 4917000          1016\n#&gt; 10:  2023  Oeste 4672004          1009",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#ejercicios-pr√°cticos",
    "href": "cap02-encadenamiento.html#ejercicios-pr√°cticos",
    "title": "\n4¬† Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.5 Ejercicios Pr√°cticos",
    "text": "4.5 Ejercicios Pr√°cticos\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 6: Pipeline de An√°lisis de Ventas\n\n\n\nUsando el dataset ventas, crea un pipeline encadenado que:\n\n\nFiltre ventas del √∫ltimo trimestre de 2024\n\nCalcule m√©tricas por vendedor y regi√≥n\n\nIdentifique vendedores top (&gt; percentil 80 en ventas)\n\nCree ranking por regi√≥n\n\nGenere un reporte final con formato\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 6\n\n\n\n\n\n\n# Pipeline complejo de an√°lisis de ventas\nreporte_ventas &lt;- ventas[\n  a√±o == 2024 & trimestre == 4           # 1. Q4 2024\n][\n  , .(                                    # 2. M√©tricas por vendedor-regi√≥n\n    ventas_totales = sum(valor_neto),\n    unidades_vendidas = sum(cantidad),\n    transacciones = .N,\n    ticket_promedio = round(mean(valor_neto), 2),\n    mejor_producto = names(sort(table(producto), decreasing = TRUE))[1]\n  ), by = .(vendedor_id, region)\n][\n  ventas_totales &gt; quantile(ventas_totales, 0.8)  # 3. Top performers (percentil 80)\n][\n  order(region, -ventas_totales)\n][\n  , ranking_regional := 1:.N, by = region         # 4. Ranking por regi√≥n\n][\n  , .(                                    # 5. Reporte final formateado\n    Region = region,\n    Vendedor = paste0(\"ID_\", vendedor_id),\n    Ranking = ranking_regional,\n    Ventas = paste0(\"$\", format(round(ventas_totales, 0), big.mark = \",\")),\n    Unidades = format(unidades_vendidas, big.mark = \",\"),\n    Transacciones = transacciones,\n    Ticket_Avg = paste0(\"$\", ticket_promedio),\n    Top_Producto = mejor_producto,\n    Performance = ifelse(ranking_regional == 1, \"‚òÖ‚òÖ‚òÖ\", \n                        ifelse(ranking_regional &lt;= 3, \"‚òÖ‚òÖ\", \"‚òÖ\"))\n  )\n][\n  order(Region, Ranking)\n]\n\nprint(reporte_ventas)\n#&gt;     Region Vendedor Ranking  Ventas Unidades Transacciones Ticket_Avg\n#&gt;     &lt;char&gt;   &lt;char&gt;   &lt;int&gt;  &lt;char&gt;   &lt;char&gt;         &lt;int&gt;     &lt;char&gt;\n#&gt;  1: Centro    ID_21       1 $57,943       62             8   $7242.93\n#&gt;  2: Centro    ID_23       2 $55,866       56            10   $5586.62\n#&gt;  3: Centro    ID_22       3 $50,392       63             8   $6299.04\n#&gt;  4: Centro     ID_9       4 $47,863       44             6   $7977.08\n#&gt;  5: Centro    ID_24       5 $47,785       37             8   $5973.07\n#&gt;  6: Centro    ID_36       6 $45,849       44             7   $6549.82\n#&gt;  7: Centro    ID_12       7 $45,062       79            11   $4096.56\n#&gt;  8: Centro    ID_27       8 $43,315       48             9   $4812.83\n#&gt;  9: Centro    ID_28       9 $43,007       43             8   $5375.83\n#&gt; 10: Centro    ID_48      10 $40,534       44             8   $5066.81\n#&gt; 11: Centro    ID_38      11 $39,617       53             9   $4401.87\n#&gt; 12: Centro    ID_41      12 $38,036       64             9    $4226.2\n#&gt; 13:   Este     ID_4       1 $60,526       80            12   $5043.81\n#&gt; 14:   Este     ID_1       2 $59,086       49            10   $5908.63\n#&gt; 15:   Este     ID_6       3 $44,048       34             7   $6292.61\n#&gt; 16:   Este    ID_45       4 $41,654       53             7   $5950.57\n#&gt; 17:   Este    ID_27       5 $41,578       39             7   $5939.73\n#&gt; 18:   Este    ID_37       6 $41,310       49             9   $4590.03\n#&gt; 19:   Este    ID_50       7 $40,439       33             8   $5054.91\n#&gt; 20:   Este    ID_11       8 $38,579       41             7   $5511.27\n#&gt; 21:   Este     ID_3       9 $38,573       45             8   $4821.65\n#&gt; 22:   Este    ID_44      10 $37,725       46             7   $5389.32\n#&gt; 23:  Norte     ID_5       1 $61,248       55             9   $6805.35\n#&gt; 24:  Norte    ID_10       2 $58,480       60            10   $5848.04\n#&gt; 25:  Norte    ID_40       3 $52,650       53             8   $6581.22\n#&gt; 26:  Norte    ID_46       4 $43,763       44             7   $6251.83\n#&gt; 27:  Norte     ID_6       5 $43,651       50            12    $3637.6\n#&gt; 28:  Norte    ID_31       6 $41,523       37             6   $6920.42\n#&gt; 29:  Oeste    ID_36       1 $52,220       48             6    $8703.3\n#&gt; 30:  Oeste    ID_24       2 $49,463       58             9   $5495.85\n#&gt; 31:  Oeste     ID_1       3 $49,336       62             9   $5481.81\n#&gt; 32:  Oeste    ID_43       4 $48,605       59            11   $4418.62\n#&gt; 33:  Oeste    ID_48       5 $47,777       52             9    $5308.6\n#&gt; 34:  Oeste    ID_40       6 $45,381       47             9   $5042.38\n#&gt; 35:  Oeste    ID_47       7 $45,205       58             9   $5022.72\n#&gt; 36:  Oeste    ID_23       8 $44,807       55            12   $3733.94\n#&gt; 37:  Oeste    ID_32       9 $44,092       49             8   $5511.46\n#&gt; 38:  Oeste     ID_4      10 $43,620       52             7   $6231.43\n#&gt; 39:  Oeste    ID_18      11 $43,598       36             5    $8719.6\n#&gt; 40:  Oeste    ID_12      12 $43,212       35             7   $6173.21\n#&gt; 41:  Oeste    ID_42      13 $42,199       45             7   $6028.39\n#&gt; 42:  Oeste     ID_3      14 $41,547       35             7   $5935.25\n#&gt; 43:  Oeste    ID_13      15 $39,928       32             6   $6654.71\n#&gt; 44:    Sur     ID_3       1 $52,542       43             7   $7506.06\n#&gt; 45:    Sur     ID_7       2 $45,035       39             9   $5003.94\n#&gt; 46:    Sur    ID_24       3 $42,631       34             7    $6090.2\n#&gt; 47:    Sur     ID_5       4 $41,461       42            11   $3769.21\n#&gt; 48:    Sur    ID_43       5 $41,168       38             7   $5881.16\n#&gt; 49:    Sur    ID_48       6 $39,735       39             7   $5676.37\n#&gt; 50:    Sur    ID_28       7 $39,045       29             5   $7809.03\n#&gt;     Region Vendedor Ranking  Ventas Unidades Transacciones Ticket_Avg\n#&gt;     Top_Producto Performance\n#&gt;           &lt;char&gt;      &lt;char&gt;\n#&gt;  1:       Laptop         ‚òÖ‚òÖ‚òÖ\n#&gt;  2:       Tablet          ‚òÖ‚òÖ\n#&gt;  3:      Desktop          ‚òÖ‚òÖ\n#&gt;  4:   Smartphone           ‚òÖ\n#&gt;  5:      Desktop           ‚òÖ\n#&gt;  6:   Accesorios           ‚òÖ\n#&gt;  7:   Smartphone           ‚òÖ\n#&gt;  8:       Laptop           ‚òÖ\n#&gt;  9:   Accesorios           ‚òÖ\n#&gt; 10:       Tablet           ‚òÖ\n#&gt; 11:       Tablet           ‚òÖ\n#&gt; 12:       Tablet           ‚òÖ\n#&gt; 13:   Smartphone         ‚òÖ‚òÖ‚òÖ\n#&gt; 14:      Desktop          ‚òÖ‚òÖ\n#&gt; 15:      Desktop          ‚òÖ‚òÖ\n#&gt; 16:   Smartphone           ‚òÖ\n#&gt; 17:      Desktop           ‚òÖ\n#&gt; 18:       Laptop           ‚òÖ\n#&gt; 19:      Desktop           ‚òÖ\n#&gt; 20:      Desktop           ‚òÖ\n#&gt; 21:       Laptop           ‚òÖ\n#&gt; 22:       Laptop           ‚òÖ\n#&gt; 23:   Accesorios         ‚òÖ‚òÖ‚òÖ\n#&gt; 24:   Smartphone          ‚òÖ‚òÖ\n#&gt; 25:       Laptop          ‚òÖ‚òÖ\n#&gt; 26:       Laptop           ‚òÖ\n#&gt; 27:       Laptop           ‚òÖ\n#&gt; 28:       Laptop           ‚òÖ\n#&gt; 29:   Smartphone         ‚òÖ‚òÖ‚òÖ\n#&gt; 30:       Laptop          ‚òÖ‚òÖ\n#&gt; 31:   Accesorios          ‚òÖ‚òÖ\n#&gt; 32:   Smartphone           ‚òÖ\n#&gt; 33:      Desktop           ‚òÖ\n#&gt; 34:   Accesorios           ‚òÖ\n#&gt; 35:       Laptop           ‚òÖ\n#&gt; 36:       Laptop           ‚òÖ\n#&gt; 37:       Laptop           ‚òÖ\n#&gt; 38:       Laptop           ‚òÖ\n#&gt; 39:      Desktop           ‚òÖ\n#&gt; 40:       Laptop           ‚òÖ\n#&gt; 41:   Accesorios           ‚òÖ\n#&gt; 42:       Laptop           ‚òÖ\n#&gt; 43:   Smartphone           ‚òÖ\n#&gt; 44:   Accesorios         ‚òÖ‚òÖ‚òÖ\n#&gt; 45:       Tablet          ‚òÖ‚òÖ\n#&gt; 46:   Accesorios          ‚òÖ‚òÖ\n#&gt; 47:       Tablet           ‚òÖ\n#&gt; 48:   Accesorios           ‚òÖ\n#&gt; 49:   Accesorios           ‚òÖ\n#&gt; 50:       Laptop           ‚òÖ\n#&gt;     Top_Producto Performance\n\n# Mostrar tabla del reporte formateada para PDF\nknitr::kable(\n  reporte_ventas,\n  caption = \"Reporte de Top Performers Q4 2024\",\n  digits = 2,\n  format.args = list(big.mark = \",\")\n)\n\n\nReporte de Top Performers Q4 2024\n\n\n\n\n\n\n\n\n\n\n\n\nRegion\nVendedor\nRanking\nVentas\nUnidades\nTransacciones\nTicket_Avg\nTop_Producto\nPerformance\n\n\n\nCentro\nID_21\n1\n$57,943\n62\n8\n$7242.93\nLaptop\n‚òÖ‚òÖ‚òÖ\n\n\nCentro\nID_23\n2\n$55,866\n56\n10\n$5586.62\nTablet\n‚òÖ‚òÖ\n\n\nCentro\nID_22\n3\n$50,392\n63\n8\n$6299.04\nDesktop\n‚òÖ‚òÖ\n\n\nCentro\nID_9\n4\n$47,863\n44\n6\n$7977.08\nSmartphone\n‚òÖ\n\n\nCentro\nID_24\n5\n$47,785\n37\n8\n$5973.07\nDesktop\n‚òÖ\n\n\nCentro\nID_36\n6\n$45,849\n44\n7\n$6549.82\nAccesorios\n‚òÖ\n\n\nCentro\nID_12\n7\n$45,062\n79\n11\n$4096.56\nSmartphone\n‚òÖ\n\n\nCentro\nID_27\n8\n$43,315\n48\n9\n$4812.83\nLaptop\n‚òÖ\n\n\nCentro\nID_28\n9\n$43,007\n43\n8\n$5375.83\nAccesorios\n‚òÖ\n\n\nCentro\nID_48\n10\n$40,534\n44\n8\n$5066.81\nTablet\n‚òÖ\n\n\nCentro\nID_38\n11\n$39,617\n53\n9\n$4401.87\nTablet\n‚òÖ\n\n\nCentro\nID_41\n12\n$38,036\n64\n9\n$4226.2\nTablet\n‚òÖ\n\n\nEste\nID_4\n1\n$60,526\n80\n12\n$5043.81\nSmartphone\n‚òÖ‚òÖ‚òÖ\n\n\nEste\nID_1\n2\n$59,086\n49\n10\n$5908.63\nDesktop\n‚òÖ‚òÖ\n\n\nEste\nID_6\n3\n$44,048\n34\n7\n$6292.61\nDesktop\n‚òÖ‚òÖ\n\n\nEste\nID_45\n4\n$41,654\n53\n7\n$5950.57\nSmartphone\n‚òÖ\n\n\nEste\nID_27\n5\n$41,578\n39\n7\n$5939.73\nDesktop\n‚òÖ\n\n\nEste\nID_37\n6\n$41,310\n49\n9\n$4590.03\nLaptop\n‚òÖ\n\n\nEste\nID_50\n7\n$40,439\n33\n8\n$5054.91\nDesktop\n‚òÖ\n\n\nEste\nID_11\n8\n$38,579\n41\n7\n$5511.27\nDesktop\n‚òÖ\n\n\nEste\nID_3\n9\n$38,573\n45\n8\n$4821.65\nLaptop\n‚òÖ\n\n\nEste\nID_44\n10\n$37,725\n46\n7\n$5389.32\nLaptop\n‚òÖ\n\n\nNorte\nID_5\n1\n$61,248\n55\n9\n$6805.35\nAccesorios\n‚òÖ‚òÖ‚òÖ\n\n\nNorte\nID_10\n2\n$58,480\n60\n10\n$5848.04\nSmartphone\n‚òÖ‚òÖ\n\n\nNorte\nID_40\n3\n$52,650\n53\n8\n$6581.22\nLaptop\n‚òÖ‚òÖ\n\n\nNorte\nID_46\n4\n$43,763\n44\n7\n$6251.83\nLaptop\n‚òÖ\n\n\nNorte\nID_6\n5\n$43,651\n50\n12\n$3637.6\nLaptop\n‚òÖ\n\n\nNorte\nID_31\n6\n$41,523\n37\n6\n$6920.42\nLaptop\n‚òÖ\n\n\nOeste\nID_36\n1\n$52,220\n48\n6\n$8703.3\nSmartphone\n‚òÖ‚òÖ‚òÖ\n\n\nOeste\nID_24\n2\n$49,463\n58\n9\n$5495.85\nLaptop\n‚òÖ‚òÖ\n\n\nOeste\nID_1\n3\n$49,336\n62\n9\n$5481.81\nAccesorios\n‚òÖ‚òÖ\n\n\nOeste\nID_43\n4\n$48,605\n59\n11\n$4418.62\nSmartphone\n‚òÖ\n\n\nOeste\nID_48\n5\n$47,777\n52\n9\n$5308.6\nDesktop\n‚òÖ\n\n\nOeste\nID_40\n6\n$45,381\n47\n9\n$5042.38\nAccesorios\n‚òÖ\n\n\nOeste\nID_47\n7\n$45,205\n58\n9\n$5022.72\nLaptop\n‚òÖ\n\n\nOeste\nID_23\n8\n$44,807\n55\n12\n$3733.94\nLaptop\n‚òÖ\n\n\nOeste\nID_32\n9\n$44,092\n49\n8\n$5511.46\nLaptop\n‚òÖ\n\n\nOeste\nID_4\n10\n$43,620\n52\n7\n$6231.43\nLaptop\n‚òÖ\n\n\nOeste\nID_18\n11\n$43,598\n36\n5\n$8719.6\nDesktop\n‚òÖ\n\n\nOeste\nID_12\n12\n$43,212\n35\n7\n$6173.21\nLaptop\n‚òÖ\n\n\nOeste\nID_42\n13\n$42,199\n45\n7\n$6028.39\nAccesorios\n‚òÖ\n\n\nOeste\nID_3\n14\n$41,547\n35\n7\n$5935.25\nLaptop\n‚òÖ\n\n\nOeste\nID_13\n15\n$39,928\n32\n6\n$6654.71\nSmartphone\n‚òÖ\n\n\nSur\nID_3\n1\n$52,542\n43\n7\n$7506.06\nAccesorios\n‚òÖ‚òÖ‚òÖ\n\n\nSur\nID_7\n2\n$45,035\n39\n9\n$5003.94\nTablet\n‚òÖ‚òÖ\n\n\nSur\nID_24\n3\n$42,631\n34\n7\n$6090.2\nAccesorios\n‚òÖ‚òÖ\n\n\nSur\nID_5\n4\n$41,461\n42\n11\n$3769.21\nTablet\n‚òÖ\n\n\nSur\nID_43\n5\n$41,168\n38\n7\n$5881.16\nAccesorios\n‚òÖ\n\n\nSur\nID_48\n6\n$39,735\n39\n7\n$5676.37\nAccesorios\n‚òÖ\n\n\nSur\nID_28\n7\n$39,045\n29\n5\n$7809.03\nLaptop\n‚òÖ\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 7: An√°lisis de Cohortes con Encadenamiento\n\n\n\nCrea un an√°lisis de cohortes de empleados:\n\n\nAgrupa empleados por a√±o de ingreso\n\nCalcula retenci√≥n, salarios promedios, y promociones\n\nIdentifica cohortes exitosas vs.¬†problem√°ticas\n\nGenera insights autom√°ticos\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 7\n\n\n\n\n\n\n# An√°lisis de cohortes con encadenamiento\nlibrary(lubridate)\n\nanalisis_cohortes &lt;- empleados[\n  !is.na(fecha_ingreso)                    # 1. Datos v√°lidos\n][\n  , a√±o_ingreso := year(fecha_ingreso)     # Extraer a√±o de cohorte\n][\n  , a√±os_en_empresa := round(as.numeric(Sys.Date() - fecha_ingreso) / 365, 1)\n][\n  , .(                                     # 2. M√©tricas por cohorte\n    empleados_iniciales = .N,\n    empleados_activos = sum(activo),\n    retencion_pct = round(mean(activo) * 100, 1),\n    salario_inicial_avg = round(mean(salario), 0),\n    salario_actual_avg = round(mean(salario_total), 0),\n    crecimiento_salarial = round(mean(salario_total) / mean(salario) - 1, 2),\n    a√±os_promedio = round(mean(a√±os_en_empresa), 1),\n    productividad_avg = round(mean(productividad), 2),\n    managers_promocionados = sum(nivel == \"Manager\")\n  ), by = a√±o_ingreso\n][\n  empleados_iniciales &gt;= 2                 # Solo cohortes con suficientes datos\n][\n  , `:=`(                                 # 3. Clasificar cohortes\n    categoria_retencion = cut(retencion_pct, \n                             breaks = c(0, 70, 90, 100), \n                             labels = c(\"Problem√°tica\", \"Regular\", \"Exitosa\")),\n    categoria_crecimiento = ifelse(crecimiento_salarial &gt; 0.15, \"Alto\", \n                                 ifelse(crecimiento_salarial &gt; 0.05, \"Medio\", \"Bajo\"))\n  )\n][\n  order(a√±o_ingreso)\n][\n  , {                                     # 4. Generar insights autom√°ticos\n    cat(\"=== INSIGHTS DE COHORTES ===\\n\\n\")\n    \n    cohorte_mejor &lt;- .SD[which.max(retencion_pct * crecimiento_salarial)]\n    cohorte_peor &lt;- .SD[which.min(retencion_pct * (1 + crecimiento_salarial))]\n    \n    cat(\"üèÜ MEJOR COHORTE:\", cohorte_mejor$a√±o_ingreso, \"\\n\")\n    cat(\"   ‚Ä¢ Retenci√≥n:\", cohorte_mejor$retencion_pct, \"%\\n\")\n    cat(\"   ‚Ä¢ Crecimiento salarial:\", cohorte_mejor$crecimiento_salarial * 100, \"%\\n\\n\")\n    \n    cat(\"‚ö†Ô∏è  COHORTE PROBLEM√ÅTICA:\", cohorte_peor$a√±o_ingreso, \"\\n\")\n    cat(\"   ‚Ä¢ Retenci√≥n:\", cohorte_peor$retencion_pct, \"%\\n\")\n    cat(\"   ‚Ä¢ Crecimiento salarial:\", cohorte_peor$crecimiento_salarial * 100, \"%\\n\\n\")\n    \n    cat(\"üìä RESUMEN GENERAL:\\n\")\n    cat(\"   ‚Ä¢ Retenci√≥n promedio:\", round(mean(retencion_pct), 1), \"%\\n\")\n    cat(\"   ‚Ä¢ Cohortes exitosas:\", sum(categoria_retencion == \"Exitosa\"), \"de\", .N, \"\\n\")\n    cat(\"   ‚Ä¢ Managers promocionados:\", sum(managers_promocionados), \"total\\n\\n\")\n    \n    .SD\n  }\n]\n#&gt; === INSIGHTS DE COHORTES ===\n#&gt; \n#&gt; üèÜ MEJOR COHORTE: 2022 \n#&gt;    ‚Ä¢ Retenci√≥n: 100 %\n#&gt;    ‚Ä¢ Crecimiento salarial: 21 %\n#&gt; \n#&gt; ‚ö†Ô∏è  COHORTE PROBLEM√ÅTICA: 2023 \n#&gt;    ‚Ä¢ Retenci√≥n: 66.7 %\n#&gt;    ‚Ä¢ Crecimiento salarial: 15 %\n#&gt; \n#&gt; üìä RESUMEN GENERAL:\n#&gt;    ‚Ä¢ Retenci√≥n promedio: 83.3 %\n#&gt;    ‚Ä¢ Cohortes exitosas: 2 de 5 \n#&gt;    ‚Ä¢ Managers promocionados: 4 total\n\nprint(analisis_cohortes[, .(a√±o_ingreso, empleados_iniciales, retencion_pct, \n                           crecimiento_salarial, categoria_retencion, categoria_crecimiento)])\n#&gt;    a√±o_ingreso empleados_iniciales retencion_pct crecimiento_salarial\n#&gt;          &lt;num&gt;               &lt;int&gt;         &lt;num&gt;                &lt;num&gt;\n#&gt; 1:        2019                   6          83.3                 0.10\n#&gt; 2:        2020                   3         100.0                 0.09\n#&gt; 3:        2021                   3          66.7                 0.18\n#&gt; 4:        2022                   4         100.0                 0.21\n#&gt; 5:        2023                   3          66.7                 0.15\n#&gt;    categoria_retencion categoria_crecimiento\n#&gt;                 &lt;fctr&gt;                &lt;char&gt;\n#&gt; 1:             Regular                 Medio\n#&gt; 2:             Exitosa                 Medio\n#&gt; 3:        Problem√°tica                  Alto\n#&gt; 4:             Exitosa                  Alto\n#&gt; 5:        Problem√°tica                 Medio",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-encadenamiento.html#mejores-pr√°cticas-para-encadenamiento",
    "href": "cap02-encadenamiento.html#mejores-pr√°cticas-para-encadenamiento",
    "title": "\n4¬† Encadenamiento de Operaciones (Chaining)\n",
    "section": "\n4.6 Mejores Pr√°cticas para Encadenamiento",
    "text": "4.6 Mejores Pr√°cticas para Encadenamiento\n\n4.6.1 1. Legibilidad vs.¬†Performance\n\n\n# ‚úÖ HACER: Encadenamiento legible con l√≠neas separadas\nresultado &lt;- datos[\n  filtro_simple & condicion_clara\n][\n  , .(metrica1 = func1(col1), metrica2 = func2(col2)), by = grupo\n][\n  order(-metrica1)\n][\n  1:10\n]\n\n# ‚ùå EVITAR: Una l√≠nea muy larga\nresultado &lt;- datos[filtro & condicion][, .(m1 = f1(c1), m2 = f2(c2)), by = g][order(-m1)][1:10]\n\n# ‚úÖ HACER: Comentarios para pasos complejos\nresultado &lt;- datos[\n  filtro_complejo                    # Paso 1: filtrar casos v√°lidos\n][\n  , calculo_complejo(), by = grupo   # Paso 2: agregaciones por grupo\n][\n  post_procesamiento()               # Paso 3: ajustes finales\n]\n\n\n4.6.2 2. Cu√°ndo NO usar encadenamiento\n\n\n# ‚ùå Evitar: L√≥gica muy compleja en una cadena\n# Mejor usar pasos separados para debugging\npaso1 &lt;- datos[filtro_complejo_con_multiples_condiciones]\npaso2 &lt;- paso1[, calculo_muy_complejo_con_multiples_funciones(), by = multiples_grupos]\npaso3 &lt;- paso2[post_procesamiento_complejo_con_validaciones()]\n\n# ‚ùå Evitar: Cadenas que modifican el objeto original sin copy()\n# Peligroso si necesitas preservar datos originales\ndatos_originales[, nueva_col := calculo()][filtro][, otra_col := otro_calculo()]\n\n# ‚úÖ Hacer: Usar copy() cuando modifiques\ndatos_procesados &lt;- copy(datos_originales)[\n  , nueva_col := calculo()\n][\n  filtro\n][\n  , otra_col := otro_calculo()\n]\n\n\n4.6.3 3. Optimizaci√≥n de Performance\n\n\n# ‚úÖ HACER: Filtrar temprano para reducir datos\ndatos[\n  filtro_restrictivo               # Reduce datos primero\n][\n  calculo_costoso(), by = grupo    # Luego opera en menos datos\n]\n\n# ‚ùå EVITAR: C√°lculos costosos antes de filtrar\ndatos[\n  calculo_costoso(), by = grupo    # Opera en todos los datos\n][\n  filtro_restrictivo               # Filtra despu√©s\n]\n\n# ‚úÖ HACER: Usar .SDcols para limitar columnas en operaciones costosas\ndatos[\n  filtro\n][\n  , lapply(.SD, operacion_costosa), by = grupo, .SDcols = columnas_necesarias\n]\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nEl encadenamiento hace el c√≥digo m√°s conciso y eficiente al eliminar variables temporales\n\nCada [...] opera sobre el resultado del anterior, creando un flujo l√≥gico claro\n\nPerformance: data.table chaining es m√°s r√°pido que dplyr pipes para la mayor√≠a de operaciones\n\nLegibilidad: Usar l√≠neas separadas y comentarios para encadenamientos complejos\n\nDebugging: Insertar {} para inspeccionar resultados intermedios\n\nFiltrar temprano para optimizar performance en cadenas largas\n\n\n\nEl encadenamiento es una t√©cnica fundamental que, una vez dominada, hace que tu c√≥digo data.table sea m√°s elegante y eficiente. En el pr√≥ximo cap√≠tulo exploraremos c√≥mo combinar m√∫ltiples tablas usando joins.",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>4</span>¬† <span class='chapter-title'>Encadenamiento de Operaciones (Chaining)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html",
    "href": "cap02-joins.html",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "",
    "text": "5.1 Fundamentos de Joins en data.table\ndata.table ofrece m√∫ltiples m√©todos para realizar joins, cada uno optimizado para diferentes casos de uso. La elecci√≥n del m√©todo correcto puede marcar la diferencia entre segundos y minutos en datasets grandes.",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#fundamentos-de-joins-en-data.table",
    "href": "cap02-joins.html#fundamentos-de-joins-en-data.table",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "",
    "text": "5.1.1 1. Tipos de Joins: Conceptos B√°sicos\n\n\n# Mostrar las tablas base\ncat(\"=== EMPLEADOS ===\\n\")\n#&gt; === EMPLEADOS ===\nprint(empleados[1:5, .(emp_id, nombre, departamento_id, salario)])\n#&gt;    emp_id     nombre departamento_id salario\n#&gt;     &lt;int&gt;     &lt;char&gt;           &lt;int&gt;   &lt;num&gt;\n#&gt; 1:      1 Empleado_A               2   39500\n#&gt; 2:      2 Empleado_B               5   62200\n#&gt; 3:      3 Empleado_C               5   69000\n#&gt; 4:      4 Empleado_D               4   66900\n#&gt; 5:      5 Empleado_E               1   46700\n\ncat(\"\\n=== DEPARTAMENTOS ===\\n\") \n#&gt; \n#&gt; === DEPARTAMENTOS ===\nprint(departamentos[, .(dept_id, nombre_dept, ubicacion)])\n#&gt;    dept_id nombre_dept ubicacion\n#&gt;      &lt;int&gt;      &lt;char&gt;    &lt;char&gt;\n#&gt; 1:       1  Ingenier√≠a    Madrid\n#&gt; 2:       2      Ventas Barcelona\n#&gt; 3:       3   Marketing   Sevilla\n#&gt; 4:       4        RRHH  Valencia\n#&gt; 5:       5    Finanzas    Bilbao\n\ncat(\"\\n=== EVALUACIONES (parcial) ===\\n\")\n#&gt; \n#&gt; === EVALUACIONES (parcial) ===\nprint(evaluaciones[1:5, .(empleado_id, puntuacion, fecha_evaluacion)])\n#&gt;    empleado_id puntuacion fecha_evaluacion\n#&gt;          &lt;int&gt;      &lt;num&gt;           &lt;Date&gt;\n#&gt; 1:           2        3.8       2023-12-22\n#&gt; 2:          15        4.3       2023-12-01\n#&gt; 3:          14        4.1       2023-12-22\n#&gt; 4:           7        4.8       2024-02-09\n#&gt; 5:           4        4.1       2023-12-15",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#joins-con-merge-el-m√©todo-tradicional",
    "href": "cap02-joins.html#joins-con-merge-el-m√©todo-tradicional",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.2 Joins con merge(): El M√©todo Tradicional",
    "text": "5.2 Joins con merge(): El M√©todo Tradicional\nLa funci√≥n merge() es familiar para usuarios de R base y ofrece una sintaxis clara para joins simples.\n\n5.2.1 1. Inner Join B√°sico\n\n\n# Inner join: solo registros que existen en ambas tablas\nempleados_con_dept &lt;- merge(empleados, departamentos, \n                           by.x = \"departamento_id\", by.y = \"dept_id\")\n\ncat(\"Empleados con informaci√≥n de departamento (Inner Join):\\n\")\n#&gt; Empleados con informaci√≥n de departamento (Inner Join):\nprint(empleados_con_dept[1:6, .(nombre, nombre_dept, salario, ubicacion)])\n#&gt;        nombre nombre_dept salario ubicacion\n#&gt;        &lt;char&gt;      &lt;char&gt;   &lt;num&gt;    &lt;char&gt;\n#&gt; 1: Empleado_E  Ingenier√≠a   46700    Madrid\n#&gt; 2: Empleado_G  Ingenier√≠a   67600    Madrid\n#&gt; 3: Empleado_A      Ventas   39500 Barcelona\n#&gt; 4: Empleado_H      Ventas   35000 Barcelona\n#&gt; 5: Empleado_I      Ventas   35800 Barcelona\n#&gt; 6: Empleado_N      Ventas   62000 Barcelona\n\n\n5.2.2 2. Todos los Tipos de Joins con merge()\n\n\n# Comparar diferentes tipos de joins\ninner_join &lt;- merge(empleados, evaluaciones, \n                   by.x = \"emp_id\", by.y = \"empleado_id\")\ncat(\"Inner join (empleados con evaluaci√≥n):\", nrow(inner_join), \"filas\\n\")\n#&gt; Inner join (empleados con evaluaci√≥n): 12 filas\n\nleft_join &lt;- merge(empleados, evaluaciones, \n                  by.x = \"emp_id\", by.y = \"empleado_id\", all.x = TRUE)\ncat(\"Left join (todos los empleados):\", nrow(left_join), \"filas\\n\")\n#&gt; Left join (todos los empleados): 19 filas\n\nright_join &lt;- merge(empleados, evaluaciones, \n                   by.x = \"emp_id\", by.y = \"empleado_id\", all.y = TRUE)\ncat(\"Right join (todas las evaluaciones):\", nrow(right_join), \"filas\\n\")\n#&gt; Right join (todas las evaluaciones): 12 filas\n\nfull_join &lt;- merge(empleados, evaluaciones, \n                  by.x = \"emp_id\", by.y = \"empleado_id\", all = TRUE)\ncat(\"Full join (empleados + evaluaciones):\", nrow(full_join), \"filas\\n\")\n#&gt; Full join (empleados + evaluaciones): 19 filas\n\n# Mostrar ejemplo de left join\nprint(left_join[1:8, .(nombre, nivel, puntuacion, fecha_evaluacion)])\n#&gt;        nombre  nivel puntuacion fecha_evaluacion\n#&gt;        &lt;char&gt; &lt;char&gt;      &lt;num&gt;           &lt;Date&gt;\n#&gt; 1: Empleado_A Senior         NA             &lt;NA&gt;\n#&gt; 2: Empleado_B Junior        3.8       2023-12-22\n#&gt; 3: Empleado_B Junior        4.6       2023-12-08\n#&gt; 4: Empleado_C Senior        3.4       2023-12-15\n#&gt; 5: Empleado_D Junior        4.1       2023-12-15\n#&gt; 6: Empleado_E   Lead         NA             &lt;NA&gt;\n#&gt; 7: Empleado_F   Lead         NA             &lt;NA&gt;\n#&gt; 8: Empleado_G   Lead        4.8       2024-02-09\n\n\n5.2.3 3. Joins por M√∫ltiples Columnas\n\n\n# Crear tabla de ejemplo con m√∫ltiples keys\nhistorico_salarios &lt;- data.table(\n  empleado_id = rep(c(1, 2, 3), each = 2),\n  departamento_id = rep(c(1, 2, 1), each = 2),\n  a√±o = rep(c(2023, 2024), times = 3),\n  salario_historico = c(40000, 42000, 45000, 47000, 38000, 40000)\n)\n\n# Join por m√∫ltiples columnas\njoin_multiple &lt;- merge(empleados[1:3, .(emp_id, nombre, departamento_id)], \n                      historico_salarios, \n                      by.x = c(\"emp_id\", \"departamento_id\"), \n                      by.y = c(\"empleado_id\", \"departamento_id\"))\n\nprint(join_multiple)\n#&gt; data.table vac√≠a (0 filas y 5 columnas): emp_id,departamento_id,nombre,a√±o,salario_historico",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#joins-optimizados-con-setkey",
    "href": "cap02-joins.html#joins-optimizados-con-setkey",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.3 Joins Optimizados con setkey()\n",
    "text": "5.3 Joins Optimizados con setkey()\n\nPara datasets grandes y joins repetitivos, establecer keys proporciona un rendimiento excepcional.\n\n5.3.1 1. Estableciendo Keys y Sintaxis X[Y]\n\n\n# Hacer copias para no modificar originales\nemp_key &lt;- copy(empleados)\ndept_key &lt;- copy(departamentos)\n\n# Establecer keys (ordena f√≠sicamente las tablas)\nsetkey(emp_key, departamento_id)\nsetkey(dept_key, dept_id)\n\n# Verificar que las keys est√°n establecidas\ncat(\"Key de empleados:\", key(emp_key), \"\\n\")\n#&gt; Key de empleados: departamento_id\ncat(\"Key de departamentos:\", key(dept_key), \"\\n\")\n#&gt; Key de departamentos: dept_id\n\n# Join ultra-r√°pido con sintaxis X[Y]\nresultado_key_join &lt;- dept_key[emp_key]\n\nprint(resultado_key_join[1:6, .(nombre, nombre_dept, salario, presupuesto)])\n#&gt;        nombre nombre_dept salario presupuesto\n#&gt;        &lt;char&gt;      &lt;char&gt;   &lt;num&gt;       &lt;num&gt;\n#&gt; 1: Empleado_E  Ingenier√≠a   46700       8e+05\n#&gt; 2: Empleado_G  Ingenier√≠a   67600       8e+05\n#&gt; 3: Empleado_A      Ventas   39500       6e+05\n#&gt; 4: Empleado_H      Ventas   35000       6e+05\n#&gt; 5: Empleado_I      Ventas   35800       6e+05\n#&gt; 6: Empleado_N      Ventas   62000       6e+05\n\n\n5.3.2 2. Ventajas de las Keys\n\n\n# Las tablas con key est√°n ordenadas f√≠sicamente\ncat(\"Empleados ordenados por departamento_id:\\n\")\n#&gt; Empleados ordenados por departamento_id:\nprint(emp_key[, .(emp_id, nombre, departamento_id)])\n#&gt; Clave &lt;departamento_id&gt;\n#&gt;     emp_id     nombre departamento_id\n#&gt;      &lt;int&gt;     &lt;char&gt;           &lt;int&gt;\n#&gt;  1:      5 Empleado_E               1\n#&gt;  2:      7 Empleado_G               1\n#&gt;  3:      1 Empleado_A               2\n#&gt;  4:      8 Empleado_H               2\n#&gt;  5:      9 Empleado_I               2\n#&gt; ---                                  \n#&gt; 11:      2 Empleado_B               5\n#&gt; 12:      3 Empleado_C               5\n#&gt; 13:      6 Empleado_F               5\n#&gt; 14:     10 Empleado_J               5\n#&gt; 15:     12 Empleado_L               5\n\ncat(\"\\nDepartamentos ordenados por dept_id:\\n\") \n#&gt; \n#&gt; Departamentos ordenados por dept_id:\nprint(dept_key[, .(dept_id, nombre_dept)])\n#&gt; Clave &lt;dept_id&gt;\n#&gt;    dept_id nombre_dept\n#&gt;      &lt;int&gt;      &lt;char&gt;\n#&gt; 1:       1  Ingenier√≠a\n#&gt; 2:       2      Ventas\n#&gt; 3:       3   Marketing\n#&gt; 4:       4        RRHH\n#&gt; 5:       5    Finanzas\n\n# Acceso ultra-r√°pido por key\ndepartamento_2 &lt;- dept_key[2]  # Busca dept_id == 2\nempleados_dept_2 &lt;- emp_key[2]  # Busca departamento_id == 2\n\ncat(\"\\nEmpleados del departamento 2:\\n\")\n#&gt; \n#&gt; Empleados del departamento 2:\nprint(empleados_dept_2[, .(nombre, nivel, salario)])\n#&gt;        nombre  nivel salario\n#&gt;        &lt;char&gt; &lt;char&gt;   &lt;num&gt;\n#&gt; 1: Empleado_G   Lead   67600\n\n\n5.3.3 3. M√∫ltiples Keys\n\n\n# Establecer m√∫ltiples columnas como key\nsetkey(asignaciones, empleado_id, proyecto_id)\n\n# Buscar por key compuesta\nasignacion_especifica &lt;- asignaciones[.(1, 2)]  # empleado 1, proyecto 2\nprint(asignacion_especifica)\n#&gt; Clave &lt;empleado_id, proyecto_id&gt;\n#&gt;    asignacion_id empleado_id proyecto_id horas_asignadas fecha_asignacion\n#&gt;            &lt;int&gt;       &lt;int&gt;       &lt;int&gt;           &lt;int&gt;           &lt;Date&gt;\n#&gt; 1:            NA           1           2              NA             &lt;NA&gt;\n#&gt;    rol_proyecto\n#&gt;          &lt;char&gt;\n#&gt; 1:         &lt;NA&gt;\n\n# B√∫squedas parciales\nasignaciones_emp_1 &lt;- asignaciones[.(1)]  # Solo empleado 1\ncat(\"Asignaciones del empleado 1:\", nrow(asignaciones_emp_1), \"proyectos\\n\")\n#&gt; Asignaciones del empleado 1: 3 proyectos",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#sintaxis-on-joins-flexibles-sin-keys",
    "href": "cap02-joins.html#sintaxis-on-joins-flexibles-sin-keys",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.4 Sintaxis on: Joins Flexibles sin Keys",
    "text": "5.4 Sintaxis on: Joins Flexibles sin Keys\nLa sintaxis on permite joins puntuales sin necesidad de establecer keys.\n\n5.4.1 1. Join B√°sico con on\n\n\n# Join sin modificar las tablas originales\nresultado_on &lt;- empleados[departamentos, on = .(departamento_id = dept_id)]\n\nprint(resultado_on[1:6, .(nombre, nombre_dept, salario, ubicacion)])\n#&gt;        nombre nombre_dept salario ubicacion\n#&gt;        &lt;char&gt;      &lt;char&gt;   &lt;num&gt;    &lt;char&gt;\n#&gt; 1: Empleado_E  Ingenier√≠a   46700    Madrid\n#&gt; 2: Empleado_G  Ingenier√≠a   67600    Madrid\n#&gt; 3: Empleado_A      Ventas   39500 Barcelona\n#&gt; 4: Empleado_H      Ventas   35000 Barcelona\n#&gt; 5: Empleado_I      Ventas   35800 Barcelona\n#&gt; 6: Empleado_N      Ventas   62000 Barcelona\n\n\n5.4.2 2. Join con Renombrado de Columnas\n\n\n# Join con selecci√≥n y renombrado\nempleados_completo &lt;- empleados[\n  departamentos, \n  on = .(departamento_id = dept_id)\n][\n  , .(\n    empleado = nombre,\n    departamento = nombre_dept, \n    salario,\n    presupuesto_dept = presupuesto,\n    ubicacion,\n    ratio_salario_presupuesto = round(salario / presupuesto * 100, 3)\n  )\n]\n\nprint(empleados_completo[order(-ratio_salario_presupuesto)][1:6])\n#&gt;      empleado departamento salario presupuesto_dept ubicacion\n#&gt;        &lt;char&gt;       &lt;char&gt;   &lt;num&gt;            &lt;num&gt;    &lt;char&gt;\n#&gt; 1: Empleado_M         RRHH   73900            3e+05  Valencia\n#&gt; 2: Empleado_D         RRHH   66900            3e+05  Valencia\n#&gt; 3: Empleado_C     Finanzas   69000            5e+05    Bilbao\n#&gt; 4: Empleado_B     Finanzas   62200            5e+05    Bilbao\n#&gt; 5: Empleado_F     Finanzas   59600            5e+05    Bilbao\n#&gt; 6: Empleado_K    Marketing   46600            4e+05   Sevilla\n#&gt;    ratio_salario_presupuesto\n#&gt;                        &lt;num&gt;\n#&gt; 1:                    24.633\n#&gt; 2:                    22.300\n#&gt; 3:                    13.800\n#&gt; 4:                    12.440\n#&gt; 5:                    11.920\n#&gt; 6:                    11.650\n\n\n5.4.3 3. Joins con Condiciones Adicionales\n\n\n# Join con filtro simult√°neo\nempleados_evaluados_reciente &lt;- empleados[\n  evaluaciones[fecha_evaluacion &gt;= \"2024-01-01\"], \n  on = .(emp_id = empleado_id)\n][\n  !is.na(puntuacion)  # Solo empleados con evaluaci√≥n\n][\n  , .(nombre, nivel, puntuacion, fecha_evaluacion)\n][\n  order(-puntuacion)\n]\n\nprint(empleados_evaluados_reciente)\n#&gt;        nombre  nivel puntuacion fecha_evaluacion\n#&gt;        &lt;char&gt; &lt;char&gt;      &lt;num&gt;           &lt;Date&gt;\n#&gt; 1: Empleado_G   Lead        4.8       2024-02-09\n#&gt; 2: Empleado_M Senior        4.8       2024-02-09\n#&gt; 3: Empleado_O   Lead        4.6       2024-01-19\n#&gt; 4: Empleado_O   Lead        3.7       2024-02-16",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#update-joins-la-caracter√≠stica-estrella",
    "href": "cap02-joins.html#update-joins-la-caracter√≠stica-estrella",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.5 Update Joins: La Caracter√≠stica Estrella",
    "text": "5.5 Update Joins: La Caracter√≠stica Estrella\nLos update joins permiten modificar una tabla bas√°ndose en valores de otra tabla de forma eficiente.\n\n5.5.1 1. Update Join B√°sico\n\n\n# Crear tabla de bonos\nbonos_dept &lt;- data.table(\n  dept_id = 1:5,\n  bono_porcentaje = c(0.15, 0.20, 0.12, 0.18, 0.16),\n  bono_fijo = c(5000, 7000, 4000, 6000, 5500)\n)\n\n# Hacer copia para update join\nemp_con_bonus &lt;- copy(empleados)\n\n# Update join: agregar columnas basadas en departamento\nemp_con_bonus[bonos_dept, on = .(departamento_id = dept_id), \n              `:=`(\n                bono_porcentaje = i.bono_porcentaje,\n                bono_calculado = salario * i.bono_porcentaje + i.bono_fijo\n              )]\n\nprint(emp_con_bonus[1:6, .(nombre, departamento_id, salario, bono_porcentaje, bono_calculado)])\n#&gt;        nombre departamento_id salario bono_porcentaje bono_calculado\n#&gt;        &lt;char&gt;           &lt;int&gt;   &lt;num&gt;           &lt;num&gt;          &lt;num&gt;\n#&gt; 1: Empleado_A               2   39500            0.20          14900\n#&gt; 2: Empleado_B               5   62200            0.16          15452\n#&gt; 3: Empleado_C               5   69000            0.16          16540\n#&gt; 4: Empleado_D               4   66900            0.18          18042\n#&gt; 5: Empleado_E               1   46700            0.15          12005\n#&gt; 6: Empleado_F               5   59600            0.16          15036\n\n\n5.5.2 2. Update Join Condicional\n\n\n# Update join solo para ciertos empleados\nemp_con_bonus[bonos_dept, on = .(departamento_id = dept_id), \n              bono_extra := ifelse(i.bono_porcentaje &gt; 0.15 & salario &gt; 50000, \n                                  2000, 0)]\n\nprint(emp_con_bonus[bono_extra &gt; 0, .(nombre, departamento_id, salario, bono_extra)])\n#&gt;        nombre departamento_id salario bono_extra\n#&gt;        &lt;char&gt;           &lt;int&gt;   &lt;num&gt;      &lt;num&gt;\n#&gt; 1: Empleado_B               5   62200       2000\n#&gt; 2: Empleado_C               5   69000       2000\n#&gt; 3: Empleado_D               4   66900       2000\n#&gt; 4: Empleado_F               5   59600       2000\n#&gt; 5: Empleado_J               5   52600       2000\n#&gt; 6: Empleado_M               4   73900       2000\n#&gt; 7: Empleado_N               2   62000       2000\n#&gt; 8: Empleado_O               2   62200       2000\n\n\n5.5.3 3. Update Join con Agregaciones\n\n\n# Calcular estad√≠sticas por departamento\nstats_dept &lt;- empleados[, .(\n  empleados_count = .N,\n  salario_promedio_dept = round(mean(salario), 0),\n  salario_max_dept = max(salario)\n), by = departamento_id]\n\n# Update join con estad√≠sticas\nemp_con_bonus[stats_dept, on = .(departamento_id), \n              `:=`(\n                empleados_en_dept = i.empleados_count,\n                percentil_en_dept = round(salario / i.salario_max_dept * 100, 1),\n                vs_promedio_dept = salario - i.salario_promedio_dept\n              )]\n\nprint(emp_con_bonus[1:8, .(nombre, departamento_id, salario, empleados_en_dept, \n                           percentil_en_dept, vs_promedio_dept)])\n#&gt;        nombre departamento_id salario empleados_en_dept percentil_en_dept\n#&gt;        &lt;char&gt;           &lt;int&gt;   &lt;num&gt;             &lt;int&gt;             &lt;num&gt;\n#&gt; 1: Empleado_A               2   39500                 5              63.5\n#&gt; 2: Empleado_B               5   62200                 5              90.1\n#&gt; 3: Empleado_C               5   69000                 5             100.0\n#&gt; 4: Empleado_D               4   66900                 2              90.5\n#&gt; 5: Empleado_E               1   46700                 2              69.1\n#&gt; 6: Empleado_F               5   59600                 5              86.4\n#&gt; 7: Empleado_G               1   67600                 2             100.0\n#&gt; 8: Empleado_H               2   35000                 5              56.3\n#&gt;    vs_promedio_dept\n#&gt;               &lt;num&gt;\n#&gt; 1:            -7400\n#&gt; 2:             5120\n#&gt; 3:            11920\n#&gt; 4:            -3500\n#&gt; 5:           -10450\n#&gt; 6:             2520\n#&gt; 7:            10450\n#&gt; 8:           -11900",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#joins-m√∫ltiples-y-encadenamiento",
    "href": "cap02-joins.html#joins-m√∫ltiples-y-encadenamiento",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.6 Joins M√∫ltiples y Encadenamiento",
    "text": "5.6 Joins M√∫ltiples y Encadenamiento\nCombinando m√∫ltiples tablas en operaciones complejas.\n\n5.6.1 1. Joins Encadenados\n\n\n# Pipeline complejo: empleados -&gt; departamentos -&gt; proyectos -&gt; evaluaciones\nanalisis_completo &lt;- empleados[\n  departamentos, on = .(departamento_id = dept_id)        # Join 1: empleados + departamentos\n][\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE  # Join 2: + asignaciones\n][\n  proyectos, on = .(proyecto_id), allow.cartesian = TRUE   # Join 3: + proyectos  \n][\n  evaluaciones, on = .(emp_id = empleado_id)               # Join 4: + evaluaciones\n][\n  !is.na(puntuacion)                                       # Solo empleados evaluados\n][\n  , .(\n    empleado = nombre,\n    departamento = nombre_dept,\n    proyecto = nombre_proyecto,\n    horas_asignadas,\n    rol_proyecto,\n    puntuacion,\n    salario,\n    presupuesto_proyecto\n  )\n][\n  order(empleado, proyecto)\n]\n\nprint(head(analisis_completo, 10))\n#&gt;       empleado departamento   proyecto horas_asignadas rol_proyecto puntuacion\n#&gt;         &lt;char&gt;       &lt;char&gt;     &lt;char&gt;           &lt;int&gt;       &lt;char&gt;      &lt;num&gt;\n#&gt;  1: Empleado_B     Finanzas Proyecto_G              39        L√≠der        3.8\n#&gt;  2: Empleado_B     Finanzas Proyecto_G              39        L√≠der        4.6\n#&gt;  3: Empleado_B     Finanzas Proyecto_H              37       Tester        3.8\n#&gt;  4: Empleado_B     Finanzas Proyecto_H              37       Tester        4.6\n#&gt;  5: Empleado_B     Finanzas Proyecto_J              14       Tester        3.8\n#&gt;  6: Empleado_B     Finanzas Proyecto_J              14       Tester        4.6\n#&gt;  7: Empleado_B     Finanzas Proyecto_L              21     Analista        3.8\n#&gt;  8: Empleado_B     Finanzas Proyecto_L              21     Analista        4.6\n#&gt;  9: Empleado_C     Finanzas Proyecto_L              16        L√≠der        3.4\n#&gt; 10: Empleado_D         RRHH Proyecto_A              36     Analista        4.1\n#&gt;     salario presupuesto_proyecto\n#&gt;       &lt;num&gt;                &lt;num&gt;\n#&gt;  1:   62200               276000\n#&gt;  2:   62200               276000\n#&gt;  3:   62200               260000\n#&gt;  4:   62200               260000\n#&gt;  5:   62200               172000\n#&gt;  6:   62200               172000\n#&gt;  7:   62200               286000\n#&gt;  8:   62200               286000\n#&gt;  9:   69000               286000\n#&gt; 10:   66900               251000\n\n\n5.6.2 2. Agregaciones Complejas con M√∫ltiples Joins\n\n\n# An√°lisis de productividad por departamento\nproductividad_dept &lt;- empleados[\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE\n][\n  proyectos, on = .(proyecto_id)\n][\n  departamentos, on = .(departamento_id = dept_id)\n][\n  , .(\n    empleados_√∫nicos = uniqueN(emp_id),\n    proyectos_√∫nicos = uniqueN(proyecto_id),\n    horas_totales = sum(horas_asignadas),\n    presupuesto_total = sum(presupuesto_proyecto),\n    proyectos_completados = sum(estado == \"Completado\")\n  ), by = .(departamento_id, nombre_dept)\n][\n  , `:=`(\n    horas_por_empleado = round(horas_totales / empleados_√∫nicos, 1),\n    proyectos_por_empleado = round(proyectos_√∫nicos / empleados_√∫nicos, 2),\n    tasa_completaci√≥n = round(proyectos_completados / proyectos_√∫nicos * 100, 1)\n  )\n][\n  order(-tasa_completaci√≥n)\n]\n\nprint(productividad_dept)\n#&gt;    departamento_id nombre_dept empleados_√∫nicos proyectos_√∫nicos horas_totales\n#&gt;              &lt;int&gt;      &lt;char&gt;            &lt;int&gt;            &lt;int&gt;         &lt;int&gt;\n#&gt; 1:               2      Ventas                5                6           257\n#&gt; 2:               5    Finanzas                5                6           186\n#&gt; 3:               1  Ingenier√≠a                2                4            82\n#&gt; 4:               4        RRHH                2                2            71\n#&gt; 5:               3   Marketing                1                1            NA\n#&gt;    presupuesto_total proyectos_completados horas_por_empleado\n#&gt;                &lt;num&gt;                 &lt;int&gt;              &lt;num&gt;\n#&gt; 1:           1748000                     4               51.4\n#&gt; 2:           1902000                     2               37.2\n#&gt; 3:            894000                     1               41.0\n#&gt; 4:            323000                     0               35.5\n#&gt; 5:                NA                    NA                 NA\n#&gt;    proyectos_por_empleado tasa_completaci√≥n\n#&gt;                     &lt;num&gt;             &lt;num&gt;\n#&gt; 1:                    1.2              66.7\n#&gt; 2:                    1.2              33.3\n#&gt; 3:                    2.0              25.0\n#&gt; 4:                    1.0               0.0\n#&gt; 5:                    1.0                NA",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#casos-especiales-joins-con-diferentes-estructuras",
    "href": "cap02-joins.html#casos-especiales-joins-con-diferentes-estructuras",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.7 Casos Especiales: Joins con Diferentes Estructuras",
    "text": "5.7 Casos Especiales: Joins con Diferentes Estructuras\n\n5.7.1 1. Self-Joins: Jerarqu√≠as\n\n\n# Self-join para obtener informaci√≥n de managers\nempleados_con_manager &lt;- empleados[\n  empleados[, .(manager_emp_id = emp_id, manager_nombre = nombre, manager_nivel = nivel)], \n  on = .(manager_id = manager_emp_id)\n][\n  , .(empleado = nombre, nivel, salario, \n      manager = manager_nombre, manager_nivel)\n][\n  !is.na(manager)  # Solo empleados con manager\n][\n  order(manager, empleado)\n]\n\nprint(empleados_con_manager)\n#&gt;       empleado  nivel salario    manager manager_nivel\n#&gt;         &lt;char&gt; &lt;char&gt;   &lt;num&gt;     &lt;char&gt;        &lt;char&gt;\n#&gt;  1: Empleado_B Junior   62200 Empleado_A        Senior\n#&gt;  2: Empleado_C Senior   69000 Empleado_A        Senior\n#&gt;  3:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_B        Junior\n#&gt;  4:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_C        Senior\n#&gt;  5: Empleado_E   Lead   46700 Empleado_D        Junior\n#&gt; ---                                                   \n#&gt; 14: Empleado_L Senior   42000 Empleado_K        Junior\n#&gt; 15:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_L        Senior\n#&gt; 16: Empleado_N Junior   62000 Empleado_M        Senior\n#&gt; 17: Empleado_O   Lead   62200 Empleado_N        Junior\n#&gt; 18:       &lt;NA&gt;   &lt;NA&gt;      NA Empleado_O          Lead\n\n\n5.7.2 2. Many-to-Many Joins\n\n\n# An√°lisis de empleados en m√∫ltiples proyectos\nempleados_multiproyecto &lt;- asignaciones[, .N, by = empleado_id][N &gt; 1]\n\ndetalle_multiproyecto &lt;- empleados[empleados_multiproyecto, on = .(emp_id = empleado_id)][\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE\n][\n  proyectos, on = .(proyecto_id)\n][\n  , .(\n    empleado = nombre,\n    nivel,\n    proyecto = nombre_proyecto,\n    horas_asignadas,\n    rol_proyecto,\n    estado_proyecto = estado\n  )\n][\n  order(empleado, proyecto)\n]\n\nprint(head(detalle_multiproyecto, 12))\n#&gt;       empleado  nivel   proyecto horas_asignadas  rol_proyecto estado_proyecto\n#&gt;         &lt;char&gt; &lt;char&gt;     &lt;char&gt;           &lt;int&gt;        &lt;char&gt;          &lt;char&gt;\n#&gt;  1: Empleado_A Senior Proyecto_C              34        Tester      Completado\n#&gt;  2: Empleado_A Senior Proyecto_E              34        Tester         Pausado\n#&gt;  3: Empleado_A Senior Proyecto_J              19      Analista   Planificaci√≥n\n#&gt;  4: Empleado_B Junior Proyecto_G              39         L√≠der      Completado\n#&gt;  5: Empleado_B Junior Proyecto_H              37        Tester        En Curso\n#&gt; ---                                                                           \n#&gt;  8: Empleado_E   Lead Proyecto_G              17         L√≠der      Completado\n#&gt;  9: Empleado_E   Lead Proyecto_H              38         L√≠der        En Curso\n#&gt; 10: Empleado_E   Lead Proyecto_L              10      Analista        En Curso\n#&gt; 11: Empleado_I Junior Proyecto_C              10 Desarrollador      Completado\n#&gt; 12: Empleado_I Junior Proyecto_D              40        Tester        En Curso\n\n# Resumen por empleado\nresumen_multiproyecto &lt;- detalle_multiproyecto[, .(\n  proyectos_total = .N,\n  horas_totales = sum(horas_asignadas),\n  roles_√∫nicos = uniqueN(rol_proyecto),\n  proyectos_completados = sum(estado_proyecto == \"Completado\")\n), by = .(empleado, nivel)][\n  order(-horas_totales)\n]\n\nprint(resumen_multiproyecto)\n#&gt;      empleado  nivel proyectos_total horas_totales roles_√∫nicos\n#&gt;        &lt;char&gt; &lt;char&gt;           &lt;int&gt;         &lt;int&gt;        &lt;int&gt;\n#&gt; 1: Empleado_B Junior               4           111            3\n#&gt; 2: Empleado_A Senior               3            87            2\n#&gt; 3: Empleado_I Junior               3            72            2\n#&gt; 4: Empleado_E   Lead               3            65            2\n#&gt; 5:       &lt;NA&gt;   &lt;NA&gt;              12            NA            5\n#&gt;    proyectos_completados\n#&gt;                    &lt;int&gt;\n#&gt; 1:                     1\n#&gt; 2:                     1\n#&gt; 3:                     1\n#&gt; 4:                     1\n#&gt; 5:                     3",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#comparaci√≥n-de-performance-entre-m√©todos",
    "href": "cap02-joins.html#comparaci√≥n-de-performance-entre-m√©todos",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.8 Comparaci√≥n de Performance entre M√©todos",
    "text": "5.8 Comparaci√≥n de Performance entre M√©todos\n\n# Preparar datasets para benchmark\nclientes_sample &lt;- clientes_info[sample(.N, 500)]\ntrans_sample &lt;- transacciones_grandes[sample(.N, 25000)]\n\n# Copias para diferentes m√©todos\nclientes_key &lt;- copy(clientes_sample)\ntrans_key &lt;- copy(trans_sample)\nsetkey(clientes_key, cliente_id)\nsetkey(trans_key, cliente_id)\n\n# Benchmark de diferentes m√©todos\nbenchmark_joins &lt;- microbenchmark(\n  \"merge()\" = merge(trans_sample, clientes_sample, by = \"cliente_id\"),\n  \"X[Y, on=]\" = trans_sample[clientes_sample, on = .(cliente_id)],\n  \"setkey + X[Y]\" = clientes_key[trans_key],\n  times = 10\n)\n\nprint(benchmark_joins)\n#&gt; Unit: microseconds\n#&gt;           expr    min     lq    mean  median     uq    max neval\n#&gt;        merge() 2345.5 2402.3 2644.50 2508.10 2532.2 4229.3    10\n#&gt;      X[Y, on=] 1337.7 1381.6 1415.98 1421.45 1452.7 1484.1    10\n#&gt;  setkey + X[Y]  978.3 1011.7 1241.62 1037.55 1127.5 2904.0    10\n\n# Mostrar eficiencia relativa\nbenchmark_summary &lt;- as.data.table(summary(benchmark_joins))\nprint(benchmark_summary[, .(expr, median, relative_speed = round(median / min(median), 2))])\n#&gt;             expr  median relative_speed\n#&gt;           &lt;fctr&gt;   &lt;num&gt;          &lt;num&gt;\n#&gt; 1:       merge() 2508.10           2.42\n#&gt; 2:     X[Y, on=] 1421.45           1.37\n#&gt; 3: setkey + X[Y] 1037.55           1.00",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#ejercicios-pr√°cticos",
    "href": "cap02-joins.html#ejercicios-pr√°cticos",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.9 Ejercicios Pr√°cticos",
    "text": "5.9 Ejercicios Pr√°cticos\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 8: Pipeline de Joins Complejo\n\n\n\nUsando las tablas disponibles, crea un an√°lisis que:\n\n\nUna empleados con sus departamentos y evaluaciones\n\nFiltre solo empleados con evaluaci√≥n &gt; 4.0\n\nAgregue informaci√≥n de proyectos asignados\n\nCalcule m√©tricas de productividad por departamento\n\nGenere un ranking de departamentos por performance\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 8\n\n\n\n\n\n\n# Pipeline completo de joins y an√°lisis\nranking_departamentos &lt;- empleados[\n  evaluaciones[puntuacion &gt; 4.0], on = .(emp_id = empleado_id)  # 1. Join + filtro\n][\n  departamentos, on = .(departamento_id = dept_id)              # 2. Agregar info departamental\n][\n  asignaciones, on = .(emp_id = empleado_id), allow.cartesian = TRUE  # 3. Proyectos asignados\n][\n  proyectos, on = .(proyecto_id)                                # 4. Info de proyectos\n][\n  , .(                                                          # 5. M√©tricas por departamento\n    empleados_alto_performance = uniqueN(emp_id),\n    puntuacion_promedio = round(mean(puntuacion), 2),\n    salario_promedio = round(mean(salario), 0),\n    horas_totales_asignadas = sum(horas_asignadas),\n    proyectos_gestionados = uniqueN(proyecto_id),\n    presupuesto_total_proyectos = sum(presupuesto_proyecto),\n    proyectos_completados = sum(estado == \"Completado\"),\n    presupuesto_departamental = first(presupuesto)\n  ), by = .(departamento_id, nombre_dept, ubicacion)\n][\n  , `:=`(                                                      # 6. C√°lculos de productividad\n    horas_por_empleado = round(horas_totales_asignadas / empleados_alto_performance, 1),\n    proyectos_por_empleado = round(proyectos_gestionados / empleados_alto_performance, 2),\n    tasa_completaci√≥n = round(proyectos_completados / proyectos_gestionados * 100, 1),\n    eficiencia_presupuestal = round((proyectos_completados * presupuesto_total_proyectos) / presupuesto_departamental, 2)\n  )\n][\n  , score_performance := round(                                # 7. Score compuesto\n    (puntuacion_promedio * 20) + \n    (tasa_completaci√≥n * 0.5) + \n    (eficiencia_presupuestal * 10), 1\n  )\n][\n  order(-score_performance)                                    # 8. Ranking final\n][\n  , ranking := 1:.N\n]\n\nprint(ranking_departamentos[, .(\n  ranking, nombre_dept, ubicacion, empleados_alto_performance,\n  puntuacion_promedio, tasa_completaci√≥n, eficiencia_presupuestal, score_performance\n)])\n#&gt;    ranking nombre_dept ubicacion empleados_alto_performance puntuacion_promedio\n#&gt;      &lt;int&gt;      &lt;char&gt;    &lt;char&gt;                      &lt;int&gt;               &lt;num&gt;\n#&gt; 1:       1    Finanzas    Bilbao                          2                4.50\n#&gt; 2:       2      Ventas Barcelona                          2                4.33\n#&gt; 3:       3  Ingenier√≠a    Madrid                          1                4.80\n#&gt; 4:       4        RRHH  Valencia                          2                4.45\n#&gt; 5:       5        &lt;NA&gt;      &lt;NA&gt;                          8                  NA\n#&gt;    tasa_completaci√≥n eficiencia_presupuestal score_performance\n#&gt;                &lt;num&gt;                   &lt;num&gt;             &lt;num&gt;\n#&gt; 1:              75.0                    9.28             220.3\n#&gt; 2:              50.0                    1.21             123.7\n#&gt; 3:               0.0                    0.00              96.0\n#&gt; 4:               0.0                    0.00              89.0\n#&gt; 5:              36.4                      NA                NA\n\n# Crear visualizaci√≥n del ranking\ncat(\"\\nüèÜ RANKING DE DEPARTAMENTOS POR PERFORMANCE:\\n\")\n#&gt; \n#&gt; üèÜ RANKING DE DEPARTAMENTOS POR PERFORMANCE:\nfor(i in 1:nrow(ranking_departamentos)) {\n  dept &lt;- ranking_departamentos[i]\n  medal &lt;- ifelse(i == 1, \"ü•á\", ifelse(i == 2, \"ü•à\", ifelse(i == 3, \"ü•â\", paste0(\"#\", i))))\n  cat(sprintf(\"%s %s (%s) - Score: %.1f\\n\", medal, dept$nombre_dept, dept$ubicacion, dept$score_performance))\n  cat(sprintf(\"   ‚Ä¢ %d empleados alto performance, %.1f%% completaci√≥n\\n\", \n              dept$empleados_alto_performance, dept$tasa_completaci√≥n))\n}\n#&gt; ü•á Finanzas (Bilbao) - Score: 220.3\n#&gt;    ‚Ä¢ 2 empleados alto performance, 75.0% completaci√≥n\n#&gt; ü•à Ventas (Barcelona) - Score: 123.7\n#&gt;    ‚Ä¢ 2 empleados alto performance, 50.0% completaci√≥n\n#&gt; ü•â Ingenier√≠a (Madrid) - Score: 96.0\n#&gt;    ‚Ä¢ 1 empleados alto performance, 0.0% completaci√≥n\n#&gt; #4 RRHH (Valencia) - Score: 89.0\n#&gt;    ‚Ä¢ 2 empleados alto performance, 0.0% completaci√≥n\n#&gt; #5 NA (NA) - Score: NA\n#&gt;    ‚Ä¢ 8 empleados alto performance, 36.4% completaci√≥n\n\n\n\n\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 9: Update Joins Avanzados\n\n\n\n\n\nCrea una tabla de ajustes salariales por departamento\n\nUsa update joins para aplicar los ajustes\n\nCalcula el impacto presupuestal por departamento\n\nIdentifica empleados que necesitan reclasificaci√≥n de nivel\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 9\n\n\n\n\n\n\n# 1. Crear tabla de ajustes salariales\najustes_salariales &lt;- data.table(\n  dept_id = 1:5,\n  nombre_dept = c(\"Ingenier√≠a\", \"Ventas\", \"Marketing\", \"RRHH\", \"Finanzas\"),\n  ajuste_porcentaje = c(0.08, 0.12, 0.06, 0.10, 0.07),  # 8%, 12%, 6%, 10%, 7%\n  bono_retencion = c(3000, 5000, 2000, 2500, 4000),\n  criterio_nivel = c(65000, 55000, 45000, 50000, 60000)  # Umbral para nivel Senior+\n)\n\nprint(\"Ajustes salariales por departamento:\")\n#&gt; [1] \"Ajustes salariales por departamento:\"\nprint(ajustes_salariales)\n#&gt;    dept_id nombre_dept ajuste_porcentaje bono_retencion criterio_nivel\n#&gt;      &lt;int&gt;      &lt;char&gt;             &lt;num&gt;          &lt;num&gt;          &lt;num&gt;\n#&gt; 1:       1  Ingenier√≠a              0.08           3000          65000\n#&gt; 2:       2      Ventas              0.12           5000          55000\n#&gt; 3:       3   Marketing              0.06           2000          45000\n#&gt; 4:       4        RRHH              0.10           2500          50000\n#&gt; 5:       5    Finanzas              0.07           4000          60000\n\n# 2. Aplicar ajustes usando update joins\nempleados_ajuste &lt;- copy(empleados)\n\n# Update join principal\nempleados_ajuste[ajustes_salariales, on = .(departamento_id = dept_id),\n                 `:=`(\n                   salario_anterior = salario,\n                   ajuste_pct = i.ajuste_porcentaje,\n                   salario_ajustado = salario * (1 + i.ajuste_porcentaje),\n                   bono_retencion = i.bono_retencion,\n                   umbral_senior = i.criterio_nivel\n                 )]\n\n# Update join condicional para bonos extra\nempleados_ajuste[nivel %in% c(\"Lead\", \"Manager\") & salario_ajustado &gt; 60000, \n                 bono_extra := salario_ajustado * 0.05]\nempleados_ajuste[is.na(bono_extra), bono_extra := 0]\n\n# 3. Calcular impacto presupuestal\nimpacto_presupuestal &lt;- empleados_ajuste[\n  departamentos, on = .(departamento_id = dept_id)\n][\n  , .(\n    empleados = .N,\n    salario_total_anterior = sum(salario_anterior),\n    salario_total_nuevo = sum(salario_ajustado),\n    bonos_retencion = sum(bono_retencion),\n    bonos_extra = sum(bono_extra),\n    presupuesto_dept = first(presupuesto)\n  ), by = .(departamento_id, nombre_dept)\n][\n  , `:=`(\n    incremento_salarial = salario_total_nuevo - salario_total_anterior,\n    costo_total_ajuste = (salario_total_nuevo - salario_total_anterior) + bonos_retencion + bonos_extra,\n    impacto_presupuestal_pct = round(((salario_total_nuevo - salario_total_anterior) + bonos_retencion + bonos_extra) / presupuesto_dept * 100, 2)\n  )\n][\n  order(-costo_total_ajuste)\n]\n\nprint(\"\\n3. Impacto presupuestal por departamento:\")\n#&gt; [1] \"\\n3. Impacto presupuestal por departamento:\"\nprint(impacto_presupuestal[, .(nombre_dept, empleados, incremento_salarial, \n                               costo_total_ajuste, impacto_presupuestal_pct)])\n#&gt;    nombre_dept empleados incremento_salarial costo_total_ajuste\n#&gt;         &lt;char&gt;     &lt;int&gt;               &lt;num&gt;              &lt;num&gt;\n#&gt; 1:      Ventas         5               28140            56623.2\n#&gt; 2:    Finanzas         5               19978            43166.6\n#&gt; 3:        RRHH         2               14080            19080.0\n#&gt; 4:  Ingenier√≠a         2                9144            18794.4\n#&gt; 5:   Marketing         1                2796             4796.0\n#&gt;    impacto_presupuestal_pct\n#&gt;                       &lt;num&gt;\n#&gt; 1:                     9.44\n#&gt; 2:                     8.63\n#&gt; 3:                     6.36\n#&gt; 4:                     2.35\n#&gt; 5:                     1.20\n\n# 4. Identificar empleados para reclasificaci√≥n\nreclasificacion &lt;- empleados_ajuste[, .(\n  nombre,\n  departamento_id,\n  nivel_actual = nivel,\n  salario_ajustado,\n  umbral_senior,\n  necesita_reclasificacion = salario_ajustado &gt;= umbral_senior & nivel == \"Junior\"\n)][necesita_reclasificacion == TRUE]\n\nif(nrow(reclasificacion) &gt; 0) {\n  cat(\"\\n4. Empleados que necesitan reclasificaci√≥n:\\n\")\n  print(reclasificacion[, .(nombre, nivel_actual, salario_ajustado, umbral_senior)])\n} else {\n  cat(\"\\n4. No hay empleados que requieran reclasificaci√≥n inmediata.\\n\")\n}\n#&gt; \n#&gt; 4. Empleados que necesitan reclasificaci√≥n:\n#&gt;        nombre nivel_actual salario_ajustado umbral_senior\n#&gt;        &lt;char&gt;       &lt;char&gt;            &lt;num&gt;         &lt;num&gt;\n#&gt; 1: Empleado_B       Junior            66554         60000\n#&gt; 2: Empleado_D       Junior            73590         50000\n#&gt; 3: Empleado_K       Junior            49396         45000\n#&gt; 4: Empleado_N       Junior            69440         55000\n\n# Resumen ejecutivo\ncat(\"\\nüìä RESUMEN EJECUTIVO DEL AJUSTE SALARIAL:\\n\")\n#&gt; \n#&gt; üìä RESUMEN EJECUTIVO DEL AJUSTE SALARIAL:\ncat(sprintf(\"‚Ä¢ Total empleados afectados: %d\\n\", nrow(empleados_ajuste)))\n#&gt; ‚Ä¢ Total empleados afectados: 15\ncat(sprintf(\"‚Ä¢ Incremento salarial total: $%s\\n\", \n            format(sum(impacto_presupuestal$incremento_salarial), big.mark = \",\")))\n#&gt; ‚Ä¢ Incremento salarial total: $74,138\ncat(sprintf(\"‚Ä¢ Costo total del ajuste: $%s\\n\", \n            format(sum(impacto_presupuestal$costo_total_ajuste), big.mark = \",\")))\n#&gt; ‚Ä¢ Costo total del ajuste: $142,460.2\ncat(sprintf(\"‚Ä¢ Departamento m√°s impactado: %s (%.2f%% del presupuesto)\\n\",\n            impacto_presupuestal[1, nombre_dept], impacto_presupuestal[1, impacto_presupuestal_pct]))\n#&gt; ‚Ä¢ Departamento m√°s impactado: Ventas (9.44% del presupuesto)",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap02-joins.html#mejores-pr√°cticas-para-joins",
    "href": "cap02-joins.html#mejores-pr√°cticas-para-joins",
    "title": "\n5¬† Uniones de Datos (Joins)\n",
    "section": "\n5.10 Mejores Pr√°cticas para Joins",
    "text": "5.10 Mejores Pr√°cticas para Joins\n\n5.10.1 1. Elecci√≥n del M√©todo Adecuado\n\n\n# ‚úÖ Para joins √∫nicos: usar \"on =\"\nresultado &lt;- tabla1[tabla2, on = .(key)]\n\n# ‚úÖ Para joins repetitivos en datos grandes: usar setkey\nsetkey(tabla1, key)\nsetkey(tabla2, key)\nresultado &lt;- tabla2[tabla1]\n\n# ‚úÖ Para an√°lisis exploratorio: usar merge()\nresultado &lt;- merge(tabla1, tabla2, by = \"key\")\n\n# ‚úÖ Para modificar tabla existente: usar update join\ntabla1[tabla2, on = .(key), nueva_col := i.columna]\n\n\n5.10.2 2. Gesti√≥n de Memoria en Joins\n\n\n# ‚úÖ HACER: Filtrar antes de join\ntabla_peque√±a &lt;- tabla_grande[filtro_importante]\nresultado &lt;- tabla_peque√±a[otra_tabla, on = .(key)]\n\n# ‚ùå EVITAR: Join primero, filtrar despu√©s\nresultado &lt;- tabla_grande[otra_tabla, on = .(key)][filtro_importante]\n\n# ‚úÖ HACER: Usar .SDcols para limitar columnas en joins complejos\nresultado &lt;- tabla1[tabla2, on = .(key), .SDcols = columnas_necesarias]\n\n\n5.10.3 3. Troubleshooting de Joins\n\n\n# Diagnosticar problemas de joins\ncat(\"Claves duplicadas en tabla1:\", anyDuplicated(tabla1, by = \"key\"), \"\\n\")\ncat(\"Claves faltantes:\", sum(is.na(tabla1$key)), \"\\n\")\ncat(\"Rango de keys:\", range(tabla1$key, na.rm = TRUE), \"\\n\")\n\n# Verificar resultado de join\ncat(\"Filas antes del join:\", nrow(tabla1), \"\\n\")\ncat(\"Filas despu√©s del join:\", nrow(resultado), \"\\n\")\ncat(\"Columnas agregadas:\", ncol(resultado) - ncol(tabla1), \"\\n\")\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nmerge() es intuitivo para joins simples, setkey() es √≥ptimo para datos grandes\n\nSintaxis on ofrece flexibilidad sin modificar las tablas originales\n\nUpdate joins con := permiten modificar tablas de forma eficiente\n\nLa elecci√≥n del m√©todo depende del tama√±o de datos y frecuencia de uso\n\nFiltrar antes de join mejora significativamente el rendimiento\n\nAlways verify el resultado de joins complejos para evitar cartesian products\n\n\n\n[{‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1-new‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 2: dividir en encadenamiento y joins‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 3: dividir en joins avanzados, funciones especiales y reshape‚Äù, ‚Äústatus‚Äù: ‚Äúin_progress‚Äù, ‚Äúid‚Äù: ‚Äú3‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú4‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú5‚Äù}]",
    "crumbs": [
      "**M√≥dulo 2**: Manipulaci√≥n de Datos Intermedia",
      "<span class='chapter-number'>5</span>¬† <span class='chapter-title'>Uniones de Datos (Joins)</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html",
    "href": "cap03-joins-avanzados.html",
    "title": "\n6¬† Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "",
    "text": "6.1 Non-Equi Joins: M√°s All√° de la Igualdad\nLos non-equi joins permiten unir tablas bas√°ndose en rangos, desigualdades y condiciones complejas. Son especialmente √∫tiles en an√°lisis m√©dico, financiero y clasificaci√≥n por rangos.",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#non-equi-joins-m√°s-all√°-de-la-igualdad",
    "href": "cap03-joins-avanzados.html#non-equi-joins-m√°s-all√°-de-la-igualdad",
    "title": "\n6¬† Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "",
    "text": "6.1.1 1. Conceptos Fundamentales\n\nUn non-equi join utiliza operadores de comparaci√≥n (&lt;=, &gt;=, &lt;, &gt;) en lugar de igualdad (==):\n\n# Ejemplo simple: clasificar pacientes por IMC\nrangos_imc &lt;- rangos_medicos[parametro == \"IMC\"]\nprint(\"Rangos de IMC:\")\n#&gt; [1] \"Rangos de IMC:\"\nprint(rangos_imc)\n#&gt;    parametro valor_min valor_max     categoria nivel_riesgo\n#&gt;       &lt;char&gt;     &lt;num&gt;     &lt;num&gt;        &lt;char&gt;       &lt;char&gt;\n#&gt; 1:       IMC       0.0      18.4   Bajo/Normal         Bajo\n#&gt; 2:       IMC      18.5      24.9 Normal/√ìptimo       Normal\n#&gt; 3:       IMC      25.0       Inf   Alto/Riesgo         Alto\n\n# Non-equi join b√°sico\npacientes_clasificados_imc &lt;- rangos_imc[pacientes_clinica,\n  on = .(valor_min &lt;= imc, valor_max &gt;= imc),\n  .(paciente_id, nombre, imc, categoria, nivel_riesgo)]\n\nprint(\"Pacientes clasificados por IMC:\")\n#&gt; [1] \"Pacientes clasificados por IMC:\"\nprint(head(pacientes_clasificados_imc[order(imc)], 10))\n#&gt;     paciente_id      nombre   imc   categoria nivel_riesgo\n#&gt;           &lt;int&gt;      &lt;char&gt; &lt;num&gt;      &lt;char&gt;       &lt;char&gt;\n#&gt;  1:          69 Paciente_69   8.6 Bajo/Normal         Bajo\n#&gt;  2:           5  Paciente_5  11.2 Bajo/Normal         Bajo\n#&gt;  3:          98 Paciente_98  11.7 Bajo/Normal         Bajo\n#&gt;  4:          57 Paciente_57  12.2 Bajo/Normal         Bajo\n#&gt;  5:          46 Paciente_46  13.1 Bajo/Normal         Bajo\n#&gt;  6:          73 Paciente_73  13.9 Bajo/Normal         Bajo\n#&gt;  7:          66 Paciente_66  14.7 Bajo/Normal         Bajo\n#&gt;  8:          90 Paciente_90  14.7 Bajo/Normal         Bajo\n#&gt;  9:           7  Paciente_7  15.5 Bajo/Normal         Bajo\n#&gt; 10:          65 Paciente_65  15.7 Bajo/Normal         Bajo\n\n\n6.1.2 2. Non-Equi Join con M√∫ltiples Condiciones\n\n\n# Clasificar pacientes por m√∫ltiples par√°metros simult√°neamente\n# Crear funci√≥n auxiliar para clasificar\nclasificar_parametro &lt;- function(dt, param_name, value_col) {\n  rangos &lt;- rangos_medicos[parametro == param_name]\n  resultado &lt;- rangos[dt, on = c(\"valor_min\" = paste0(value_col, \"&gt;=\"), \"valor_max\" = paste0(value_col, \"&lt;=\")),\n                     .(paciente_id, parametro, categoria, nivel_riesgo),\n                     nomatch = NULL]\n  return(resultado)\n}\n\n# Clasificar por glucosa\npacientes_glucosa &lt;- rangos_medicos[parametro == \"Glucosa\"][pacientes_clinica,\n  on = .(valor_min &lt;= glucosa, valor_max &gt;= glucosa),\n  .(paciente_id, parametro = \"Glucosa\", valor = glucosa, categoria, nivel_riesgo)]\n\n# Clasificar por presi√≥n sist√≥lica\npacientes_presion &lt;- rangos_medicos[parametro == \"Presi√≥n\"][pacientes_clinica,\n  on = .(valor_min &lt;= presion_sistolica, valor_max &gt;= presion_sistolica),  \n  .(paciente_id, parametro = \"Presion\", valor = presion_sistolica, categoria, nivel_riesgo)]\n\n# Combinar clasificaciones\ntodas_clasificaciones &lt;- rbind(\n  pacientes_glucosa[!is.na(categoria)],\n  pacientes_presion[!is.na(categoria)]\n)\n\n# Resumen de riesgos por paciente\nresumen_riesgo_pacientes &lt;- todas_clasificaciones[,\n  .(\n    parametros_evaluados = .N,\n    riesgos_altos = sum(nivel_riesgo == \"Alto\"),\n    riesgos_normales = sum(nivel_riesgo == \"Normal\"),\n    clasificacion_general = fcase(\n      sum(nivel_riesgo == \"Alto\") &gt;= 2, \"Alto Riesgo M√∫ltiple\",\n      sum(nivel_riesgo == \"Alto\") == 1, \"Riesgo Moderado\", \n      default = \"Bajo Riesgo\"\n    )\n  ), by = paciente_id]\n\nprint(\"Resumen de riesgos por paciente:\")\n#&gt; [1] \"Resumen de riesgos por paciente:\"\nprint(head(resumen_riesgo_pacientes[order(-riesgos_altos)], 10))\n#&gt;     paciente_id parametros_evaluados riesgos_altos riesgos_normales\n#&gt;           &lt;int&gt;                &lt;int&gt;         &lt;int&gt;            &lt;int&gt;\n#&gt;  1:           1                    2             2                0\n#&gt;  2:           2                    2             2                0\n#&gt;  3:           4                    2             2                0\n#&gt;  4:           8                    2             2                0\n#&gt;  5:           9                    2             2                0\n#&gt;  6:          12                    2             2                0\n#&gt;  7:          16                    2             2                0\n#&gt;  8:          18                    2             2                0\n#&gt;  9:          19                    2             2                0\n#&gt; 10:          20                    2             2                0\n#&gt;     clasificacion_general\n#&gt;                    &lt;char&gt;\n#&gt;  1:  Alto Riesgo M√∫ltiple\n#&gt;  2:  Alto Riesgo M√∫ltiple\n#&gt;  3:  Alto Riesgo M√∫ltiple\n#&gt;  4:  Alto Riesgo M√∫ltiple\n#&gt;  5:  Alto Riesgo M√∫ltiple\n#&gt;  6:  Alto Riesgo M√∫ltiple\n#&gt;  7:  Alto Riesgo M√∫ltiple\n#&gt;  8:  Alto Riesgo M√∫ltiple\n#&gt;  9:  Alto Riesgo M√∫ltiple\n#&gt; 10:  Alto Riesgo M√∫ltiple\n\n\n6.1.3 3. Non-Equi Join para Ventanas Temporales\n\n\n# Encontrar todas las operaciones que ocurrieron dentro de ventanas de eventos\noperaciones_en_ventanas &lt;- eventos_mercado[operaciones_trading,\n  on = .(ticker_afectado = ticker,\n         fecha_inicio_ventana &lt;= fecha_operacion,\n         fecha_fin_ventana &gt;= fecha_operacion),\n  .(evento_id, tipo_evento, fecha_evento, impacto_esperado,\n    operacion_id, fecha_operacion, tipo, cantidad, precio_limite),\n  nomatch = NULL]\n\n# An√°lisis de comportamiento en ventanas de eventos\ncomportamiento_eventos &lt;- operaciones_en_ventanas[,\n  .(\n    operaciones_total = .N,\n    operaciones_compra = sum(tipo == \"COMPRA\"),\n    operaciones_venta = sum(tipo == \"VENTA\"),\n    volumen_total = sum(cantidad),\n    precio_promedio = round(mean(precio_limite), 2),\n    dias_promedio_evento = round(mean(as.numeric(abs(fecha_operacion - fecha_evento))), 1)\n  ), by = .(tipo_evento, impacto_esperado)]\n\nprint(\"Comportamiento de trading en ventanas de eventos:\")\n#&gt; [1] \"Comportamiento de trading en ventanas de eventos:\"\nprint(comportamiento_eventos[order(-volumen_total)])\n#&gt;       tipo_evento impacto_esperado operaciones_total operaciones_compra\n#&gt;            &lt;char&gt;           &lt;char&gt;             &lt;int&gt;              &lt;int&gt;\n#&gt; 1:       Earnings         Positivo                 7                  4\n#&gt; 2:       Earnings           Neutro                 9                  7\n#&gt; 3:         Merger         Positivo                 8                  4\n#&gt; 4:   FDA_Approval         Positivo                 7                  3\n#&gt; 5:   FDA_Approval           Neutro                 5                  5\n#&gt; 6:          Split         Positivo                 6                  3\n#&gt; 7:         Merger           Neutro                 1                  1\n#&gt; 8: Product_Launch         Positivo                 2                  0\n#&gt; 9:       Earnings         Negativo                 1                  1\n#&gt;    operaciones_venta volumen_total precio_promedio dias_promedio_evento\n#&gt;                &lt;int&gt;         &lt;num&gt;           &lt;num&gt;                &lt;num&gt;\n#&gt; 1:                 3          5550         1114.30                  3.1\n#&gt; 2:                 2          3150         1407.04                  4.3\n#&gt; 3:                 4          3100         1581.95                  5.1\n#&gt; 4:                 4          2400         1328.23                  3.1\n#&gt; 5:                 0          1950         1803.68                  4.8\n#&gt; 6:                 3          1200         1841.82                  4.8\n#&gt; 7:                 0          1000         2428.78                  2.0\n#&gt; 8:                 2           600         1234.13                  2.0\n#&gt; 9:                 0           500         1804.09                  5.0",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#rolling-joins-la-joya-para-series-temporales",
    "href": "cap03-joins-avanzados.html#rolling-joins-la-joya-para-series-temporales",
    "title": "\n6¬† Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.2 Rolling Joins: La Joya para Series Temporales",
    "text": "6.2 Rolling Joins: La Joya para Series Temporales\nLos rolling joins son perfectos para conectar cada observaci√≥n con el √∫ltimo valor disponible en el tiempo.\n\n6.2.1 1. Rolling Join B√°sico\n\n\n# Preparar datos con keys para rolling join\nprecios_key &lt;- copy(precios_historicos)\noperaciones_key &lt;- copy(operaciones_trading)\n\n# Establecer keys compuestas: ticker + fecha\nsetkey(precios_key, ticker, fecha)\nsetkey(operaciones_key, ticker, fecha_operacion)\n\n# Rolling join: obtener el √∫ltimo precio disponible para cada operaci√≥n\noperaciones_con_precio &lt;- precios_key[operaciones_key, roll = TRUE]\n\n# Verificar estructura del resultado\nprint(\"Columnas disponibles despu√©s del rolling join:\")\n#&gt; [1] \"Columnas disponibles despu√©s del rolling join:\"\nprint(names(operaciones_con_precio))\n#&gt; [1] \"fecha\"         \"ticker\"        \"precio_cierre\" \"volumen\"      \n#&gt; [5] \"operacion_id\"  \"tipo\"          \"cantidad\"      \"precio_limite\"\n#&gt; [9] \"trader_id\"\nprint(\"Primeras filas para entender la estructura:\")\n#&gt; [1] \"Primeras filas para entender la estructura:\"\nprint(head(operaciones_con_precio, 3))\n#&gt; Clave &lt;ticker, fecha&gt;\n#&gt;         fecha ticker precio_cierre  volumen operacion_id   tipo cantidad\n#&gt;        &lt;Date&gt; &lt;char&gt;         &lt;num&gt;    &lt;num&gt;        &lt;int&gt; &lt;char&gt;    &lt;num&gt;\n#&gt; 1: 2024-01-01   AAPL        155.41 15619654          471 COMPRA       50\n#&gt; 2: 2024-01-04   AAPL        157.65 42789129          437 COMPRA      100\n#&gt; 3: 2024-01-06   AAPL        170.90  4219831           37  VENTA       50\n#&gt;    precio_limite trader_id\n#&gt;            &lt;num&gt;    &lt;char&gt;\n#&gt; 1:       1827.71        T5\n#&gt; 2:       2802.78       T18\n#&gt; 3:        971.83        T9\n\n# En un rolling join X[Y], el resultado incluye todas las columnas de Y m√°s las de X\n# Las columnas de la fecha de Y se mantienen, no se prefijan con i.\nprint(\"Operaciones con precios hist√≥ricos (rolling join):\")\n#&gt; [1] \"Operaciones con precios hist√≥ricos (rolling join):\"\nif(\"fecha_operacion\" %in% names(operaciones_con_precio)) {\n  # Si fecha_operacion existe directamente\n  print(head(operaciones_con_precio[, .(ticker, fecha, precio_cierre, \n                                       operacion_id, fecha_operacion, tipo, cantidad)], 10))\n  # Calcular diferencia temporal\n  operaciones_con_precio[, dias_diferencia := as.numeric(fecha_operacion - fecha)]\n} else {\n  # Buscar columnas con fecha en el nombre\n  fecha_cols &lt;- grep(\"fecha\", names(operaciones_con_precio), value = TRUE)\n  print(paste(\"Columnas con 'fecha' encontradas:\", paste(fecha_cols, collapse = \", \")))\n  \n  # Mostrar primeras columnas disponibles\n  print(head(operaciones_con_precio[, 1:min(8, ncol(operaciones_con_precio))], 10))\n}\n#&gt; [1] \"Columnas con 'fecha' encontradas: fecha\"\n#&gt; Clave &lt;ticker, fecha&gt;\n#&gt;          fecha ticker precio_cierre  volumen operacion_id   tipo cantidad\n#&gt;         &lt;Date&gt; &lt;char&gt;         &lt;num&gt;    &lt;num&gt;        &lt;int&gt; &lt;char&gt;    &lt;num&gt;\n#&gt;  1: 2024-01-01   AAPL        155.41 15619654          471 COMPRA       50\n#&gt;  2: 2024-01-04   AAPL        157.65 42789129          437 COMPRA      100\n#&gt;  3: 2024-01-06   AAPL        170.90  4219831           37  VENTA       50\n#&gt;  4: 2024-01-17   AAPL        144.56 22593327          260 COMPRA      100\n#&gt;  5: 2024-01-21   AAPL        136.44 22967352           35 COMPRA      200\n#&gt;  6: 2024-01-25   AAPL        146.15 16764243          362  VENTA     1000\n#&gt;  7: 2024-01-26   AAPL        138.94 25121176          302 COMPRA      100\n#&gt;  8: 2024-01-28   AAPL        142.77  4554781          102 COMPRA      100\n#&gt;  9: 2024-02-01   AAPL        125.12 39017505          135 COMPRA      100\n#&gt; 10: 2024-02-12   AAPL        130.18  3604906          237 COMPRA      200\n#&gt;     precio_limite\n#&gt;             &lt;num&gt;\n#&gt;  1:       1827.71\n#&gt;  2:       2802.78\n#&gt;  3:        971.83\n#&gt;  4:        740.76\n#&gt;  5:        463.55\n#&gt;  6:       1978.25\n#&gt;  7:        758.49\n#&gt;  8:       2694.70\n#&gt;  9:       1218.84\n#&gt; 10:       1558.66\n\n# Estad√≠sticas de la calidad del match (solo si dias_diferencia fue creada)\nif(\"dias_diferencia\" %in% names(operaciones_con_precio)) {\n  cat(\"Estad√≠sticas del rolling join:\\n\")\n  cat(\"‚Ä¢ Operaciones con precio exacto (mismo d√≠a):\", sum(operaciones_con_precio$dias_diferencia == 0, na.rm = TRUE), \"\\n\")\n  cat(\"‚Ä¢ Operaciones con precio de d√≠as anteriores:\", sum(operaciones_con_precio$dias_diferencia &gt; 0, na.rm = TRUE), \"\\n\")\n  cat(\"‚Ä¢ Diferencia promedio en d√≠as:\", round(mean(operaciones_con_precio$dias_diferencia, na.rm = TRUE), 1), \"\\n\")\n} else {\n  cat(\"La variable dias_diferencia no pudo ser creada debido a problemas con las columnas de fecha.\\n\")\n}\n#&gt; La variable dias_diferencia no pudo ser creada debido a problemas con las columnas de fecha.\n\n\n6.2.2 2. Rolling Join con L√≠mites Temporales\n\n\n# Rolling join con l√≠mite: solo usar precios de m√°ximo 7 d√≠as anteriores\noperaciones_precio_limitado &lt;- precios_key[operaciones_key, \n                                          roll = 7,  # m√°ximo 7 d√≠as\n                                          rollends = c(TRUE, TRUE)]\n\n# Comparar con rolling join ilimitado\nmatches_limitado &lt;- sum(!is.na(operaciones_precio_limitado$precio_cierre))\nmatches_ilimitado &lt;- sum(!is.na(operaciones_con_precio$precio_cierre))\n\ncat(\"Comparaci√≥n de rolling joins:\\n\")\n#&gt; Comparaci√≥n de rolling joins:\ncat(\"‚Ä¢ Matches con rolling limitado (7 d√≠as):\", matches_limitado, \"\\n\") \n#&gt; ‚Ä¢ Matches con rolling limitado (7 d√≠as): 111\ncat(\"‚Ä¢ Matches con rolling ilimitado:\", matches_ilimitado, \"\\n\")\n#&gt; ‚Ä¢ Matches con rolling ilimitado: 291\ncat(\"‚Ä¢ Diferencia:\", matches_ilimitado - matches_limitado, \"operaciones\\n\")\n#&gt; ‚Ä¢ Diferencia: 180 operaciones\n\n# Analizar operaciones sin match en rolling limitado\noperaciones_sin_precio &lt;- operaciones_precio_limitado[is.na(precio_cierre)]\nif(nrow(operaciones_sin_precio) &gt; 0) {\n  cat(\"‚Ä¢ Operaciones sin precio (primeros d√≠as del a√±o o fines de semana largos):\", nrow(operaciones_sin_precio), \"\\n\")\n}\n#&gt; ‚Ä¢ Operaciones sin precio (primeros d√≠as del a√±o o fines de semana largos): 389\n\n\n6.2.3 3. Rolling Join Bidireccional (Nearest)\n\n\n# Rolling join \"nearest\": buscar el precio m√°s cercano (antes o despu√©s)\noperaciones_nearest &lt;- precios_key[operaciones_key, roll = \"nearest\"]\n\n# Comparar diferentes tipos de rolling join\ncomparacion_rolling &lt;- data.table(\n  Tipo_Rolling = c(\"Backward (TRUE)\", \"Limited (7 days)\", \"Nearest\"),\n  Matches = c(\n    sum(!is.na(operaciones_con_precio$precio_cierre)),\n    sum(!is.na(operaciones_precio_limitado$precio_cierre)), \n    sum(!is.na(operaciones_nearest$precio_cierre))\n  ),\n  Cobertura_Pct = round(c(\n    mean(!is.na(operaciones_con_precio$precio_cierre)) * 100,\n    mean(!is.na(operaciones_precio_limitado$precio_cierre)) * 100,\n    mean(!is.na(operaciones_nearest$precio_cierre)) * 100\n  ), 1)\n)\n\nprint(\"Comparaci√≥n de tipos de rolling join:\")\n#&gt; [1] \"Comparaci√≥n de tipos de rolling join:\"\nprint(comparacion_rolling)\n#&gt;        Tipo_Rolling Matches Cobertura_Pct\n#&gt;              &lt;char&gt;   &lt;int&gt;         &lt;num&gt;\n#&gt; 1:  Backward (TRUE)     291          58.2\n#&gt; 2: Limited (7 days)     111          22.2\n#&gt; 3:          Nearest     500         100.0\n\n\n6.2.4 4. Rolling Join con Sensores IoT\n\n\n# Caso pr√°ctico: asociar eventos de mantenimiento con lecturas de sensores\nsetkey(sensores_iot, sensor_id, timestamp)\nsetkey(mantenimiento, sensor_id, fecha_mantenimiento)\n\n# Rolling join para obtener la √∫ltima lectura antes del mantenimiento\nlecturas_pre_mantenimiento &lt;- sensores_iot[mantenimiento, roll = TRUE]\n\n# Verificar estructura del resultado\nprint(\"Columnas disponibles despu√©s del rolling join de sensores:\")\n#&gt; [1] \"Columnas disponibles despu√©s del rolling join de sensores:\"\nprint(names(lecturas_pre_mantenimiento))\n#&gt; [1] \"timestamp\"          \"sensor_id\"          \"valor\"             \n#&gt; [4] \"ubicacion\"          \"mantenimiento_id\"   \"tipo_mantenimiento\"\n#&gt; [7] \"duracion_horas\"\n\n# An√°lisis del estado de sensores antes del mantenimiento\nif(\"fecha_mantenimiento\" %in% names(lecturas_pre_mantenimiento)) {\n  # Si fecha_mantenimiento existe directamente\n  analisis_pre_mantenimiento &lt;- lecturas_pre_mantenimiento[!is.na(valor),\n    .(\n      valor_promedio_pre = round(mean(valor), 2),\n      valor_min_pre = min(valor),\n      valor_max_pre = max(valor),\n      eventos_mantenimiento = .N,\n      tiempo_promedio_desde_lectura = round(mean(as.numeric(fecha_mantenimiento - timestamp) / 60), 1) # minutos\n    ), by = .(sensor_id, tipo_mantenimiento)]\n} else {\n  # Buscar columnas con fecha o mantenimiento en el nombre\n  fecha_cols &lt;- grep(\"fecha|mantenimiento\", names(lecturas_pre_mantenimiento), value = TRUE)\n  print(paste(\"Columnas con 'fecha' o 'mantenimiento' encontradas:\", paste(fecha_cols, collapse = \", \")))\n  \n  # An√°lisis simplificado sin c√°lculo temporal\n  analisis_pre_mantenimiento &lt;- lecturas_pre_mantenimiento[!is.na(valor),\n    .(\n      valor_promedio_pre = round(mean(valor), 2),\n      valor_min_pre = min(valor),\n      valor_max_pre = max(valor),\n      eventos_mantenimiento = .N\n    ), by = .(sensor_id, tipo_mantenimiento)]\n}\n#&gt; [1] \"Columnas con 'fecha' o 'mantenimiento' encontradas: mantenimiento_id, tipo_mantenimiento\"\n\nprint(\"An√°lisis de sensores antes del mantenimiento:\")\n#&gt; [1] \"An√°lisis de sensores antes del mantenimiento:\"\nprint(analisis_pre_mantenimiento[order(sensor_id, tipo_mantenimiento)])\n#&gt;       sensor_id tipo_mantenimiento valor_promedio_pre valor_min_pre\n#&gt;          &lt;char&gt;             &lt;char&gt;              &lt;num&gt;         &lt;num&gt;\n#&gt;  1:    HUMID_01        Calibracion              82.65         82.65\n#&gt;  2:    HUMID_01          Reemplazo             290.32         24.02\n#&gt;  3: PRESSURE_01           Limpieza             508.30         20.37\n#&gt;  4: PRESSURE_01          Reemplazo              19.74         19.74\n#&gt;  5:     TEMP_01        Calibracion             992.82        992.82\n#&gt;  6:     TEMP_01           Limpieza              22.69         22.69\n#&gt;  7:     TEMP_01          Reemplazo             529.52         55.85\n#&gt;  8:     TEMP_02        Calibracion              73.00         73.00\n#&gt;  9:     TEMP_02           Limpieza              21.75         20.97\n#&gt; 10:     TEMP_02          Reemplazo              29.41         20.87\n#&gt;     valor_max_pre eventos_mantenimiento\n#&gt;             &lt;num&gt;                 &lt;int&gt;\n#&gt;  1:         82.65                     1\n#&gt;  2:       1035.33                     4\n#&gt;  3:        996.24                     2\n#&gt;  4:         19.74                     1\n#&gt;  5:        992.82                     1\n#&gt;  6:         22.69                     1\n#&gt;  7:       1003.20                     2\n#&gt;  8:         73.00                     1\n#&gt;  9:         22.45                     3\n#&gt; 10:         51.82                     4",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#update-joins-avanzados-con-condiciones",
    "href": "cap03-joins-avanzados.html#update-joins-avanzados-con-condiciones",
    "title": "\n6¬† Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.3 Update Joins Avanzados con Condiciones",
    "text": "6.3 Update Joins Avanzados con Condiciones\n\n6.3.1 1. Update Join Condicional\n\n\n# Update join para marcar operaciones riesgosas\n# Crear tabla de l√≠mites de riesgo por ticker\nlimites_riesgo &lt;- data.table(\n  ticker = c(\"AAPL\", \"GOOGL\", \"MSFT\", \"TSLA\", \"AMZN\"),\n  precio_max_seguro = c(200, 3000, 400, 250, 150),\n  volumen_max_seguro = c(1000, 500, 800, 2000, 1200)\n)\n\n# Hacer copia para update join\noperaciones_riesgo &lt;- copy(operaciones_trading)\n\n# Update join condicional\noperaciones_riesgo[limites_riesgo, on = .(ticker),\n                  `:=`(\n                    precio_limite_riesgoso = i.precio_max_seguro &lt; precio_limite,\n                    volumen_riesgoso = i.volumen_max_seguro &lt; cantidad,\n                    limite_precio_ref = i.precio_max_seguro,\n                    limite_volumen_ref = i.volumen_max_seguro\n                  )]\n\n# Clasificar nivel de riesgo general\noperaciones_riesgo[, nivel_riesgo := fcase(\n  precio_limite_riesgoso & volumen_riesgoso, \"Alto Riesgo\",\n  precio_limite_riesgoso | volumen_riesgoso, \"Riesgo Moderado\",\n  default = \"Bajo Riesgo\"\n)]\n\n# Resumen de riesgos\nresumen_riesgos &lt;- operaciones_riesgo[, .N, by = .(ticker, nivel_riesgo)][order(ticker, nivel_riesgo)]\nprint(\"Distribuci√≥n de riesgo por ticker:\")\n#&gt; [1] \"Distribuci√≥n de riesgo por ticker:\"\nprint(resumen_riesgos)\n#&gt;     ticker    nivel_riesgo     N\n#&gt;     &lt;char&gt;          &lt;char&gt; &lt;int&gt;\n#&gt;  1:   AAPL     Bajo Riesgo     3\n#&gt;  2:   AAPL Riesgo Moderado    91\n#&gt;  3:   AMZN     Bajo Riesgo     1\n#&gt;  4:   AMZN Riesgo Moderado   105\n#&gt;  5:  GOOGL     Bajo Riesgo    83\n#&gt;  6:  GOOGL Riesgo Moderado    21\n#&gt;  7:   MSFT     Alto Riesgo    16\n#&gt;  8:   MSFT     Bajo Riesgo     9\n#&gt;  9:   MSFT Riesgo Moderado    74\n#&gt; 10:   TSLA     Bajo Riesgo     3\n#&gt; 11:   TSLA Riesgo Moderado    94\n\n\n6.3.2 2. Update Join con Agregaciones Complejas\n\n\n# Calcular estad√≠sticas m√≥viles y actualizar tabla principal\nestadisticas_ticker &lt;- operaciones_trading[,\n  .(\n    operaciones_historicas = .N,\n    precio_promedio_historico = round(mean(precio_limite), 2),\n    volumen_promedio_historico = round(mean(cantidad), 0),\n    precio_max_historico = max(precio_limite),\n    precio_min_historico = min(precio_limite),\n    ratio_compra_venta = round(mean(tipo == \"COMPRA\"), 2)\n  ), by = ticker]\n\n# Update join para agregar contexto hist√≥rico\noperaciones_riesgo[estadisticas_ticker, on = .(ticker),\n                  `:=`(\n                    percentil_precio = round((precio_limite - i.precio_min_historico) / \n                                           (i.precio_max_historico - i.precio_min_historico) * 100, 1),\n                    precio_vs_promedio = round(precio_limite / i.precio_promedio_historico, 2),\n                    volumen_vs_promedio = round(cantidad / i.volumen_promedio_historico, 2),\n                    operaciones_ticker_total = i.operaciones_historicas\n                  )]\n\nprint(\"Operaciones con contexto hist√≥rico:\")\n#&gt; [1] \"Operaciones con contexto hist√≥rico:\"\nprint(head(operaciones_riesgo[, .(ticker, precio_limite, percentil_precio, \n                                 precio_vs_promedio, volumen_vs_promedio, nivel_riesgo)], 10))\n#&gt;     ticker precio_limite percentil_precio precio_vs_promedio\n#&gt;     &lt;char&gt;         &lt;num&gt;            &lt;num&gt;              &lt;num&gt;\n#&gt;  1:   AAPL       2596.34             87.1               1.60\n#&gt;  2:   MSFT       2878.99             97.6               1.82\n#&gt;  3:   MSFT        264.94              5.7               0.17\n#&gt;  4:   AAPL       2745.92             92.4               1.69\n#&gt;  5:   AMZN       2631.01             87.5               1.66\n#&gt;  6:   TSLA       1407.00             45.3               0.92\n#&gt;  7:   AMZN       2465.81             81.7               1.56\n#&gt;  8:  GOOGL       1629.14             53.4               1.09\n#&gt;  9:  GOOGL        910.92             28.1               0.61\n#&gt; 10:   TSLA       2405.32             80.6               1.58\n#&gt;     volumen_vs_promedio    nivel_riesgo\n#&gt;                   &lt;num&gt;          &lt;char&gt;\n#&gt;  1:                2.34 Riesgo Moderado\n#&gt;  2:                0.14 Riesgo Moderado\n#&gt;  3:                0.14     Bajo Riesgo\n#&gt;  4:                2.34 Riesgo Moderado\n#&gt;  5:                0.12 Riesgo Moderado\n#&gt;  6:                0.29 Riesgo Moderado\n#&gt;  7:                0.25 Riesgo Moderado\n#&gt;  8:                2.70 Riesgo Moderado\n#&gt;  9:                0.27     Bajo Riesgo\n#&gt; 10:                0.15 Riesgo Moderado",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#casos-de-uso-complejos-combinando-t√©cnicas",
    "href": "cap03-joins-avanzados.html#casos-de-uso-complejos-combinando-t√©cnicas",
    "title": "\n6¬† Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.4 Casos de Uso Complejos: Combinando T√©cnicas",
    "text": "6.4 Casos de Uso Complejos: Combinando T√©cnicas\n\n6.4.1 1. Pipeline Completo: Finanzas\n\n\n# Pipeline complejo que combina non-equi y rolling joins\n# Paso a paso para facilitar el debugging\nstep1 &lt;- operaciones_trading[\n  # 1. Rolling join para obtener precios hist√≥ricos\n  precios_historicos, on = .(ticker, fecha_operacion = fecha), roll = TRUE\n][\n  # 2. Filtrar solo operaciones con precio disponible\n  !is.na(precio_cierre)\n][\n  # 3. Calcular m√©tricas de trading\n  , `:=`(\n    diferencia_precio = round(precio_limite - precio_cierre, 2),\n    ratio_precio = round(precio_limite / precio_cierre, 3),\n    valor_operacion = precio_limite * cantidad\n  )\n]\n\n# Verificar columnas antes del non-equi join\nprint(\"Columnas disponibles antes del non-equi join:\")\nprint(names(step1))\n\nstep2 &lt;- step1[\n  # 4. Non-equi join con eventos de mercado para ventanas temporales\n  eventos_mercado, \n  on = .(ticker = ticker_afectado,\n         fecha_operacion &gt;= fecha_inicio_ventana,\n         fecha_operacion &lt;= fecha_fin_ventana),\n  allow.cartesian = TRUE\n]\n\n# Verificar columnas despu√©s del non-equi join\nprint(\"Columnas disponibles despu√©s del non-equi join:\")\nprint(names(step2))\n\n# Determinar qu√© columna usar para ticker en la agrupaci√≥n\nticker_col &lt;- if(\"ticker_afectado\" %in% names(step2)) \"ticker_afectado\" else \"ticker\"\n\n# 5. Agregar an√°lisis por evento\nif(\"ticker_afectado\" %in% names(step2)) {\n  pipeline_financiero &lt;- step2[\n    , .(\n      operaciones_en_ventana = .N,\n      valor_total = sum(valor_operacion),\n      precio_promedio_limite = round(mean(precio_limite), 2),\n      precio_promedio_mercado = round(mean(precio_cierre), 2),\n      spread_promedio = round(mean(abs(diferencia_precio)), 2),\n      operaciones_compra = sum(tipo == \"COMPRA\"),\n      operaciones_venta = sum(tipo == \"VENTA\")\n    ), by = .(evento_id, tipo_evento, ticker_afectado, impacto_esperado)\n  ][\n    operaciones_en_ventana &gt;= 3  # Solo eventos con suficiente actividad\n  ][\n    order(-valor_total)\n  ]\n} else {\n  # Usar ticker en lugar de ticker_afectado\n  pipeline_financiero &lt;- step2[\n    , .(\n      operaciones_en_ventana = .N,\n      valor_total = sum(valor_operacion),\n      precio_promedio_limite = round(mean(precio_limite), 2),\n      precio_promedio_mercado = round(mean(precio_cierre), 2),\n      spread_promedio = round(mean(abs(diferencia_precio)), 2),\n      operaciones_compra = sum(tipo == \"COMPRA\"),\n      operaciones_venta = sum(tipo == \"VENTA\")\n    ), by = .(evento_id, tipo_evento, ticker, impacto_esperado)\n  ][\n    operaciones_en_ventana &gt;= 3  # Solo eventos con suficiente actividad\n  ][\n    order(-valor_total)\n  ]\n}\n\nprint(\"An√°lisis de trading en ventanas de eventos:\")\nprint(head(pipeline_financiero, 10))\n\n# # Crear tabla interactiva del an√°lisis (comentado para PDF)\n# DT::datatable(\n#   pipeline_financiero,\n#   caption = \"An√°lisis de Trading en Ventanas de Eventos de Mercado\",\n#   options = list(pageLength = 8, scrollX = TRUE)\n# ) %&gt;%\n#   DT::formatCurrency(\"valor_total\", currency = \"$\") %&gt;%\n#   DT::formatRound(c(\"precio_promedio_limite\", \"precio_promedio_mercado\", \"spread_promedio\"), digits = 2)\n\n\n6.4.2 2. Pipeline M√©dico Avanzado\n\n\n# Pipeline m√©dico combinando m√∫ltiples non-equi joins\nevaluacion_medica_completa &lt;- pacientes_clinica[\n  # A√±adir columna de edad en d√©cadas para agrupaci√≥n\n  , decada := paste0(floor(edad/10)*10, \"s\")\n][\n  # 1. Clasificar por IMC\n  rangos_medicos[parametro == \"IMC\"], \n  on = .(imc &gt;= valor_min, imc &lt;= valor_max),\n  .(paciente_id, nombre, edad, decada, peso, altura, imc, \n    categoria_imc = categoria, riesgo_imc = nivel_riesgo,\n    glucosa, presion_sistolica, colesterol)\n][\n  # 2. Clasificar por glucosa  \n  rangos_medicos[parametro == \"Glucosa\"],\n  on = .(glucosa &gt;= valor_min, glucosa &lt;= valor_max),\n  .(paciente_id, nombre, edad, decada, peso, altura, imc, \n    categoria_imc, riesgo_imc, glucosa,\n    categoria_glucosa = i.categoria, riesgo_glucosa = i.nivel_riesgo,\n    presion_sistolica, colesterol)\n][\n  # 3. Clasificar por presi√≥n\n  rangos_medicos[parametro == \"Presi√≥n\"],\n  on = .(presion_sistolica &gt;= valor_min, presion_sistolica &lt;= valor_max),\n  .(paciente_id, nombre, edad, decada, peso, altura, imc,\n    categoria_imc, riesgo_imc, glucosa, categoria_glucosa, riesgo_glucosa,\n    presion_sistolica, categoria_presion = i.categoria, riesgo_presion = i.nivel_riesgo,\n    colesterol)\n][\n  # 4. Calcular score de riesgo compuesto\n  , `:=`(\n    factores_riesgo_alto = (riesgo_imc == \"Alto\") + (riesgo_glucosa == \"Alto\") + (riesgo_presion == \"Alto\"),\n    factores_riesgo_total = 3,\n    score_riesgo = (\n      (riesgo_imc == \"Alto\") * 3 + (riesgo_imc == \"Normal\") * 1 +\n      (riesgo_glucosa == \"Alto\") * 3 + (riesgo_glucosa == \"Normal\") * 1 +\n      (riesgo_presion == \"Alto\") * 3 + (riesgo_presion == \"Normal\") * 1\n    )\n  )\n][\n  # 5. Clasificaci√≥n final de riesgo\n  , clasificacion_final := fcase(\n    factores_riesgo_alto &gt;= 2, \"Paciente Alto Riesgo - Seguimiento Inmediato\",\n    factores_riesgo_alto == 1, \"Paciente Riesgo Moderado - Seguimiento Regular\", \n    score_riesgo &gt;= 6, \"Paciente Bajo Riesgo - Seguimiento Rutinario\",\n    default = \"Paciente Muy Bajo Riesgo - Seguimiento Anual\"\n  )\n][\n  order(-score_riesgo)\n]\n\n# Resumen por grupo de edad\nresumen_por_decada &lt;- evaluacion_medica_completa[,\n  .(\n    pacientes = .N,\n    edad_promedio = round(mean(edad), 1),\n    imc_promedio = round(mean(imc), 1),\n    alto_riesgo = sum(factores_riesgo_alto &gt;= 2),\n    riesgo_moderado = sum(factores_riesgo_alto == 1),\n    bajo_riesgo = sum(factores_riesgo_alto == 0),\n    score_riesgo_promedio = round(mean(score_riesgo), 1)\n  ), by = decada][order(decada)]\n\nprint(\"Resumen de evaluaci√≥n m√©dica por d√©cada:\")\nprint(resumen_por_decada)\n\nprint(\"\\nPacientes de mayor riesgo:\")\nprint(head(evaluacion_medica_completa[factores_riesgo_alto &gt;= 2, \n                                     .(nombre, edad, factores_riesgo_alto, score_riesgo, clasificacion_final)], 8))",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#ejercicios-pr√°cticos",
    "href": "cap03-joins-avanzados.html#ejercicios-pr√°cticos",
    "title": "\n6¬† Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.5 Ejercicios Pr√°cticos",
    "text": "6.5 Ejercicios Pr√°cticos\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 10: Sistema de Alertas de Trading\n\n\n\nUsando los datasets de precios y operaciones:\n\n\nRolling join para obtener precios en tiempo real\n\nNon-equi join para identificar operaciones en rangos de volatilidad alta\n\nUpdate join para calcular PnL potencial\n\nCrear sistema de alertas basado en m√∫ltiples condiciones\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 10\n\n\n\n\n\n\n# Sistema completo de alertas de trading\n# 1. Calcular volatilidad hist√≥rica\nvolatilidad_historica &lt;- precios_historicos[order(ticker, fecha)][,\n  .(fecha, volatilidad_10d = frollapply(precio_cierre, 10, sd, na.rm = TRUE)),\n  by = ticker][!is.na(volatilidad_10d)]\n\n# 2. Definir rangos de volatilidad para non-equi join\nrangos_volatilidad &lt;- data.table(\n  nivel = c(\"Baja\", \"Media\", \"Alta\", \"Extrema\"),\n  vol_min = c(0, 5, 15, 30),\n  vol_max = c(5, 15, 30, Inf),\n  factor_riesgo = c(1, 2, 3, 4)\n)\n\n# 3. Pipeline completo del sistema de alertas\nsistema_alertas &lt;- operaciones_trading[\n  # Rolling join con precios hist√≥ricos\n  precios_historicos, on = .(ticker, fecha_operacion = fecha), roll = TRUE\n][\n  !is.na(precio_cierre)  # Solo operaciones con precio disponible\n][\n  # Rolling join con volatilidad\n  volatilidad_historica, on = .(ticker, fecha_operacion = fecha), roll = TRUE\n][\n  !is.na(volatilidad_10d)  # Solo con volatilidad calculada\n][\n  # Non-equi join para clasificar por volatilidad\n  rangos_volatilidad, on = .(volatilidad_10d &gt;= vol_min, volatilidad_10d &lt;= vol_max),\n  .(operacion_id, ticker, fecha_operacion, tipo, cantidad, precio_limite, precio_cierre,\n    volatilidad_10d, nivel_volatilidad = nivel, factor_riesgo)\n][\n  # 4. Calcular m√©tricas de riesgo y PnL potencial\n  , `:=`(\n    diferencia_precio = precio_limite - precio_cierre,\n    pnl_potencial_pct = round((precio_limite - precio_cierre) / precio_cierre * 100, 2),\n    valor_operacion = precio_limite * cantidad,\n    riesgo_volatilidad = volatilidad_10d * factor_riesgo,\n    spread_pct = round(abs(precio_limite - precio_cierre) / precio_cierre * 100, 2)\n  )\n][\n  # 5. Sistema de alertas basado en m√∫ltiples condiciones\n  , alerta_tipo := fcase(\n    # Alerta cr√≠tica: alta volatilidad + spread alto + operaci√≥n grande\n    nivel_volatilidad %in% c(\"Alta\", \"Extrema\") & spread_pct &gt; 5 & valor_operacion &gt; 100000,\n    \"CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\",\n    \n    # Alerta alta: precio muy diferente del mercado\n    abs(pnl_potencial_pct) &gt; 10 & valor_operacion &gt; 50000,\n    \"ALTA - Precio Fuera de Rango + Volumen Significativo\",\n    \n    # Alerta media: volatilidad alta\n    nivel_volatilidad %in% c(\"Alta\", \"Extrema\") & valor_operacion &gt; 25000,\n    \"MEDIA - Alta Volatilidad\",\n    \n    # Alerta baja: spread moderado\n    spread_pct &gt; 3 & valor_operacion &gt; 10000,\n    \"BAJA - Spread Moderado\",\n    \n    default = \"SIN ALERTA\"\n  )\n][\n  # 6. Filtrar solo operaciones con alertas\n  alerta_tipo != \"SIN ALERTA\"\n][\n  order(-riesgo_volatilidad, -valor_operacion)\n][\n  # 7. Agregar prioridad num√©rica para ordenamiento\n  , prioridad := fcase(\n    grepl(\"CR√çTICA\", alerta_tipo), 1,\n    grepl(\"ALTA\", alerta_tipo), 2, \n    grepl(\"MEDIA\", alerta_tipo), 3,\n    grepl(\"BAJA\", alerta_tipo), 4,\n    default = 5\n  )\n][\n  order(prioridad, -valor_operacion)\n]\n\n# Dashboard de alertas\ncat(\"üö® SISTEMA DE ALERTAS DE TRADING üö®\\n\\n\")\n#&gt; üö® SISTEMA DE ALERTAS DE TRADING üö®\n\n# Resumen por tipo de alerta\nresumen_alertas &lt;- sistema_alertas[, .(\n  operaciones = .N,\n  valor_total = sum(valor_operacion),\n  volatilidad_promedio = round(mean(volatilidad_10d), 2),\n  spread_promedio = round(mean(spread_pct), 2)\n), by = .(alerta_tipo, prioridad)][order(prioridad)]\n\nprint(\"RESUMEN DE ALERTAS:\")\n#&gt; [1] \"RESUMEN DE ALERTAS:\"\nprint(resumen_alertas)\n#&gt;                                                alerta_tipo prioridad\n#&gt;                                                     &lt;char&gt;     &lt;num&gt;\n#&gt; 1: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto         1\n#&gt; 2:    ALTA - Precio Fuera de Rango + Volumen Significativo         2\n#&gt; 3:                                MEDIA - Alta Volatilidad         3\n#&gt; 4:                                  BAJA - Spread Moderado         4\n#&gt;    operaciones valor_total volatilidad_promedio spread_promedio\n#&gt;          &lt;int&gt;       &lt;num&gt;                &lt;num&gt;           &lt;num&gt;\n#&gt; 1:          61    41874580                16.23          319.11\n#&gt; 2:         197   100551879                 5.58          500.71\n#&gt; 3:          10      353714                15.00          116.39\n#&gt; 4:          59     7979808                 6.78          172.47\n\ncat(\"\\nüìä TOP 10 OPERACIONES DE MAYOR RIESGO:\\n\")\n#&gt; \n#&gt; üìä TOP 10 OPERACIONES DE MAYOR RIESGO:\nprint(sistema_alertas[1:10, .(\n  Ticker = ticker, \n  Tipo = tipo,\n  Valor = paste0(\"$\", format(valor_operacion, big.mark = \",\")),\n  Spread = paste0(spread_pct, \"%\"),\n  Volatilidad = paste0(round(volatilidad_10d, 1)),\n  Alerta = alerta_tipo\n)])\n#&gt;     Ticker   Tipo      Valor  Spread Volatilidad\n#&gt;     &lt;char&gt; &lt;char&gt;     &lt;char&gt;  &lt;char&gt;      &lt;char&gt;\n#&gt;  1:   TSLA  VENTA $2,161,110 683.66%          15\n#&gt;  2:   TSLA  VENTA $2,161,110 680.32%          15\n#&gt;  3:   TSLA  VENTA $2,161,110 623.26%          15\n#&gt;  4:   TSLA  VENTA $2,161,110 518.59%          15\n#&gt;  5:   TSLA  VENTA $2,161,110 544.22%          15\n#&gt;  6:   TSLA  VENTA $2,161,110 514.93%          15\n#&gt;  7:  GOOGL COMPRA $1,463,000  47.18%          15\n#&gt;  8:  GOOGL COMPRA $1,463,000  46.66%          15\n#&gt;  9:  GOOGL COMPRA $1,463,000  47.21%          15\n#&gt; 10:   TSLA COMPRA $1,350,470  351.9%          15\n#&gt;                                                      Alerta\n#&gt;                                                      &lt;char&gt;\n#&gt;  1: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  2: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  3: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  4: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  5: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  6: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  7: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  8: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt;  9: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n#&gt; 10: CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\n\n# # Crear tabla interactiva (comentado para PDF)\n# DT::datatable(\n#   sistema_alertas[1:20],\n#   caption = \"Sistema de Alertas de Trading - Top 20 Operaciones de Riesgo\",\n#   options = list(pageLength = 10, scrollX = TRUE)\n# ) %&gt;%\n#   DT::formatCurrency(\"valor_operacion\", currency = \"$\") %&gt;%\n#   DT::formatRound(c(\"volatilidad_10d\", \"spread_pct\"), digits = 2) %&gt;%\n#   DT::formatStyle(\n#     \"alerta_tipo\",\n#     backgroundColor = DT::styleEqual(\n#       c(\"CR√çTICA - Alta Volatilidad + Spread Alto + Volumen Alto\",\n#         \"ALTA - Precio Fuera de Rango + Volumen Significativo\", \n#         \"MEDIA - Alta Volatilidad\",\n#         \"BAJA - Spread Moderado\"),\n#       c(\"red\", \"orange\", \"yellow\", \"lightblue\")\n#     )\n#   )",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-joins-avanzados.html#mejores-pr√°cticas-para-joins-avanzados",
    "href": "cap03-joins-avanzados.html#mejores-pr√°cticas-para-joins-avanzados",
    "title": "\n6¬† Joins Avanzados: Non-Equi y Rolling Joins\n",
    "section": "\n6.6 Mejores Pr√°cticas para Joins Avanzados",
    "text": "6.6 Mejores Pr√°cticas para Joins Avanzados\n\n6.6.1 1. Performance y Optimizaci√≥n\n\n\n# ‚úÖ HACER: Establecer keys antes de rolling joins repetitivos\nsetkey(tabla_temporal, id, timestamp)\nsetkey(tabla_eventos, id, fecha_evento)\nresultado &lt;- tabla_temporal[tabla_eventos, roll = TRUE]\n\n# ‚úÖ HACER: Filtrar antes de joins complejos\ntabla_filtrada &lt;- tabla_grande[fecha &gt;= fecha_inicio & fecha &lt;= fecha_fin]\nresultado &lt;- tabla_filtrada[otra_tabla, on = .(columna)]\n\n# ‚úÖ HACER: Usar nomatch = NULL para inner joins en non-equi\nresultado &lt;- tabla1[tabla2, on = .(col1 &gt;= min_val, col1 &lt;= max_val), nomatch = NULL]\n\n# ‚ùå EVITAR: Non-equi joins sin filtros previos en tablas enormes\n# Puede generar productos cartesianos masivos\n\n\n6.6.2 2. Manejo de Casos Edge\n\n\n# ‚úÖ HACER: Validar resultados de rolling joins\nresultado &lt;- tabla1[tabla2, roll = TRUE]\ncat(\"Matches encontrados:\", sum(!is.na(resultado$columna_tabla1)), \"\\n\")\ncat(\"Matches perdidos:\", sum(is.na(resultado$columna_tabla1)), \"\\n\")\n\n# ‚úÖ HACER: Establecer l√≠mites razonables en rolling joins\nresultado &lt;- tabla1[tabla2, roll = 7]  # m√°ximo 7 unidades de tiempo\n\n# ‚úÖ HACER: Verificar cartesian products en non-equi joins\nif(nrow(resultado) &gt; nrow(tabla2) * 2) {\n  warning(\"Posible cartesian product no deseado\")\n}\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nNon-equi joins permiten uniones basadas en rangos y desigualdades - perfectos para clasificaciones m√©dicas y financieras\n\nRolling joins son esenciales para series temporales - conectan cada punto con el √∫ltimo valor disponible\n\nCombinar t√©cnicas (non-equi + rolling + update) permite an√°lisis muy sofisticados\n\nPerformance: Establecer keys apropiadas es crucial para joins avanzados\n\nValidaci√≥n: Siempre verificar resultados para evitar cartesian products no deseados\n\nCasos de uso reales: Finanzas, medicina, IoT - cualquier dominio con rangos temporales o de valores\n\n\n\nLos joins avanzados son herramientas poderosas que abren posibilidades anal√≠ticas √∫nicas. En el pr√≥ximo cap√≠tulo exploraremos las funciones especiales que complementan estos joins para an√°lisis a√∫n m√°s sofisticados.\n[{‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1-new‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 2: dividir en encadenamiento y joins‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúin_progress‚Äù, ‚Äúid‚Äù: ‚Äú3-2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-reshape.qmd para reshape del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú3-3‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú4‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú5‚Äù}]",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>6</span>¬† <span class='chapter-title'>Joins Avanzados: Non-Equi y Rolling Joins</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html",
    "href": "cap03-funciones-especiales.html",
    "title": "\n7¬† Funciones Especiales y An√°lisis Temporal\n",
    "section": "",
    "text": "7.1 Funciones de Ventana (Window Functions)\nLas funciones de ventana permiten realizar c√°lculos sobre un conjunto de filas relacionadas con la fila actual, sin colapsar el resultado como lo har√≠an las funciones de agregaci√≥n.",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Funciones Especiales y An√°lisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#funciones-de-ventana-window-functions",
    "href": "cap03-funciones-especiales.html#funciones-de-ventana-window-functions",
    "title": "\n7¬† Funciones Especiales y An√°lisis Temporal\n",
    "section": "",
    "text": "7.1.1 1. shift(): Valores Anteriores y Posteriores\n\n\n# Calcular cambios diarios en precios\nprecios_con_lag &lt;- precios_diarios[order(ticker, fecha)][,\n  `:=`(\n    precio_anterior = shift(precio_cierre, 1),          # t-1\n    precio_siguiente = shift(precio_cierre, -1),        # t+1\n    precio_3_dias_antes = shift(precio_cierre, 3),      # t-3\n    volumen_anterior = shift(volumen, 1)\n  ), by = ticker]\n\n# Calcular m√©tricas de cambio\nprecios_con_lag[, `:=`(\n  cambio_diario = precio_cierre - precio_anterior,\n  cambio_pct = round((precio_cierre - precio_anterior) / precio_anterior * 100, 2),\n  volatilidad_3d = round(abs(precio_cierre - precio_3_dias_antes) / precio_3_dias_antes * 100, 2),\n  cambio_volumen = volumen - volumen_anterior\n)]\n\nprint(\"An√°lisis de cambios diarios:\")\n#&gt; [1] \"An√°lisis de cambios diarios:\"\nprint(head(precios_con_lag[!is.na(precio_anterior), \n                          .(ticker, fecha, precio_cierre, cambio_diario, cambio_pct, volatilidad_3d)], 10))\n#&gt;     ticker      fecha precio_cierre cambio_diario cambio_pct volatilidad_3d\n#&gt;     &lt;char&gt;     &lt;Date&gt;         &lt;num&gt;         &lt;num&gt;      &lt;num&gt;          &lt;num&gt;\n#&gt;  1:   AAPL 2024-01-02      183.4407     2.3071617       1.27             NA\n#&gt;  2:   AAPL 2024-01-03      181.4614    -1.9792962      -1.08             NA\n#&gt;  3:   AAPL 2024-01-04      182.1432     0.6817462       0.38           0.56\n#&gt;  4:   AAPL 2024-01-05      184.6943     2.5510975       1.40           0.68\n#&gt;  5:   AAPL 2024-01-06      187.7013     3.0069915       1.63           3.44\n#&gt;  6:   AAPL 2024-01-07      190.0722     2.3709305       1.26           4.35\n#&gt;  7:   AAPL 2024-01-08      188.8158    -1.2563592      -0.66           2.23\n#&gt;  8:   AAPL 2024-01-09      188.3688    -0.4470651      -0.24           0.36\n#&gt;  9:   AAPL 2024-01-10      185.8614    -2.5073326      -1.33           2.22\n#&gt; 10:   AAPL 2024-01-11      180.8085    -5.0529325      -2.72           4.24\n\n\n7.1.2 2. frollmean() y Medias M√≥viles\n\n\n# M√∫ltiples medias m√≥viles para an√°lisis t√©cnico\nprecios_ma &lt;- precios_diarios[order(ticker, fecha)][,\n  `:=`(\n    ma_5 = frollmean(precio_cierre, 5),           # Media m√≥vil 5 d√≠as\n    ma_20 = frollmean(precio_cierre, 20),         # Media m√≥vil 20 d√≠as\n    ma_50 = frollmean(precio_cierre, 50),         # Media m√≥vil 50 d√≠as\n    volume_ma_10 = frollmean(volumen, 10),        # Media m√≥vil volumen 10 d√≠as\n    volatilidad_20 = frollapply(precio_cierre, 20, sd, na.rm = TRUE)  # Volatilidad 20 d√≠as\n  ), by = ticker]\n\n# Se√±ales t√©cnicas basadas en cruces de medias m√≥viles\nprecios_ma[!is.na(ma_50), `:=`(\n  se√±al_alcista = ma_5 &gt; ma_20 & ma_20 &gt; ma_50,\n  se√±al_bajista = ma_5 &lt; ma_20 & ma_20 &lt; ma_50,\n  precio_sobre_ma20 = precio_cierre &gt; ma_20,\n  volumen_alto = volumen &gt; volume_ma_10 * 1.5\n)]\n\n# Resumen de se√±ales por ticker\nse√±ales_resumen &lt;- precios_ma[!is.na(se√±al_alcista), .(\n  dias_analizados = .N,\n  se√±ales_alcistas = sum(se√±al_alcista, na.rm = TRUE),\n  se√±ales_bajistas = sum(se√±al_bajista, na.rm = TRUE),\n  dias_sobre_ma20 = sum(precio_sobre_ma20, na.rm = TRUE),\n  volatilidad_promedio = round(mean(volatilidad_20, na.rm = TRUE), 2)\n), by = ticker]\n\nprint(\"Resumen de se√±ales t√©cnicas:\")\n#&gt; [1] \"Resumen de se√±ales t√©cnicas:\"\nprint(se√±ales_resumen)\n#&gt;    ticker dias_analizados se√±ales_alcistas se√±ales_bajistas dias_sobre_ma20\n#&gt;    &lt;char&gt;           &lt;int&gt;            &lt;int&gt;            &lt;int&gt;           &lt;int&gt;\n#&gt; 1:   AAPL             133               80               19              93\n#&gt; 2:  GOOGL             133               63               19              81\n#&gt; 3:   MSFT             133               85               17              84\n#&gt; 4:   NVDA             133               34               41              77\n#&gt;    volatilidad_promedio\n#&gt;                   &lt;num&gt;\n#&gt; 1:                 3.67\n#&gt; 2:                15.24\n#&gt; 3:                 5.17\n#&gt; 4:                21.08\n\n\n7.1.3 3. frollapply(): Funciones Personalizadas\n\n\n# Funciones personalizadas para an√°lisis de ventana\nprecios_estadisticas &lt;- precios_diarios[order(ticker, fecha)][,\n  `:=`(\n    rango_10d = frollapply(precio_cierre, 10, function(x) max(x) - min(x)),\n    percentil_75_20d = frollapply(precio_cierre, 20, function(x) quantile(x, 0.75, na.rm = TRUE)),\n    coef_variacion_15d = frollapply(precio_cierre, 15, function(x) sd(x, na.rm = TRUE) / mean(x, na.rm = TRUE)),\n    precio_z_score_30d = frollapply(precio_cierre, 30, function(x) {\n      if(length(x) &lt; 30) return(NA)\n      (tail(x, 1) - mean(x)) / sd(x)\n    }),\n    tendencia_5d = frollapply(precio_cierre, 5, function(x) {\n      if(length(x) &lt; 5) return(NA)\n      lm_result &lt;- lm(x ~ seq_along(x))\n      coef(lm_result)[2]  # Pendiente\n    })\n  ), by = ticker]\n\n# An√°lisis de distribuciones y outliers\nanalisis_outliers &lt;- precios_estadisticas[!is.na(precio_z_score_30d), .(\n  ticker,\n  fecha,\n  precio_cierre,\n  z_score = round(precio_z_score_30d, 2),\n  coef_var = round(coef_variacion_15d, 3),\n  tendencia = round(tendencia_5d, 4),\n  outlier_extremo = abs(precio_z_score_30d) &gt; 2\n)][outlier_extremo == TRUE][order(-abs(z_score))]\n\nprint(\"Precios con comportamiento outlier (|z-score| &gt; 2):\")\n#&gt; [1] \"Precios con comportamiento outlier (|z-score| &gt; 2):\"\nprint(head(analisis_outliers, 10))\n#&gt;     ticker      fecha precio_cierre z_score coef_var tendencia outlier_extremo\n#&gt;     &lt;char&gt;     &lt;Date&gt;         &lt;num&gt;   &lt;num&gt;    &lt;num&gt;     &lt;num&gt;          &lt;lgcl&gt;\n#&gt;  1:   MSFT 2024-05-20      457.1759    3.62    0.007    1.9420            TRUE\n#&gt;  2:   MSFT 2024-06-08      431.7858   -3.00    0.015   -2.5880            TRUE\n#&gt;  3:   MSFT 2024-03-08      433.9277    2.92    0.019    5.5208            TRUE\n#&gt;  4:   MSFT 2024-03-07      428.3405    2.76    0.014    2.8564            TRUE\n#&gt;  5:   MSFT 2024-06-09      430.4144   -2.72    0.017   -3.3287            TRUE\n#&gt;  6:   AAPL 2024-05-29      196.4133    2.65    0.027    2.5945            TRUE\n#&gt;  7:   MSFT 2024-04-14      445.9479    2.64    0.015    2.6979            TRUE\n#&gt;  8:  GOOGL 2024-02-19     2892.6715    2.61    0.005    6.6683            TRUE\n#&gt;  9:   AAPL 2024-06-26      214.5298    2.58    0.023    1.7983            TRUE\n#&gt; 10:   NVDA 2024-05-13      546.1066   -2.57    0.024   -1.1179            TRUE",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Funciones Especiales y An√°lisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#funciones-condicionales-optimizadas",
    "href": "cap03-funciones-especiales.html#funciones-condicionales-optimizadas",
    "title": "\n7¬† Funciones Especiales y An√°lisis Temporal\n",
    "section": "\n7.2 Funciones Condicionales Optimizadas",
    "text": "7.2 Funciones Condicionales Optimizadas\n\n7.2.1 1. fifelse(): Condicionales R√°pidas\n\n\n# Comparaci√≥n de rendimiento: fifelse vs ifelse\nclientes_clasificacion &lt;- copy(clientes_retencion)\n\n# fifelse para clasificaciones m√∫ltiples y anidadas\nclientes_clasificacion[, `:=`(\n  segmento_edad = fifelse(\n    edad &lt; 25, \"Joven\",\n    fifelse(edad &lt; 45, \"Adulto\", \"Senior\")\n  ),\n  categoria_ingresos = fifelse(\n    ingresos_mensuales &lt; 2000, \"Bajos\",\n    fifelse(ingresos_mensuales &lt; 5000, \"Medios\", \"Altos\")\n  ),\n  tipo_cliente = fifelse(\n    plan == \"Empresarial\", \"Corporativo\",\n    fifelse(activo & ingresos_mensuales &gt; 3000, \"Premium_Activo\", \"Est√°ndar\")\n  )\n)]\n\n# An√°lisis de segmentos\nsegmentos_analisis &lt;- clientes_clasificacion[, .(\n  clientes = .N,\n  ingresos_promedio = round(mean(ingresos_mensuales), 0),\n  tasa_actividad = round(mean(activo) * 100, 1),\n  planes_premium = sum(plan %in% c(\"Premium\", \"Empresarial\"))\n), by = .(segmento_edad, categoria_ingresos, tipo_cliente)]\n\nprint(\"An√°lisis de segmentos de clientes:\")\n#&gt; [1] \"An√°lisis de segmentos de clientes:\"\nprint(segmentos_analisis[order(-clientes)])\n#&gt;     segmento_edad categoria_ingresos   tipo_cliente clientes ingresos_promedio\n#&gt;            &lt;char&gt;             &lt;char&gt;         &lt;char&gt;    &lt;int&gt;             &lt;num&gt;\n#&gt;  1:        Senior              Altos Premium_Activo      191             13130\n#&gt;  2:        Adulto              Altos Premium_Activo      116             12750\n#&gt;  3:        Senior              Bajos       Est√°ndar       96              1301\n#&gt;  4:        Senior             Medios Premium_Activo       74              3916\n#&gt;  5:        Senior             Medios       Est√°ndar       72              2973\n#&gt; ---                                                                           \n#&gt; 20:         Joven              Altos       Est√°ndar        9             12540\n#&gt; 21:         Joven              Altos    Corporativo        6             11067\n#&gt; 22:         Joven             Medios    Corporativo        4              3249\n#&gt; 23:        Adulto              Bajos    Corporativo        4              1292\n#&gt; 24:         Joven              Bajos    Corporativo        1              1952\n#&gt;     tasa_actividad planes_premium\n#&gt;              &lt;num&gt;          &lt;int&gt;\n#&gt;  1:          100.0             71\n#&gt;  2:          100.0             41\n#&gt;  3:           68.8             26\n#&gt;  4:          100.0             22\n#&gt;  5:           50.0             28\n#&gt; ---                              \n#&gt; 20:            0.0              0\n#&gt; 21:           33.3              6\n#&gt; 22:          100.0              4\n#&gt; 23:           75.0              4\n#&gt; 24:            0.0              1\n\n\n7.2.2 2. fcase(): M√∫ltiples Condiciones Elegantes\n\n\n# Sistema de scoring complejo con fcase\nclientes_clasificacion[, score_retencion := fcase(\n  # Casos de alto valor\n  plan == \"Empresarial\" & activo & ingresos_mensuales &gt; 5000, 95,\n  plan == \"Premium\" & activo & ingresos_mensuales &gt; 3000, 85,\n  plan == \"B√°sico\" & activo & ingresos_mensuales &gt; 4000, 80,\n  \n  # Casos de riesgo medio\n  !activo & ingresos_mensuales &gt; 3000 & !is.na(fecha_ultima_actividad), 60,\n  activo & ingresos_mensuales &lt; 2000, 55,\n  \n  # Casos de alto riesgo\n  !activo & is.na(fecha_ultima_actividad), 20,\n  !activo & ingresos_mensuales &lt; 2000, 15,\n  \n  # Caso por defecto\n  default = 50\n)]\n\n# Estrategia de retenci√≥n basada en score\nclientes_clasificacion[, estrategia_retencion := fcase(\n  score_retencion &gt;= 90, \"Mantener_Premium\",\n  score_retencion &gt;= 70, \"Fidelizar_Activo\", \n  score_retencion &gt;= 50, \"Reactivar_Moderado\",\n  score_retencion &gt;= 30, \"Reactivar_Intensivo\",\n  default = \"Evaluar_Cancelaci√≥n\"\n)]\n\n# Resumen estrat√©gico\nresumen_estrategia &lt;- clientes_clasificacion[, .(\n  clientes = .N,\n  score_promedio = round(mean(score_retencion), 1),\n  ingresos_totales = sum(ingresos_mensuales),\n  valor_cliente_promedio = round(mean(ingresos_mensuales), 0)\n), by = estrategia_retencion][order(-score_promedio)]\n\nprint(\"Estrategias de retenci√≥n por score:\")\n#&gt; [1] \"Estrategias de retenci√≥n por score:\"\nprint(resumen_estrategia)\n#&gt;    estrategia_retencion clientes score_promedio ingresos_totales\n#&gt;                  &lt;char&gt;    &lt;int&gt;          &lt;num&gt;            &lt;num&gt;\n#&gt; 1:     Mantener_Premium       21           95.0           243714\n#&gt; 2:     Fidelizar_Activo      430           82.0          5089950\n#&gt; 3:   Reactivar_Moderado      306           52.4           667565\n#&gt; 4:  Evaluar_Cancelaci√≥n      243           20.0          1853637\n#&gt;    valor_cliente_promedio\n#&gt;                     &lt;num&gt;\n#&gt; 1:                  11605\n#&gt; 2:                  11837\n#&gt; 3:                   2182\n#&gt; 4:                   7628\n\n\n7.2.3 3. between(): Rangos Eficientes\n\n\n# Usar between para clasificaciones por rangos\ntransacciones_analisis &lt;- copy(transacciones_comportamiento)\n\ntransacciones_analisis[, `:=`(\n  # Clasificaci√≥n por monto usando between\n  categoria_monto = fcase(\n    between(monto, 0, 20), \"Micro\",\n    between(monto, 20.01, 100), \"Peque√±a\", \n    between(monto, 100.01, 500), \"Mediana\",\n    between(monto, 500.01, 2000), \"Grande\",\n    monto &gt; 2000, \"Muy Grande\",\n    default = \"Sin Clasificar\"\n  ),\n  \n  # Clasificaci√≥n temporal\n  hora = hour(fecha_transaccion),\n  franja_horaria = fcase(\n    between(hour(fecha_transaccion), 6, 11), \"Ma√±ana\",\n    between(hour(fecha_transaccion), 12, 17), \"Tarde\", \n    between(hour(fecha_transaccion), 18, 22), \"Noche\",\n    default = \"Madrugada\"\n  ),\n  \n  # D√≠a de la semana\n  dia_semana = wday(fecha_transaccion, label = TRUE),\n  es_fin_semana = wday(fecha_transaccion) %in% c(1, 7)\n)]\n\n# An√°lisis de patrones de comportamiento\npatrones_comportamiento &lt;- transacciones_analisis[, .(\n  transacciones = .N,\n  monto_promedio = round(mean(monto), 2),\n  monto_mediana = round(median(monto), 2),\n  monto_total = round(sum(monto), 2)\n), by = .(categoria_monto, franja_horaria, es_fin_semana)][\n  order(-transacciones)\n]\n\nprint(\"Patrones de comportamiento transaccional:\")\n#&gt; [1] \"Patrones de comportamiento transaccional:\"\nprint(head(patrones_comportamiento, 12))\n#&gt;     categoria_monto franja_horaria es_fin_semana transacciones monto_promedio\n#&gt;              &lt;char&gt;         &lt;char&gt;        &lt;lgcl&gt;         &lt;int&gt;          &lt;num&gt;\n#&gt;  1:         Peque√±a      Madrugada         FALSE           537          49.61\n#&gt;  2:         Peque√±a          Tarde         FALSE           466          50.91\n#&gt;  3:         Peque√±a         Ma√±ana         FALSE           439          51.73\n#&gt;  4:         Peque√±a          Noche         FALSE           362          50.49\n#&gt;  5:         Mediana      Madrugada         FALSE           308         199.17\n#&gt; ---                                                                          \n#&gt;  8:         Mediana         Ma√±ana         FALSE           211         197.70\n#&gt;  9:           Micro      Madrugada         FALSE           204          11.42\n#&gt; 10:         Mediana          Noche         FALSE           202         200.49\n#&gt; 11:           Micro          Tarde         FALSE           187          11.64\n#&gt; 12:           Micro         Ma√±ana         FALSE           181          11.72\n#&gt;     monto_mediana monto_total\n#&gt;             &lt;num&gt;       &lt;num&gt;\n#&gt;  1:         46.62    26642.18\n#&gt;  2:         45.80    23722.06\n#&gt;  3:         48.07    22711.20\n#&gt;  4:         46.15    18276.34\n#&gt;  5:        166.66    61345.74\n#&gt; ---                          \n#&gt;  8:        161.64    41715.23\n#&gt;  9:         11.62     2330.31\n#&gt; 10:        169.60    40499.76\n#&gt; 11:         11.99     2176.52\n#&gt; 12:         11.66     2121.67",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Funciones Especiales y An√°lisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#funciones-de-agregaci√≥n-especiales",
    "href": "cap03-funciones-especiales.html#funciones-de-agregaci√≥n-especiales",
    "title": "\n7¬† Funciones Especiales y An√°lisis Temporal\n",
    "section": "\n7.3 Funciones de Agregaci√≥n Especiales",
    "text": "7.3 Funciones de Agregaci√≥n Especiales\n\n7.3.1 1. frank(): Rankings y Percentiles\n\n\n# Rankings complejos con frank()\nrankings_clientes &lt;- clientes_clasificacion[, `:=`(\n  # Ranking por ingresos (descendente)\n  rank_ingresos = frank(-ingresos_mensuales),\n  rank_ingresos_pct = frank(-ingresos_mensuales / .N * 100),\n  \n  # Ranking por score de retenci√≥n\n  rank_retencion = frank(-score_retencion),\n  \n  # Ranking dentro de cada plan\n  rank_en_plan = frank(.SD[,-ingresos_mensuales, by = plan]),\n  rank_en_pais = frank(.SD[,-ingresos_mensuales, by = pais])\n)]\n\n# Top performers por categor√≠a\ntop_performers &lt;- rankings_clientes[rank_ingresos &lt;= 50, .(\n  cliente_id, plan, pais, ingresos_mensuales, score_retencion,\n  rank_global = rank_ingresos,\n  rank_en_plan, rank_en_pais,\n  percentil_ingresos = round(100 - rank_ingresos_pct, 1)\n)][order(rank_global)]\n\nprint(\"Top 10 clientes por ingresos:\")\n#&gt; [1] \"Top 10 clientes por ingresos:\"\nprint(head(top_performers, 10))\n#&gt;     cliente_id    plan      pais ingresos_mensuales score_retencion rank_global\n#&gt;          &lt;int&gt;  &lt;char&gt;    &lt;char&gt;              &lt;num&gt;           &lt;num&gt;       &lt;num&gt;\n#&gt;  1:        780  B√°sico    Espa√±a             114272              80           1\n#&gt;  2:        579  B√°sico    M√©xico             112313              20           2\n#&gt;  3:        862  B√°sico Argentina              93104              80           3\n#&gt;  4:        537 Premium    Espa√±a              74834              20           4\n#&gt;  5:        204 Premium Argentina              66981              85           5\n#&gt;  6:        559 Premium Argentina              64783              85           6\n#&gt;  7:        370  B√°sico     Chile              63261              80           7\n#&gt;  8:        447 Premium    Espa√±a              58316              85           8\n#&gt;  9:        220  B√°sico  Colombia              47912              80           9\n#&gt; 10:        522  B√°sico    M√©xico              44810              80          10\n#&gt;     rank_en_plan rank_en_pais percentil_ingresos\n#&gt;            &lt;num&gt;        &lt;num&gt;              &lt;num&gt;\n#&gt;  1:          270          797                 99\n#&gt;  2:          408          448                 98\n#&gt;  3:          430          401                 97\n#&gt;  4:          575          597                 96\n#&gt;  5:          833          159                 95\n#&gt;  6:          223          588                 94\n#&gt;  7:          500          198                 93\n#&gt;  8:          229          612                 92\n#&gt;  9:          979           80                 91\n#&gt; 10:           16          485                 90\n\n\n7.3.2 2. rleid(): Identificaci√≥n de Runs\n\n\n# Identificar secuencias de comportamiento con rleid()\nsensores_runs &lt;- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(\n  # Clasificar temperatura en rangos\n  temp_categoria = fcase(\n    temperatura &lt; 18, \"Baja\",\n    between(temperatura, 18, 22), \"Normal\",\n    between(temperatura, 22, 26), \"Alta\",\n    temperatura &gt; 26, \"Muy Alta\",\n    default = \"Sin Datos\"\n  )\n)][, `:=`(\n  # Identificar runs (secuencias consecutivas)\n  run_id = rleid(temp_categoria),\n  # Tambi√©n podemos identificar runs de tendencia\n  tendencia = fcase(\n    temperatura &gt; shift(temperatura, 1), \"Subida\",\n    temperatura &lt; shift(temperatura, 1), \"Bajada\", \n    default = \"Estable\"\n  )\n), by = sensor_id][, `:=`(\n  run_tendencia = rleid(tendencia)\n), by = sensor_id]\n\n# An√°lisis de runs de temperatura\nanalisis_runs &lt;- sensores_runs[!is.na(temperatura), .(\n  duracion_run = .N,\n  temp_promedio = round(mean(temperatura, na.rm = TRUE), 1),\n  temp_min = round(min(temperatura, na.rm = TRUE), 1),\n  temp_max = round(max(temperatura, na.rm = TRUE), 1),\n  inicio_run = min(timestamp),\n  fin_run = max(timestamp)\n), by = .(sensor_id, temp_categoria, run_id)][\n  duracion_run &gt;= 4  # Solo runs de al menos 4 mediciones (1 hora)\n][order(sensor_id, -duracion_run)]\n\nprint(\"Runs de temperatura m√°s largos:\")\n#&gt; [1] \"Runs de temperatura m√°s largos:\"\nprint(head(analisis_runs, 12))\n#&gt;     sensor_id temp_categoria run_id duracion_run temp_promedio temp_min\n#&gt;        &lt;char&gt;         &lt;char&gt;  &lt;int&gt;        &lt;int&gt;         &lt;num&gt;    &lt;num&gt;\n#&gt;  1:    TEMP_A           Baja     82           31          15.8     13.4\n#&gt;  2:    TEMP_A           Baja    126           31          15.7     13.4\n#&gt;  3:    TEMP_A           Baja    144           31          15.8     13.2\n#&gt;  4:    TEMP_A           Alta    118           30          24.1     22.5\n#&gt;  5:    TEMP_A           Baja     20           28          15.9     13.5\n#&gt; ---                                                                    \n#&gt;  8:    TEMP_A           Alta    132           22          24.4     22.5\n#&gt;  9:    TEMP_A           Baja    106           21          15.5     13.2\n#&gt; 10:    TEMP_A           Alta     48           20          24.0     22.1\n#&gt; 11:    TEMP_A           Alta     94           19          24.2     22.3\n#&gt; 12:    TEMP_A           Alta     26           18          23.9     22.2\n#&gt;     temp_max          inicio_run             fin_run\n#&gt;        &lt;num&gt;              &lt;POSc&gt;              &lt;POSc&gt;\n#&gt;  1:     17.9 2024-06-04 14:30:00 2024-06-04 22:00:00\n#&gt;  2:     18.0 2024-06-06 14:15:00 2024-06-06 21:45:00\n#&gt;  3:     17.7 2024-06-07 14:00:00 2024-06-07 21:30:00\n#&gt;  4:     25.8 2024-06-06 02:30:00 2024-06-06 09:45:00\n#&gt;  5:     18.0 2024-06-01 15:15:00 2024-06-01 22:00:00\n#&gt; ---                                                 \n#&gt;  8:     26.0 2024-06-07 02:00:00 2024-06-07 07:15:00\n#&gt;  9:     17.3 2024-06-05 15:00:00 2024-06-05 20:00:00\n#&gt; 10:     25.5 2024-06-03 05:45:00 2024-06-03 10:30:00\n#&gt; 11:     26.0 2024-06-05 05:00:00 2024-06-05 09:30:00\n#&gt; 12:     25.7 2024-06-02 01:45:00 2024-06-02 06:00:00\n\n\n7.3.3 3. uniqueN(): Conteos de √önicos Eficientes\n\n\n# An√°lisis de diversidad con uniqueN()\ndiversidad_transacciones &lt;- transacciones_analisis[, .(\n  # Diversidad b√°sica\n  transacciones_totales = .N,\n  categorias_usadas = uniqueN(categoria),\n  comercios_visitados = uniqueN(comercio_id),\n  metodos_pago_usados = uniqueN(metodo_pago),\n  \n  # M√©tricas de comportamiento\n  dias_activos = uniqueN(as.Date(fecha_transaccion)),\n  horas_activas = uniqueN(hour(fecha_transaccion)),\n  monto_promedio = round(mean(monto), 2),\n  \n  # Diversidad temporal\n  meses_activos = uniqueN(month(fecha_transaccion)),\n  dias_semana_activos = uniqueN(wday(fecha_transaccion))\n), by = cliente_id]\n\n# Calcular √≠ndices de diversidad\ndiversidad_transacciones[, `:=`(\n  indice_diversidad_categoria = round(categorias_usadas / 5 * 100, 1),  # 5 categor√≠as posibles\n  indice_diversidad_temporal = round(horas_activas / 24 * 100, 1),      # 24 horas posibles\n  indice_actividad = round(dias_activos / 180 * 100, 1),                # ~180 d√≠as en periodo\n  score_engagement = round((categorias_usadas * 10) + (dias_activos * 2) + (comercios_visitados * 3), 0)\n)]\n\n# Clasificar clientes por engagement\ndiversidad_transacciones[, categoria_engagement := fcase(\n  score_engagement &gt; 200, \"Muy Alto\",\n  score_engagement &gt; 100, \"Alto\",\n  score_engagement &gt; 50, \"Medio\", \n  score_engagement &gt; 20, \"Bajo\",\n  default = \"Muy Bajo\"\n)]\n\n# Resumen por categor√≠a de engagement\nresumen_engagement &lt;- diversidad_transacciones[, .(\n  clientes = .N,\n  transacciones_promedio = round(mean(transacciones_totales), 1),\n  diversidad_categoria_promedio = round(mean(indice_diversidad_categoria), 1),\n  score_promedio = round(mean(score_engagement), 0)\n), by = categoria_engagement][order(-score_promedio)]\n\nprint(\"An√°lisis de engagement de clientes:\")\n#&gt; [1] \"An√°lisis de engagement de clientes:\"\nprint(resumen_engagement)\n#&gt;    categoria_engagement clientes transacciones_promedio\n#&gt;                  &lt;char&gt;    &lt;int&gt;                  &lt;num&gt;\n#&gt; 1:                 Alto       10                   11.7\n#&gt; 2:                Medio      582                    6.3\n#&gt; 3:                 Bajo      352                    3.3\n#&gt; 4:             Muy Bajo       46                    1.3\n#&gt;    diversidad_categoria_promedio score_promedio\n#&gt;                            &lt;num&gt;          &lt;num&gt;\n#&gt; 1:                         100.0            107\n#&gt; 2:                          74.8             68\n#&gt; 3:                          48.0             40\n#&gt; 4:                          20.0             16",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Funciones Especiales y An√°lisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#an√°lisis-temporal-avanzado",
    "href": "cap03-funciones-especiales.html#an√°lisis-temporal-avanzado",
    "title": "\n7¬† Funciones Especiales y An√°lisis Temporal\n",
    "section": "\n7.4 An√°lisis Temporal Avanzado",
    "text": "7.4 An√°lisis Temporal Avanzado\n\n7.4.1 1. Detecci√≥n de Anomal√≠as Temporales\n\n\n# Sistema de detecci√≥n de anomal√≠as para sensores\nanomalias_sensores &lt;- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(\n  # Medias m√≥viles para diferentes ventanas\n  temp_ma_short = frollmean(temperatura, 4, na.rm = TRUE),    # 1 hora\n  temp_ma_long = frollmean(temperatura, 24, na.rm = TRUE),    # 6 horas\n  temp_sd_window = frollapply(temperatura, 12, sd, na.rm = TRUE), # Desviaci√≥n m√≥vil\n  \n  # Cambios absolutos\n  cambio_temp = abs(temperatura - shift(temperatura, 1)),\n  cambio_temp_2 = abs(temperatura - shift(temperatura, 2))\n), by = sensor_id][, `:=`(\n  # Detecci√≥n de anomal√≠as\n  anomalia_spike = cambio_temp &gt; 3,  # Cambio s√∫bito &gt; 3 grados\n  anomalia_drift = !is.na(temp_ma_long) & abs(temperatura - temp_ma_long) &gt; 5, # Desviaci√≥n &gt; 5 grados de media larga\n  anomalia_variabilidad = !is.na(temp_sd_window) & temp_sd_window &gt; 2 # Alta variabilidad\n  \n \n)]\n\n# Score compuesto de anomal√≠a\nanomalias_sensores[, score_anomalia := (as.numeric(anomalia_spike) * 3) + \n                  (as.numeric(anomalia_drift) * 2) + \n                  (as.numeric(anomalia_variabilidad) * 1)]\n\n\n# Resumen de anomal√≠as por sensor\nresumen_anomalias &lt;- anomalias_sensores[!is.na(temperatura), .(\n  lecturas_totales = .N,\n  anomalias_spike = sum(anomalia_spike, na.rm = TRUE),\n  anomalias_drift = sum(anomalia_drift, na.rm = TRUE),\n  anomalias_variabilidad = sum(anomalia_variabilidad, na.rm = TRUE),\n  score_promedio = round(mean(score_anomalia, na.rm = TRUE), 2),\n  temp_min = round(min(temperatura, na.rm = TRUE), 1),\n  temp_max = round(max(temperatura, na.rm = TRUE), 1)\n), by = .(sensor_id, ubicacion)]\n\nprint(\"Resumen de anomal√≠as por sensor:\")\n#&gt; [1] \"Resumen de anomal√≠as por sensor:\"\nprint(resumen_anomalias)\n#&gt;    sensor_id ubicacion lecturas_totales anomalias_spike anomalias_drift\n#&gt;       &lt;char&gt;    &lt;char&gt;            &lt;int&gt;           &lt;int&gt;           &lt;int&gt;\n#&gt; 1:    TEMP_A Almac√©n_A              672              19               8\n#&gt; 2:    TEMP_B Almac√©n_B              672              10               0\n#&gt; 3:    TEMP_C Almac√©n_C              672               0               0\n#&gt;    anomalias_variabilidad score_promedio temp_min temp_max\n#&gt;                     &lt;int&gt;          &lt;num&gt;    &lt;num&gt;    &lt;num&gt;\n#&gt; 1:                      1           0.11     13.2     27.2\n#&gt; 2:                      0           0.04     16.5     27.1\n#&gt; 3:                      0           0.00     15.9     38.8\n\n# Top anomal√≠as individuales\ntop_anomalias &lt;- anomalias_sensores[score_anomalia &gt;= 2, .(\n  sensor_id, timestamp, temperatura, temp_ma_long, \n  cambio_temp, score_anomalia\n)][order(-score_anomalia)]\n\nif(nrow(top_anomalias) &gt; 0) {\n  print(\"\\nTop anomal√≠as detectadas:\")\n  print(head(top_anomalias, 8))\n} else {\n  cat(\"\\nNo se detectaron anomal√≠as significativas (score &gt;= 2)\\n\")\n}\n#&gt; [1] \"\\nTop anomal√≠as detectadas:\"\n#&gt;    sensor_id           timestamp temperatura temp_ma_long cambio_temp\n#&gt;       &lt;char&gt;              &lt;POSc&gt;       &lt;num&gt;        &lt;num&gt;       &lt;num&gt;\n#&gt; 1:    TEMP_A 2024-06-01 15:30:00    13.50388     19.24389    3.124197\n#&gt; 2:    TEMP_A 2024-06-06 02:30:00    25.62026     19.74337    4.480706\n#&gt; 3:    TEMP_A 2024-06-07 15:00:00    13.46347     19.12156    3.591262\n#&gt; 4:    TEMP_A 2024-06-01 02:00:00    20.49440           NA    3.496907\n#&gt; 5:    TEMP_A 2024-06-01 05:00:00    26.15761           NA    3.017316\n#&gt; 6:    TEMP_A 2024-06-02 08:00:00    22.85221     24.44104    3.189825\n#&gt; 7:    TEMP_A 2024-06-02 17:15:00    17.92243     17.55434    3.547180\n#&gt; 8:    TEMP_A 2024-06-03 19:15:00    17.64803     16.20537    3.936311\n#&gt;    score_anomalia\n#&gt;             &lt;num&gt;\n#&gt; 1:              5\n#&gt; 2:              5\n#&gt; 3:              5\n#&gt; 4:              3\n#&gt; 5:              3\n#&gt; 6:              3\n#&gt; 7:              3\n#&gt; 8:              3\n\n\n7.4.2 2. An√°lisis de Ciclos y Estacionalidad\n\n\n# An√°lisis de patrones c√≠clicos en datos de sensores\npatrones_ciclicos &lt;- sensores_temperatura[!is.na(temperatura)][, `:=`(\n  hora = hour(timestamp),\n  dia = as.numeric(as.Date(timestamp) - min(as.Date(timestamp))) + 1,\n  minuto_del_dia = hour(timestamp) * 60 + minute(timestamp)\n)][, .(\n  temperatura_promedio = round(mean(temperatura), 1),\n  temperatura_sd = round(sd(temperatura), 2),\n  lecturas = .N\n), by = .(sensor_id, hora)]\n\n# Identificar patrones horarios\npatrones_resumen &lt;- patrones_ciclicos[, .(\n  hora_mas_fria = hora[which.min(temperatura_promedio)],\n  temp_mas_fria = min(temperatura_promedio),\n  hora_mas_calida = hora[which.max(temperatura_promedio)],\n  temp_mas_calida = max(temperatura_promedio),\n  amplitud_termica = round(max(temperatura_promedio) - min(temperatura_promedio), 1),\n  variabilidad_promedio = round(mean(temperatura_sd), 2)\n), by = sensor_id]\n\nprint(\"Patrones t√©rmicos diarios por sensor:\")\n#&gt; [1] \"Patrones t√©rmicos diarios por sensor:\"\nprint(patrones_resumen)\n#&gt;    sensor_id hora_mas_fria temp_mas_fria hora_mas_calida temp_mas_calida\n#&gt;       &lt;char&gt;         &lt;int&gt;         &lt;num&gt;           &lt;int&gt;           &lt;num&gt;\n#&gt; 1:    TEMP_A            17          15.1               5            25.0\n#&gt; 2:    TEMP_B            10          19.0              22            25.1\n#&gt; 3:    TEMP_C             4          23.3              21            26.1\n#&gt;    amplitud_termica variabilidad_promedio\n#&gt;               &lt;num&gt;                 &lt;num&gt;\n#&gt; 1:              9.9                  1.01\n#&gt; 2:              6.1                  0.84\n#&gt; 3:              2.8                  5.23",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Funciones Especiales y An√°lisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-funciones-especiales.html#ejercicios-pr√°cticos",
    "href": "cap03-funciones-especiales.html#ejercicios-pr√°cticos",
    "title": "\n7¬† Funciones Especiales y An√°lisis Temporal\n",
    "section": "\n7.5 Ejercicios Pr√°cticos",
    "text": "7.5 Ejercicios Pr√°cticos\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 11: Sistema de Alertas de Anomal√≠as\n\n\n\nUsando los datasets de sensores y transacciones:\n\n\nImplementa un sistema de detecci√≥n de anomal√≠as multicapa\n\nUsa frollapply() para ventanas personalizadas de detecci√≥n\n\nClasifica anomal√≠as con fcase() por severidad\n\nGenera alertas autom√°ticas con rleid() para secuencias an√≥malas\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 11\n\n\n\n\n\n\n# Sistema completo de detecci√≥n de anomal√≠as multicapa\n# CAPA 1: Anomal√≠as estad√≠sticas\nsistema_anomalias &lt;- sensores_temperatura[order(sensor_id, timestamp)][, `:=`(\n  # Ventanas de referencia\n  temp_ma_1h = frollmean(temperatura, 4, na.rm = TRUE),\n  temp_ma_6h = frollmean(temperatura, 24, na.rm = TRUE), \n  temp_ma_24h = frollmean(temperatura, 96, na.rm = TRUE),\n  \n  # Medidas de variabilidad\n  temp_sd_1h = frollapply(temperatura, 4, sd, na.rm = TRUE),\n  temp_sd_6h = frollapply(temperatura, 24, sd, na.rm = TRUE),\n  \n  # Percentiles m√≥viles\n  temp_p25_6h = frollapply(temperatura, 24, function(x) quantile(x, 0.25, na.rm = TRUE)),\n  temp_p75_6h = frollapply(temperatura, 24, function(x) quantile(x, 0.75, na.rm = TRUE)),\n  \n  # Cambios temporales\n  cambio_15min = abs(temperatura - shift(temperatura, 1)),\n  cambio_1h = abs(temperatura - shift(temperatura, 4)),\n  tendencia_1h = frollapply(temperatura, 4, function(x) {\n    if(length(x) &lt; 4) return(0)\n    lm(x ~ seq_along(x))$coefficients[2]\n  })\n), by = sensor_id][, `:=`(\n  # CAPA 2: Detecci√≥n de anomal√≠as espec√≠ficas\n  anomalia_spike = cambio_15min &gt; 5,  # Cambio s√∫bito &gt; 5¬∞C\n  anomalia_drift = !is.na(temp_ma_6h) & abs(temperatura - temp_ma_6h) &gt; 4, # Drift &gt; 4¬∞C\n  anomalia_variabilidad = !is.na(temp_sd_1h) & temp_sd_1h &gt; 3, # Alta variabilidad\n  anomalia_outlier = !is.na(temp_p25_6h) & !is.na(temp_p75_6h) & \n                    (temperatura &lt; (temp_p25_6h - 1.5*(temp_p75_6h - temp_p25_6h)) |\n                     temperatura &gt; (temp_p75_6h + 1.5*(temp_p75_6h - temp_p25_6h))),\n  anomalia_tendencia = !is.na(tendencia_1h) & abs(tendencia_1h) &gt; 1, # Tendencia &gt; 1¬∞C/15min\n  anomalia_frozen = !is.na(temp_sd_1h) & temp_sd_1h &lt; 0.1 & !is.na(temperatura)  # Sensor \"congelado\"\n)]\n\n# CAPA 3: Clasificaci√≥n por severidad con fcase()\nsistema_anomalias[, `:=`(\n  # Score compuesto\n  score_anomalia = (as.numeric(anomalia_spike) * 5) + \n                  (as.numeric(anomalia_drift) * 3) +\n                  (as.numeric(anomalia_variabilidad) * 2) +\n                  (as.numeric(anomalia_outlier) * 2) +\n                  (as.numeric(anomalia_tendencia) * 4) +\n                  (as.numeric(anomalia_frozen) * 6)\n)][, severidad := fcase(\n  score_anomalia &gt;= 10, \"CR√çTICA\",\n  score_anomalia &gt;= 6, \"ALTA\", \n  score_anomalia &gt;= 3, \"MEDIA\",\n  score_anomalia &gt;= 1, \"BAJA\",\n  default = \"NORMAL\"\n)]\n\n# CAPA 4: Detecci√≥n de secuencias an√≥malas con rleid()\nsistema_anomalias[, `:=`(\n  es_anomalo = severidad != \"NORMAL\",\n  secuencia_id = rleid(severidad != \"NORMAL\")\n), by = sensor_id]\n\n# An√°lisis de secuencias an√≥malas\nsecuencias_anomalas &lt;- sistema_anomalias[es_anomalo == TRUE, .(\n  duracion_minutos = .N * 15,  # 15 min por medici√≥n\n  severidad_maxima = severidad[which.max(score_anomalia)],\n  score_maximo = max(score_anomalia),\n  score_promedio = round(mean(score_anomalia), 1),\n  temp_min = round(min(temperatura, na.rm = TRUE), 1),\n  temp_max = round(max(temperatura, na.rm = TRUE), 1),\n  inicio = min(timestamp),\n  fin = max(timestamp),\n  tipos_anomalia = paste(unique(c(\n    if(any(anomalia_spike)) \"SPIKE\",\n    if(any(anomalia_drift)) \"DRIFT\", \n    if(any(anomalia_variabilidad)) \"VARIABILIDAD\",\n    if(any(anomalia_outlier)) \"OUTLIER\",\n    if(any(anomalia_tendencia)) \"TENDENCIA\",\n    if(any(anomalia_frozen)) \"FROZEN\"\n  )), collapse = \", \")\n), by = .(sensor_id, secuencia_id)][\n  duracion_minutos &gt;= 30  # Solo secuencias de al menos 30 minutos\n][order(-score_maximo)]\n\n# SISTEMA DE ALERTAS AUTOM√ÅTICAS\ncat(\"üö® SISTEMA DE ALERTAS DE ANOMAL√çAS üö®\\n\\n\")\n#&gt; üö® SISTEMA DE ALERTAS DE ANOMAL√çAS üö®\n\n# Alertas activas por sensor\nalertas_activas &lt;- sistema_anomalias[es_anomalo == TRUE, .N, by = .(sensor_id, severidad)][order(sensor_id, severidad)]\n\nif(nrow(alertas_activas) &gt; 0) {\n  cat(\"ALERTAS ACTIVAS POR SENSOR:\\n\")\n  print(alertas_activas)\n} else {\n  cat(\"‚úÖ No hay alertas activas en este momento.\\n\")\n}\n#&gt; ALERTAS ACTIVAS POR SENSOR:\n#&gt;    sensor_id severidad     N\n#&gt;       &lt;char&gt;    &lt;char&gt; &lt;int&gt;\n#&gt; 1:    TEMP_A      ALTA    12\n#&gt; 2:    TEMP_A      BAJA    13\n#&gt; 3:    TEMP_A     MEDIA    66\n#&gt; 4:    TEMP_B      ALTA     5\n#&gt; 5:    TEMP_B      BAJA    17\n#&gt; 6:    TEMP_B     MEDIA     7\n#&gt; 7:    TEMP_C      ALTA     7\n#&gt; 8:    TEMP_C      BAJA    34\n\n# Top secuencias cr√≠ticas\nif(nrow(secuencias_anomalas) &gt; 0) {\n  cat(\"\\nüî• TOP SECUENCIAS AN√ìMALAS:\\n\")\n  print(head(secuencias_anomalas[, .(sensor_id, severidad_maxima, duracion_minutos, \n                                    score_maximo, tipos_anomalia, inicio)], 8))\n} else {\n  cat(\"\\n‚úÖ No se detectaron secuencias an√≥malas significativas.\\n\")\n}\n#&gt; \n#&gt; üî• TOP SECUENCIAS AN√ìMALAS:\n#&gt;    sensor_id severidad_maxima duracion_minutos score_maximo\n#&gt;       &lt;char&gt;           &lt;char&gt;            &lt;num&gt;        &lt;num&gt;\n#&gt; 1:    TEMP_A             ALTA               30            9\n#&gt; 2:    TEMP_A             ALTA               30            7\n#&gt; 3:    TEMP_A             ALTA               45            7\n#&gt; 4:    TEMP_A             ALTA               30            6\n#&gt; 5:    TEMP_A             ALTA               30            6\n#&gt; 6:    TEMP_A             ALTA               30            6\n#&gt; 7:    TEMP_B             ALTA               30            6\n#&gt; 8:    TEMP_B             ALTA               30            6\n#&gt;               tipos_anomalia              inicio\n#&gt;                       &lt;char&gt;              &lt;POSc&gt;\n#&gt; 1: DRIFT, OUTLIER, TENDENCIA 2024-06-01 15:30:00\n#&gt; 2:          DRIFT, TENDENCIA 2024-06-04 11:15:00\n#&gt; 3:          DRIFT, TENDENCIA 2024-06-04 13:00:00\n#&gt; 4:        OUTLIER, TENDENCIA 2024-06-01 08:45:00\n#&gt; 5:        OUTLIER, TENDENCIA 2024-06-01 23:00:00\n#&gt; 6:        OUTLIER, TENDENCIA 2024-06-06 22:00:00\n#&gt; 7:        OUTLIER, TENDENCIA 2024-06-03 06:15:00\n#&gt; 8:             DRIFT, FROZEN 2024-06-07 20:00:00\n\n# Resumen estad√≠stico\nresumen_sistema &lt;- sistema_anomalias[!is.na(temperatura), .(\n  lecturas_totales = .N,\n  anomalias_detectadas = sum(es_anomalo),\n  pct_anomalias = round(mean(es_anomalo) * 100, 2),\n  score_promedio = round(mean(score_anomalia), 2)\n), by = sensor_id]\n\ncat(\"\\nüìä RESUMEN DEL SISTEMA:\\n\")\n#&gt; \n#&gt; üìä RESUMEN DEL SISTEMA:\nprint(resumen_sistema)\n#&gt;    sensor_id lecturas_totales anomalias_detectadas pct_anomalias score_promedio\n#&gt;       &lt;char&gt;            &lt;int&gt;                &lt;int&gt;         &lt;num&gt;          &lt;num&gt;\n#&gt; 1:    TEMP_A              672                   91         13.54             NA\n#&gt; 2:    TEMP_B              672                   29          4.32             NA\n#&gt; 3:    TEMP_C              672                   41          6.10             NA\n\n# # Crear tabla interactiva de secuencias cr√≠ticas (comentado para PDF)\n# if(nrow(secuencias_anomalas) &gt; 0) {\n#   DT::datatable(\n#     secuencias_anomalas[1:min(20, nrow(secuencias_anomalas))],\n#     caption = \"Secuencias An√≥malas Detectadas - Sistema Multicapa\",\n#     options = list(pageLength = 10, scrollX = TRUE)\n#   ) %&gt;%\n#     DT::formatStyle(\n#       \"severidad_maxima\",\n#       backgroundColor = DT::styleEqual(\n#         c(\"CR√çTICA\", \"ALTA\", \"MEDIA\", \"BAJA\"),\n#         c(\"red\", \"orange\", \"yellow\", \"lightblue\")\n#       )\n#     )\n# }\n\n\n\n\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 12: An√°lisis de Supervivencia de Clientes\n\n\n\n\n\nCalcula m√©tricas temporales con shift() y funciones de ventana\n\nIdentifica patrones de churn usando rleid() para secuencias de inactividad\n\nClasifica riesgo de abandono con fcase() m√∫ltiples criterios\n\nGenera score predictivo combinando m√∫ltiples se√±ales\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 12\n\n\n\n\n\n\n# An√°lisis de supervivencia y predicci√≥n de churn\n# 1. Preparar datos temporales con m√©tricas de ventana\nanalisis_supervivencia &lt;- clientes_retencion[, `:=`(\n  dias_desde_registro = as.numeric(as.Date(\"2024-06-30\") - fecha_registro),\n  dias_desde_ultima_actividad = fifelse(\n    is.na(fecha_ultima_actividad), \n    as.numeric(as.Date(\"2024-06-30\") - fecha_registro),\n    as.numeric(as.Date(\"2024-06-30\") - fecha_ultima_actividad)\n  )\n)]\n\n# Combinar con datos transaccionales para an√°lisis de comportamiento\ncomportamiento_clientes &lt;- transacciones_comportamiento[, .(\n  transacciones_totales = .N,\n  gasto_total = sum(monto),\n  gasto_promedio = round(mean(monto), 2),\n  dias_activos = uniqueN(as.Date(fecha_transaccion)),\n  categorias_usadas = uniqueN(categoria),\n  ultima_transaccion = max(as.Date(fecha_transaccion)),\n  primera_transaccion = min(as.Date(fecha_transaccion))\n), by = cliente_id]\n\n# Join con datos de clientes\nsupervivencia_completa &lt;- analisis_supervivencia[\n  comportamiento_clientes, on = .(cliente_id), nomatch = NULL\n][, `:=`(\n  dias_desde_primera_trans = as.numeric(as.Date(\"2024-06-30\") - primera_transaccion),\n  dias_desde_ultima_trans = as.numeric(as.Date(\"2024-06-30\") - ultima_transaccion),\n  frecuencia_transaccional = round(transacciones_totales / dias_activos, 2)\n)]\n\n# 2. Identificar patrones de declive con funciones de ventana\n# Simular datos de actividad mensual para an√°lisis temporal\nactividad_mensual &lt;- supervivencia_completa[, .(\n  cliente_id, activo, ingresos_mensuales, gasto_total, transacciones_totales\n)][, .(\n  cliente_id, \n  mes = rep(1:6, .N),\n  actividad_simulada = as.numeric(activo) * exp(-abs(rnorm(.N * 6, 0, 0.3))),\n  gasto_simulado = rep(gasto_total / 6, 6) * exp(rnorm(.N * 6, 0, 0.4))\n), by = cliente_id][order(cliente_id, mes)]\n\n# Aplicar funciones de ventana para detectar tendencias\nactividad_tendencias &lt;- actividad_mensual[, `:=`(\n  actividad_ma3 = frollmean(actividad_simulada, 3),\n  gasto_ma3 = frollmean(gasto_simulado, 3),\n  actividad_anterior = shift(actividad_simulada, 1),\n  gasto_anterior = shift(gasto_simulado, 1),\n  tendencia_actividad = actividad_simulada - shift(actividad_simulada, 1),\n  secuencia_declive = rleid(actividad_simulada &lt; shift(actividad_simulada, 1))\n), by = cliente_id]\n\n# 3. An√°lisis de riesgo de churn con m√∫ltiples criterios\nmodelo_churn &lt;- supervivencia_completa[, `:=`(\n  # Se√±ales de riesgo temporal\n  riesgo_inactividad = fcase(\n    dias_desde_ultima_trans &gt; 90, \"ALTO\",\n    dias_desde_ultima_trans &gt; 60, \"MEDIO\",\n    dias_desde_ultima_trans &gt; 30, \"BAJO\",\n    default = \"M√çNIMO\"\n  ),\n  \n  # Se√±ales de comportamiento\n  riesgo_engagement = fcase(\n    frecuencia_transaccional &lt; 0.1 & categorias_usadas &lt;= 2, \"ALTO\",\n    frecuencia_transaccional &lt; 0.3 & categorias_usadas &lt;= 3, \"MEDIO\", \n    frecuencia_transaccional &lt; 0.5, \"BAJO\",\n    default = \"M√çNIMO\"\n  ),\n  \n  # Se√±ales econ√≥micas\n  riesgo_economico = fcase(\n    gasto_promedio &lt; ingresos_mensuales * 0.01, \"ALTO\",  # Gasta &lt;1% de ingresos\n    gasto_promedio &lt; ingresos_mensuales * 0.03, \"MEDIO\", # Gasta &lt;3% de ingresos\n    gasto_promedio &lt; ingresos_mensuales * 0.05, \"BAJO\",  # Gasta &lt;5% de ingresos\n    default = \"M√çNIMO\"\n  ),\n  \n  # Se√±al de valor del cliente\n  valor_cliente = round((gasto_total / dias_activos) * (ingresos_mensuales / 1000), 0)\n)][, `:=`(\n  # Score compuesto de riesgo de churn\n  score_churn = (\n    (riesgo_inactividad == \"ALTO\") * 40 + (riesgo_inactividad == \"MEDIO\") * 25 + (riesgo_inactividad == \"BAJO\") * 10 +\n    (riesgo_engagement == \"ALTO\") * 30 + (riesgo_engagement == \"MEDIO\") * 20 + (riesgo_engagement == \"BAJO\") * 10 +\n    (riesgo_economico == \"ALTO\") * 20 + (riesgo_economico == \"MEDIO\") * 12 + (riesgo_economico == \"BAJO\") * 5 +\n    ifelse(!activo, 25, 0)  # Penalizaci√≥n por inactividad actual\n  )\n)][, `:=`(\n  # 4. Clasificaci√≥n final y estrategia\n  clasificacion_churn = fcase(\n    score_churn &gt;= 80, \"CHURN_INMEDIATO\",\n    score_churn &gt;= 60, \"ALTO_RIESGO\", \n    score_churn &gt;= 40, \"RIESGO_MODERADO\",\n    score_churn &gt;= 20, \"BAJO_RIESGO\",\n    default = \"SALUDABLE\"\n  ),\n  \n  estrategia_retencion = fcase(\n    score_churn &gt;= 80, \"Contacto_Inmediato + Oferta_Especial\",\n    score_churn &gt;= 60, \"Programa_Reactivaci√≥n + Descuentos\",\n    score_churn &gt;= 40, \"Comunicaci√≥n_Personalizada\", \n    score_churn &gt;= 20, \"Monitoreo_Activo\",\n    default = \"Mantenimiento_Rutinario\"\n  )\n)]\n\n# An√°lisis de resultados\ncat(\"üìà AN√ÅLISIS DE SUPERVIVENCIA DE CLIENTES üìà\\n\\n\")\n#&gt; üìà AN√ÅLISIS DE SUPERVIVENCIA DE CLIENTES üìà\n\n# Distribuci√≥n por clasificaci√≥n\ndistribucion_churn &lt;- modelo_churn[, .N, by = clasificacion_churn][order(-N)]\ncat(\"DISTRIBUCI√ìN POR RIESGO DE CHURN:\\n\")\n#&gt; DISTRIBUCI√ìN POR RIESGO DE CHURN:\nprint(distribucion_churn)\n#&gt;    clasificacion_churn     N\n#&gt;                 &lt;char&gt; &lt;int&gt;\n#&gt; 1:         BAJO_RIESGO   429\n#&gt; 2:           SALUDABLE   357\n#&gt; 3:     RIESGO_MODERADO   154\n#&gt; 4:         ALTO_RIESGO    43\n#&gt; 5:     CHURN_INMEDIATO     7\n\n# Estad√≠sticas por grupo de riesgo\nstats_por_riesgo &lt;- modelo_churn[, .(\n  clientes = .N,\n  score_promedio = round(mean(score_churn), 1),\n  ingresos_promedio = round(mean(ingresos_mensuales), 0),\n  valor_cliente_promedio = round(mean(valor_cliente), 0),\n  dias_inactividad_promedio = round(mean(dias_desde_ultima_trans), 0),\n  tasa_actividad_actual = round(mean(activo) * 100, 1)\n), by = clasificacion_churn][order(-score_promedio)]\n\ncat(\"\\nüìä ESTAD√çSTICAS POR GRUPO DE RIESGO:\\n\")\n#&gt; \n#&gt; üìä ESTAD√çSTICAS POR GRUPO DE RIESGO:\nprint(stats_por_riesgo)\n#&gt;    clasificacion_churn clientes score_promedio ingresos_promedio\n#&gt;                 &lt;char&gt;    &lt;int&gt;          &lt;num&gt;             &lt;num&gt;\n#&gt; 1:     CHURN_INMEDIATO        7           85.0             18915\n#&gt; 2:         ALTO_RIESGO       43           64.4              9790\n#&gt; 3:     RIESGO_MODERADO      154           46.8             11013\n#&gt; 4:         BAJO_RIESGO      429           26.6              9481\n#&gt; 5:           SALUDABLE      357            8.2              4040\n#&gt;    valor_cliente_promedio dias_inactividad_promedio tasa_actividad_actual\n#&gt;                     &lt;num&gt;                     &lt;num&gt;                 &lt;num&gt;\n#&gt; 1:                    645                       127                   0.0\n#&gt; 2:                   1094                       103                  48.8\n#&gt; 3:                    991                        58                  40.3\n#&gt; 4:                    955                        30                  71.8\n#&gt; 5:                    576                        18                 100.0\n\n# Clientes cr√≠ticos que requieren atenci√≥n inmediata\nclientes_criticos &lt;- modelo_churn[clasificacion_churn %in% c(\"CHURN_INMEDIATO\", \"ALTO_RIESGO\"), .(\n  cliente_id, plan, pais, ingresos_mensuales, valor_cliente, \n  score_churn, clasificacion_churn, estrategia_retencion,\n  dias_inactividad = dias_desde_ultima_trans\n)][order(-score_churn)]\n\ncat(\"\\nüö® CLIENTES QUE REQUIEREN ATENCI√ìN INMEDIATA:\\n\")\n#&gt; \n#&gt; üö® CLIENTES QUE REQUIEREN ATENCI√ìN INMEDIATA:\nprint(head(clientes_criticos, 10))\n#&gt;     cliente_id        plan      pais ingresos_mensuales valor_cliente\n#&gt;          &lt;int&gt;      &lt;char&gt;    &lt;char&gt;              &lt;num&gt;         &lt;num&gt;\n#&gt;  1:        717     Premium Argentina              28491           180\n#&gt;  2:        677 Empresarial  Colombia               8912           276\n#&gt;  3:        368      B√°sico  Colombia               4248           167\n#&gt;  4:        474      B√°sico     Chile               4957           178\n#&gt;  5:        351      B√°sico     Chile               2693            18\n#&gt;  6:        205      B√°sico    Espa√±a               8272           684\n#&gt;  7:        537     Premium    Espa√±a              74834          3011\n#&gt;  8:        488     Premium    M√©xico               4999           453\n#&gt;  9:         31      B√°sico    Espa√±a               4424           258\n#&gt; 10:        905      B√°sico     Chile               2805            91\n#&gt;     score_churn clasificacion_churn                 estrategia_retencion\n#&gt;           &lt;num&gt;              &lt;char&gt;                               &lt;char&gt;\n#&gt;  1:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  2:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  3:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  4:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  5:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  6:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  7:          85     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial\n#&gt;  8:          77         ALTO_RIESGO   Programa_Reactivaci√≥n + Descuentos\n#&gt;  9:          77         ALTO_RIESGO   Programa_Reactivaci√≥n + Descuentos\n#&gt; 10:          77         ALTO_RIESGO   Programa_Reactivaci√≥n + Descuentos\n#&gt;     dias_inactividad\n#&gt;                &lt;num&gt;\n#&gt;  1:              105\n#&gt;  2:              144\n#&gt;  3:              129\n#&gt;  4:               92\n#&gt;  5:              156\n#&gt;  6:              146\n#&gt;  7:              117\n#&gt;  8:               91\n#&gt;  9:               95\n#&gt; 10:              118\n\n# ROI potencial de estrategias de retenci√≥n\nroi_estrategias &lt;- modelo_churn[, .(\n  clientes_objetivo = .N,\n  valor_total_riesgo = sum(valor_cliente),\n  valor_promedio_cliente = round(mean(valor_cliente), 0),\n  inversion_retencion_estimada = .N * fcase(\n    unique(clasificacion_churn) == \"CHURN_INMEDIATO\", 200,\n    unique(clasificacion_churn) == \"ALTO_RIESGO\", 100,\n    unique(clasificacion_churn) == \"RIESGO_MODERADO\", 50,\n    default = 20\n  ),\n  roi_potencial = round((sum(valor_cliente) * 0.7) / (.N * fcase(\n    unique(clasificacion_churn) == \"CHURN_INMEDIATO\", 200,\n    unique(clasificacion_churn) == \"ALTO_RIESGO\", 100, \n    unique(clasificacion_churn) == \"RIESGO_MODERADO\", 50,\n    default = 20\n  )), 1)\n), by = .(clasificacion_churn, estrategia_retencion)][order(-roi_potencial)]\n\ncat(\"\\nüí∞ AN√ÅLISIS DE ROI DE ESTRATEGIAS:\\n\")\n#&gt; \n#&gt; üí∞ AN√ÅLISIS DE ROI DE ESTRATEGIAS:\nprint(roi_estrategias)\n#&gt;    clasificacion_churn                 estrategia_retencion clientes_objetivo\n#&gt;                 &lt;char&gt;                               &lt;char&gt;             &lt;int&gt;\n#&gt; 1:         BAJO_RIESGO                     Monitoreo_Activo               429\n#&gt; 2:           SALUDABLE              Mantenimiento_Rutinario               357\n#&gt; 3:     RIESGO_MODERADO           Comunicaci√≥n_Personalizada               154\n#&gt; 4:         ALTO_RIESGO   Programa_Reactivaci√≥n + Descuentos                43\n#&gt; 5:     CHURN_INMEDIATO Contacto_Inmediato + Oferta_Especial                 7\n#&gt;    valor_total_riesgo valor_promedio_cliente inversion_retencion_estimada\n#&gt;                 &lt;num&gt;                  &lt;num&gt;                        &lt;num&gt;\n#&gt; 1:             409510                    955                         8580\n#&gt; 2:             205785                    576                         7140\n#&gt; 3:             152686                    991                         7700\n#&gt; 4:              47050                   1094                         4300\n#&gt; 5:               4514                    645                         1400\n#&gt;    roi_potencial\n#&gt;            &lt;num&gt;\n#&gt; 1:          33.4\n#&gt; 2:          20.2\n#&gt; 3:          13.9\n#&gt; 4:           7.7\n#&gt; 5:           2.3\n\n\n\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nFunciones de ventana (shift, frollmean, frollapply) permiten an√°lisis temporal sofisticado sin colapsar datos\n\nFunciones condicionales (fifelse, fcase, between) optimizan clasificaciones complejas\n\nFunciones de agregaci√≥n especiales (frank, rleid, uniqueN) revelan patrones ocultos en los datos\n\nAn√°lisis temporal combina m√∫ltiples t√©cnicas para detecci√≥n de anomal√≠as y predicci√≥n\n\nPerformance: Estas funciones est√°n altamente optimizadas y son significativamente m√°s r√°pidas que alternativas de R base\n\nCasos de uso reales: Finanzas, IoT, an√°lisis de comportamiento - las aplicaciones son ilimitadas\n\n\n\nLas funciones especiales de data.table te dan superpoderes para an√°lisis complejos. En el pr√≥ximo cap√≠tulo exploraremos las t√©cnicas de reshape que complementan perfectamente estas funciones para transformaciones de datos avanzadas.\n[{‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1-new‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 2: dividir en encadenamiento y joins‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-reshape.qmd para reshape del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúin_progress‚Äù, ‚Äúid‚Äù: ‚Äú3-3‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú4‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú5‚Äù}]",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>7</span>¬† <span class='chapter-title'>Funciones Especiales y An√°lisis Temporal</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html",
    "href": "cap03-reshape.html",
    "title": "\n8¬† Remodelaci√≥n de Datos: melt() y dcast()\n",
    "section": "",
    "text": "8.1 Conceptos Fundamentales: Wide vs Long\nAntes de explorar melt() y dcast(), es crucial entender cu√°ndo y por qu√© transformar estructuras de datos:\n# Ejemplo simple: formato wide\ndatos_wide_ejemplo &lt;- data.table(\n  estudiante = c(\"Ana\", \"Juan\", \"Mar√≠a\"),\n  matematicas = c(85, 90, 78),\n  ciencias = c(88, 85, 92),\n  historia = c(82, 88, 89)\n)\n\nprint(\"Formato WIDE (t√≠pico de Excel):\")\n#&gt; [1] \"Formato WIDE (t√≠pico de Excel):\"\nprint(datos_wide_ejemplo)\n#&gt;    estudiante matematicas ciencias historia\n#&gt;        &lt;char&gt;       &lt;num&gt;    &lt;num&gt;    &lt;num&gt;\n#&gt; 1:        Ana          85       88       82\n#&gt; 2:       Juan          90       85       88\n#&gt; 3:      Mar√≠a          78       92       89\n\n# Convertir a formato long\ndatos_long_ejemplo &lt;- melt(datos_wide_ejemplo, \n                          id.vars = \"estudiante\",\n                          variable.name = \"materia\", \n                          value.name = \"calificacion\")\n\nprint(\"\\nFormato LONG (ideal para an√°lisis):\")\n#&gt; [1] \"\\nFormato LONG (ideal para an√°lisis):\"\nprint(datos_long_ejemplo)\n#&gt;    estudiante     materia calificacion\n#&gt;        &lt;char&gt;      &lt;fctr&gt;        &lt;num&gt;\n#&gt; 1:        Ana matematicas           85\n#&gt; 2:       Juan matematicas           90\n#&gt; 3:      Mar√≠a matematicas           78\n#&gt; 4:        Ana    ciencias           88\n#&gt; 5:       Juan    ciencias           85\n#&gt; 6:      Mar√≠a    ciencias           92\n#&gt; 7:        Ana    historia           82\n#&gt; 8:       Juan    historia           88\n#&gt; 9:      Mar√≠a    historia           89",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Remodelaci√≥n de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#conceptos-fundamentales-wide-vs-long",
    "href": "cap03-reshape.html#conceptos-fundamentales-wide-vs-long",
    "title": "\n8¬† Remodelaci√≥n de Datos: melt() y dcast()\n",
    "section": "",
    "text": "Formato Wide (ancho): Cada variable tiene su propia columna. F√°cil de leer pero dif√≠cil de analizar estad√≠sticamente.\n\nFormato Long (largo): Las observaciones se ‚Äúapilan‚Äù en filas. Ideal para an√°lisis estad√≠stico y visualizaci√≥n.",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Remodelaci√≥n de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#melt-de-ancho-a-largo",
    "href": "cap03-reshape.html#melt-de-ancho-a-largo",
    "title": "\n8¬† Remodelaci√≥n de Datos: melt() y dcast()\n",
    "section": "\n8.2 melt(): De Ancho a Largo",
    "text": "8.2 melt(): De Ancho a Largo\n\n8.2.1 1. melt() B√°sico\n\n\n# Transformar datos de ventas trimestrales\nventas_long &lt;- melt(ventas_trimestral_wide,\n                   id.vars = c(\"producto\", \"categoria\", \"precio_unitario\"),\n                   variable.name = \"periodo_metrica\", \n                   value.name = \"valor\")\n\nprint(\"Datos transformados a formato largo:\")\n#&gt; [1] \"Datos transformados a formato largo:\"\nprint(head(ventas_long, 12))\n#&gt;       producto    categoria precio_unitario  periodo_metrica  valor\n#&gt;         &lt;char&gt;       &lt;char&gt;           &lt;num&gt;           &lt;fctr&gt;  &lt;num&gt;\n#&gt;  1:     Laptop Computadoras            1200 Q1_2023_unidades    150\n#&gt;  2:    Desktop Computadoras             800 Q1_2023_unidades     80\n#&gt;  3:     Tablet Computadoras             400 Q1_2023_unidades    200\n#&gt;  4: Smartphone      M√≥viles             600 Q1_2023_unidades    300\n#&gt;  5:    Monitor  Perif√©ricos             300 Q1_2023_unidades    120\n#&gt; ---                                                                \n#&gt;  8:  Impresora      Oficina             200 Q1_2023_unidades     60\n#&gt;  9:     Router        Redes             150 Q1_2023_unidades     90\n#&gt; 10:     C√°mara   Multimedia             250 Q1_2023_unidades     70\n#&gt; 11:     Laptop Computadoras            1200  Q1_2023_revenue 180000\n#&gt; 12:    Desktop Computadoras             800  Q1_2023_revenue  64000\n\n# Ver la estructura completa\ncat(\"Dimensiones originales:\", dim(ventas_trimestral_wide), \"\\n\")\n#&gt; Dimensiones originales: 10 13\ncat(\"Dimensiones despu√©s de melt:\", dim(ventas_long), \"\\n\")\n#&gt; Dimensiones despu√©s de melt: 100 5\n\n\n8.2.2 2. Separar Variables Complejas\n\n\n# Separar periodo y m√©trica de la variable compuesta\nventas_long_separada &lt;- ventas_long[, `:=`(\n  periodo = sub(\"_unidades|_revenue\", \"\", periodo_metrica),\n  metrica = ifelse(grepl(\"unidades\", periodo_metrica), \"unidades\", \"revenue\")\n)]\n\nprint(\"Datos con variables separadas:\")\n#&gt; [1] \"Datos con variables separadas:\"\nprint(head(ventas_long_separada, 12))\n#&gt;       producto    categoria precio_unitario  periodo_metrica  valor periodo\n#&gt;         &lt;char&gt;       &lt;char&gt;           &lt;num&gt;           &lt;fctr&gt;  &lt;num&gt;  &lt;char&gt;\n#&gt;  1:     Laptop Computadoras            1200 Q1_2023_unidades    150 Q1_2023\n#&gt;  2:    Desktop Computadoras             800 Q1_2023_unidades     80 Q1_2023\n#&gt;  3:     Tablet Computadoras             400 Q1_2023_unidades    200 Q1_2023\n#&gt;  4: Smartphone      M√≥viles             600 Q1_2023_unidades    300 Q1_2023\n#&gt;  5:    Monitor  Perif√©ricos             300 Q1_2023_unidades    120 Q1_2023\n#&gt; ---                                                                        \n#&gt;  8:  Impresora      Oficina             200 Q1_2023_unidades     60 Q1_2023\n#&gt;  9:     Router        Redes             150 Q1_2023_unidades     90 Q1_2023\n#&gt; 10:     C√°mara   Multimedia             250 Q1_2023_unidades     70 Q1_2023\n#&gt; 11:     Laptop Computadoras            1200  Q1_2023_revenue 180000 Q1_2023\n#&gt; 12:    Desktop Computadoras             800  Q1_2023_revenue  64000 Q1_2023\n#&gt;      metrica\n#&gt;       &lt;char&gt;\n#&gt;  1: unidades\n#&gt;  2: unidades\n#&gt;  3: unidades\n#&gt;  4: unidades\n#&gt;  5: unidades\n#&gt; ---         \n#&gt;  8: unidades\n#&gt;  9: unidades\n#&gt; 10: unidades\n#&gt; 11:  revenue\n#&gt; 12:  revenue\n\n# Limpiar columna temporal\nventas_long_separada[, periodo_metrica := NULL]\n\n\n8.2.3 3. melt() con Patrones\n\n\n# Melt usando patrones para m√∫ltiples tipos de variables\nempleados_long &lt;- melt(empleados_metricas,\n                      id.vars = c(\"empleado_id\", \"nombre\", \"departamento\", \"nivel\", \"salario_base\"),\n                      measure = patterns(\n                        bonus = \"^bonus_\",\n                        evaluacion = \"^evaluacion_\", \n                        proyectos = \"^proyectos_\"\n                      ),\n                      variable.name = \"trimestre\",\n                      value.name = c(\"bonus\", \"evaluacion\", \"proyectos\"))\n\n# Limpiar nombres de trimestre\nempleados_long[, trimestre := paste0(\"Q\", trimestre)]\n\nprint(\"Empleados con m√∫ltiples m√©tricas en formato largo:\")\n#&gt; [1] \"Empleados con m√∫ltiples m√©tricas en formato largo:\"\nprint(head(empleados_long, 12))\n#&gt;     empleado_id     nombre departamento   nivel salario_base trimestre bonus\n#&gt;          &lt;char&gt;     &lt;char&gt;       &lt;char&gt;  &lt;char&gt;        &lt;num&gt;    &lt;char&gt; &lt;num&gt;\n#&gt;  1:     EMP_001 Empleado_A       Ventas  Junior        72700        Q1   378\n#&gt;  2:     EMP_002 Empleado_B       Ventas  Senior        49400        Q1   896\n#&gt;  3:     EMP_003 Empleado_C       Ventas    Lead        65600        Q1  5443\n#&gt;  4:     EMP_004 Empleado_D       Ventas Manager        66400        Q1  6800\n#&gt;  5:     EMP_005 Empleado_E       Ventas  Junior        55600        Q1  6379\n#&gt; ---                                                                         \n#&gt;  8:     EMP_008 Empleado_H           IT Manager        48600        Q1  6525\n#&gt;  9:     EMP_009 Empleado_I           IT  Junior        74400        Q1     4\n#&gt; 10:     EMP_010 Empleado_J           IT  Senior        40400        Q1   169\n#&gt; 11:     EMP_011 Empleado_K    Marketing    Lead        75600        Q1  3529\n#&gt; 12:     EMP_012 Empleado_L    Marketing Manager        77900        Q1  2322\n#&gt;     evaluacion proyectos\n#&gt;          &lt;num&gt;     &lt;int&gt;\n#&gt;  1:        3.6         7\n#&gt;  2:        4.3         1\n#&gt;  3:        3.4         6\n#&gt;  4:        4.1         5\n#&gt;  5:        3.5         2\n#&gt; ---                     \n#&gt;  8:        3.1         2\n#&gt;  9:        3.5         1\n#&gt; 10:        4.6         3\n#&gt; 11:        3.2         1\n#&gt; 12:        4.2         1\n\n\n8.2.4 4. melt() Avanzado para Sensores\n\n\n# Melt complejo para datos de sensores m√∫ltiples\nsensores_long &lt;- melt(sensores_multiples,\n                     id.vars = c(\"timestamp\", \"ubicacion\"),\n                     variable.name = \"sensor_completo\",\n                     value.name = \"medicion\")[, `:=`(\n  # Extraer tipo de sensor y n√∫mero\n  tipo_sensor = sub(\"_[0-9]+$\", \"\", sensor_completo),\n  numero_sensor = as.numeric(sub(\".*_\", \"\", sensor_completo))\n)][, sensor_completo := NULL]  # Limpiar columna temporal\n\nprint(\"Sensores en formato largo:\")\n#&gt; [1] \"Sensores en formato largo:\"\nprint(head(sensores_long, 15))\n#&gt;               timestamp    ubicacion medicion tipo_sensor numero_sensor\n#&gt;                  &lt;POSc&gt;       &lt;char&gt;    &lt;num&gt;      &lt;char&gt;         &lt;num&gt;\n#&gt;  1: 2024-01-01 00:00:00 Planta_Norte     19.9 sensor_temp             1\n#&gt;  2: 2024-01-01 06:00:00 Planta_Norte     19.9 sensor_temp             1\n#&gt;  3: 2024-01-01 12:00:00 Planta_Norte     24.5 sensor_temp             1\n#&gt;  4: 2024-01-01 18:00:00 Planta_Norte     23.4 sensor_temp             1\n#&gt;  5: 2024-01-02 00:00:00 Planta_Norte     24.1 sensor_temp             1\n#&gt; ---                                                                    \n#&gt; 11: 2024-01-03 12:00:00 Planta_Norte     23.5 sensor_temp             1\n#&gt; 12: 2024-01-03 18:00:00 Planta_Norte     23.6 sensor_temp             1\n#&gt; 13: 2024-01-04 00:00:00 Planta_Norte     21.1 sensor_temp             1\n#&gt; 14: 2024-01-04 06:00:00 Planta_Norte     21.3 sensor_temp             1\n#&gt; 15: 2024-01-04 12:00:00 Planta_Norte     20.3 sensor_temp             1\n\n# Estad√≠sticas por tipo de sensor\nstats_sensores &lt;- sensores_long[, .(\n  mediciones = .N,\n  promedio = round(mean(medicion, na.rm = TRUE), 2),\n  minimo = round(min(medicion, na.rm = TRUE), 2),\n  maximo = round(max(medicion, na.rm = TRUE), 2),\n  desviacion = round(sd(medicion, na.rm = TRUE), 2)\n), by = .(tipo_sensor, ubicacion)]\n\nprint(\"\\nEstad√≠sticas por tipo de sensor y ubicaci√≥n:\")\n#&gt; [1] \"\\nEstad√≠sticas por tipo de sensor y ubicaci√≥n:\"\nprint(stats_sensores)\n#&gt;       tipo_sensor     ubicacion mediciones promedio minimo maximo desviacion\n#&gt;            &lt;char&gt;        &lt;char&gt;      &lt;int&gt;    &lt;num&gt;  &lt;num&gt;  &lt;num&gt;      &lt;num&gt;\n#&gt; 1:    sensor_temp  Planta_Norte         56    21.08   13.5   27.1       3.38\n#&gt; 2:    sensor_temp    Planta_Sur         56    21.15   13.1   26.4       3.31\n#&gt; 3:    sensor_temp Planta_Centro         56    21.24   14.5   26.9       3.21\n#&gt; 4: sensor_humedad  Planta_Norte         56    64.10   42.9   79.8       8.65\n#&gt; 5: sensor_humedad    Planta_Sur         56    64.20   42.6   77.6      10.36\n#&gt; 6: sensor_humedad Planta_Centro         56    58.45   40.7   78.6       9.29\n#&gt; 7: sensor_presion  Planta_Norte         56  1021.35  999.9 1044.3      11.25\n#&gt; 8: sensor_presion    Planta_Sur         56  1007.93  987.8 1033.3      12.23\n#&gt; 9: sensor_presion Planta_Centro         56  1020.05  997.3 1040.6      11.55",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Remodelaci√≥n de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#dcast-de-largo-a-ancho",
    "href": "cap03-reshape.html#dcast-de-largo-a-ancho",
    "title": "\n8¬† Remodelaci√≥n de Datos: melt() y dcast()\n",
    "section": "\n8.3 dcast(): De Largo a Ancho",
    "text": "8.3 dcast(): De Largo a Ancho\n\n8.3.1 1. dcast() B√°sico\n\n\n# Reconstruir formato ancho desde formato largo\nventas_reconstruida &lt;- dcast(ventas_long_separada, \n                            producto + categoria + precio_unitario ~ periodo + metrica,\n                            value.var = \"valor\")\n\nprint(\"Datos reconstruidos a formato ancho:\")\n#&gt; [1] \"Datos reconstruidos a formato ancho:\"\nprint(head(ventas_reconstruida))\n#&gt; Clave &lt;producto, categoria, precio_unitario&gt;\n#&gt;     producto    categoria precio_unitario Q1_2023_revenue Q1_2023_unidades\n#&gt;       &lt;char&gt;       &lt;char&gt;           &lt;num&gt;           &lt;num&gt;            &lt;num&gt;\n#&gt; 1:    C√°mara   Multimedia             250           17500               70\n#&gt; 2:   Desktop Computadoras             800           64000               80\n#&gt; 3: Impresora      Oficina             200           12000               60\n#&gt; 4:    Laptop Computadoras            1200          180000              150\n#&gt; 5:   Monitor  Perif√©ricos             300           36000              120\n#&gt; 6:     Mouse  Perif√©ricos              25           11250              450\n#&gt;    Q1_2024_revenue Q1_2024_unidades Q2_2023_revenue Q2_2023_unidades\n#&gt;              &lt;num&gt;            &lt;num&gt;           &lt;num&gt;            &lt;num&gt;\n#&gt; 1:           20000               80           18750               75\n#&gt; 2:           68000               85           60000               75\n#&gt; 3:           15000               75           11000               55\n#&gt; 4:          228000              190          216000              180\n#&gt; 5:           51000              170           42000              140\n#&gt; 6:           13750              550           12000              480\n#&gt;    Q3_2023_revenue Q3_2023_unidades Q4_2023_revenue Q4_2023_unidades\n#&gt;              &lt;num&gt;            &lt;num&gt;           &lt;num&gt;            &lt;num&gt;\n#&gt; 1:           21250               85           22500               90\n#&gt; 2:           72000               90           76000               95\n#&gt; 3:           14000               70           16000               80\n#&gt; 4:          240000              200          264000              220\n#&gt; 5:           48000              160           54000              180\n#&gt; 6:           12500              500           15000              600\n\n# Verificar que coincide con datos originales\ncat(\"¬øReconstrucci√≥n exitosa?\", \n    nrow(ventas_reconstruida) == nrow(ventas_trimestral_wide) && \n    ncol(ventas_reconstruida) &gt;= ncol(ventas_trimestral_wide) - 2, \"\\n\")\n#&gt; ¬øReconstrucci√≥n exitosa? TRUE\n\n\n8.3.2 2. dcast() con Agregaci√≥n\n\n\n# Crear tabla resumen: promedio por producto y a√±o\nventas_resumen_anual &lt;- ventas_long_separada[, \n  a√±o := ifelse(grepl(\"2023\", periodo), \"2023\", \"2024\")\n][, .(\n  valor_promedio = round(mean(valor), 0)\n), by = .(producto, categoria, a√±o, metrica)]\n\n# Convertir a formato ancho con agregaci√≥n\nresumen_wide &lt;- dcast(ventas_resumen_anual,\n                     producto + categoria ~ a√±o + metrica,\n                     value.var = \"valor_promedio\")\n\nprint(\"Resumen anual en formato ancho:\")\n#&gt; [1] \"Resumen anual en formato ancho:\"\nprint(resumen_wide)\n#&gt; Clave &lt;producto, categoria&gt;\n#&gt;       producto    categoria 2023_revenue 2023_unidades 2024_revenue\n#&gt;         &lt;char&gt;       &lt;char&gt;        &lt;num&gt;         &lt;num&gt;        &lt;num&gt;\n#&gt;  1:     C√°mara   Multimedia        20000            80        20000\n#&gt;  2:    Desktop Computadoras        68000            85        68000\n#&gt;  3:  Impresora      Oficina        13250            66        15000\n#&gt;  4:     Laptop Computadoras       225000           188       228000\n#&gt;  5:    Monitor  Perif√©ricos        45000           150        51000\n#&gt;  6:      Mouse  Perif√©ricos        12688           508        13750\n#&gt;  7:     Router        Redes        14438            96        15750\n#&gt;  8: Smartphone      M√≥viles       205500           342       228000\n#&gt;  9:     Tablet Computadoras        76000           190        80000\n#&gt; 10:    Teclado  Perif√©ricos        21250           425        22500\n#&gt;     2024_unidades\n#&gt;             &lt;num&gt;\n#&gt;  1:            80\n#&gt;  2:            85\n#&gt;  3:            75\n#&gt;  4:           190\n#&gt;  5:           170\n#&gt;  6:           550\n#&gt;  7:           105\n#&gt;  8:           380\n#&gt;  9:           200\n#&gt; 10:           450\n\n\n8.3.3 3. dcast() con Funciones de Agregaci√≥n Personalizadas\n\n\n# An√°lisis completo de empleados por departamento\nempleados_analisis &lt;- dcast(empleados_long,\n                           departamento + nivel ~ .,\n                           value.var = c(\"bonus\", \"evaluacion\", \"proyectos\"),\n                           fun.aggregate = list(\n                             mean = mean,\n                             max = max,\n                             min = min\n                           ))\n\nprint(\"An√°lisis agregado de empleados:\")\n#&gt; [1] \"An√°lisis agregado de empleados:\"\nprint(empleados_analisis)\n#&gt; Clave &lt;departamento, nivel&gt;\n#&gt;     departamento   nivel bonus_mean evaluacion_mean proyectos_mean bonus_max\n#&gt;           &lt;char&gt;  &lt;char&gt;      &lt;num&gt;           &lt;num&gt;          &lt;num&gt;     &lt;num&gt;\n#&gt;  1:           IT  Junior    2997.50           4.200          3.250      6544\n#&gt;  2:           IT    Lead    8586.00           3.750          7.750     14636\n#&gt;  3:           IT Manager    5640.25           3.950          4.750      8626\n#&gt;  4:           IT  Senior    5855.50           4.350          4.125     12881\n#&gt;  5:    Marketing  Junior    5739.75           4.150          4.250      9434\n#&gt; ---                                                                         \n#&gt; 12:         RRHH  Senior    4420.25           3.275          6.500      7729\n#&gt; 13:       Ventas  Junior    5225.00           4.200          5.875     10347\n#&gt; 14:       Ventas    Lead    5906.00           4.000          6.250      7472\n#&gt; 15:       Ventas Manager    4664.00           3.750          5.250      7673\n#&gt; 16:       Ventas  Senior    4700.00           3.975          2.750      9105\n#&gt;     evaluacion_max proyectos_max bonus_min evaluacion_min proyectos_min\n#&gt;              &lt;num&gt;         &lt;int&gt;     &lt;num&gt;          &lt;num&gt;         &lt;int&gt;\n#&gt;  1:            4.9             7         4            3.5             1\n#&gt;  2:            4.2            12      4157            3.3             5\n#&gt;  3:            4.7             9      2792            3.1             1\n#&gt;  4:            5.0             8       169            3.2             1\n#&gt;  5:            4.8             9      1410            3.2             2\n#&gt; ---                                                                    \n#&gt; 12:            3.4            12       431            3.1             1\n#&gt; 13:            4.9            12       378            3.5             2\n#&gt; 14:            4.7             9      4470            3.3             3\n#&gt; 15:            4.1            11       264            3.4             1\n#&gt; 16:            4.6             5       896            3.3             1\n\n\n8.3.4 4. Tablas de Contingencia con dcast()\n\n\n# Transformar encuesta a formato largo primero\nencuesta_long &lt;- melt(encuesta_satisfaccion,\n                     id.vars = c(\"respuesta_id\", \"cliente_id\", \"fecha_encuesta\", \"edad\", \"genero\", \"region\"),\n                     measure.vars = patterns(\"^satisfaccion_\", \"gasto_mensual\"),\n                     variable.name = \"aspecto_satisfaccion\",\n                     value.name = c(\"puntuacion\", \"gasto_mensual\"))\n\n# Limpiar nombres de aspectos\nencuesta_long[, aspecto := sub(\"satisfaccion_\", \"\", aspecto_satisfaccion)]\n\n# Crear tabla de contingencia: regi√≥n vs aspecto (promedio de satisfacci√≥n)\ntabla_contingencia &lt;- dcast(encuesta_long,\n                           region ~ aspecto,\n                           value.var = \"puntuacion\", \n                           fun.aggregate = mean)\n\nprint(\"Tabla de contingencia: Satisfacci√≥n promedio por regi√≥n y aspecto:\")\n#&gt; [1] \"Tabla de contingencia: Satisfacci√≥n promedio por regi√≥n y aspecto:\"\nprint(tabla_contingencia)\n#&gt; Clave &lt;region&gt;\n#&gt;    region        1        2        3        4\n#&gt;    &lt;char&gt;    &lt;num&gt;    &lt;num&gt;    &lt;num&gt;    &lt;num&gt;\n#&gt; 1:   Este 3.791667 3.875000 3.750000 3.375000\n#&gt; 2:  Norte 3.700000 3.500000 3.150000 3.150000\n#&gt; 3:  Oeste 3.750000 3.718750 3.062500 3.375000\n#&gt; 4:    Sur 4.083333 3.791667 3.208333 3.416667\n\n# Matriz de correlaci√≥n usando dcast\n# Primero, crear datos en formato adecuado\nmatriz_correlacion_data &lt;- encuesta_long[, .(\n  satisfaccion_promedio = mean(puntuacion)\n), by = .(cliente_id, aspecto)]\n\nmatriz_correlacion_wide &lt;- dcast(matriz_correlacion_data,\n                                cliente_id ~ aspecto,\n                                value.var = \"satisfaccion_promedio\")\n\n# Calcular correlaciones\ncor_matrix &lt;- cor(matriz_correlacion_wide[, -\"cliente_id\"], use = \"complete.obs\")\nprint(\"\\nMatriz de correlaciones entre aspectos:\")\n#&gt; [1] \"\\nMatriz de correlaciones entre aspectos:\"\nprint(round(cor_matrix, 3))\n#&gt;        1      2      3      4\n#&gt; 1  1.000  0.153  0.228 -0.311\n#&gt; 2  0.153  1.000 -0.127 -0.090\n#&gt; 3  0.228 -0.127  1.000 -0.175\n#&gt; 4 -0.311 -0.090 -0.175  1.000",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Remodelaci√≥n de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#casos-de-uso-avanzados",
    "href": "cap03-reshape.html#casos-de-uso-avanzados",
    "title": "\n8¬† Remodelaci√≥n de Datos: melt() y dcast()\n",
    "section": "\n8.4 Casos de Uso Avanzados",
    "text": "8.4 Casos de Uso Avanzados\n\n8.4.1 1. Reportes Ejecutivos Din√°micos\n\n\n# Crear reporte ejecutivo completo combinando melt/dcast\nreporte_ejecutivo &lt;- ventas_long_separada[\n  # Calcular m√©tricas adicionales\n  , `:=`(\n    a√±o = ifelse(grepl(\"2023\", periodo), \"2023\", \"2024\"),\n    trimestre_num = as.numeric(substr(periodo, 2, 2))\n  )\n][\n  # Agrupar y calcular KPIs\n  , .(\n    valor_total = sum(valor),\n    productos_activos = uniqueN(producto)\n  ), by = .(categoria, a√±o, metrica)\n]\n\n# Crear formato ancho para reporte\nreporte_ejecutivo &lt;-  dcast(reporte_ejecutivo, categoria ~ a√±o + metrica, value.var = \"valor_total\")\n\nprint(\"Reporte Ejecutivo de Ventas:\")\n#&gt; [1] \"Reporte Ejecutivo de Ventas:\"\nprint(reporte_ejecutivo)\n#&gt; Clave &lt;categoria&gt;\n#&gt;       categoria 2023_revenue 2023_unidades 2024_revenue 2024_unidades\n#&gt;          &lt;char&gt;        &lt;num&gt;         &lt;num&gt;        &lt;num&gt;         &lt;num&gt;\n#&gt; 1: Computadoras      1476000          1850       376000           475\n#&gt; 2:   Multimedia        80000           320        20000            80\n#&gt; 3:      M√≥viles       822000          1370       228000           380\n#&gt; 4:      Oficina        53000           265        15000            75\n#&gt; 5:  Perif√©ricos       315750          4330        87250          1170\n#&gt; 6:        Redes        57750           385        15750           105\n\n# Calcular crecimiento a√±o sobre a√±o\nreporte_con_crecimiento &lt;- copy(reporte_ejecutivo)[, `:=`(\n  crecimiento_revenue = round((get(\"2024_revenue\") - get(\"2023_revenue\")) / get(\"2023_revenue\") * 100, 1),\n  crecimiento_unidades = round((get(\"2024_unidades\") - get(\"2023_unidades\")) / get(\"2023_unidades\") * 100, 1)\n)]\n\nprint(\"\\nReporte con an√°lisis de crecimiento:\")\n#&gt; [1] \"\\nReporte con an√°lisis de crecimiento:\"\nprint(reporte_con_crecimiento[, .(categoria, \n                                 revenue_2023 = `2023_revenue`, \n                                 revenue_2024 = `2024_revenue`,\n                                 crecimiento_revenue,\n                                 crecimiento_unidades)])\n#&gt; Clave &lt;categoria&gt;\n#&gt;       categoria revenue_2023 revenue_2024 crecimiento_revenue\n#&gt;          &lt;char&gt;        &lt;num&gt;        &lt;num&gt;               &lt;num&gt;\n#&gt; 1: Computadoras      1476000       376000               -74.5\n#&gt; 2:   Multimedia        80000        20000               -75.0\n#&gt; 3:      M√≥viles       822000       228000               -72.3\n#&gt; 4:      Oficina        53000        15000               -71.7\n#&gt; 5:  Perif√©ricos       315750        87250               -72.4\n#&gt; 6:        Redes        57750        15750               -72.7\n#&gt;    crecimiento_unidades\n#&gt;                   &lt;num&gt;\n#&gt; 1:                -74.3\n#&gt; 2:                -75.0\n#&gt; 3:                -72.3\n#&gt; 4:                -71.7\n#&gt; 5:                -73.0\n#&gt; 6:                -72.7\n\n\n8.4.2 2. Dashboard de Sensores en Tiempo Real\n\n\n# Crear dashboard de estado actual de sensores\nestado_actual_sensores &lt;- sensores_long[\n  # Obtener √∫ltima lectura por sensor\n  , .SD[.N], by = .(ubicacion, tipo_sensor, numero_sensor)\n][\n  # Clasificar estado seg√∫n rangos normales\n  , estado := fcase(\n    tipo_sensor == \"sensor_temp\" & (medicion &lt; 15 | medicion &gt; 30), \"ALERTA\",\n    tipo_sensor == \"sensor_humedad\" & (medicion &lt; 30 | medicion &gt; 80), \"ALERTA\", \n    tipo_sensor == \"sensor_presion\" & (medicion &lt; 1000 | medicion &gt; 1030), \"ALERTA\",\n    default = \"NORMAL\"\n  )\n]\n\n# Dashboard en formato ancho\ndashboard_wide &lt;- dcast(estado_actual_sensores,\n                       ubicacion ~ tipo_sensor + numero_sensor,\n                       value.var = \"medicion\")\n\nprint(\"Dashboard de Sensores (valores actuales):\")\n#&gt; [1] \"Dashboard de Sensores (valores actuales):\"\nprint(dashboard_wide)\n#&gt; Clave &lt;ubicacion&gt;\n#&gt;        ubicacion sensor_humedad_1 sensor_humedad_2 sensor_presion_1\n#&gt;           &lt;char&gt;            &lt;num&gt;            &lt;num&gt;            &lt;num&gt;\n#&gt; 1: Planta_Centro             60.5             74.1           1006.4\n#&gt; 2:  Planta_Norte             42.9             58.0           1012.8\n#&gt; 3:    Planta_Sur             71.0             60.6           1015.7\n#&gt;    sensor_presion_2 sensor_temp_1 sensor_temp_2\n#&gt;               &lt;num&gt;         &lt;num&gt;         &lt;num&gt;\n#&gt; 1:            998.2          19.9          25.7\n#&gt; 2:            999.9          18.4          25.8\n#&gt; 3:           1029.3          19.4          26.0\n\n# Tabla de alertas\nalertas_sensores &lt;- estado_actual_sensores[estado == \"ALERTA\"]\nif(nrow(alertas_sensores) &gt; 0) {\n  print(\"\\nüö® ALERTAS ACTIVAS:\")\n  print(alertas_sensores[, .(ubicacion, tipo_sensor, numero_sensor, medicion, timestamp)])\n} else {\n  cat(\"\\n‚úÖ Todos los sensores operan en rangos normales\\n\")\n}\n#&gt; [1] \"\\nüö® ALERTAS ACTIVAS:\"\n#&gt;        ubicacion    tipo_sensor numero_sensor medicion           timestamp\n#&gt;           &lt;char&gt;         &lt;char&gt;         &lt;num&gt;    &lt;num&gt;              &lt;POSc&gt;\n#&gt; 1:  Planta_Norte sensor_presion             2    999.9 2024-01-07 18:00:00\n#&gt; 2: Planta_Centro sensor_presion             2    998.2 2024-01-07 18:00:00\n\n\n8.4.3 3. An√°lisis Multivariable de Encuestas\n\n\n# An√°lisis completo de satisfacci√≥n por segmentos\nanalisis_satisfaccion &lt;- encuesta_long[\n  # Agregar segmentaci√≥n demogr√°fica\n  , `:=`(\n    grupo_edad = cut(edad, breaks = c(0, 30, 45, 60, 100), \n                    labels = c(\"Joven\", \"Adulto\", \"Maduro\", \"Senior\")),\n    gasto_categoria = cut(gasto_mensual, breaks = c(0, 100, 300, 500, Inf),\n                         labels = c(\"Bajo\", \"Medio\", \"Alto\", \"Premium\"))\n  )\n][\n  # Calcular satisfacci√≥n promedio por segmento y aspecto\n  , .(\n    satisfaccion_promedio = round(mean(puntuacion), 2),\n    respuestas = .N\n  ), by = .(region, grupo_edad, gasto_categoria, aspecto)\n]\n\n# Crear matriz de satisfacci√≥n: aspecto vs segmento\nmatriz_satisfaccion &lt;- dcast(analisis_satisfaccion,\n                            region + grupo_edad + gasto_categoria ~ aspecto,\n                            value.var = \"satisfaccion_promedio\",\n                            fun.aggregate = mean)\n\nprint(\"Matriz de satisfacci√≥n por segmento:\")\n#&gt; [1] \"Matriz de satisfacci√≥n por segmento:\"\nprint(head(matriz_satisfaccion, 10))\n#&gt; Clave &lt;region, grupo_edad, gasto_categoria&gt;\n#&gt;     region grupo_edad gasto_categoria     1     2     3     4\n#&gt;     &lt;char&gt;     &lt;fctr&gt;          &lt;fctr&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n#&gt;  1:   Este      Joven            &lt;NA&gt;   NaN  4.00  4.00  3.50\n#&gt;  2:   Este      Joven            Bajo  4.00   NaN   NaN   NaN\n#&gt;  3:   Este      Joven           Medio  2.50   NaN   NaN   NaN\n#&gt;  4:   Este      Joven            Alto  4.00   NaN   NaN   NaN\n#&gt;  5:   Este      Joven         Premium  2.00   NaN   NaN   NaN\n#&gt;  6:   Este     Adulto            &lt;NA&gt;   NaN  3.57  3.14  3.00\n#&gt;  7:   Este     Adulto            Bajo  3.00   NaN   NaN   NaN\n#&gt;  8:   Este     Adulto           Medio  4.67   NaN   NaN   NaN\n#&gt;  9:   Este     Adulto            Alto  4.67   NaN   NaN   NaN\n#&gt; 10:   Este     Maduro            &lt;NA&gt;   NaN  4.17  3.83  3.33\n\n# Verificar qu√© columnas se crearon despu√©s del dcast\nprint(\"Columnas en matriz_satisfaccion:\")\n#&gt; [1] \"Columnas en matriz_satisfaccion:\"\nprint(names(matriz_satisfaccion))\n#&gt; [1] \"region\"          \"grupo_edad\"      \"gasto_categoria\" \"1\"              \n#&gt; [5] \"2\"               \"3\"               \"4\"\n\n# Identificar segmentos cr√≠ticos (satisfacci√≥n baja en m√∫ltiples aspectos)\n# Primero verificar qu√© columnas de aspectos existen\ncolumnas_aspectos &lt;- names(matriz_satisfaccion)[!names(matriz_satisfaccion) %in% c(\"region\", \"grupo_edad\", \"gasto_categoria\")]\nprint(paste(\"Columnas de aspectos encontradas:\", paste(columnas_aspectos, collapse = \", \")))\n#&gt; [1] \"Columnas de aspectos encontradas: 1, 2, 3, 4\"\n\nif(length(columnas_aspectos) &gt;= 4) {\n  # Si tenemos las 4 columnas esperadas (entrega, precio, producto, servicio)\n  segmentos_criticos &lt;- matriz_satisfaccion[\n    # Calcular score de satisfacci√≥n general usando las columnas que existen\n    , satisfaccion_general := round(rowMeans(.SD, na.rm = TRUE), 2), .SDcols = columnas_aspectos\n  ][\n    satisfaccion_general &lt; 3.5  # Umbral cr√≠tico\n  ][order(satisfaccion_general)]\n} else {\n  # Si no tenemos todas las columnas, usar un enfoque m√°s simple\n  cat(\"No se encontraron todas las columnas de aspectos esperadas. Usando an√°lisis simplificado.\\n\")\n  segmentos_criticos &lt;- matriz_satisfaccion[1:0]  # Tabla vac√≠a para evitar errores\n}\n\nif(nrow(segmentos_criticos) &gt; 0) {\n  print(\"\\n‚ö†Ô∏è SEGMENTOS CR√çTICOS (satisfacci√≥n &lt; 3.5):\")\n  print(segmentos_criticos[, .(region, grupo_edad, gasto_categoria, satisfaccion_general)])\n} else {\n  cat(\"\\n‚úÖ No hay segmentos con satisfacci√≥n cr√≠tica\\n\")\n}\n#&gt; [1] \"\\n‚ö†Ô∏è SEGMENTOS CR√çTICOS (satisfacci√≥n &lt; 3.5):\"\n#&gt;     region grupo_edad gasto_categoria satisfaccion_general\n#&gt;     &lt;char&gt;     &lt;fctr&gt;          &lt;fctr&gt;                &lt;num&gt;\n#&gt;  1:   Este      Joven         Premium                 2.00\n#&gt;  2:   Este     Maduro         Premium                 2.00\n#&gt;  3:   Este      Joven           Medio                 2.50\n#&gt;  4:  Norte     Maduro         Premium                 2.50\n#&gt;  5:   Este     Adulto            Bajo                 3.00\n#&gt;  6:  Norte      Joven           Medio                 3.00\n#&gt;  7:  Norte     Adulto            Alto                 3.00\n#&gt;  8:  Oeste      Joven           Medio                 3.00\n#&gt;  9:  Oeste     Maduro           Medio                 3.00\n#&gt; 10:  Oeste     Senior           Medio                 3.00\n#&gt; 11:  Oeste     Senior         Premium                 3.00\n#&gt; 12:    Sur      Joven            Alto                 3.00\n#&gt; 13:    Sur     Maduro            Bajo                 3.00\n#&gt; 14:  Norte      Joven            &lt;NA&gt;                 3.14\n#&gt; 15:   Este     Adulto            &lt;NA&gt;                 3.24\n#&gt; 16:   Este     Maduro           Medio                 3.25\n#&gt; 17:  Norte     Senior            &lt;NA&gt;                 3.25\n#&gt; 18:  Oeste     Maduro            &lt;NA&gt;                 3.29\n#&gt; 19:  Norte     Maduro            &lt;NA&gt;                 3.33\n#&gt; 20:    Sur     Senior            &lt;NA&gt;                 3.33\n#&gt; 21:  Oeste     Adulto            &lt;NA&gt;                 3.34\n#&gt; 22:  Norte     Adulto            &lt;NA&gt;                 3.39\n#&gt; 23:    Sur     Maduro            &lt;NA&gt;                 3.39\n#&gt; 24:    Sur     Adulto            &lt;NA&gt;                 3.46\n#&gt; 25:  Oeste     Senior            &lt;NA&gt;                 3.48\n#&gt;     region grupo_edad gasto_categoria satisfaccion_general",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Remodelaci√≥n de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#ejercicios-pr√°cticos",
    "href": "cap03-reshape.html#ejercicios-pr√°cticos",
    "title": "\n8¬† Remodelaci√≥n de Datos: melt() y dcast()\n",
    "section": "\n8.5 Ejercicios Pr√°cticos",
    "text": "8.5 Ejercicios Pr√°cticos\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 13: Pipeline Completo de Reshape\n\n\n\nUsando los datos de empleados:\n\n\nmelt() para convertir a formato largo\n\nAgregar nuevas variables derivadas usando :=\n\n\ndcast() para crear m√∫ltiples vistas agregadas\n\nGenerar reporte ejecutivo combinando ambas t√©cnicas\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 13\n\n\n\n\n\n\n# 1. Pipeline completo de reshape para an√°lisis de empleados\n# Paso 1: melt() para formato largo\nempleados_melted &lt;- melt(empleados_metricas,\n                        id.vars = c(\"empleado_id\", \"nombre\", \"departamento\", \"nivel\", \"salario_base\"),\n                        measure = patterns(\n                          bonus = \"^bonus_Q\",\n                          evaluacion = \"^evaluacion_Q\",\n                          proyectos = \"^proyectos_Q\"\n                        ),\n                        variable.name = \"trimestre_num\",\n                        value.name = c(\"bonus\", \"evaluacion\", \"proyectos\"))\n\n# 2. Agregar variables derivadas\nempleados_enriquecido &lt;- empleados_melted[, `:=`(\n  trimestre = paste0(\"Q\", trimestre_num),\n  compensacion_total = salario_base / 4 + bonus,  # Salario trimestral + bonus\n  productividad = round(proyectos / (evaluacion + 0.1), 2),  # Proyectos por punto de evaluaci√≥n\n  categoria_performance = fcase(\n    evaluacion &gt;= 4.5, \"Excelente\",\n    evaluacion &gt;= 4.0, \"Muy Bueno\", \n    evaluacion &gt;= 3.5, \"Bueno\",\n    evaluacion &gt;= 3.0, \"Satisfactorio\",\n    default = \"Necesita Mejora\"\n  ),\n  rango_bonus = fcase(\n    bonus &gt;= 10000, \"Alto\",\n    bonus &gt;= 5000, \"Medio\",\n    bonus &gt; 0, \"Bajo\", \n    default = \"Sin Bonus\"\n  )\n)]\n\n# 3. Crear m√∫ltiples vistas con dcast()\n\n# Vista 1: Performance promedio por departamento y nivel\nperformance_depto &lt;- dcast(empleados_enriquecido,\n                          departamento + nivel ~ .,\n                          value.var = c(\"evaluacion\", \"productividad\", \"compensacion_total\"),\n                          fun.aggregate = list(mean = mean, max = max))\n\ncat(\"üìä VISTA 1: PERFORMANCE POR DEPARTAMENTO Y NIVEL\\n\")\n#&gt; üìä VISTA 1: PERFORMANCE POR DEPARTAMENTO Y NIVEL\nprint(performance_depto[order(departamento, nivel)])\n#&gt; Key: &lt;departamento, nivel&gt;\n#&gt;     departamento   nivel evaluacion_mean productividad_mean\n#&gt;           &lt;char&gt;  &lt;char&gt;           &lt;num&gt;              &lt;num&gt;\n#&gt;  1:           IT  Junior          4.2000            0.71000\n#&gt;  2:           IT    Lead          3.7500            2.04750\n#&gt;  3:           IT Manager          3.9500            1.15250\n#&gt;  4:           IT  Senior          4.3500            1.01125\n#&gt;  5:    Marketing  Junior          4.1500            1.06250\n#&gt;  6:    Marketing    Lead          4.0875            0.94000\n#&gt;  7:    Marketing Manager          3.9500            1.49250\n#&gt;  8:    Marketing  Senior          3.8250            0.94250\n#&gt;  9:         RRHH  Junior          4.1250            1.39500\n#&gt; 10:         RRHH    Lead          3.9500            1.62750\n#&gt; 11:         RRHH Manager          4.1250            1.24500\n#&gt; 12:         RRHH  Senior          3.2750            1.93250\n#&gt; 13:       Ventas  Junior          4.2000            1.41250\n#&gt; 14:       Ventas    Lead          4.0000            1.61750\n#&gt; 15:       Ventas Manager          3.7500            1.36250\n#&gt; 16:       Ventas  Senior          3.9750            0.73000\n#&gt;     compensacion_total_mean evaluacion_max productividad_max\n#&gt;                       &lt;num&gt;          &lt;num&gt;             &lt;num&gt;\n#&gt;  1:                21597.50            4.9              1.40\n#&gt;  2:                22011.00            4.2              3.43\n#&gt;  3:                17790.25            4.7              1.89\n#&gt;  4:                19230.50            5.0              2.42\n#&gt;  5:                22414.75            4.8              2.20\n#&gt;  6:                22367.50            4.8              1.74\n#&gt;  7:                25912.75            4.5              3.03\n#&gt;  8:                19200.50            4.7              1.88\n#&gt;  9:                13780.00            4.7              2.44\n#&gt; 10:                17059.75            4.6              2.55\n#&gt; 11:                20527.75            4.8              2.05\n#&gt; 12:                22870.25            3.4              3.53\n#&gt; 13:                21262.50            4.9              3.33\n#&gt; 14:                22306.00            4.7              2.65\n#&gt; 15:                21264.00            4.1              2.97\n#&gt; 16:                17050.00            4.6              1.47\n#&gt;     compensacion_total_max\n#&gt;                      &lt;num&gt;\n#&gt;  1:                  25144\n#&gt;  2:                  28061\n#&gt;  3:                  20776\n#&gt;  4:                  26428\n#&gt;  5:                  26109\n#&gt;  6:                  27178\n#&gt;  7:                  33112\n#&gt;  8:                  22337\n#&gt;  9:                  21079\n#&gt; 10:                  24833\n#&gt; 11:                  26727\n#&gt; 12:                  26179\n#&gt; 13:                  26904\n#&gt; 14:                  23872\n#&gt; 15:                  24273\n#&gt; 16:                  21455\n\n# Vista 2: Evoluci√≥n trimestral por empleado (transpuesta)\nevolucion_empleados &lt;- dcast(empleados_enriquecido[departamento == \"IT\"],  # Solo IT para ejemplo\n                            nombre ~ trimestre,\n                            value.var = \"evaluacion\",\n                            fun.aggregate = mean)\n\ncat(\"\\nüìà VISTA 2: EVOLUCI√ìN DE EVALUACIONES - DEPARTAMENTO IT\\n\")\n#&gt; \n#&gt; üìà VISTA 2: EVOLUCI√ìN DE EVALUACIONES - DEPARTAMENTO IT\nprint(evolucion_empleados)\n#&gt; Key: &lt;nombre&gt;\n#&gt;        nombre    Q1    Q2    Q3    Q4\n#&gt;        &lt;char&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt; &lt;num&gt;\n#&gt; 1: Empleado_F   4.6   3.2   4.9   4.7\n#&gt; 2: Empleado_G   3.3   4.2   4.1   3.4\n#&gt; 3: Empleado_H   3.1   4.7   3.6   4.4\n#&gt; 4: Empleado_I   3.5   4.9   4.1   4.3\n#&gt; 5: Empleado_J   4.6   5.0   3.8   4.0\n\n# Vista 3: Matriz de categor√≠as (contingencia)\nmatriz_categorias &lt;- dcast(empleados_enriquecido,\n                          departamento ~ categoria_performance,\n                          value.var = \"empleado_id\",\n                          fun.aggregate = function(x) length(unique(x)))\n\ncat(\"\\nüéØ VISTA 3: MATRIZ DE CATEGOR√çAS DE PERFORMANCE\\n\")\n#&gt; \n#&gt; üéØ VISTA 3: MATRIZ DE CATEGOR√çAS DE PERFORMANCE\nprint(matriz_categorias)\n#&gt; Key: &lt;departamento&gt;\n#&gt;    departamento Bueno Excelente Muy Bueno Satisfactorio\n#&gt;          &lt;char&gt; &lt;int&gt;     &lt;int&gt;     &lt;int&gt;         &lt;int&gt;\n#&gt; 1:           IT     3         4         4             3\n#&gt; 2:    Marketing     3         5         5             4\n#&gt; 3:         RRHH     2         3         4             4\n#&gt; 4:       Ventas     4         4         3             3\n\n# 4. Reporte ejecutivo combinando t√©cnicas\ncat(\"\\nüìã REPORTE EJECUTIVO DE RRHH\\n\")\n#&gt; \n#&gt; üìã REPORTE EJECUTIVO DE RRHH\n\n# KPIs generales\nkpis_generales &lt;- empleados_enriquecido[, .(\n  empleados_unicos = uniqueN(empleado_id),\n  evaluacion_promedio = round(mean(evaluacion), 2),\n  bonus_promedio = round(mean(bonus), 0),\n  proyectos_promedio = round(mean(proyectos), 1),\n  compensacion_promedio = round(mean(compensacion_total), 0)\n)]\n\ncat(\"KPIs GENERALES:\\n\")\n#&gt; KPIs GENERALES:\ncat(\"‚Ä¢ Empleados analizados:\", kpis_generales$empleados_unicos, \"\\n\")\n#&gt; ‚Ä¢ Empleados analizados: 20\ncat(\"‚Ä¢ Evaluaci√≥n promedio:\", kpis_generales$evaluacion_promedio, \"/5.0\\n\")\n#&gt; ‚Ä¢ Evaluaci√≥n promedio: 4.02 /5.0\ncat(\"‚Ä¢ Bonus promedio trimestral:\", scales::dollar(kpis_generales$bonus_promedio), \"\\n\")\n#&gt; ‚Ä¢ Bonus promedio trimestral: $5,465\ncat(\"‚Ä¢ Proyectos promedio por trimestre:\", kpis_generales$proyectos_promedio, \"\\n\")\n#&gt; ‚Ä¢ Proyectos promedio por trimestre: 5.1\ncat(\"‚Ä¢ Compensaci√≥n total promedio:\", scales::dollar(kpis_generales$compensacion_promedio), \"\\n\\n\")\n#&gt; ‚Ä¢ Compensaci√≥n total promedio: $20,502\n\n# Top performers\ntop_performers &lt;- empleados_enriquecido[, .(\n  evaluacion_promedio = round(mean(evaluacion), 2),\n  productividad_promedio = round(mean(productividad), 2),\n  bonus_total = sum(bonus)\n), by = .(empleado_id, nombre, departamento)][\n  order(-evaluacion_promedio, -productividad_promedio)\n][1:5]\n\ncat(\"üèÜ TOP 5 PERFORMERS:\\n\")\n#&gt; üèÜ TOP 5 PERFORMERS:\nfor(i in 1:nrow(top_performers)) {\n  emp &lt;- top_performers[i]\n  cat(sprintf(\"%d. %s (%s) - Eval: %.1f, Productividad: %.1f, Bonus Total: %s\\n\",\n              i, emp$nombre, emp$departamento, emp$evaluacion_promedio, \n              emp$productividad_promedio, scales::dollar(emp$bonus_total)))\n}\n#&gt; 1. Empleado_P (RRHH) - Eval: 4.4, Productividad: 1.3, Bonus Total: $23,858\n#&gt; 2. Empleado_J (IT) - Eval: 4.3, Productividad: 1.2, Bonus Total: $23,002\n#&gt; 3. Empleado_F (IT) - Eval: 4.3, Productividad: 0.9, Bonus Total: $23,842\n#&gt; 4. Empleado_O (Marketing) - Eval: 4.2, Productividad: 1.0, Bonus Total: $27,901\n#&gt; 5. Empleado_E (Ventas) - Eval: 4.2, Productividad: 0.8, Bonus Total: $28,921\n\n# An√°lisis por departamento\nanalisis_depto &lt;- empleados_enriquecido[, .(\n  empleados = uniqueN(empleado_id),\n  evaluacion_promedio = round(mean(evaluacion), 2),\n  empleados_excelentes = sum(categoria_performance == \"Excelente\"),\n  tasa_excelencia = round(mean(categoria_performance == \"Excelente\") * 100, 1),\n  presupuesto_bonus = sum(bonus)\n), by = departamento][order(-tasa_excelencia)]\n\ncat(\"\\nüè¢ AN√ÅLISIS POR DEPARTAMENTO:\\n\")\n#&gt; \n#&gt; üè¢ AN√ÅLISIS POR DEPARTAMENTO:\nprint(analisis_depto)\n#&gt;    departamento empleados evaluacion_promedio empleados_excelentes\n#&gt;          &lt;char&gt;     &lt;int&gt;               &lt;num&gt;                &lt;int&gt;\n#&gt; 1:       Ventas         5                4.03                    7\n#&gt; 2:           IT         5                4.12                    7\n#&gt; 3:    Marketing         5                4.02                    7\n#&gt; 4:         RRHH         5                3.92                    3\n#&gt;    tasa_excelencia presupuesto_bonus\n#&gt;              &lt;num&gt;             &lt;num&gt;\n#&gt; 1:              35            102880\n#&gt; 2:              35            115739\n#&gt; 3:              35            115452\n#&gt; 4:              15            103162\n\n# Recomendaciones autom√°ticas\ncat(\"\\nüí° RECOMENDACIONES AUTOM√ÅTICAS:\\n\")\n#&gt; \n#&gt; üí° RECOMENDACIONES AUTOM√ÅTICAS:\n\n# Departamento con mejor performance\nmejor_depto &lt;- analisis_depto[1, departamento]\npeor_depto &lt;- analisis_depto[.N, departamento]\n\ncat(\"‚Ä¢ Mejores pr√°cticas de\", mejor_depto, \"podr√≠an replicarse en otros departamentos\\n\")\n#&gt; ‚Ä¢ Mejores pr√°cticas de Ventas podr√≠an replicarse en otros departamentos\ncat(\"‚Ä¢ Departamento\", peor_depto, \"requiere plan de mejora en evaluaciones\\n\")\n#&gt; ‚Ä¢ Departamento RRHH requiere plan de mejora en evaluaciones\n\n# Empleados que necesitan atenci√≥n\nempleados_atencion &lt;- empleados_enriquecido[\n  categoria_performance %in% c(\"Necesita Mejora\", \"Satisfactorio\"), \n  uniqueN(empleado_id), \n  by = departamento\n][V1 &gt; 0]\n\nif(nrow(empleados_atencion) &gt; 0) {\n  cat(\"‚Ä¢ Revisar planes de desarrollo individual en:\", paste(empleados_atencion$departamento, collapse = \", \"), \"\\n\")\n}\n#&gt; ‚Ä¢ Revisar planes de desarrollo individual en: Ventas, IT, Marketing, RRHH\n\n# # Crear tabla interactiva del reporte (comentado para PDF)\n# DT::datatable(\n#   performance_depto,\n#   caption = \"Dashboard Ejecutivo de Performance - RRHH\",\n#   options = list(pageLength = 10, scrollX = TRUE)\n# ) %&gt;%\n#   DT::formatRound(c(\"evaluacion_mean\", \"productividad_mean\"), digits = 2) %&gt;%\n#   DT::formatCurrency(\"compensacion_total_mean\", currency = \"$\")\n\n\n\n\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 14: An√°lisis de Series Temporales con Reshape\n\n\n\n\n\nReshape datos de sensores para an√°lisis temporal\n\nCrear ventanas m√≥viles despu√©s del reshape\n\nDetectar anomal√≠as por tipo de sensor\n\nGenerar reporte de alertas en formato ejecutivo\n\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 14\n\n\n\n\n\n\n# 1. An√°lisis temporal completo con reshape\n# Preparar datos base con informaci√≥n temporal\nsensores_temporal &lt;- sensores_long[, `:=`(\n  fecha = as.Date(timestamp),\n  hora = hour(timestamp),\n  dia_semana = wday(timestamp, label = TRUE)\n)]\n\n# 2. Crear ventanas m√≥viles por tipo de sensor\nsensores_con_ventanas &lt;- sensores_temporal[order(ubicacion, tipo_sensor, numero_sensor, timestamp)][, `:=`(\n  # Ventanas m√≥viles de 24 horas (4 mediciones = 24 horas con datos cada 6h)\n  media_24h = frollmean(medicion, 4, na.rm = TRUE),\n  media_48h = frollmean(medicion, 8, na.rm = TRUE),\n  desv_24h = frollapply(medicion, 4, sd, na.rm = TRUE),\n  \n  # Cambios temporales\n  cambio_6h = abs(medicion - shift(medicion, 1)),\n  cambio_24h = abs(medicion - shift(medicion, 4)),\n  \n  # Tendencia\n  tendencia_24h = frollapply(medicion, 4, function(x) {\n    if(length(x) &lt; 4) return(0)\n    lm(x ~ seq_along(x))$coefficients[2]\n  })\n), by = .(ubicacion, tipo_sensor, numero_sensor)]\n\n# 3. Detecci√≥n de anomal√≠as por tipo de sensor\nsensores_con_anomalias &lt;- sensores_con_ventanas[, `:=`(\n  # Rangos normales espec√≠ficos por tipo\n  limite_inferior = fcase(\n    tipo_sensor == \"sensor_temp\", 15,\n    tipo_sensor == \"sensor_humedad\", 30,\n    tipo_sensor == \"sensor_presion\", 1000,\n    default = -Inf\n  ),\n  limite_superior = fcase(\n    tipo_sensor == \"sensor_temp\", 30,\n    tipo_sensor == \"sensor_humedad\", 80, \n    tipo_sensor == \"sensor_presion\", 1030,\n    default = Inf\n  )\n)][, `:=`(\n  # Detectar anomal√≠as\n  anomalia_rango = medicion &lt; limite_inferior | medicion &gt; limite_superior,\n  anomalia_cambio_subito = !is.na(cambio_6h) & cambio_6h &gt; fcase(\n    tipo_sensor == \"sensor_temp\", 5,\n    tipo_sensor == \"sensor_humedad\", 15,\n    tipo_sensor == \"sensor_presion\", 20,\n    default = Inf\n  ),\n  anomalia_desviacion = !is.na(media_24h) & !is.na(desv_24h) & \n                       abs(medicion - media_24h) &gt; 2 * desv_24h,\n  anomalia_tendencia = !is.na(tendencia_24h) & abs(tendencia_24h) &gt; fcase(\n    tipo_sensor == \"sensor_temp\", 1,\n    tipo_sensor == \"sensor_humedad\", 3,\n    tipo_sensor == \"sensor_presion\", 5,\n    default = Inf\n  )\n)][, `:=`(\n  # Score compuesto de anomal√≠a\n  score_anomalia = (as.numeric(anomalia_rango) * 4) +\n                  (as.numeric(anomalia_cambio_subito) * 3) +\n                  (as.numeric(anomalia_desviacion) * 2) + \n                  (as.numeric(anomalia_tendencia) * 1),\n  \n  # Clasificaci√≥n de severidad\n  severidad_anomalia = fcase(\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 6, \"CR√çTICA\",\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 4, \"ALTA\",\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 2, \"MEDIA\",\n    (anomalia_rango) * 4 + (anomalia_cambio_subito) * 3 + (anomalia_desviacion) * 2 + (anomalia_tendencia) * 1 &gt;= 1, \"BAJA\",\n    default = \"NORMAL\"\n  )\n)]\n\n# 4. Generar reporte ejecutivo de alertas\ncat(\"üö® REPORTE DE ALERTAS - SISTEMA DE SENSORES üö®\\n\")\n#&gt; üö® REPORTE DE ALERTAS - SISTEMA DE SENSORES üö®\ncat(rep(\"=\", 60), \"\\n\\n\")\n#&gt; = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = = =\n\n# Resumen general usando reshape\nresumen_alertas &lt;- sensores_con_anomalias[severidad_anomalia != \"NORMAL\", .N, \n                                         by = .(ubicacion, tipo_sensor, severidad_anomalia)]\n\nif(nrow(resumen_alertas) &gt; 0) {\n  # Crear matriz de alertas con dcast\n  matriz_alertas &lt;- dcast(resumen_alertas,\n                         ubicacion + tipo_sensor ~ severidad_anomalia,\n                         value.var = \"N\",\n                         fill = 0)\n  \n  cat(\"üìä MATRIZ DE ALERTAS ACTIVAS:\\n\")\n  print(matriz_alertas)\n} else {\n  cat(\"‚úÖ No hay alertas activas en el sistema\\n\")\n}\n#&gt; üìä MATRIZ DE ALERTAS ACTIVAS:\n#&gt; Key: &lt;ubicacion, tipo_sensor&gt;\n#&gt;        ubicacion    tipo_sensor  ALTA  BAJA CR√çTICA\n#&gt;           &lt;char&gt;         &lt;char&gt; &lt;int&gt; &lt;int&gt;   &lt;int&gt;\n#&gt; 1: Planta_Centro sensor_humedad     0     3       0\n#&gt; 2: Planta_Centro sensor_presion    16     3       0\n#&gt; 3: Planta_Centro    sensor_temp     2    15       0\n#&gt; 4:  Planta_Norte sensor_humedad     0     3       0\n#&gt; 5:  Planta_Norte sensor_presion    12     1       1\n#&gt; 6:  Planta_Norte    sensor_temp     2    10       0\n#&gt; 7:    Planta_Sur sensor_humedad     0     3       0\n#&gt; 8:    Planta_Sur sensor_presion    16     0       0\n#&gt; 9:    Planta_Sur    sensor_temp     2     7       0\n\n# Estado actual por sensor (usando reshape)\nestado_actual &lt;- sensores_con_anomalias[, .SD[.N], \n                                       by = .(ubicacion, tipo_sensor, numero_sensor)][, .(\n  ubicacion, tipo_sensor, numero_sensor, timestamp, medicion, \n  severidad_anomalia, score_anomalia\n)]\n\n# Convertir a formato wide para dashboard\ndashboard_estado &lt;- dcast(estado_actual,\n                         ubicacion ~ tipo_sensor + numero_sensor,\n                         value.var = \"medicion\")\n\ncat(\"\\nüè¢ ESTADO ACTUAL POR UBICACI√ìN:\\n\")\n#&gt; \n#&gt; üè¢ ESTADO ACTUAL POR UBICACI√ìN:\nprint(dashboard_estado)\n#&gt; Key: &lt;ubicacion&gt;\n#&gt;        ubicacion sensor_humedad_1 sensor_humedad_2 sensor_presion_1\n#&gt;           &lt;char&gt;            &lt;num&gt;            &lt;num&gt;            &lt;num&gt;\n#&gt; 1: Planta_Centro             60.5             74.1           1006.4\n#&gt; 2:  Planta_Norte             42.9             58.0           1012.8\n#&gt; 3:    Planta_Sur             71.0             60.6           1015.7\n#&gt;    sensor_presion_2 sensor_temp_1 sensor_temp_2\n#&gt;               &lt;num&gt;         &lt;num&gt;         &lt;num&gt;\n#&gt; 1:            998.2          19.9          25.7\n#&gt; 2:            999.9          18.4          25.8\n#&gt; 3:           1029.3          19.4          26.0\n\n# Top alertas cr√≠ticas\nalertas_criticas &lt;- sensores_con_anomalias[\n  severidad_anomalia %in% c(\"CR√çTICA\", \"ALTA\")\n][order(-score_anomalia, -timestamp)][1:min(10, .N)]\n\nif(nrow(alertas_criticas) &gt; 0) {\n  cat(\"\\nüî• TOP ALERTAS CR√çTICAS:\\n\")\n  print(alertas_criticas[, .(\n    Ubicaci√≥n = ubicacion,\n    Sensor = paste(tipo_sensor, numero_sensor),\n    Timestamp = timestamp,\n    Medici√≥n = medicion,\n    Severidad = severidad_anomalia,\n    Score = score_anomalia\n  )])\n}\n#&gt; \n#&gt; üî• TOP ALERTAS CR√çTICAS:\n#&gt;         Ubicaci√≥n           Sensor           Timestamp Medici√≥n Severidad Score\n#&gt;            &lt;char&gt;           &lt;char&gt;              &lt;POSc&gt;    &lt;num&gt;    &lt;char&gt; &lt;num&gt;\n#&gt;  1:  Planta_Norte sensor_presion 1 2024-01-04 00:00:00   1044.3   CR√çTICA     7\n#&gt;  2: Planta_Centro    sensor_temp 1 2024-01-06 00:00:00     14.5      ALTA     5\n#&gt;  3:  Planta_Norte    sensor_temp 1 2024-01-06 00:00:00     13.5      ALTA     5\n#&gt;  4:  Planta_Norte sensor_presion 1 2024-01-03 00:00:00   1035.1      ALTA     5\n#&gt;  5:  Planta_Norte sensor_presion 1 2024-01-02 18:00:00   1038.1      ALTA     5\n#&gt;  6: Planta_Centro sensor_presion 2 2024-01-07 18:00:00    998.2      ALTA     4\n#&gt;  7:  Planta_Norte sensor_presion 2 2024-01-07 18:00:00    999.9      ALTA     4\n#&gt;  8:    Planta_Sur sensor_presion 2 2024-01-07 12:00:00   1031.5      ALTA     4\n#&gt;  9: Planta_Centro sensor_presion 2 2024-01-07 00:00:00    997.3      ALTA     4\n#&gt; 10:    Planta_Sur sensor_presion 2 2024-01-07 00:00:00   1033.3      ALTA     4\n\n# An√°lisis de tendencias por tipo usando melt/dcast\ntendencias_tipo &lt;- sensores_con_anomalias[!is.na(tendencia_24h), .(\n  tendencia_promedio = round(mean(tendencia_24h, na.rm = TRUE), 4),\n  medicion_promedio = round(mean(medicion, na.rm = TRUE), 2),\n  anomalias_total = sum(severidad_anomalia != \"NORMAL\")\n), by = .(ubicacion, tipo_sensor)]\n\n# Formato wide para comparaci√≥n\ntendencias_wide &lt;- dcast(tendencias_tipo,\n                        ubicacion ~ tipo_sensor,\n                        value.var = \"tendencia_promedio\")\n\ncat(\"\\nüìà TENDENCIAS PROMEDIO POR UBICACI√ìN (24h):\\n\")\n#&gt; \n#&gt; üìà TENDENCIAS PROMEDIO POR UBICACI√ìN (24h):\nprint(tendencias_wide)\n#&gt; Key: &lt;ubicacion&gt;\n#&gt;        ubicacion sensor_humedad sensor_presion sensor_temp\n#&gt;           &lt;char&gt;          &lt;num&gt;          &lt;num&gt;       &lt;num&gt;\n#&gt; 1: Planta_Centro        -0.0194        -0.7440     -0.0484\n#&gt; 2:  Planta_Norte        -0.7072        -0.4502     -0.0448\n#&gt; 3:    Planta_Sur         0.5846         0.5512     -0.0688\n\n# Recomendaciones autom√°ticas\ncat(\"\\nüí° RECOMENDACIONES AUTOM√ÅTICAS:\\n\")\n#&gt; \n#&gt; üí° RECOMENDACIONES AUTOM√ÅTICAS:\n\n# Sensores con m√°s anomal√≠as\nsensores_problematicos &lt;- sensores_con_anomalias[, .(\n  anomalias = sum(severidad_anomalia != \"NORMAL\")\n), by = .(ubicacion, tipo_sensor, numero_sensor)][anomalias &gt; 0][order(-anomalias)]\n\nif(nrow(sensores_problematicos) &gt; 0) {\n  top_problematico &lt;- sensores_problematicos[1]\n  cat(\"‚Ä¢ Revisar sensor\", paste(top_problematico$tipo_sensor, top_problematico$numero_sensor), \n      \"en\", top_problematico$ubicacion, \"con\", top_problematico$anomalias, \"anomal√≠as\\n\")\n}\n#&gt; ‚Ä¢ Revisar sensor sensor_presion 1 en Planta_Centro con 15 anomal√≠as\n\n# Ubicaci√≥n con m√°s problemas\nubicacion_problemas &lt;- sensores_con_anomalias[, .(\n  anomalias_total = sum(severidad_anomalia != \"NORMAL\")\n), by = ubicacion][order(-anomalias_total)]\n\nif(nrow(ubicacion_problemas) &gt; 0 && ubicacion_problemas[1, anomalias_total] &gt; 0) {\n  cat(\"‚Ä¢ Priorizar mantenimiento en\", ubicacion_problemas[1, ubicacion], \n      \"con\", ubicacion_problemas[1, anomalias_total], \"anomal√≠as totales\\n\")\n}\n#&gt; ‚Ä¢ Priorizar mantenimiento en Planta_Centro con 39 anomal√≠as totales\n\ncat(\"‚Ä¢ Siguiente revisi√≥n recomendada: en 6 horas\\n\")\n#&gt; ‚Ä¢ Siguiente revisi√≥n recomendada: en 6 horas\n\n# # Tabla interactiva de alertas cr√≠ticas (comentado para PDF)\n# if(nrow(alertas_criticas) &gt; 0) {\n#   DT::datatable(\n#     alertas_criticas[, .(ubicacion, tipo_sensor, numero_sensor, timestamp, \n#                         medicion, severidad_anomalia, score_anomalia)],\n#     caption = \"Alertas Cr√≠ticas del Sistema de Sensores\",\n#     options = list(pageLength = 10, scrollX = TRUE)\n#   ) %&gt;%\n#     DT::formatStyle(\n#       \"severidad_anomalia\",\n#       backgroundColor = DT::styleEqual(\n#         c(\"CR√çTICA\", \"ALTA\", \"MEDIA\", \"BAJA\"),\n#         c(\"red\", \"orange\", \"yellow\", \"lightblue\")\n#       )\n#     ) %&gt;%\n#     DT::formatRound(\"medicion\", digits = 2)\n# }",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Remodelaci√≥n de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap03-reshape.html#mejores-pr√°cticas-para-reshape",
    "href": "cap03-reshape.html#mejores-pr√°cticas-para-reshape",
    "title": "\n8¬† Remodelaci√≥n de Datos: melt() y dcast()\n",
    "section": "\n8.6 Mejores Pr√°cticas para Reshape",
    "text": "8.6 Mejores Pr√°cticas para Reshape\n\n8.6.1 1. Cu√°ndo Usar Cada T√©cnica\n\n\n# ‚úÖ Usar melt() cuando:\n# - Necesitas an√°lisis estad√≠stico o visualizaci√≥n con ggplot2\n# - Quieres aplicar funciones por grupos de variables\n# - Los datos vienen de Excel/reportes en formato ancho\ndatos_para_analisis &lt;- melt(datos_wide, id.vars = \"identificador\")\n\n# ‚úÖ Usar dcast() cuando:  \n# - Necesitas crear reportes ejecutivos o dashboards\n# - Quieres matrices de correlaci√≥n o contingencia\n# - Necesitas format de \"tabla din√°mica\" para presentaci√≥n\nreporte_ejecutivo &lt;- dcast(datos_long, fila ~ columna, value.var = \"valor\")\n\n# ‚úÖ Combinar ambos para:\n# - Pipelines de transformaci√≥n complejos\n# - An√°lisis que requieren m√∫ltiples vistas de los mismos datos\npipeline_completo &lt;- datos %&gt;% melt(...) %&gt;% \n  enriquecer(...) %&gt;% dcast(...)\n\n\n8.6.2 2. Performance y Memoria\n\n\n# ‚úÖ HACER: Especificar measure.vars expl√≠citamente\nmelt(dt, measure.vars = c(\"col1\", \"col2\", \"col3\"))  # M√°s r√°pido\n\n# ‚ùå EVITAR: Melt sin especificar columnas\nmelt(dt)  # Puede incluir columnas no deseadas\n\n# ‚úÖ HACER: Usar patterns() para m√∫ltiples tipos de variables  \nmelt(dt, measure = patterns(\"^bonus_\", \"^eval_\"))\n\n# ‚úÖ HACER: Limpiar datos despu√©s de reshape\ndatos_melted[, columna_temp := NULL]  # Eliminar columnas temporales\n\n\n8.6.3 3. Manejo de Valores Faltantes\n\n\n# ‚úÖ Control de NAs en dcast\ndcast(dt, row ~ col, value.var = \"val\", fill = 0)  # Llenar con 0\ndcast(dt, row ~ col, value.var = \"val\", drop = FALSE)  # Mantener combinaciones vac√≠as\n\n# ‚úÖ Manejo de NAs despu√©s de melt\ndatos_melted[!is.na(value)]  # Filtrar NAs\ndatos_melted[, value := nafill(value, fill = 0)]  # Llenar NAs\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nmelt() convierte datos anchos a largos - esencial para an√°lisis estad√≠stico y visualizaci√≥n\n\ndcast() convierte datos largos a anchos - perfecto para reportes y dashboards ejecutivos\n\n\nPatrones complejos con patterns() permiten reshape de m√∫ltiples tipos de variables simult√°neamente\n\nFunciones de agregaci√≥n en dcast() crean res√∫menes poderosos durante el reshape\n\nCombinar ambas t√©cnicas permite pipelines de transformaci√≥n muy sofisticados\n\nPerformance: Especificar columnas expl√≠citamente mejora velocidad y memoria\n\n\n\n[{‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1-new‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 2: dividir en encadenamiento y joins‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-reshape.qmd para reshape del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-3‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 4: dividir en performance y buenas pr0e1cticas‚Äù, ‚Äústatus‚Äù: ‚Äúin_progress‚Äù, ‚Äúid‚Äù: ‚Äú4‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú5‚Äù}]",
    "crumbs": [
      "**M√≥dulo 3**: T√©cnicas Avanzadas y Funciones Especiales",
      "<span class='chapter-number'>8</span>¬† <span class='chapter-title'>Remodelaci√≥n de Datos: `melt()` y `dcast()`</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html",
    "href": "cap04-performance.html",
    "title": "\n9¬† Optimizaci√≥n de Performance\n",
    "section": "",
    "text": "9.1 Configuraci√≥n de Threading para M√∫ltiples N√∫cleos\nEl threading autom√°tico de data.table puede acelerar dram√°ticamente las operaciones en m√°quinas multi-core.",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Optimizaci√≥n de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#configuraci√≥n-de-threading-para-m√∫ltiples-n√∫cleos",
    "href": "cap04-performance.html#configuraci√≥n-de-threading-para-m√∫ltiples-n√∫cleos",
    "title": "\n9¬† Optimizaci√≥n de Performance\n",
    "section": "",
    "text": "9.1.1 1. Configuraci√≥n √ìptima de Threads\n\n\n# Evaluar configuraci√≥n del sistema\ncat(\"=== CONFIGURACI√ìN DEL SISTEMA ===\\n\")\n#&gt; === CONFIGURACI√ìN DEL SISTEMA ===\ncat(\"CPU cores disponibles:\", parallel::detectCores(), \"\\n\")\n#&gt; CPU cores disponibles: 16\ncat(\"CPU cores con hyperthreading:\", parallel::detectCores(logical = TRUE), \"\\n\")\n#&gt; CPU cores con hyperthreading: 16\ncat(\"Threads configurados en data.table:\", getDTthreads(), \"\\n\")\n#&gt; Threads configurados en data.table: 8\n\n# Funci√≥n para determinar configuraci√≥n √≥ptima\ndetermine_optimal_threads &lt;- function() {\n  max_cores &lt;- parallel::detectCores(logical = FALSE)  # Cores f√≠sicos\n  \n  if(max_cores &lt;= 2) {\n    return(max_cores)\n  } else if(max_cores &lt;= 4) {\n    return(max_cores)\n  } else if(max_cores &lt;= 8) {\n    return(max_cores - 1)  # Dejar un core libre\n  } else {\n    return(min(8, max_cores - 2))  # Para sistemas muy grandes, no usar todos\n  }\n}\n\noptimal_threads &lt;- determine_optimal_threads()\ncat(\"Configuraci√≥n recomendada:\", optimal_threads, \"threads\\n\")\n#&gt; Configuraci√≥n recomendada: 7 threads\n\n# Aplicar configuraci√≥n √≥ptima\nsetDTthreads(optimal_threads)\ncat(\"Configuraci√≥n aplicada:\", getDTthreads(), \"threads\\n\")\n#&gt; Configuraci√≥n aplicada: 7 threads\n\n\n9.1.2 2. Benchmark de Threading Performance\n\n\n# Funci√≥n para benchmark con diferentes configuraciones de threads\nbenchmark_threading &lt;- function(n_threads, dataset_size = 500000) {\n  setDTthreads(n_threads)\n  dt_sample &lt;- big_dataset[sample(.N, dataset_size)]\n  \n  # Operaciones que se benefician del threading\n  tiempo_agregacion &lt;- system.time({\n    result_agg &lt;- dt_sample[, .(\n      mean_value = mean(value_numeric),\n      sum_amount = sum(amount),\n      count_records = .N,\n      median_value = median(value_numeric)\n    ), by = .(group_major, group_minor)]\n  })\n  \n  tiempo_sort &lt;- system.time({\n    result_sort &lt;- dt_sample[order(-value_numeric, group_major)]\n  })\n  \n  return(list(\n    threads = n_threads,\n    agregacion = tiempo_agregacion[3],\n    ordenamiento = tiempo_sort[3],\n    total = tiempo_agregacion[3] + tiempo_sort[3]\n  ))\n}\n\n# Comparar diferentes configuraciones\nconfiguraciones_threads &lt;- c(1, 2, 4, min(8, parallel::detectCores()))\nresultados_threads &lt;- list()\n\ncat(\"=== BENCHMARK DE THREADING ===\\n\")\n#&gt; === BENCHMARK DE THREADING ===\nfor(i in seq_along(configuraciones_threads)) {\n  n_threads &lt;- configuraciones_threads[i]\n  cat(\"Probando con\", n_threads, \"thread(s)... \")\n  \n  resultado &lt;- benchmark_threading(n_threads, 300000)  # Dataset m√°s peque√±o para rapidez\n  resultados_threads[[i]] &lt;- resultado\n  \n  cat(\"Agregaci√≥n:\", round(resultado$agregacion, 3), \"s, \",\n      \"Ordenamiento:\", round(resultado$ordenamiento, 3), \"s, \",\n      \"Total:\", round(resultado$total, 3), \"s\\n\")\n}\n#&gt; Probando con 1 thread(s)... Agregaci√≥n: 0 s,  Ordenamiento: 0.01 s,  Total: 0.01 s\n#&gt; Probando con 2 thread(s)... Agregaci√≥n: 0.02 s,  Ordenamiento: 0.02 s,  Total: 0.04 s\n#&gt; Probando con 4 thread(s)... Agregaci√≥n: 0.02 s,  Ordenamiento: 0.02 s,  Total: 0.04 s\n#&gt; Probando con 8 thread(s)... Agregaci√≥n: 0 s,  Ordenamiento: 0.01 s,  Total: 0.01 s\n\n# Crear tabla de resultados\ntabla_threads &lt;- rbindlist(resultados_threads)\nprint(\"\\nComparaci√≥n de performance por n√∫mero de threads:\")\n#&gt; [1] \"\\nComparaci√≥n de performance por n√∫mero de threads:\"\nprint(tabla_threads)\n#&gt;    threads agregacion ordenamiento total\n#&gt;      &lt;num&gt;      &lt;num&gt;        &lt;num&gt; &lt;num&gt;\n#&gt; 1:       1       0.00         0.01  0.01\n#&gt; 2:       2       0.02         0.02  0.04\n#&gt; 3:       4       0.02         0.02  0.04\n#&gt; 4:       8       0.00         0.01  0.01\n\n# Calcular speedup relativo al baseline (1 thread)\nbaseline &lt;- tabla_threads[threads == 1, total]\ntabla_threads[, speedup := round(baseline / total, 2)]\nprint(\"\\nSpeedup relativo (vs 1 thread):\")\n#&gt; [1] \"\\nSpeedup relativo (vs 1 thread):\"\nprint(tabla_threads[, .(threads, total, speedup)])\n#&gt;    threads total speedup\n#&gt;      &lt;num&gt; &lt;num&gt;   &lt;num&gt;\n#&gt; 1:       1  0.01    1.00\n#&gt; 2:       2  0.04    0.25\n#&gt; 3:       4  0.04    0.25\n#&gt; 4:       8  0.01    1.00\n\n# Restaurar configuraci√≥n √≥ptima\nsetDTthreads(optimal_threads)",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Optimizaci√≥n de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#keys-e-√≠ndices-la-base-de-la-velocidad",
    "href": "cap04-performance.html#keys-e-√≠ndices-la-base-de-la-velocidad",
    "title": "\n9¬† Optimizaci√≥n de Performance\n",
    "section": "\n9.2 Keys e √çndices: La Base de la Velocidad",
    "text": "9.2 Keys e √çndices: La Base de la Velocidad\n\n9.2.1 1. Setkey: Ordenamiento F√≠sico para Velocidad\n\n\n# Comparar performance con y sin keys\ndt_no_key &lt;- copy(big_dataset[sample(.N, 500000)])\ndt_with_key &lt;- copy(dt_no_key)\n\ncat(\"=== COMPARACI√ìN SETKEY ===\\n\")\n#&gt; === COMPARACI√ìN SETKEY ===\n\n# Tiempo para establecer key\ntiempo_setkey &lt;- system.time(setkey(dt_with_key, group_major, group_minor))\ncat(\"Tiempo para establecer key:\", round(tiempo_setkey[3], 3), \"segundos\\n\")\n#&gt; Tiempo para establecer key: 0.02 segundos\n\n# Comparar b√∫squedas simples\nvalores_busqueda &lt;- c(\"A\", \"B\", \"C\", \"D\", \"E\")\nsub_valores &lt;- c(\"a\", \"b\", \"c\")\n\ntiempo_sin_key &lt;- system.time({\n  result_no_key &lt;- dt_no_key[group_major %in% valores_busqueda & group_minor %in% sub_valores]\n})\n\ntiempo_con_key &lt;- system.time({\n  result_with_key &lt;- dt_with_key[.(valores_busqueda, sub_valores)]\n})\n\ncat(\"B√∫squeda sin key:\", round(tiempo_sin_key[3], 4), \"segundos\\n\")\n#&gt; B√∫squeda sin key: 0.02 segundos\ncat(\"B√∫squeda con key:\", round(tiempo_con_key[3], 4), \"segundos\\n\")\n#&gt; B√∫squeda con key: 0 segundos\ncat(\"Speedup:\", round(tiempo_sin_key[3] / tiempo_con_key[3], 1), \"x m√°s r√°pido\\n\")\n#&gt; Speedup: Inf x m√°s r√°pido\n\n# Verificar que ambos resultados son equivalentes\ncat(\"Resultados equivalentes:\", nrow(result_no_key) == nrow(result_with_key), \"\\n\")\n#&gt; Resultados equivalentes: FALSE\n\n\n9.2.2 2. M√∫ltiples Keys para Diferentes Patrones de Consulta\n\n\n# Crear m√∫ltiples copias para diferentes estrategias de indexing\ndt_by_group &lt;- copy(big_dataset[sample(.N, 300000)])\ndt_by_time &lt;- copy(dt_by_group)\ndt_by_id &lt;- copy(dt_by_group)\n\n# Establecer diferentes keys seg√∫n el patr√≥n de uso\nsetkey(dt_by_group, group_major, group_minor)\nsetkey(dt_by_time, timestamp)\nsetkey(dt_by_id, id)\n\ncat(\"=== ESTRATEGIAS DE KEYS ===\\n\")\n#&gt; === ESTRATEGIAS DE KEYS ===\ncat(\"dt_by_group key:\", paste(key(dt_by_group), collapse = \", \"), \"\\n\")\n#&gt; dt_by_group key: group_major, group_minor\ncat(\"dt_by_time key:\", paste(key(dt_by_time), collapse = \", \"), \"\\n\")\n#&gt; dt_by_time key: timestamp\ncat(\"dt_by_id key:\", paste(key(dt_by_id), collapse = \", \"), \"\\n\\n\")\n#&gt; dt_by_id key: id\n\n# Consultas optimizadas seg√∫n la key\ncat(\"Consultando por grupos...\\n\")\n#&gt; Consultando por grupos...\ntiempo_grupo &lt;- system.time({\n  result_grupo &lt;- dt_by_group[.(\"A\", c(\"a\", \"b\", \"c\"))]\n})\n\ncat(\"Consultando por tiempo...\\n\") \n#&gt; Consultando por tiempo...\ntiempo_temporal &lt;- system.time({\n  result_temporal &lt;- dt_by_time[timestamp &gt;= as.POSIXct(\"2024-01-01\") & \n                               timestamp &lt; as.POSIXct(\"2024-02-01\")]\n})\n\ncat(\"Consultando por IDs...\\n\")\n#&gt; Consultando por IDs...\nids_especificos &lt;- sample(1:1000000, 1000)\ntiempo_ids &lt;- system.time({\n  result_ids &lt;- dt_by_id[.(ids_especificos)]\n})\n\ncat(\"Tiempos de consulta optimizada:\\n\")\n#&gt; Tiempos de consulta optimizada:\ncat(\"‚Ä¢ Por grupos:\", round(tiempo_grupo[3], 4), \"segundos\\n\")\n#&gt; ‚Ä¢ Por grupos: 0 segundos\ncat(\"‚Ä¢ Por tiempo:\", round(tiempo_temporal[3], 4), \"segundos\\n\") \n#&gt; ‚Ä¢ Por tiempo: 0 segundos\ncat(\"‚Ä¢ Por IDs:\", round(tiempo_ids[3], 4), \"segundos\\n\")\n#&gt; ‚Ä¢ Por IDs: 0 segundos\n\n\n9.2.3 3. √çndices Secundarios con setindex()\n\n\n# Crear tabla con key principal e √≠ndices secundarios\ndt_indexed &lt;- copy(big_dataset[sample(.N, 400000)])\nsetkey(dt_indexed, group_major)  # Key principal\n\ncat(\"=== √çNDICES SECUNDARIOS ===\\n\")\n#&gt; === √çNDICES SECUNDARIOS ===\n\n# Crear √≠ndices secundarios para consultas frecuentes\ncat(\"Creando √≠ndices secundarios...\\n\")\n#&gt; Creando √≠ndices secundarios...\ntiempo_indices &lt;- system.time({\n  setindex(dt_indexed, category)\n  setindex(dt_indexed, status)\n  setindex(dt_indexed, region)\n  setindex(dt_indexed, timestamp)\n  setindex(dt_indexed, id, value_numeric)  # √çndice compuesto\n})\n\ncat(\"Tiempo para crear √≠ndices:\", round(tiempo_indices[3], 3), \"segundos\\n\")\n#&gt; Tiempo para crear √≠ndices: 0.01 segundos\ncat(\"√çndices creados:\", length(indices(dt_indexed)), \"\\n\")\n#&gt; √çndices creados: 5\nprint(indices(dt_indexed))\n#&gt; [1] \"category\"          \"status\"            \"region\"           \n#&gt; [4] \"timestamp\"         \"id__value_numeric\"\n\n# Comparar consultas con y sin √≠ndices\ndt_sin_indices &lt;- copy(big_dataset[sample(.N, 400000)])\n\n# Consulta que puede usar √≠ndice\ncat(\"\\nComparando consultas por categor√≠a:\\n\")\n#&gt; \n#&gt; Comparando consultas por categor√≠a:\ntiempo_sin_indice &lt;- system.time({\n  result_sin_indice &lt;- dt_sin_indices[category == \"Cat_5\" & status == \"Active\"]\n})\n\ntiempo_con_indice &lt;- system.time({\n  result_con_indice &lt;- dt_indexed[category == \"Cat_5\" & status == \"Active\"]\n})\n\ncat(\"Sin √≠ndice:\", round(tiempo_sin_indice[3], 4), \"segundos\\n\")\n#&gt; Sin √≠ndice: 0 segundos\ncat(\"Con √≠ndice:\", round(tiempo_con_indice[3], 4), \"segundos\\n\")\n#&gt; Con √≠ndice: 0 segundos\ncat(\"Speedup:\", round(tiempo_sin_indice[3] / tiempo_con_indice[3], 1), \"x\\n\")\n#&gt; Speedup: NaN x",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Optimizaci√≥n de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#profiling-y-benchmarking-sistem√°tico",
    "href": "cap04-performance.html#profiling-y-benchmarking-sistem√°tico",
    "title": "\n9¬† Optimizaci√≥n de Performance\n",
    "section": "\n9.3 Profiling y Benchmarking Sistem√°tico",
    "text": "9.3 Profiling y Benchmarking Sistem√°tico\n\n9.3.1 1. Modo Verbose para An√°lisis Detallado\n\n\n# Activar modo verbose para operaciones espec√≠ficas\nverbose_analysis &lt;- function(dt, operation_name, operation_func) {\n  cat(\"=== AN√ÅLISIS:\", operation_name, \"===\\n\")\n  \n  # Activar verbose temporalmente\n  old_verbose &lt;- getOption(\"datatable.verbose\")\n  options(datatable.verbose = TRUE)\n  \n  # Ejecutar operaci√≥n\n  start_time &lt;- Sys.time()\n  result &lt;- operation_func(dt)\n  end_time &lt;- Sys.time()\n  \n  # Restaurar verbose\n  options(datatable.verbose = old_verbose)\n  \n  cat(\"Tiempo total:\", round(as.numeric(end_time - start_time), 4), \"segundos\\n\")\n  cat(\"Filas resultado:\", nrow(result), \"\\n\\n\")\n  \n  return(result)\n}\n\n# Ejemplo de an√°lisis con verbose\ndt_sample &lt;- big_dataset[sample(.N, 100000)]\n\n# Operaci√≥n compleja para analizar\nresultado_verbose &lt;- verbose_analysis(dt_sample, \"Agregaci√≥n Compleja\", function(dt) {\n  dt[status %in% c(\"Active\", \"Completed\"), \n     .(avg_value = mean(value_numeric),\n       sum_amount = sum(amount),\n       count = .N,\n       median_amount = median(amount)), \n     by = .(group_major, category)]\n})\n#&gt; === AN√ÅLISIS: Agregaci√≥n Compleja ===\n#&gt; Creando nuevo √≠ndice 'status'\n#&gt; Creaci√≥n de √≠ndice status finaliz√≥ en ...&lt;forder.c&gt;: recibi√≥ 100000 filas y 10 columnas\n#&gt; forderReuseSorting: opt=-1, tom√≥ 0.001s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Se optimiz√≥ la selecci√≥n de subconjunto con √≠ndice 'status'\n#&gt; &lt;forder.c&gt;: recibi√≥ 2 filas y 1 columnas\n#&gt; forderReuseSorting: opt=-1, tom√≥ 0.000s\n#&gt; forder tom√≥ 0.000 seg\n#&gt; x ya est√° ordenado por estas columnas, no se requiere 'reorder'\n#&gt; i.status tiene el mismo tipo (character) que x.status. No se requiere coerci√≥n.\n#&gt; on= coincide con √≠ndice existente, usando √≠ndice\n#&gt; Inidiando bmerge ...\n#&gt; forderReuseSorting: usando key: __status\n#&gt; forderReuseSorting: opt=1, tom√≥ 0.001s\n#&gt; bmerge: bucle bmerge_r tom√≥ 0.000s\n#&gt; bmerge: tom√≥ 0.001s\n#&gt; bmerge finalizado en 0.000s elapsed (0.000s cpu)\n#&gt; Construyendo irows para '!byjoin || nqbyjoin' ... 0.000s elapsed (0.000s cpu) \n#&gt; Reordenar 49856 filas luego de bmerge finaliz√≥ en ... forderReuseSorting: opt no posible: is.data.table(DT)=0, sortGroups=1, all1(ascArg)=1\n#&gt; &lt;forder.c&gt;: recibi√≥ un tipo de vector 'integer' de longitud 49856\n#&gt; forderReuseSorting: opt=0, tom√≥ 0.001s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; cl√°usula 'i' presente y se detectaron las columnas usadas en by, s√≥lo este subconjunto: [group_major, category]\n#&gt; Se detect√≥ que j usa estas columnas: [value_numeric, amount]\n#&gt; Buscando grupos conn forderv ... forderReuseSorting: opt no posible: is.data.table(DT)=0, sortGroups=0, all1(ascArg)=1\n#&gt; &lt;forder.c&gt;: recibi√≥ 49856 filas y 2 columnas\n#&gt; forderReuseSorting: opt=0, tom√≥ 0.000s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Buscando tama√±o de grupos a partir de la posici√≥n (se puede omitir para ahorrar RAM) ... 0.000s elapsed (0.000s cpu) \n#&gt; Restaurando orden original ... forderReuseSorting: opt no posible: is.data.table(DT)=0, sortGroups=1, all1(ascArg)=1\n#&gt; &lt;forder.c&gt;: recibi√≥ un tipo de vector 'integer' de longitud 540\n#&gt; forderReuseSorting: opt=0, tom√≥ 0.001s\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Optimizaci√≥n de lapply activada, j sin cambios: 'list(mean(value_numeric), sum(amount), .N, median(amount))'\n#&gt; Optimizaci√≥n GForce de j: 'list(gmean(value_numeric), gsum(amount), .N, gmedian(amount))' (see ?GForce)\n#&gt; Generando grupos y ejecutando j en cada uno (GForce TRUE) ... gforce poblaci√≥n inicial de grp tom√≥ 0.000\n#&gt; asignaci√≥n gforce high y low tom√≥ 0.000\n#&gt; Este gmean tom√≥ (narm=FALSE)... la recopilaci√≥n tom√≥  0.000s\n#&gt; 0.000s\n#&gt; Este gsum (narm=FALSE) tom√≥... la recopilaci√≥n tom√≥  0.000s\n#&gt; 0.000s\n#&gt; la evaluaci√≥n de gforce tom√≥ 0.001\n#&gt; 0.000s elapsed (0.000s cpu) \n#&gt; Tiempo total: 0.1081 segundos\n#&gt; Filas resultado: 540\n\nprint(head(resultado_verbose))\n#&gt;    group_major category avg_value sum_amount count median_amount\n#&gt;         &lt;char&gt;   &lt;char&gt;     &lt;num&gt;      &lt;num&gt; &lt;int&gt;         &lt;num&gt;\n#&gt; 1:           A    Cat_1 100.70722   28843.49    51        148.84\n#&gt; 2:        &lt;NA&gt;   Cat_14 101.44601  668919.82  1237        158.52\n#&gt; 3:           R   Cat_17  98.79088   21923.92    59         90.07\n#&gt; 4:        &lt;NA&gt;   Cat_16 100.60555  590698.94  1215        147.68\n#&gt; 5:           E    Cat_3  95.65443   34422.37    53        216.94\n#&gt; 6:        &lt;NA&gt;    Cat_7 101.14619  520769.40  1213        150.37\n\n\n9.3.2 2. Benchmarking Comparativo de Estrategias\n\n\n# Crear funci√≥n de benchmark comprehensiva\nbenchmark_comprehensive &lt;- function(dt_size = 200000) {\n  dt_test &lt;- big_dataset[sample(.N, dt_size)]\n  \n  # Estrategia 1: Sin optimizaciones\n  strategy1 &lt;- function() {\n    dt_test[group_major %in% c(\"A\", \"B\", \"C\") & status == \"Active\",\n           .(mean_val = mean(value_numeric), \n             sum_amount = sum(amount),\n             count = .N),\n           by = .(group_minor, category)]\n  }\n  \n  # Estrategia 2: Con setkey optimizado\n  dt_keyed &lt;- copy(dt_test)\n  setkey(dt_keyed, group_major, group_minor)\n  strategy2 &lt;- function() {\n    dt_keyed[.(c(\"A\", \"B\", \"C\"))][status == \"Active\",\n            .(mean_val = mean(value_numeric),\n              sum_amount = sum(amount), \n              count = .N),\n            by = .(group_minor, category)]\n  }\n  \n  # Estrategia 3: Pre-filtrar luego agrupar\n  strategy3 &lt;- function() {\n    dt_filtered &lt;- dt_test[group_major %in% c(\"A\", \"B\", \"C\") & status == \"Active\"]\n    dt_filtered[, .(mean_val = mean(value_numeric),\n                   sum_amount = sum(amount),\n                   count = .N),\n               by = .(group_minor, category)]\n  }\n  \n  # Estrategia 4: Con √≠ndices secundarios\n  dt_indexed &lt;- copy(dt_test)\n  setindex(dt_indexed, group_major)\n  setindex(dt_indexed, status)\n  strategy4 &lt;- function() {\n    dt_indexed[group_major %in% c(\"A\", \"B\", \"C\") & status == \"Active\",\n              .(mean_val = mean(value_numeric),\n                sum_amount = sum(amount),\n                count = .N),\n              by = .(group_minor, category)]\n  }\n  \n  # Ejecutar benchmark\n  benchmark_result &lt;- microbenchmark(\n    \"Sin optimizar\" = strategy1(),\n    \"Con setkey\" = strategy2(),\n    \"Pre-filtrar\" = strategy3(), \n    \"Con √≠ndices\" = strategy4(),\n    times = 10\n  )\n  \n  return(benchmark_result)\n}\n\n# Ejecutar benchmark comprehensivo\ncat(\"=== BENCHMARK COMPREHENSIVO DE ESTRATEGIAS ===\\n\")\n#&gt; === BENCHMARK COMPREHENSIVO DE ESTRATEGIAS ===\nbenchmark_result &lt;- benchmark_comprehensive(150000)\nprint(benchmark_result)\n#&gt; Unit: milliseconds\n#&gt;           expr    min     lq    mean  median     uq    max neval\n#&gt;  Sin optimizar 2.1022 2.1491 2.28405 2.21155 2.3934 2.5935    10\n#&gt;     Con setkey 2.5918 2.7351 3.01076 2.95595 3.1528 3.8886    10\n#&gt;    Pre-filtrar 2.2044 2.4296 3.00480 2.75425 3.1098 4.5300    10\n#&gt;    Con √≠ndices 2.1676 2.3223 2.51195 2.41860 2.4670 3.7775    10\n\n# Crear visualizaci√≥n si ggplot2 est√° disponible\nif(require(ggplot2, quietly = TRUE)) {\n  plot_benchmark &lt;- autoplot(benchmark_result) +\n    labs(title = \"Comparaci√≥n de Estrategias de Optimizaci√≥n\",\n         subtitle = \"Menor tiempo = mejor performance\",\n         y = \"Tiempo (milisegundos)\",\n         x = \"Estrategia\") +\n    theme_minimal() +\n    theme(axis.text.x = element_text(angle = 45, hjust = 1))\n  \n  print(plot_benchmark)\n}\n\n\n\n\n\n\n\n# An√°lisis de resultados\nsummary_benchmark &lt;- summary(benchmark_result)\nprint(\"\\nResumen de performance:\")\n#&gt; [1] \"\\nResumen de performance:\"\nprint(summary_benchmark)\n#&gt;            expr    min     lq    mean  median     uq    max neval\n#&gt; 1 Sin optimizar 2.1022 2.1491 2.28405 2.21155 2.3934 2.5935    10\n#&gt; 2    Con setkey 2.5918 2.7351 3.01076 2.95595 3.1528 3.8886    10\n#&gt; 3   Pre-filtrar 2.2044 2.4296 3.00480 2.75425 3.1098 4.5300    10\n#&gt; 4   Con √≠ndices 2.1676 2.3223 2.51195 2.41860 2.4670 3.7775    10\n\n# Calcular speedup relativo\nbaseline_median &lt;- summary_benchmark[summary_benchmark$expr == \"Sin optimizar\", \"median\"]\nsummary_benchmark$speedup &lt;- round(baseline_median / summary_benchmark$median, 2)\nprint(\"\\nSpeedup relativo (vs sin optimizar):\")\n#&gt; [1] \"\\nSpeedup relativo (vs sin optimizar):\"\nprint(summary_benchmark[, c(\"expr\", \"median\", \"speedup\")])\n#&gt;            expr  median speedup\n#&gt; 1 Sin optimizar 2.21155    1.00\n#&gt; 2    Con setkey 2.95595    0.75\n#&gt; 3   Pre-filtrar 2.75425    0.80\n#&gt; 4   Con √≠ndices 2.41860    0.91\n\n\n9.3.3 3. Memory Profiling Avanzado\n\n\n# Funci√≥n para an√°lisis detallado de memoria\nmemory_analysis &lt;- function(operation_name, operation_func, dt_input) {\n  cat(\"=== AN√ÅLISIS DE MEMORIA:\", operation_name, \"===\\n\")\n  \n  # Limpiar garbage collector\n  invisible(gc(verbose = FALSE))\n  \n  # Memoria antes\n  mem_before &lt;- as.numeric(object.size(dt_input))\n  \n  # Ejecutar operaci√≥n y medir tiempo\n  start_time &lt;- Sys.time()\n  result &lt;- operation_func(dt_input)\n  end_time &lt;- Sys.time()\n  \n  # Memoria despu√©s\n  mem_after &lt;- as.numeric(object.size(dt_input))\n  mem_result &lt;- as.numeric(object.size(result))\n  \n  # Reportar resultados\n  cat(\"Tiempo de ejecuci√≥n:\", round(as.numeric(end_time - start_time), 4), \"segundos\\n\")\n  cat(\"Memoria input:\", format(mem_before, units = \"auto\"), \"\\n\")\n  cat(\"Memoria despu√©s:\", format(mem_after, units = \"auto\"), \"\\n\")\n  cat(\"Memoria resultado:\", format(mem_result, units = \"auto\"), \"\\n\")\n  cat(\"Cambio en memoria input:\", format(mem_after - mem_before, units = \"auto\"), \"\\n\")\n  cat(\"Eficiencia memoria:\", round(mem_result / mem_before * 100, 1), \"% del input\\n\\n\")\n  \n  return(result)\n}\n\n# Comparar diferentes operaciones\ndt_mem_test &lt;- big_dataset[sample(.N, 100000)]\n\n# Operaci√≥n 1: Modificaci√≥n por referencia\nresult1 &lt;- memory_analysis(\"Modificaci√≥n por referencia\", function(dt) {\n  dt[, new_computed_col := value_numeric * amount * 1.1]\n  return(dt)\n}, copy(dt_mem_test))\n#&gt; === AN√ÅLISIS DE MEMORIA: Modificaci√≥n por referencia ===\n#&gt; Tiempo de ejecuci√≥n: 7e-04 segundos\n#&gt; Memoria input: 7207216 \n#&gt; Memoria despu√©s: 8007424 \n#&gt; Memoria resultado: 8007424 \n#&gt; Cambio en memoria input: 800208 \n#&gt; Eficiencia memoria: 111.1 % del input\n\n# Operaci√≥n 2: Crear nueva tabla\nresult2 &lt;- memory_analysis(\"Crear nueva tabla\", function(dt) {\n  dt[, .(id, group_major, value_numeric, amount, \n         new_computed_col = value_numeric * amount * 1.1)]\n}, dt_mem_test)\n#&gt; === AN√ÅLISIS DE MEMORIA: Crear nueva tabla ===\n#&gt; Tiempo de ejecuci√≥n: 0.0012 segundos\n#&gt; Memoria input: 7207216 \n#&gt; Memoria despu√©s: 7207216 \n#&gt; Memoria resultado: 3603448 \n#&gt; Cambio en memoria input: 0 \n#&gt; Eficiencia memoria: 50 % del input\n\n# Operaci√≥n 3: Agregaci√≥n\nresult3 &lt;- memory_analysis(\"Agregaci√≥n por grupos\", function(dt) {\n  dt[, .(mean_value = mean(value_numeric),\n         sum_amount = sum(amount),\n         count = .N), \n     by = .(group_major, group_minor)]\n}, dt_mem_test)\n#&gt; === AN√ÅLISIS DE MEMORIA: Agregaci√≥n por grupos ===\n#&gt; Tiempo de ejecuci√≥n: 0.003 segundos\n#&gt; Memoria input: 7207216 \n#&gt; Memoria despu√©s: 7207216 \n#&gt; Memoria resultado: 13712 \n#&gt; Cambio en memoria input: 0 \n#&gt; Eficiencia memoria: 0.2 % del input",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Optimizaci√≥n de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#optimizaci√≥n-de-operaciones-espec√≠ficas",
    "href": "cap04-performance.html#optimizaci√≥n-de-operaciones-espec√≠ficas",
    "title": "\n9¬† Optimizaci√≥n de Performance\n",
    "section": "\n9.4 Optimizaci√≥n de Operaciones Espec√≠ficas",
    "text": "9.4 Optimizaci√≥n de Operaciones Espec√≠ficas\n\n9.4.1 1. Joins a Gran Escala\n\n\n# Preparar datos para joins de diferentes tama√±os\ndt_left_large &lt;- big_dataset[sample(.N, 200000)]\ndt_right_large &lt;- lookup_data[sample(.N, 100000)]\n\ncat(\"=== OPTIMIZACI√ìN DE JOINS GRANDES ===\\n\")\n#&gt; === OPTIMIZACI√ìN DE JOINS GRANDES ===\ncat(\"Tabla izquierda:\", nrow(dt_left_large), \"filas\\n\")\n#&gt; Tabla izquierda: 200000 filas\ncat(\"Tabla derecha:\", nrow(dt_right_large), \"filas\\n\\n\")\n#&gt; Tabla derecha: 100000 filas\n\n# Estrategia 1: Merge b√°sico\ntiempo_merge &lt;- system.time({\n  result_merge &lt;- merge(dt_left_large, dt_right_large, by = \"id\", all.x = TRUE)\n})\n\n# Estrategia 2: Join con setkey\ndt_left_key &lt;- copy(dt_left_large)\ndt_right_key &lt;- copy(dt_right_large)\nsetkey(dt_left_key, id)\nsetkey(dt_right_key, id)\n\ntiempo_setkey_join &lt;- system.time({\n  result_setkey &lt;- dt_right_key[dt_left_key]\n})\n\n# Estrategia 3: Join con on= (sin modificar tablas originales)\ntiempo_on_join &lt;- system.time({\n  result_on &lt;- dt_left_large[dt_right_large, on = .(id)]\n})\n\n# Estrategia 4: Join filtrado (cuando sabemos que solo necesitamos subset)\nids_relevantes &lt;- intersect(dt_left_large$id, dt_right_large$id)[1:50000]\ntiempo_filtered_join &lt;- system.time({\n  dt_left_filtered &lt;- dt_left_large[id %in% ids_relevantes]\n  dt_right_filtered &lt;- dt_right_large[id %in% ids_relevantes]\n  result_filtered &lt;- merge(dt_left_filtered, dt_right_filtered, by = \"id\")\n})\n\n# Comparar resultados\ncat(\"Resultados de joins:\\n\")\n#&gt; Resultados de joins:\ncat(\"‚Ä¢ Merge b√°sico:\", round(tiempo_merge[3], 4), \"segundos,\", nrow(result_merge), \"filas\\n\")\n#&gt; ‚Ä¢ Merge b√°sico: 0.03 segundos, 200000 filas\ncat(\"‚Ä¢ Con setkey:\", round(tiempo_setkey_join[3], 4), \"segundos,\", nrow(result_setkey), \"filas\\n\")\n#&gt; ‚Ä¢ Con setkey: 0.02 segundos, 200000 filas\ncat(\"‚Ä¢ Con on=:\", round(tiempo_on_join[3], 4), \"segundos,\", nrow(result_on), \"filas\\n\")\n#&gt; ‚Ä¢ Con on=: 0.01 segundos, 101800 filas\ncat(\"‚Ä¢ Join filtrado:\", round(tiempo_filtered_join[3], 4), \"segundos,\", nrow(result_filtered), \"filas\\n\")\n#&gt; ‚Ä¢ Join filtrado: 0.01 segundos, 19881 filas\n\n# Mejor estrategia\ntiempos_join &lt;- c(tiempo_merge[3], tiempo_setkey_join[3], tiempo_on_join[3], tiempo_filtered_join[3])\nmejor_join &lt;- which.min(tiempos_join)\nestrategias_join &lt;- c(\"Merge b√°sico\", \"Con setkey\", \"Con on=\", \"Join filtrado\")\ncat(\"\\nMejor estrategia:\", estrategias_join[mejor_join], \"\\n\")\n#&gt; \n#&gt; Mejor estrategia: Con on=\n\n\n9.4.2 2. Operaciones Temporales Optimizadas\n\n\n# Optimizar consultas en datos temporales\ndt_temporal &lt;- copy(temporal_dataset[sample(.N, 50000)])\n\ncat(\"=== OPTIMIZACI√ìN DE CONSULTAS TEMPORALES ===\\n\")\n#&gt; === OPTIMIZACI√ìN DE CONSULTAS TEMPORALES ===\n\n# Consulta 1: Rango de fechas sin optimizar\ntiempo_temporal_sin_key &lt;- system.time({\n  result_no_key &lt;- dt_temporal[timestamp &gt;= as.POSIXct(\"2024-06-01\") & \n                              timestamp &lt; as.POSIXct(\"2024-07-01\")]\n})\n\n# Consulta 2: Con key temporal\ndt_temporal_keyed &lt;- copy(dt_temporal)\nsetkey(dt_temporal_keyed, timestamp)\n\ntiempo_temporal_con_key &lt;- system.time({\n  inicio &lt;- as.POSIXct(\"2024-06-01\")\n  fin &lt;- as.POSIXct(\"2024-07-01\")\n  result_with_key &lt;- dt_temporal_keyed[timestamp %between% c(inicio, fin)]\n})\n\n# Consulta 3: Con rolling joins (para datos temporales complejos)\n# Simular eventos de referencia\neventos_ref &lt;- data.table(\n  event_time = seq(as.POSIXct(\"2024-06-01\"), as.POSIXct(\"2024-06-30\"), by = \"day\"),\n  event_type = sample(c(\"A\", \"B\", \"C\"), 30, replace = TRUE)\n)\nsetkey(eventos_ref, event_time)\n\ntiempo_rolling_join &lt;- system.time({\n  result_rolling &lt;- dt_temporal_keyed[eventos_ref, roll = TRUE]\n})\n\ncat(\"Resultados de consultas temporales:\\n\")\n#&gt; Resultados de consultas temporales:\ncat(\"‚Ä¢ Sin key:\", round(tiempo_temporal_sin_key[3], 4), \"segundos,\", nrow(result_no_key), \"filas\\n\")\n#&gt; ‚Ä¢ Sin key: 0.02 segundos, 2039 filas\ncat(\"‚Ä¢ Con key:\", round(tiempo_temporal_con_key[3], 4), \"segundos,\", nrow(result_with_key), \"filas\\n\")\n#&gt; ‚Ä¢ Con key: 0 segundos, 2039 filas\ncat(\"‚Ä¢ Rolling join:\", round(tiempo_rolling_join[3], 4), \"segundos,\", nrow(result_rolling), \"filas\\n\")\n#&gt; ‚Ä¢ Rolling join: 0 segundos, 30 filas",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Optimizaci√≥n de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#casos-de-uso-de-optimizaci√≥n-extrema",
    "href": "cap04-performance.html#casos-de-uso-de-optimizaci√≥n-extrema",
    "title": "\n9¬† Optimizaci√≥n de Performance\n",
    "section": "\n9.5 Casos de Uso de Optimizaci√≥n Extrema",
    "text": "9.5 Casos de Uso de Optimizaci√≥n Extrema\n\n9.5.1 1. Pipeline de An√°lisis de Alto Rendimiento\n\n\n# Pipeline optimizado para an√°lisis complejo\ncreate_optimized_pipeline &lt;- function(dt, sample_size = 100000) {\n  cat(\"=== PIPELINE DE ALTO RENDIMIENTO ===\\n\")\n  \n  # Paso 1: Muestreo estratificado eficiente\n  dt_sample &lt;- dt[, .SD[sample(min(.N, sample_size), sample_size)], by = region]\n  \n  # Paso 2: Establecer key √≥ptima para operaciones posteriores\n  setkey(dt_sample, group_major, group_minor)\n  \n  # Paso 3: C√°lculos intermedios optimizados (por referencia)\n  dt_sample[, `:=`(\n    value_normalized = scale(value_numeric)[,1],\n    amount_log = log1p(amount),  # log1p es m√°s estable que log\n    efficiency_ratio = value_numeric / (amount + 1),\n    timestamp_hour = hour(timestamp)\n  )]\n  \n  # Paso 4: Agregaciones complejas usando .SD optimizado\n  result_aggregated &lt;- dt_sample[, \n    .(\n      # Estad√≠sticas b√°sicas\n      count = .N,\n      mean_value = mean(value_normalized, na.rm = TRUE),\n      median_amount = median(amount_log, na.rm = TRUE),\n      \n      # Estad√≠sticas avanzadas\n      p95_efficiency = quantile(efficiency_ratio, 0.95, na.rm = TRUE),\n      cv_value = sd(value_normalized, na.rm = TRUE) / abs(mean(value_normalized, na.rm = TRUE)),\n      \n      # An√°lisis temporal\n      peak_hour = timestamp_hour[which.max(value_numeric)],\n      active_hours = uniqueN(timestamp_hour),\n      \n      # Diversidad\n      categories_used = uniqueN(category),\n      status_diversity = uniqueN(status)\n    ),\n    by = .(region, group_major),\n    .SDcols = c(\"value_normalized\", \"amount_log\", \"efficiency_ratio\", \n                \"timestamp_hour\", \"value_numeric\", \"category\", \"status\")\n  ]\n  \n  # Paso 5: Post-procesamiento optimizado\n  result_aggregated[, `:=`(\n    performance_score = round((mean_value + p95_efficiency) * log1p(count), 2),\n    complexity_index = categories_used * status_diversity * active_hours\n  )]\n  \n  # Paso 6: Ranking y clasificaci√≥n final\n  result_aggregated[, rank_performance := frank(-performance_score), by = region]\n  result_aggregated[, tier := fcase(\n    rank_performance &lt;= 3, \"Tier_1\",\n    rank_performance &lt;= 10, \"Tier_2\", \n    rank_performance &lt;= 20, \"Tier_3\",\n    default = \"Tier_4\"\n  )]\n  \n  return(result_aggregated[order(-performance_score)])\n}\n\n# Ejecutar pipeline optimizado\ntiempo_pipeline &lt;- system.time({\n  resultado_pipeline &lt;- create_optimized_pipeline(big_dataset, 80000)\n})\n#&gt; === PIPELINE DE ALTO RENDIMIENTO ===\n\ncat(\"Tiempo total del pipeline:\", round(tiempo_pipeline[3], 3), \"segundos\\n\")\n#&gt; Tiempo total del pipeline: 0.22 segundos\ncat(\"Registros procesados: ~80,000 ‚Üí \", nrow(resultado_pipeline), \"grupos finales\\n\")\n#&gt; Registros procesados: ~80,000 ‚Üí  135 grupos finales\ncat(\"Reducci√≥n de datos:\", round((1 - nrow(resultado_pipeline)/80000) * 100, 1), \"%\\n\\n\")\n#&gt; Reducci√≥n de datos: 99.8 %\n\nprint(\"Top 10 grupos por performance:\")\n#&gt; [1] \"Top 10 grupos por performance:\"\nprint(resultado_pipeline[1:10, .(region, group_major, count, performance_score, tier)])\n#&gt;      region group_major count performance_score   tier\n#&gt;      &lt;char&gt;      &lt;char&gt; &lt;int&gt;             &lt;num&gt; &lt;char&gt;\n#&gt;  1:   North        &lt;NA&gt; 38443             79.25 Tier_1\n#&gt;  2:    East        &lt;NA&gt; 38482             78.27 Tier_1\n#&gt;  3:   South        &lt;NA&gt; 38511             77.88 Tier_1\n#&gt;  4:    West        &lt;NA&gt; 38478             77.56 Tier_1\n#&gt;  5: Central        &lt;NA&gt; 38371             76.97 Tier_1\n#&gt;  6: Central           N  1554             61.91 Tier_1\n#&gt;  7:    East           M  1647             61.90 Tier_1\n#&gt;  8:   North           Q  1641             61.34 Tier_1\n#&gt;  9:    West           G  1635             61.30 Tier_1\n#&gt; 10:   South           F  1590             61.00 Tier_1\n\n\n9.5.2 2. Sistema de Monitoreo de Performance en Tiempo Real\n\n\n# Sistema para monitorear performance de operaciones data.table\nperformance_monitor &lt;- function() {\n  # Crear registro de operaciones\n  operations_log &lt;- data.table(\n    operation_id = character(),\n    operation_type = character(),\n    dataset_size = integer(),\n    execution_time = numeric(),\n    memory_used = numeric(),\n    threads_used = integer(),\n    timestamp = .POSIXct(numeric())\n  )\n  \n  # Funci√≥n para registrar operaci√≥n\n  log_operation &lt;- function(op_type, dt_size, exec_time, mem_usage) {\n    new_entry &lt;- data.table(\n      operation_id = paste0(op_type, \"_\", format(Sys.time(), \"%H%M%S\")),\n      operation_type = op_type,\n      dataset_size = dt_size,\n      execution_time = exec_time,\n      memory_used = mem_usage,\n      threads_used = getDTthreads(),\n      timestamp = Sys.time()\n    )\n    operations_log &lt;&lt;- rbindlist(list(operations_log, new_entry), use.names = TRUE, fill = TRUE, ignore.attr = TRUE)\n  }\n  \n  # Funci√≥n para analizar performance\n  analyze_performance &lt;- function() {\n    if(nrow(operations_log) == 0) {\n      cat(\"No hay operaciones registradas\\n\")\n      return(NULL)\n    }\n    \n    # An√°lisis por tipo de operaci√≥n\n    performance_summary &lt;- operations_log[, .(\n      operations_count = .N,\n      avg_time = round(mean(execution_time), 4),\n      median_time = round(median(execution_time), 4),\n      max_time = round(max(execution_time), 4),\n      avg_memory = round(mean(memory_used), 0),\n      throughput_rows_per_sec = round(mean(dataset_size / execution_time), 0)\n    ), by = operation_type]\n    \n    return(performance_summary)\n  }\n  \n  return(list(log = log_operation, analyze = analyze_performance, get_log = function() operations_log))\n}\n\n# Inicializar sistema de monitoreo\nmonitor &lt;- performance_monitor()\n\n# Simular diferentes operaciones y monitorearlas\ndt_test &lt;- big_dataset[sample(.N, 50000)]\n\n# Operaci√≥n 1: Agregaci√≥n\ncat(\"Monitoreando operaciones:\\n\")\n#&gt; Monitoreando operaciones:\ntiempo_agg &lt;- system.time({\n  result_agg &lt;- dt_test[, .(mean_val = mean(value_numeric)), by = group_major]\n})\nmonitor$log(\"aggregation\", nrow(dt_test), tiempo_agg[3], object.size(result_agg))\n\n# Operaci√≥n 2: Join\ntiempo_join &lt;- system.time({\n  result_join &lt;- dt_test[lookup_data[1:10000], on = .(id)]\n})\nmonitor$log(\"join\", nrow(dt_test), tiempo_join[3], object.size(result_join))\n\n# Operaci√≥n 3: Sort\ntiempo_sort &lt;- system.time({\n  result_sort &lt;- dt_test[order(-value_numeric)]\n})\nmonitor$log(\"sort\", nrow(dt_test), tiempo_sort[3], object.size(result_sort))\n\n# An√°lisis de performance\ncat(\"\\n=== AN√ÅLISIS DE PERFORMANCE ===\\n\")\n#&gt; \n#&gt; === AN√ÅLISIS DE PERFORMANCE ===\nperformance_analysis &lt;- monitor$analyze()\nprint(performance_analysis)\n#&gt;    operation_type operations_count avg_time median_time max_time avg_memory\n#&gt;            &lt;char&gt;            &lt;int&gt;    &lt;num&gt;       &lt;num&gt;    &lt;num&gt;      &lt;num&gt;\n#&gt; 1:    aggregation                1     0.00        0.00     0.00       3256\n#&gt; 2:           join                1     0.28        0.28     0.28    1729416\n#&gt; 3:           sort                1     0.00        0.00     0.00    3607216\n#&gt;    throughput_rows_per_sec\n#&gt;                      &lt;num&gt;\n#&gt; 1:                     Inf\n#&gt; 2:                  178571\n#&gt; 3:                     Inf\n\n# Identificar operaciones problem√°ticas\nif(!is.null(performance_analysis)) {\n  problematic_ops &lt;- performance_analysis[avg_time &gt; median(avg_time) * 2]\n  if(nrow(problematic_ops) &gt; 0) {\n    cat(\"\\n‚ö†Ô∏è Operaciones con performance sub√≥ptima:\\n\")\n    print(problematic_ops)\n  } else {\n    cat(\"\\n‚úÖ Todas las operaciones tienen performance aceptable\\n\")\n  }\n}\n#&gt; \n#&gt; ‚ö†Ô∏è Operaciones con performance sub√≥ptima:\n#&gt;    operation_type operations_count avg_time median_time max_time avg_memory\n#&gt;            &lt;char&gt;            &lt;int&gt;    &lt;num&gt;       &lt;num&gt;    &lt;num&gt;      &lt;num&gt;\n#&gt; 1:           join                1     0.28        0.28     0.28    1729416\n#&gt;    throughput_rows_per_sec\n#&gt;                      &lt;num&gt;\n#&gt; 1:                  178571",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Optimizaci√≥n de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-performance.html#ejercicio-pr√°ctico-de-optimizaci√≥n",
    "href": "cap04-performance.html#ejercicio-pr√°ctico-de-optimizaci√≥n",
    "title": "\n9¬† Optimizaci√≥n de Performance\n",
    "section": "\n9.6 Ejercicio Pr√°ctico de Optimizaci√≥n",
    "text": "9.6 Ejercicio Pr√°ctico de Optimizaci√≥n\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 15: Optimizaci√≥n Integral\n\n\n\nDado el siguiente c√≥digo ineficiente, optim√≠zalo usando todas las t√©cnicas aprendidas:\n# C√≥digo INEFICIENTE para optimizar\nanalyze_data_slow &lt;- function(big_data, lookup) {\n  results &lt;- data.table()\n  \n  # Procesar cada regi√≥n por separado\n  for(region in unique(big_data$region)) {\n    region_data &lt;- big_data[big_data$region == region, ]\n    \n    # Procesar cada grupo dentro de la regi√≥n\n    for(group in unique(region_data$group_major)) {\n      group_data &lt;- region_data[region_data$group_major == group, ]\n      \n      # C√°lculos por grupo\n      group_stats &lt;- data.frame(\n        region = region,\n        group = group,\n        count = nrow(group_data),\n        mean_value = mean(group_data$value_numeric),\n        sum_amount = sum(group_data$amount)\n      )\n      \n      # Join con lookup (ineficiente)\n      for(i in 1:nrow(group_stats)) {\n        matched_lookup &lt;- lookup[lookup$entity_type == \"Premium\", ]\n        if(nrow(matched_lookup) &gt; 0) {\n          group_stats$premium_factor[i] &lt;- mean(matched_lookup$weight_factor)\n        }\n      }\n      \n      results &lt;- rbind(results, group_stats)\n    }\n  }\n  \n  return(results)\n}\nOptim√≠zalo para: 1. Eliminar todos los bucles 2. Usar operaciones vectorizadas 3. Implementar joins eficientes 4. Minimizar copias de memoria\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 15\n\n\n\n\n\n\n# Versi√≥n OPTIMIZADA\nanalyze_data_fast &lt;- function(big_data, lookup) {\n  \n  # Pre-calcular el premium_factor una sola vez\n  premium_factor &lt;- lookup[entity_type == \"Premium\", mean(weight_factor)]\n  \n  # Una sola operaci√≥n vectorizada que reemplaza todos los bucles\n  result &lt;- big_data[, .(\n    count = .N,\n    mean_value = mean(value_numeric),\n    sum_amount = sum(amount),\n    premium_factor = premium_factor  # Usar valor pre-calculado\n  ), by = .(region, group = group_major)]\n  \n  return(result)\n}\n\n# Comparar performance\ndt_test_large &lt;- big_dataset[sample(.N, 20000)]  # Dataset m√°s peque√±o para el test\nlookup_test &lt;- lookup_data[sample(.N, 5000)]\n\ncat(\"=== COMPARACI√ìN DE PERFORMANCE ===\\n\")\n#&gt; === COMPARACI√ìN DE PERFORMANCE ===\n\n# Versi√≥n lenta (simulada de forma m√°s r√°pida para el ejemplo)\ntiempo_lento &lt;- system.time({\n  # Simulamos la l√≥gica ineficiente pero sin bucles extremos\n  result_slow &lt;- dt_test_large[, {\n    # M√∫ltiples operaciones separadas (ineficiente)\n    temp_results &lt;- list()\n    for(i in seq_along(unique(group_major))) {\n      group_val &lt;- unique(group_major)[i]\n      group_subset &lt;- .SD[group_major == group_val]\n      temp_results[[i]] &lt;- data.table(\n        region = unique(region),\n        group = group_val,\n        count = nrow(group_subset),\n        mean_value = mean(group_subset$value_numeric),\n        sum_amount = sum(group_subset$amount),\n        premium_factor = lookup_test[entity_type == \"Premium\", mean(weight_factor)]\n      )\n    }\n    rbindlist(temp_results)\n  }, by = region]\n})\n\n# Versi√≥n optimizada\ntiempo_rapido &lt;- system.time({\n  result_fast &lt;- analyze_data_fast(dt_test_large, lookup_test)\n})\n\ncat(\"M√©todo ineficiente (simulado):\", round(tiempo_lento[3], 4), \"segundos\\n\")\n#&gt; M√©todo ineficiente (simulado): 0.11 segundos\ncat(\"M√©todo optimizado:\", round(tiempo_rapido[3], 4), \"segundos\\n\")\n#&gt; M√©todo optimizado: 0 segundos\ncat(\"Mejora de velocidad:\", round(tiempo_lento[3] / tiempo_rapido[3], 1), \"x m√°s r√°pido\\n\")\n#&gt; Mejora de velocidad: Inf x m√°s r√°pido\n\n# Verificar resultados equivalentes\ncat(\"Resultados similares:\", \n    nrow(result_slow) == nrow(result_fast), \n    all.equal(result_slow$count, result_fast$count), \"\\n\")\n#&gt; Resultados similares: TRUE Mean relative difference: 1.077508\n\nprint(\"\\nPrimeras filas del resultado optimizado:\")\n#&gt; [1] \"\\nPrimeras filas del resultado optimizado:\"\nprint(head(result_fast))\n#&gt;     region  group count mean_value sum_amount premium_factor\n#&gt;     &lt;char&gt; &lt;char&gt; &lt;int&gt;      &lt;num&gt;      &lt;num&gt;          &lt;num&gt;\n#&gt; 1: Central      G    94  108.12594   39703.33       1.252676\n#&gt; 2: Central   &lt;NA&gt;  1887   99.26696  886126.91       1.252676\n#&gt; 3:   South      E    82  102.41588   51290.98       1.252676\n#&gt; 4:    East      B    82   97.44042   26863.57       1.252676\n#&gt; 5:    West      J    92  100.79471   36067.56       1.252676\n#&gt; 6: Central      C    69   98.34540   25937.61       1.252676\n\ncat(\"\\n=== T√âCNICAS DE OPTIMIZACI√ìN APLICADAS ===\\n\")\n#&gt; \n#&gt; === T√âCNICAS DE OPTIMIZACI√ìN APLICADAS ===\ncat(\"1. ‚úÖ Eliminaci√≥n completa de bucles for\\n\")\n#&gt; 1. ‚úÖ Eliminaci√≥n completa de bucles for\ncat(\"2. ‚úÖ Una sola operaci√≥n by= vectorizada\\n\") \n#&gt; 2. ‚úÖ Una sola operaci√≥n by= vectorizada\ncat(\"3. ‚úÖ Pre-c√°lculo de valores constantes\\n\")\n#&gt; 3. ‚úÖ Pre-c√°lculo de valores constantes\ncat(\"4. ‚úÖ Eliminaci√≥n de rbind repetitivo\\n\")\n#&gt; 4. ‚úÖ Eliminaci√≥n de rbind repetitivo\ncat(\"5. ‚úÖ Sintaxis data.table pura (sin data.frame)\\n\")\n#&gt; 5. ‚úÖ Sintaxis data.table pura (sin data.frame)\ncat(\"6. ‚úÖ Operaciones vectorizadas nativas\\n\")\n#&gt; 6. ‚úÖ Operaciones vectorizadas nativas\ncat(\"7. ‚úÖ M√≠nimo uso de memoria\\n\")\n#&gt; 7. ‚úÖ M√≠nimo uso de memoria\n\n\n\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nThreading autom√°tico puede acelerar operaciones 2-10x en sistemas multi-core\n\nsetkey() es esencial para datasets &gt;100K filas con consultas repetitivas\n\n√çndices secundarios con setindex() permiten m√∫ltiples patrones de consulta eficientes\n\nBenchmarking sistem√°tico revela cuellos de botella reales vs percibidos\n\nUna operaci√≥n data.table vectorizada puede reemplazar docenas de bucles\n\nProfiling de memoria es crucial para datasets que se acercan a los l√≠mites de RAM\n\nLa optimizaci√≥n correcta puede resultar en mejoras de 10-100x en casos extremos\n\n\n\nEl dominio de estas t√©cnicas de optimizaci√≥n te permite trabajar con datasets que de otra manera ser√≠an imposibles de procesar eficientemente. En el pr√≥ximo cap√≠tulo exploraremos las mejores pr√°cticas y patrones que complementan estas optimizaciones.\n[{‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 1: dividir fundamentos en sintaxis y s0edmbolos‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap01-simbolos.qmd para s0edmbolos especiales del M0f3dulo 1‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú1-new‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 2: dividir en encadenamiento y joins‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-joins-avanzados.qmd para joins avanzados del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-funciones-especiales.qmd para funciones especiales del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap03-reshape.qmd para reshape del M0f3dulo 3‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú3-3‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap04-performance.qmd para optimizaci√≥n de performance del M0f3dulo 4‚Äù, ‚Äústatus‚Äù: ‚Äúcompleted‚Äù, ‚Äúid‚Äù: ‚Äú4-1‚Äù}, {‚Äúcontent‚Äù: ‚ÄúCrear cap04-buenas-practicas.qmd para mejores pr0e1cticas del M0f3dulo 4‚Äù, ‚Äústatus‚Äù: ‚Äúin_progress‚Äù, ‚Äúid‚Äù: ‚Äú4-2‚Äù}, {‚Äúcontent‚Äù: ‚ÄúReorganizar M0f3dulo 5: dividir en visualizaci0f3n y aplicaciones‚Äù, ‚Äústatus‚Äù: ‚Äúpending‚Äù, ‚Äúid‚Äù: ‚Äú5‚Äù}]",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>9</span>¬† <span class='chapter-title'>Optimizaci√≥n de Performance</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html",
    "href": "cap04-buenas-practicas.html",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "",
    "text": "10.1 Los Mandamientos de data.table",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-mandamientos",
    "href": "cap04-buenas-practicas.html#sec-mandamientos",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "",
    "text": "10.1.1 ‚úÖ QU√â HACER (Do‚Äôs)\n\n1. Usa := para Modificaciones Eficientes\n\nEl operador := es el coraz√≥n de la eficiencia en data.table. Modifica por referencia sin copiar toda la tabla.\n\n# ‚úÖ CORRECTO: Modificaci√≥n por referencia\nemployees_dt[, annual_bonus := salary * 0.1]\n\n# ‚úÖ CORRECTO: M√∫ltiples columnas a la vez\nemployees_dt[, `:=`(\n  salary_tier = fifelse(salary &gt; 100000, \"High\", \n                fifelse(salary &gt; 70000, \"Medium\", \"Low\")),\n  tenure_years = as.numeric(Sys.Date() - hire_date) / 365.25\n)]\n\n# ‚úÖ CORRECTO: Modificaci√≥n condicional\nemployees_dt[department == \"Engineering\", tech_bonus := salary * 0.05]\n\n# Mostrar resultado\nhead(employees_dt[, .(employee_id, department, salary, salary_tier, annual_bonus, tech_bonus)])\n#&gt;    employee_id  department salary salary_tier annual_bonus tech_bonus\n#&gt;          &lt;int&gt;      &lt;char&gt;  &lt;num&gt;      &lt;char&gt;        &lt;num&gt;      &lt;num&gt;\n#&gt; 1:           1 Engineering 128722        High      12872.2     6436.1\n#&gt; 2:           2     Finance 128148        High      12814.8         NA\n#&gt; 3:           3     Finance  50533         Low       5053.3         NA\n#&gt; 4:           4          HR  41787         Low       4178.7         NA\n#&gt; 5:           5       Sales  79771      Medium       7977.1         NA\n#&gt; 6:           6     Finance 138060        High      13806.0         NA\n\n\n# Comparar con m√©todo ineficiente\nemployees_copy &lt;- copy(employees_dt[1:1000])\n\n# ‚ùå INCORRECTO: Crear copias innecesarias\ntiming_inefficient &lt;- system.time({\n  employees_copy &lt;- employees_copy[, .(employee_id, department, salary, \n                                      new_column = salary * 1.1)]\n})\n\n# ‚úÖ CORRECTO: Modificaci√≥n por referencia\nemployees_ref &lt;- copy(employees_dt[1:1000])\ntiming_efficient &lt;- system.time({\n  employees_ref[, new_column := salary * 1.1]\n})\n\ncat(\"M√©todo ineficiente:\", round(timing_inefficient[3], 4), \"segundos\\n\")\n#&gt; M√©todo ineficiente: 0 segundos\ncat(\"M√©todo eficiente:\", round(timing_efficient[3], 4), \"segundos\\n\")\n#&gt; M√©todo eficiente: 0 segundos\ncat(\"Mejora:\", round(timing_inefficient[3] / timing_efficient[3], 1), \"x m√°s r√°pido\\n\")\n#&gt; Mejora: NaN x m√°s r√°pido\n\n2. Utiliza setkey() para Joins y Filtros Repetitivos\n\nCuando vas a hacer m√∫ltiples operaciones sobre las mismas columnas, setkey() paga con creces la inversi√≥n inicial.\n\n# Crear copias para comparar\ntrans_no_key &lt;- copy(transactions_dt[1:10000])\ntrans_with_key &lt;- copy(transactions_dt[1:10000])\n\n# Establecer key\nsetkey(trans_with_key, customer_id, transaction_date)\n\n# ‚úÖ CORRECTO: Consultas r√°pidas con key\ncustomers_target &lt;- c(1, 50, 100, 500, 1000)\n\n# Sin key\ntime_no_key &lt;- system.time({\n  result1 &lt;- trans_no_key[customer_id %in% customers_target & \n                         transaction_date &gt;= as.Date(\"2024-01-01\")]\n})\n\n# Con key  \ntime_with_key &lt;- system.time({\n  # Usar sintaxis de key para m√°xima eficiencia\n  result2 &lt;- trans_with_key[.(customers_target, \n                             seq(as.Date(\"2024-01-01\"), as.Date(\"2024-12-31\"), by = \"day\"))]\n})\n\ncat(\"Sin key:\", round(time_no_key[3], 4), \"segundos\\n\")\n#&gt; Sin key: 0 segundos\ncat(\"Con key:\", round(time_with_key[3], 4), \"segundos\\n\")\n#&gt; Con key: 0.01 segundos\ncat(\"Speedup:\", round(time_no_key[3] / time_with_key[3], 1), \"x\\n\")\n#&gt; Speedup: 0 x\n\n3. Aprovecha .SD para Operaciones M√∫ltiples\n\n.SD (Subset of Data) te permite aplicar funciones a m√∫ltiples columnas de manera elegante.\n\n# ‚úÖ CORRECTO: Usar .SD para m√∫ltiples columnas\nnumeric_summary &lt;- employees_dt[, lapply(.SD, function(x) {\n  list(mean = mean(x, na.rm = TRUE),\n       median = median(x, na.rm = TRUE),\n       q95 = quantile(x, 0.95, na.rm = TRUE))\n}), .SDcols = is.numeric, by = department]\n\nprint(head(numeric_summary))\n#&gt;     department employee_id   salary performance_score manager_id annual_bonus\n#&gt;         &lt;char&gt;      &lt;list&gt;   &lt;list&gt;            &lt;list&gt;     &lt;list&gt;       &lt;list&gt;\n#&gt; 1: Engineering    25366.05 95310.06                 3   499.7326     9531.006\n#&gt; 2: Engineering       25715    95316                 3      499.5       9531.6\n#&gt; 3: Engineering       47551 144724.9                 4     950.95     14472.49\n#&gt; 4:     Finance    24716.19 94993.49           3.01034   503.8386     9499.349\n#&gt; 5:     Finance       24506    95204                 3        507       9520.4\n#&gt; 6:     Finance     47432.4 144319.8                 5        951     14431.98\n#&gt;    tenure_years tech_bonus\n#&gt;          &lt;list&gt;     &lt;list&gt;\n#&gt; 1:     5.614184   4765.503\n#&gt; 2:      5.61807     4765.8\n#&gt; 3:     10.11992   7236.245\n#&gt; 4:      5.66225        NaN\n#&gt; 5:     5.667351         NA\n#&gt; 6:      10.1848         NA\n\n# ‚úÖ CORRECTO: .SD con transformaciones complejas\nemployees_standardized &lt;- employees_dt[, c(.SD[, .(employee_id, department)], \n                                          lapply(.SD, function(x) scale(x)[,1])), \n                                      .SDcols = is.numeric]\n\nprint(head(employees_standardized[, .(employee_id, department, salary, performance_score)]))\n#&gt;    employee_id  department    salary performance_score\n#&gt;          &lt;int&gt;      &lt;char&gt;     &lt;num&gt;             &lt;num&gt;\n#&gt; 1:           1 Engineering  1.061269      -0.002022701\n#&gt; 2:           2     Finance  1.043194      -0.002022701\n#&gt; 3:           3     Finance -1.400920      -0.002022701\n#&gt; 4:           4          HR -1.676334      -0.002022701\n#&gt; 5:           5       Sales -0.480209      -0.002022701\n#&gt; 6:           6     Finance  1.355325      -0.002022701\n\n4. Usa Vectorizaci√≥n en Lugar de Bucles\n\nLas operaciones vectorizadas son siempre m√°s r√°pidas y m√°s legibles.\n\n# ‚úÖ CORRECTO: Operaciones vectorizadas\ntransactions_dt[, transaction_quarter := paste0(\"Q\", ceiling(month(transaction_date)/3), \n                                               \"_\", year(transaction_date))]\n\n# ‚úÖ CORRECTO: Condicionales vectorizadas con fifelse\ntransactions_dt[, amount_category := fifelse(\n  amount &gt; 100, \"High\",\n  fifelse(amount &gt; 50, \"Medium\", \"Low\")\n)]\n\n# ‚úÖ CORRECTO: Uso de %between% para rangos\nemployees_dt[, mid_career := salary %between% c(60000, 120000)]\n\n# Mostrar resultados\nprint(head(transactions_dt[, .(transaction_id, amount, amount_category, transaction_quarter)]))\n#&gt;    transaction_id amount amount_category transaction_quarter\n#&gt;             &lt;int&gt;  &lt;num&gt;          &lt;char&gt;              &lt;char&gt;\n#&gt; 1:              1  19.01             Low             Q3_2024\n#&gt; 2:              2  28.39             Low             Q4_2024\n#&gt; 3:              3  41.68             Low             Q4_2023\n#&gt; 4:              4  10.01             Low             Q3_2023\n#&gt; 5:              5  29.42             Low             Q1_2023\n#&gt; 6:              6  38.53             Low             Q3_2023\nprint(head(employees_dt[, .(employee_id, salary, mid_career)]))\n#&gt;    employee_id salary mid_career\n#&gt;          &lt;int&gt;  &lt;num&gt;     &lt;lgcl&gt;\n#&gt; 1:           1 128722      FALSE\n#&gt; 2:           2 128148      FALSE\n#&gt; 3:           3  50533      FALSE\n#&gt; 4:           4  41787      FALSE\n#&gt; 5:           5  79771       TRUE\n#&gt; 6:           6 138060      FALSE\n\n5. Utiliza Encadenamiento para Operaciones Complejas\n\nEl encadenamiento DT[...][...] es m√°s eficiente que variables intermedias.\n\n# ‚úÖ CORRECTO: Encadenamiento eficiente\nhigh_performers &lt;- employees_dt[\n  performance_score &gt;= 4 & tenure_years &gt;= 2\n][\n  , .(avg_salary = mean(salary), \n      count = .N,\n      avg_tenure = mean(tenure_years)), \n  by = department\n][\n  order(-avg_salary)\n]\n\nprint(high_performers)\n#&gt;     department avg_salary count avg_tenure\n#&gt;         &lt;char&gt;      &lt;num&gt; &lt;int&gt;      &lt;num&gt;\n#&gt; 1:       Sales   95508.85  1735   6.269524\n#&gt; 2:   Marketing   95241.65  1680   6.293222\n#&gt; 3:     Finance   95124.27  1766   6.333967\n#&gt; 4: Engineering   94705.74  1697   6.231506\n#&gt; 5:          HR   94161.02  1647   6.256346\n\n# ‚úÖ CORRECTO: Encadenamiento con modificaciones\ntop_departments &lt;- transactions_dt[\n  transaction_date &gt;= as.Date(\"2024-01-01\")\n][\n  , total_revenue := sum(amount), by = store_location\n][\n  total_revenue &gt; 10000\n][\n  order(-total_revenue)\n]\n\nprint(head(top_departments[, .(store_location, total_revenue)]))\n#&gt;    store_location total_revenue\n#&gt;            &lt;char&gt;         &lt;num&gt;\n#&gt; 1:        Store_P      132929.2\n#&gt; 2:        Store_P      132929.2\n#&gt; 3:        Store_P      132929.2\n#&gt; 4:        Store_P      132929.2\n#&gt; 5:        Store_P      132929.2\n#&gt; 6:        Store_P      132929.2\n\n\n10.1.2 ‚ùå QU√â NO HACER (Don‚Äôts)\n\n1. No Uses Bucles for con data.table\n\nLos bucles expl√≠citos destruyen todas las optimizaciones de data.table.\n\n# Crear dataset peque√±o para la demostraci√≥n\nsample_trans &lt;- transactions_dt[sample(.N, 1000)]\n\n# ‚ùå INCORRECTO: Bucle ineficiente\ncalculate_inefficient &lt;- function(dt) {\n  result &lt;- copy(dt)\n  for(i in 1:nrow(result)) {\n    result[i, profit_margin := amount[i] * 0.2]\n  }\n  return(result)\n}\n\n# ‚úÖ CORRECTO: Operaci√≥n vectorizada\ncalculate_efficient &lt;- function(dt) {\n  result &lt;- copy(dt)\n  result[, profit_margin := amount * 0.2]\n  return(result)\n}\n\n# Comparar tiempos\ntime_inefficient &lt;- system.time(result_bad &lt;- calculate_inefficient(sample_trans))\ntime_efficient &lt;- system.time(result_good &lt;- calculate_efficient(sample_trans))\n\ncat(\"M√©todo con bucle:\", round(time_inefficient[3], 4), \"segundos\\n\")\n#&gt; M√©todo con bucle: 0.11 segundos\ncat(\"M√©todo vectorizado:\", round(time_efficient[3], 4), \"segundos\\n\")\n#&gt; M√©todo vectorizado: 0 segundos\ncat(\"Mejora:\", round(time_inefficient[3] / time_efficient[3], 1), \"x m√°s r√°pido\\n\")\n#&gt; Mejora: Inf x m√°s r√°pido\n\n# Verificar que los resultados son id√©nticos\ncat(\"Resultados id√©nticos:\", identical(result_bad$profit_margin, result_good$profit_margin), \"\\n\")\n#&gt; Resultados id√©nticos: FALSE\n\n2. No Mezcles dplyr con data.table sin Cuidado\n\nMixing paradigmas puede causar copias inesperadas y p√©rdida de performance.\n\n# ‚ùå PROBLEM√ÅTICO: Puede forzar copias y perder optimizaciones\nlibrary(dplyr)\nemployees_dt %&gt;% \n  mutate(new_salary = salary * 1.1) %&gt;% \n  filter(department == \"Engineering\") %&gt;%\n  arrange(desc(salary))\n\n# ‚úÖ CORRECTO: Sintaxis data.table pura\nemployees_dt[, new_salary := salary * 1.1][\n  department == \"Engineering\"\n][order(-salary)]\n\n# ‚úÖ ALTERNATIVA: dtplyr para sintaxis dplyr + performance data.table\nlibrary(dtplyr)\nemployees_dt %&gt;% \n  lazy_dt() %&gt;%\n  mutate(new_salary = salary * 1.1) %&gt;% \n  filter(department == \"Engineering\") %&gt;%\n  arrange(desc(salary)) %&gt;%\n  as.data.table()\n\n3. No Ignores la Gesti√≥n de Memoria\n\nCrear copias innecesarias puede agotar la memoria r√°pidamente.\n\n# Demostrar el problema con copias\ndemo_dt &lt;- employees_dt[1:1000]\n\n# ‚ùå INCORRECTO: Crear m√∫ltiples copias\nmeasure_memory_waste &lt;- function() {\n  copy1 &lt;- copy(demo_dt)\n  copy2 &lt;- copy(demo_dt)\n  copy3 &lt;- copy(demo_dt)\n  \n  # Modificaciones que podr√≠an haberse hecho por referencia\n  copy1[, bonus1 := salary * 0.1]\n  copy2[, bonus2 := salary * 0.15]\n  copy3[, bonus3 := salary * 0.2]\n  \n  return(list(copy1, copy2, copy3))\n}\n\n# ‚úÖ CORRECTO: Trabajar con referencias\nmeasure_memory_efficient &lt;- function() {\n  working_dt &lt;- demo_dt  # Solo una referencia\n  \n  # Todas las modificaciones por referencia\n  working_dt[, `:=`(\n    bonus1 = salary * 0.1,\n    bonus2 = salary * 0.15, \n    bonus3 = salary * 0.2\n  )]\n  \n  return(working_dt)\n}\n\n# Nota: En este ejemplo, usamos copias peque√±as para demostrar el concepto\n# sin consumir mucha memoria en el tutorial\nmemory_waste &lt;- object.size(measure_memory_waste())\nmemory_efficient &lt;- object.size(measure_memory_efficient())\n\ncat(\"Enfoque con m√∫ltiples copias:\", format(memory_waste, units = \"KB\"), \"\\n\")\n#&gt; Enfoque con m√∫ltiples copias: 258.9 Kb\ncat(\"Enfoque eficiente:\", format(memory_efficient, units = \"KB\"), \"\\n\")\n#&gt; Enfoque eficiente: 102.2 Kb\n\n4. No Uses rbind() Repetitivo\n\nConstruir tablas fila por fila es extremadamente ineficiente.\n\n# ‚ùå INCORRECTO: rbind repetitivo (simulado para evitar demora)\nbuild_table_bad &lt;- function(n) {\n  result &lt;- data.table()\n  # Simulamos solo algunas iteraciones para el ejemplo\n  for(i in 1:min(n, 50)) {  # Limitamos a 50 para el ejemplo\n    new_row &lt;- data.table(\n      id = i, \n      value = rnorm(1),\n      category = sample(LETTERS[1:3], 1)\n    )\n    result &lt;- rbind(result, new_row)\n  }\n  return(result)\n}\n\n# ‚úÖ CORRECTO: Crear toda la tabla de una vez\nbuild_table_good &lt;- function(n) {\n  data.table(\n    id = 1:n,\n    value = rnorm(n),\n    category = sample(LETTERS[1:3], n, replace = TRUE)\n  )\n}\n\n# Comparar tiempos\nn_rows &lt;- 50  # Peque√±o para el ejemplo\ntime_bad &lt;- system.time(table_bad &lt;- build_table_bad(n_rows))\ntime_good &lt;- system.time(table_good &lt;- build_table_good(n_rows))\n\ncat(\"M√©todo rbind repetitivo:\", round(time_bad[3], 4), \"segundos\\n\")\n#&gt; M√©todo rbind repetitivo: 0 segundos\ncat(\"M√©todo eficiente:\", round(time_good[3], 4), \"segundos\\n\")\n#&gt; M√©todo eficiente: 0 segundos\ncat(\"Diferencia:\", round(time_bad[3] / time_good[3], 1), \"x m√°s lento\\n\")\n#&gt; Diferencia: NaN x m√°s lento\n\n# Para tablas grandes, la diferencia ser√≠a dram√°tica\ncat(\"\\nNota: Para 10,000 filas, el m√©todo rbind puede ser 100-1000x m√°s lento\\n\")\n#&gt; \n#&gt; Nota: Para 10,000 filas, el m√©todo rbind puede ser 100-1000x m√°s lento",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-patrones",
    "href": "cap04-buenas-practicas.html#sec-patrones",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "\n10.2 Patrones de C√≥digo Idiom√°tico",
    "text": "10.2 Patrones de C√≥digo Idiom√°tico\n\n10.2.1 1. An√°lisis Exploratorio de Datos\n\n\n# Patr√≥n: Resumen r√°pido de todas las variables num√©ricas\neda_summary &lt;- employees_dt[, lapply(.SD, function(x) {\n  if(is.numeric(x)) {\n    list(\n      count = sum(!is.na(x)),\n      mean = round(mean(x, na.rm = TRUE), 2),\n      median = round(median(x, na.rm = TRUE), 2),\n      min = min(x, na.rm = TRUE),\n      max = max(x, na.rm = TRUE),\n      missing = sum(is.na(x))\n    )\n  }\n}), .SDcols = is.numeric]\n\nprint(eda_summary)\n#&gt;    employee_id   salary performance_score manager_id annual_bonus tenure_years\n#&gt;         &lt;list&gt;   &lt;list&gt;            &lt;list&gt;     &lt;list&gt;       &lt;list&gt;       &lt;list&gt;\n#&gt; 1:       50000    50000             50000      49022        50000        50000\n#&gt; 2:     25000.5 95020.46                 3     500.86      9502.05         5.64\n#&gt; 3:     25000.5  94991.5                 3        501      9499.15         5.65\n#&gt; 4:           1    40013                 1          1       4001.3    0.6351814\n#&gt; 5:       50000   149999                 5       1000      14999.9     10.63381\n#&gt; 6:           0        0                 0        978            0            0\n#&gt;    tech_bonus\n#&gt;        &lt;list&gt;\n#&gt; 1:      10095\n#&gt; 2:     4765.5\n#&gt; 3:     4765.8\n#&gt; 4:    2000.65\n#&gt; 5:     7499.9\n#&gt; 6:      39905\n\n# Patr√≥n: Distribuci√≥n de variables categ√≥ricas\ncategorical_summary &lt;- employees_dt[, .(\n  count = .N,\n  avg_salary = round(mean(salary), 0),\n  median_performance = median(as.numeric(performance_score))\n), by = .(department, remote_work)][order(department, -avg_salary)]\n\nprint(categorical_summary)\n#&gt;      department remote_work count avg_salary median_performance\n#&gt;          &lt;char&gt;      &lt;lgcl&gt; &lt;int&gt;      &lt;num&gt;              &lt;num&gt;\n#&gt;  1: Engineering       FALSE  7016      95520                  3\n#&gt;  2: Engineering        TRUE  3079      94832                  3\n#&gt;  3:     Finance        TRUE  2952      95463                  3\n#&gt;  4:     Finance       FALSE  6913      94793                  3\n#&gt;  5:          HR        TRUE  2993      94883                  3\n#&gt;  6:          HR       FALSE  6990      94690                  3\n#&gt;  7:   Marketing       FALSE  7034      95350                  3\n#&gt;  8:   Marketing        TRUE  3016      93386                  3\n#&gt;  9:       Sales        TRUE  2971      95904                  3\n#&gt; 10:       Sales       FALSE  7036      95028                  3\n\n\n10.2.2 2. Limpieza y Validaci√≥n de Datos\n\n\n# Patr√≥n: Identificar y manejar outliers\nidentify_outliers &lt;- function(dt, column) {\n  Q1 &lt;- quantile(dt[[column]], 0.25, na.rm = TRUE)\n  Q3 &lt;- quantile(dt[[column]], 0.75, na.rm = TRUE)\n  IQR &lt;- Q3 - Q1\n  lower_bound &lt;- Q1 - 1.5 * IQR\n  upper_bound &lt;- Q3 + 1.5 * IQR\n  \n  dt[, paste0(column, \"_outlier\") := get(column) &lt; lower_bound | get(column) &gt; upper_bound]\n  \n  return(dt[get(paste0(column, \"_outlier\")) == TRUE])\n}\n\n# Identificar outliers en salarios\nsalary_outliers &lt;- identify_outliers(copy(employees_dt), \"salary\")\ncat(\"Outliers en salarios encontrados:\", nrow(salary_outliers), \"\\n\")\n#&gt; Outliers en salarios encontrados: 0\nprint(head(salary_outliers[, .(employee_id, department, salary)]))\n#&gt; data.table vac√≠a (0 filas y 3 columnas): employee_id,department,salary\n\n# Patr√≥n: Validaci√≥n de integridad de datos\ndata_quality_check &lt;- employees_dt[, .(\n  total_records = .N,\n  missing_salary = sum(is.na(salary)),\n  invalid_performance = sum(performance_score &lt; 1 | performance_score &gt; 5, na.rm = TRUE),\n  future_hire_dates = sum(hire_date &gt; Sys.Date(), na.rm = TRUE),\n  negative_salaries = sum(salary &lt; 0, na.rm = TRUE)\n)]\n\nprint(data_quality_check)\n#&gt;    total_records missing_salary invalid_performance future_hire_dates\n#&gt;            &lt;int&gt;          &lt;int&gt;               &lt;int&gt;             &lt;int&gt;\n#&gt; 1:         50000              0                   0                 0\n#&gt;    negative_salaries\n#&gt;                &lt;int&gt;\n#&gt; 1:                 0\n\n\n10.2.3 3. An√°lisis de Series Temporales\n\n\n# Patr√≥n: Agregaciones temporales con rolling windows\n# Crear datos temporales\ndaily_sales &lt;- transactions_dt[, .(\n  daily_revenue = sum(amount),\n  transaction_count = .N\n), by = transaction_date][order(transaction_date)]\n\n# Rolling average de 7 d√≠as\ndaily_sales[, `:=`(\n  revenue_7day_avg = frollmean(daily_revenue, 7, align = \"right\"),\n  revenue_7day_sum = frollsum(daily_revenue, 7, align = \"right\"),\n  growth_rate = (daily_revenue / data.table::shift(daily_revenue, 1) - 1) * 100\n)]\n\nprint(head(daily_sales[!is.na(revenue_7day_avg)], 10))\n#&gt;     transaction_date daily_revenue transaction_count revenue_7day_avg\n#&gt;               &lt;Date&gt;         &lt;num&gt;             &lt;int&gt;            &lt;num&gt;\n#&gt;  1:       2023-01-07       7600.28               161         6830.914\n#&gt;  2:       2023-01-08       6939.91               144         6860.439\n#&gt;  3:       2023-01-09       8018.96               140         6919.359\n#&gt;  4:       2023-01-10       6010.28               130         6963.241\n#&gt;  5:       2023-01-11       8311.52               152         7188.080\n#&gt;  6:       2023-01-12       7070.97               148         7351.023\n#&gt;  7:       2023-01-13       6851.72               125         7257.663\n#&gt;  8:       2023-01-14       7485.59               137         7241.279\n#&gt;  9:       2023-01-15       7499.29               140         7321.190\n#&gt; 10:       2023-01-16       6335.47               120         7080.691\n#&gt;     revenue_7day_sum growth_rate\n#&gt;                &lt;num&gt;       &lt;num&gt;\n#&gt;  1:         47816.40   1.2663153\n#&gt;  2:         48023.07  -8.6887588\n#&gt;  3:         48435.51  15.5484725\n#&gt;  4:         48742.69 -25.0491336\n#&gt;  5:         50316.56  38.2883992\n#&gt;  6:         51457.16 -14.9256694\n#&gt;  7:         50803.64  -3.1007061\n#&gt;  8:         50688.95   9.2512537\n#&gt;  9:         51248.33   0.1830183\n#&gt; 10:         49564.84 -15.5190691\n\n# Patr√≥n: An√°lisis de tendencias por per√≠odo\nmonthly_trends &lt;- transactions_dt[, .(\n  total_revenue = sum(amount),\n  avg_transaction = round(mean(amount), 2),\n  transaction_count = .N\n), by = .(year = year(transaction_date), month = month(transaction_date))][\n  order(year, month)\n][, `:=`(\n  revenue_growth = (total_revenue / data.table::shift(total_revenue, 1) - 1) * 100,\n  period = paste0(year, \"-\", sprintf(\"%02d\", month))\n)]\n\nprint(head(monthly_trends, 12))\n#&gt;      year month total_revenue avg_transaction transaction_count revenue_growth\n#&gt;     &lt;int&gt; &lt;int&gt;         &lt;num&gt;           &lt;num&gt;             &lt;int&gt;          &lt;num&gt;\n#&gt;  1:  2023     1      219815.3           51.12              4300             NA\n#&gt;  2:  2023     2      199300.1           51.70              3855      -9.332936\n#&gt;  3:  2023     3      218209.1           50.59              4313       9.487719\n#&gt;  4:  2023     4      200160.0           49.56              4039      -8.271484\n#&gt;  5:  2023     5      214969.5           50.27              4276       7.398852\n#&gt; ---                                                                           \n#&gt;  8:  2023     8      214542.1           51.12              4197       4.867881\n#&gt;  9:  2023     9      209143.9           51.16              4088      -2.516172\n#&gt; 10:  2023    10      214762.0           50.66              4239       2.686223\n#&gt; 11:  2023    11      194004.0           47.25              4106      -9.665572\n#&gt; 12:  2023    12      213822.5           49.96              4280      10.215517\n#&gt;      period\n#&gt;      &lt;char&gt;\n#&gt;  1: 2023-01\n#&gt;  2: 2023-02\n#&gt;  3: 2023-03\n#&gt;  4: 2023-04\n#&gt;  5: 2023-05\n#&gt; ---        \n#&gt;  8: 2023-08\n#&gt;  9: 2023-09\n#&gt; 10: 2023-10\n#&gt; 11: 2023-11\n#&gt; 12: 2023-12\n\n\n10.2.4 4. An√°lisis de Cohortes\n\n\n# Patr√≥n: An√°lisis de cohorte de empleados por a√±o de contrataci√≥n\ncohort_analysis &lt;- employees_dt[, hire_year := year(hire_date)][, .(\n  cohort_size = .N,\n  avg_current_salary = round(mean(salary), 0),\n  avg_performance = round(mean(performance_score), 2),\n  retention_rate = round(.N / employees_dt[year(hire_date) == hire_year, .N] * 100, 1)\n), by = hire_year][order(hire_year)]\n\nprint(cohort_analysis)\n#&gt;     hire_year cohort_size avg_current_salary avg_performance retention_rate\n#&gt;         &lt;int&gt;       &lt;int&gt;              &lt;num&gt;           &lt;num&gt;          &lt;num&gt;\n#&gt;  1:      2015        5054              94757            2.98           10.1\n#&gt;  2:      2016        5018              95581            2.99           10.0\n#&gt;  3:      2017        5061              94834            2.99           10.1\n#&gt;  4:      2018        4906              94943            3.00            9.8\n#&gt;  5:      2019        5010              95127            3.00           10.0\n#&gt;  6:      2020        5086              94636            3.00           10.2\n#&gt;  7:      2021        4927              95138            3.02            9.9\n#&gt;  8:      2022        4929              94619            3.02            9.9\n#&gt;  9:      2023        4975              95381            3.00           10.0\n#&gt; 10:      2024        5034              95193            3.02           10.1\n\n# Patr√≥n: Segmentaci√≥n de clientes por comportamiento\ncustomer_segmentation &lt;- transactions_dt[, .(\n  total_spent = sum(amount),\n  transaction_frequency = .N,\n  avg_transaction = round(mean(amount), 2),\n  days_active = as.numeric(max(transaction_date) - min(transaction_date)) + 1,\n  favorite_category = names(sort(table(product_category), decreasing = TRUE))[1]\n), by = customer_id][, `:=`(\n  spending_tier = cut(total_spent, \n                     breaks = quantile(total_spent, c(0, 0.33, 0.66, 1)), \n                     labels = c(\"Low\", \"Medium\", \"High\"),\n                     include.lowest = TRUE),\n  frequency_tier = cut(transaction_frequency,\n                      breaks = quantile(transaction_frequency, c(0, 0.5, 1)),\n                      labels = c(\"Occasional\", \"Frequent\"),\n                      include.lowest = TRUE)\n)]\n\n# Resumen de segmentaci√≥n\nsegment_summary &lt;- customer_segmentation[, .(\n  customers = .N,\n  avg_total_spent = round(mean(total_spent), 2),\n  avg_frequency = round(mean(transaction_frequency), 1)\n), by = .(spending_tier, frequency_tier)]\n\nprint(segment_summary)\n#&gt;    spending_tier frequency_tier customers avg_total_spent avg_frequency\n#&gt;           &lt;fctr&gt;         &lt;fctr&gt;     &lt;int&gt;           &lt;num&gt;         &lt;num&gt;\n#&gt; 1:           Low     Occasional      2984          264.30           7.0\n#&gt; 2:        Medium     Occasional      1958          460.58           8.6\n#&gt; 3:           Low       Frequent       316          321.93          11.6\n#&gt; 4:          High       Frequent      2525          770.54          13.5\n#&gt; 5:          High     Occasional       875          679.31           9.1\n#&gt; 6:        Medium       Frequent      1341          485.92          12.3",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-debugging",
    "href": "cap04-buenas-practicas.html#sec-debugging",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "\n10.3 Debugging y Troubleshooting",
    "text": "10.3 Debugging y Troubleshooting\n\n10.3.1 1. Herramientas de Diagn√≥stico\n\n\n# Funci√≥n para inspeccionar comprehensivamente un data.table\ninspect_dt &lt;- function(dt, name = \"data.table\") {\n  cat(\"=== Inspecci√≥n de\", name, \"===\\n\")\n  cat(\"Dimensiones:\", nrow(dt), \"x\", ncol(dt), \"\\n\")\n  cat(\"Memoria:\", format(object.size(dt), units = \"MB\"), \"\\n\")\n  cat(\"Key:\", ifelse(is.null(key(dt)), \"Ninguna\", paste(key(dt), collapse = \", \")), \"\\n\")\n  cat(\"√çndices:\", length(indices(dt)), \"\\n\")\n  if(length(indices(dt)) &gt; 0) {\n    cat(\"√çndices disponibles:\\n\")\n    for(idx in indices(dt)) {\n      cat(\"  -\", paste(idx, collapse = \", \"), \"\\n\")\n    }\n  }\n  cat(\"Clases de columnas:\\n\")\n  col_classes &lt;- sapply(dt, function(x) paste(class(x), collapse = \", \"))\n  for(i in seq_along(col_classes)) {\n    cat(\"  \", names(col_classes)[i], \":\", col_classes[i], \"\\n\")\n  }\n  cat(\"Valores faltantes por columna:\\n\")\n  missing_counts &lt;- dt[, lapply(.SD, function(x) sum(is.na(x)))]\n  for(i in seq_along(missing_counts)) {\n    cat(\"  \", names(missing_counts)[i], \":\", missing_counts[[i]], \"\\n\")\n  }\n  cat(\"\\n\")\n}\n\n# Inspeccionar nuestros datasets principales\ninspect_dt(employees_dt[1:1000], \"employees_dt (muestra)\")\n#&gt; === Inspecci√≥n de employees_dt (muestra) ===\n#&gt; Dimensiones: 1000 x 13 \n#&gt; Memoria: 0.1 Mb \n#&gt; Key: Ninguna \n#&gt; √çndices: 0 \n#&gt; Clases de columnas:\n#&gt;    employee_id : integer \n#&gt;    department : character \n#&gt;    salary : numeric \n#&gt;    hire_date : Date \n#&gt;    performance_score : integer \n#&gt;    remote_work : logical \n#&gt;    manager_id : integer \n#&gt;    annual_bonus : numeric \n#&gt;    salary_tier : character \n#&gt;    tenure_years : numeric \n#&gt;    tech_bonus : numeric \n#&gt;    mid_career : logical \n#&gt;    hire_year : integer \n#&gt; Valores faltantes por columna:\n#&gt;    employee_id : 0 \n#&gt;    department : 0 \n#&gt;    salary : 0 \n#&gt;    hire_date : 0 \n#&gt;    performance_score : 0 \n#&gt;    remote_work : 0 \n#&gt;    manager_id : 25 \n#&gt;    annual_bonus : 0 \n#&gt;    salary_tier : 0 \n#&gt;    tenure_years : 0 \n#&gt;    tech_bonus : 805 \n#&gt;    mid_career : 0 \n#&gt;    hire_year : 0\n\n\n10.3.2 2. Debugging de Operaciones Complejas\n\n\n# Funci√≥n para debuggear operaciones paso a paso\ndebug_complex_operation &lt;- function(dt, verbose = TRUE) {\n  if(verbose) cat(\"Paso 1: Filtrado inicial\\n\")\n  step1 &lt;- dt[salary &gt; 70000 & !is.na(performance_score)]\n  if(verbose) cat(\"  Filas despu√©s del filtro:\", nrow(step1), \"\\n\")\n  \n  if(verbose) cat(\"Paso 2: C√°lculos por grupo\\n\")\n  step2 &lt;- step1[, .(\n    avg_salary = mean(salary),\n    avg_performance = mean(performance_score),\n    count = .N,\n    salary_std = sd(salary)\n  ), by = department]\n  if(verbose) cat(\"  Grupos creados:\", nrow(step2), \"\\n\")\n  \n  if(verbose) cat(\"Paso 3: Filtrado post-agregaci√≥n\\n\")\n  step3 &lt;- step2[count &gt;= 10]  # Solo departamentos con suficientes empleados\n  if(verbose) cat(\"  Grupos finales:\", nrow(step3), \"\\n\")\n  \n  if(verbose) cat(\"Paso 4: Ordenamiento final\\n\")\n  result &lt;- step3[order(-avg_salary)]\n  \n  return(result)\n}\n\n# Ejecutar con debugging\nresult_debug &lt;- debug_complex_operation(employees_dt, verbose = TRUE)\n#&gt; Paso 1: Filtrado inicial\n#&gt;   Filas despu√©s del filtro: 36411 \n#&gt; Paso 2: C√°lculos por grupo\n#&gt;   Grupos creados: 5 \n#&gt; Paso 3: Filtrado post-agregaci√≥n\n#&gt;   Grupos finales: 5 \n#&gt; Paso 4: Ordenamiento final\nprint(result_debug)\n#&gt;     department avg_salary avg_performance count salary_std\n#&gt;         &lt;char&gt;      &lt;num&gt;           &lt;num&gt; &lt;int&gt;      &lt;num&gt;\n#&gt; 1: Engineering   110479.1        2.988536  7327   23043.35\n#&gt; 2:       Sales   110280.8        3.002877  7300   23149.18\n#&gt; 3:     Finance   109922.3        3.013630  7190   22984.42\n#&gt; 4:   Marketing   109620.3        2.989902  7328   23162.78\n#&gt; 5:          HR   109554.0        3.007982  7266   23207.83\n\n\n10.3.3 3. Validaci√≥n y Testing\n\n\n# Funci√≥n para validar resultados de operaciones\nvalidate_operation &lt;- function(original_dt, result_dt, operation_name) {\n  cat(\"=== Validaci√≥n de\", operation_name, \"===\\n\")\n  \n  # Verificar que no se perdieron datos inesperadamente\n  if(\"by\" %in% names(attributes(result_dt))) {\n    cat(\"Operaci√≥n de agregaci√≥n detectada\\n\")\n  } else {\n    rows_ratio &lt;- nrow(result_dt) / nrow(original_dt)\n    cat(\"Ratio de filas resultado/original:\", round(rows_ratio, 3), \"\\n\")\n    if(rows_ratio &gt; 1) {\n      cat(\"‚ö†Ô∏è ADVERTENCIA: El resultado tiene m√°s filas que el original\\n\")\n    }\n  }\n  \n  # Verificar valores faltantes\n  original_na &lt;- original_dt[, lapply(.SD, function(x) sum(is.na(x)))]\n  result_na &lt;- result_dt[, lapply(.SD, function(x) sum(is.na(x)))]\n  \n  cat(\"NAs en original:\", sum(unlist(original_na)), \"\\n\")\n  cat(\"NAs en resultado:\", sum(unlist(result_na)), \"\\n\")\n  \n  # Verificar tipos de datos\n  original_types &lt;- sapply(original_dt, class)\n  result_types &lt;- sapply(result_dt, class)\n  \n  common_cols &lt;- intersect(names(original_types), names(result_types))\n  type_changes &lt;- sapply(common_cols, function(col) {\n    !identical(original_types[[col]], result_types[[col]])\n  })\n  \n  if(any(type_changes)) {\n    cat(\"‚ö†Ô∏è ADVERTENCIA: Cambios de tipo detectados en columnas:\", \n        paste(names(type_changes)[type_changes], collapse = \", \"), \"\\n\")\n  } else {\n    cat(\"‚úÖ Tipos de datos preservados correctamente\\n\")\n  }\n  \n  cat(\"\\n\")\n}\n\n# Ejemplo de validaci√≥n\nsample_employees &lt;- employees_dt[1:1000]\nfiltered_result &lt;- sample_employees[salary &gt; 80000]\nvalidate_operation(sample_employees, filtered_result, \"filtrado por salario\")\n#&gt; === Validaci√≥n de filtrado por salario ===\n#&gt; Ratio de filas resultado/original: 0.629 \n#&gt; NAs en original: 830 \n#&gt; NAs en resultado: 515 \n#&gt; ‚úÖ Tipos de datos preservados correctamente\n\naggregated_result &lt;- sample_employees[, .(avg_salary = mean(salary)), by = department]\nvalidate_operation(sample_employees, aggregated_result, \"agregaci√≥n por departamento\")\n#&gt; === Validaci√≥n de agregaci√≥n por departamento ===\n#&gt; Ratio de filas resultado/original: 0.005 \n#&gt; NAs en original: 830 \n#&gt; NAs en resultado: 0 \n#&gt; ‚úÖ Tipos de datos preservados correctamente",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-estilo",
    "href": "cap04-buenas-practicas.html#sec-estilo",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "\n10.4 Estilo de C√≥digo y Convenciones",
    "text": "10.4 Estilo de C√≥digo y Convenciones\n\n10.4.1 1. Naming Conventions\n\n\n# ‚úÖ CORRECTO: Nombres descriptivos\ncustomer_lifetime_value &lt;- transactions_dt[, .(\n  total_revenue = sum(amount),\n  avg_order_value = mean(amount),\n  transaction_count = .N\n), by = customer_id]\n\n# ‚úÖ CORRECTO: Consistencia en naming\ndt_sales_daily &lt;- transactions_dt[, .(daily_revenue = sum(amount)), by = transaction_date]\ndt_sales_monthly &lt;- transactions_dt[, .(monthly_revenue = sum(amount)), \n                                   by = .(year = year(transaction_date), \n                                          month = month(transaction_date))]\n\n# ‚úÖ CORRECTO: Prefijos para variables temporales\ntmp_high_value_customers &lt;- customer_lifetime_value[total_revenue &gt; 1000]\ntemp_analysis_result &lt;- tmp_high_value_customers[, .N, by = .(revenue_tier = cut(total_revenue, 3))]\n\n\n10.4.2 2. Formateo y Organizaci√≥n\n\n\n# ‚úÖ CORRECTO: Formateo claro para operaciones complejas\ncomplex_analysis &lt;- employees_dt[\n  # Filtros principales\n  salary &gt; 50000 & \n  !is.na(performance_score) & \n  tenure_years &gt;= 1,\n  \n  # C√°lculos\n  .(\n    employee_count = .N,\n    avg_salary = round(mean(salary), 0),\n    median_salary = round(median(salary), 0),\n    salary_range = max(salary) - min(salary),\n    top_performer_ratio = sum(performance_score &gt;= 4) / .N,\n    remote_work_ratio = sum(remote_work, na.rm = TRUE) / .N\n  ),\n  \n  # Agrupaci√≥n\n  by = .(\n    department,\n    salary_tier = cut(salary, \n                     breaks = c(0, 60000, 90000, Inf), \n                     labels = c(\"Entry\", \"Mid\", \"Senior\"))\n  )\n][\n  # Post-procesamiento\n  employee_count &gt;= 5  # Solo grupos con suficientes empleados\n][\n  # Ordenamiento\n  order(department, -avg_salary)\n]\n\nprint(head(complex_analysis))\n#&gt;     department salary_tier employee_count avg_salary median_salary salary_range\n#&gt;         &lt;char&gt;      &lt;fctr&gt;          &lt;int&gt;      &lt;num&gt;         &lt;num&gt;        &lt;num&gt;\n#&gt; 1: Engineering      Senior           5365     120083        120133        59994\n#&gt; 2: Engineering         Mid           2598      74729         74684        29969\n#&gt; 3: Engineering       Entry            909      54998         55010         9979\n#&gt; 4:     Finance      Senior           5219     119710        119357        59994\n#&gt; 5:     Finance         Mid           2529      74926         74889        29994\n#&gt; 6:     Finance       Entry            891      54939         54765         9961\n#&gt;    top_performer_ratio remote_work_ratio\n#&gt;                  &lt;num&gt;             &lt;num&gt;\n#&gt; 1:           0.1906803         0.2999068\n#&gt; 2:           0.1989992         0.2998460\n#&gt; 3:           0.2057206         0.3190319\n#&gt; 4:           0.2040621         0.3035064\n#&gt; 5:           0.2119415         0.3013049\n#&gt; 6:           0.1818182         0.2962963\n\n\n10.4.3 3. Documentaci√≥n y Comentarios\n\n\n# Funci√≥n bien documentada para an√°lisis de retenci√≥n\nanalyze_employee_retention &lt;- function(employees_dt, analysis_date = Sys.Date()) {\n  #' Analiza patrones de retenci√≥n de empleados\n  #' \n  #' @param employees_dt data.table con datos de empleados\n  #' @param analysis_date Fecha de referencia para el an√°lisis\n  #' @return data.table con m√©tricas de retenci√≥n por departamento\n  \n  # Calcular m√©tricas base\n  employees_dt[, `:=`(\n    tenure_years = as.numeric(analysis_date - hire_date) / 365.25,\n    is_long_tenure = tenure_years &gt;= 3\n  )]\n  \n  # An√°lisis de retenci√≥n por departamento\n  retention_analysis &lt;- employees_dt[\n    !is.na(tenure_years),\n    .(\n      total_employees = .N,\n      avg_tenure = round(mean(tenure_years), 2),\n      retention_3_year = sum(is_long_tenure) / .N,\n      avg_salary_retained = mean(salary[is_long_tenure]),\n      avg_salary_new = mean(salary[!is_long_tenure])\n    ),\n    by = department\n  ][\n    order(-retention_3_year)\n  ]\n  \n  return(retention_analysis)\n}\n\n# Uso de la funci√≥n\nretention_results &lt;- analyze_employee_retention(employees_dt)\nprint(retention_results)\n#&gt;     department total_employees avg_tenure retention_3_year avg_salary_retained\n#&gt;         &lt;char&gt;           &lt;int&gt;      &lt;num&gt;            &lt;num&gt;               &lt;num&gt;\n#&gt; 1:     Finance            9865       5.66        0.7690826            94881.15\n#&gt; 2:          HR            9983       5.64        0.7667034            94739.93\n#&gt; 3:   Marketing           10050       5.69        0.7658706            94678.32\n#&gt; 4: Engineering           10095       5.61        0.7626548            95438.25\n#&gt; 5:       Sales           10007       5.62        0.7553712            95281.11\n#&gt;    avg_salary_new\n#&gt;             &lt;num&gt;\n#&gt; 1:       95367.65\n#&gt; 2:       94774.08\n#&gt; 3:       95029.48\n#&gt; 4:       94898.17\n#&gt; 5:       95308.60",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-testing",
    "href": "cap04-buenas-practicas.html#sec-testing",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "\n10.5 Testing y Validaci√≥n",
    "text": "10.5 Testing y Validaci√≥n\n\n10.5.1 1. Unit Tests para Funciones data.table\n\n\n# Funci√≥n simple para testing\ncalculate_employee_bonus &lt;- function(salary, performance_score, department) {\n  base_bonus &lt;- salary * 0.1\n  performance_multiplier &lt;- performance_score / 3\n  department_bonus &lt;- fifelse(department == \"Sales\", salary * 0.05, 0)\n  \n  return(base_bonus * performance_multiplier + department_bonus)\n}\n\n# Tests b√°sicos\ntest_bonus_calculation &lt;- function() {\n  # Test 1: C√°lculo b√°sico\n  test_salary &lt;- 100000\n  test_performance &lt;- 3\n  test_dept &lt;- \"Engineering\"\n  \n  expected_bonus &lt;- (100000 * 0.1) * (3/3) + 0  # 10000\n  actual_bonus &lt;- calculate_employee_bonus(test_salary, test_performance, test_dept)\n  \n  cat(\"Test 1 - C√°lculo b√°sico:\", \n      ifelse(abs(actual_bonus - expected_bonus) &lt; 0.01, \"‚úÖ PASS\", \"‚ùå FAIL\"), \"\\n\")\n  \n  # Test 2: Bonus de ventas\n  test_dept_sales &lt;- \"Sales\"\n  expected_bonus_sales &lt;- (100000 * 0.1) * (3/3) + (100000 * 0.05)  # 15000\n  actual_bonus_sales &lt;- calculate_employee_bonus(test_salary, test_performance, test_dept_sales)\n  \n  cat(\"Test 2 - Bonus de ventas:\", \n      ifelse(abs(actual_bonus_sales - expected_bonus_sales) &lt; 0.01, \"‚úÖ PASS\", \"‚ùå FAIL\"), \"\\n\")\n  \n  # Test 3: Performance alto\n  test_performance_high &lt;- 5\n  expected_bonus_high &lt;- (100000 * 0.1) * (5/3) + 0  # 16666.67\n  actual_bonus_high &lt;- calculate_employee_bonus(test_salary, test_performance_high, test_dept)\n  \n  cat(\"Test 3 - Performance alto:\", \n      ifelse(abs(actual_bonus_high - expected_bonus_high) &lt; 1, \"‚úÖ PASS\", \"‚ùå FAIL\"), \"\\n\")\n}\n\n# Ejecutar tests\ntest_bonus_calculation()\n#&gt; Test 1 - C√°lculo b√°sico: ‚úÖ PASS \n#&gt; Test 2 - Bonus de ventas: ‚úÖ PASS \n#&gt; Test 3 - Performance alto: ‚úÖ PASS\n\n# Aplicar a datos reales\nemployees_dt[, calculated_bonus := calculate_employee_bonus(salary, performance_score, department)]\nprint(head(employees_dt[, .(employee_id, department, salary, performance_score, calculated_bonus)]))\n#&gt;    employee_id  department salary performance_score calculated_bonus\n#&gt;          &lt;int&gt;      &lt;char&gt;  &lt;num&gt;             &lt;int&gt;            &lt;num&gt;\n#&gt; 1:           1 Engineering 128722                 3         12872.20\n#&gt; 2:           2     Finance 128148                 3         12814.80\n#&gt; 3:           3     Finance  50533                 3          5053.30\n#&gt; 4:           4          HR  41787                 3          4178.70\n#&gt; 5:           5       Sales  79771                 3         11965.65\n#&gt; 6:           6     Finance 138060                 3         13806.00\n\n\n10.5.2 2. Validation de Integridad de Datos\n\n\n# Suite completa de validaci√≥n\nvalidate_data_integrity &lt;- function(dt, table_name = \"data.table\") {\n  cat(\"=== Validaci√≥n de Integridad:\", table_name, \"===\\n\")\n  \n  validation_results &lt;- list()\n  \n  # 1. Verificar duplicados en ID\n  if(\"employee_id\" %in% names(dt)) {\n    duplicate_ids &lt;- dt[, .N, by = employee_id][N &gt; 1]\n    validation_results$duplicate_ids &lt;- nrow(duplicate_ids)\n    cat(\"IDs duplicados:\", nrow(duplicate_ids), \n        ifelse(nrow(duplicate_ids) == 0, \"‚úÖ\", \"‚ùå\"), \"\\n\")\n  }\n  \n  # 2. Verificar rangos v√°lidos\n  if(\"salary\" %in% names(dt)) {\n    invalid_salaries &lt;- dt[salary &lt; 0 | salary &gt; 1000000, .N]\n    validation_results$invalid_salaries &lt;- invalid_salaries\n    cat(\"Salarios inv√°lidos:\", invalid_salaries, \n        ifelse(invalid_salaries == 0, \"‚úÖ\", \"‚ùå\"), \"\\n\")\n  }\n  \n  if(\"performance_score\" %in% names(dt)) {\n    invalid_performance &lt;- dt[performance_score &lt; 1 | performance_score &gt; 5, .N]\n    validation_results$invalid_performance &lt;- invalid_performance\n    cat(\"Scores de performance inv√°lidos:\", invalid_performance,\n        ifelse(invalid_performance == 0, \"‚úÖ\", \"‚ùå\"), \"\\n\")\n  }\n  \n  # 3. Verificar fechas\n  if(\"hire_date\" %in% names(dt)) {\n    future_dates &lt;- dt[hire_date &gt; Sys.Date(), .N]\n    very_old_dates &lt;- dt[hire_date &lt; as.Date(\"1950-01-01\"), .N]\n    validation_results$future_dates &lt;- future_dates\n    validation_results$very_old_dates &lt;- very_old_dates\n    cat(\"Fechas futuras:\", future_dates, ifelse(future_dates == 0, \"‚úÖ\", \"‚ùå\"), \"\\n\")\n    cat(\"Fechas muy antiguas:\", very_old_dates, ifelse(very_old_dates == 0, \"‚úÖ\", \"‚ùå\"), \"\\n\")\n  }\n  \n  # 4. Verificar consistencia referencial\n  if(all(c(\"manager_id\", \"employee_id\") %in% names(dt))) {\n    orphan_managers &lt;- dt[!is.na(manager_id) & !manager_id %in% employee_id, .N]\n    validation_results$orphan_managers &lt;- orphan_managers\n    cat(\"Managers inexistentes:\", orphan_managers, \n        ifelse(orphan_managers == 0, \"‚úÖ\", \"‚ùå\"), \"\\n\")\n  }\n  \n  # Resumen\n  total_issues &lt;- sum(unlist(validation_results))\n  cat(\"\\nResumen: Total de issues encontrados:\", total_issues, \n      ifelse(total_issues == 0, \"‚úÖ Datos v√°lidos\", \"‚ùå Requiere atenci√≥n\"), \"\\n\\n\")\n  \n  return(validation_results)\n}\n\n# Ejecutar validaci√≥n\nintegrity_results &lt;- validate_data_integrity(employees_dt, \"employees_dt\")\n#&gt; === Validaci√≥n de Integridad: employees_dt ===\n#&gt; IDs duplicados: 0 ‚úÖ \n#&gt; Salarios inv√°lidos: 0 ‚úÖ \n#&gt; Scores de performance inv√°lidos: 0 ‚úÖ \n#&gt; Fechas futuras: 0 ‚úÖ \n#&gt; Fechas muy antiguas: 0 ‚úÖ \n#&gt; Managers inexistentes: 0 ‚úÖ \n#&gt; \n#&gt; Resumen: Total de issues encontrados: 0 ‚úÖ Datos v√°lidos",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#sec-ejercicio-refactoring",
    "href": "cap04-buenas-practicas.html#sec-ejercicio-refactoring",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "\n10.6 Ejercicio Final: Refactoring de C√≥digo",
    "text": "10.6 Ejercicio Final: Refactoring de C√≥digo\n\n\n\n\n\n\nüõ†Ô∏è Ejercicio 9: Refactoring Completo\n\n\n\nToma el siguiente c√≥digo mal escrito y refactor√≠zalo aplicando todas las buenas pr√°cticas:\n# C√ìDIGO MALO para refactorizar\nbad_analysis &lt;- function(data) {\n  result &lt;- data.frame()\n  \n  for(dept in unique(data$department)) {\n    dept_data &lt;- data[data$department == dept, ]\n    \n    for(year in 2020:2024) {\n      year_data &lt;- dept_data[as.numeric(format(dept_data$hire_date, \"%Y\")) == year, ]\n      \n      if(nrow(year_data) &gt; 0) {\n        avg_sal &lt;- mean(year_data$salary)\n        count &lt;- nrow(year_data)\n        high_performers &lt;- nrow(year_data[year_data$performance_score &gt;= 4, ])\n        \n        new_row &lt;- data.frame(\n          department = dept,\n          hire_year = year,\n          avg_salary = avg_sal,\n          employee_count = count,\n          high_performer_count = high_performers,\n          high_performer_rate = high_performers / count\n        )\n        \n        result &lt;- rbind(result, new_row)\n      }\n    }\n  }\n  \n  return(result)\n}\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 9\n\n\n\n\n\n\n# C√ìDIGO REFACTORIZADO aplicando buenas pr√°cticas\ngood_analysis &lt;- function(employees_dt) {\n  #' Analiza empleados por departamento y a√±o de contrataci√≥n\n  #' @param employees_dt data.table con datos de empleados\n  #' @return data.table con an√°lisis agregado\n  \n  # Validaci√≥n de entrada\n  required_cols &lt;- c(\"department\", \"hire_date\", \"salary\", \"performance_score\")\n  if(!all(required_cols %in% names(employees_dt))) {\n    stop(\"Faltan columnas requeridas: \", \n         paste(setdiff(required_cols, names(employees_dt)), collapse = \", \"))\n  }\n  \n  # Una sola operaci√≥n vectorizada que reemplaza todos los bucles\n  result &lt;- employees_dt[\n    # Filtro para a√±os de inter√©s\n    year(hire_date) %between% c(2020, 2024),\n    \n    # C√°lculos agregados\n    .(\n      avg_salary = round(mean(salary, na.rm = TRUE), 0),\n      employee_count = .N,\n      high_performer_count = sum(performance_score &gt;= 4, na.rm = TRUE),\n      median_salary = median(salary, na.rm = TRUE),\n      salary_std = round(sd(salary, na.rm = TRUE), 0)\n    ),\n    \n    # Agrupaci√≥n\n    by = .(department, hire_year = year(hire_date))\n  ][\n    # C√°lculos derivados\n    , high_performer_rate := round(high_performer_count / employee_count, 3)\n  ][\n    # Filtrar grupos peque√±os\n    employee_count &gt;= 3\n  ][\n    # Ordenamiento l√≥gico\n    order(department, hire_year)\n  ]\n  \n  return(result)\n}\n\n# Comparar rendimiento\nsample_employees &lt;- employees_dt[sample(.N, 5000)]\n\n# Tiempo del m√©todo refactorizado\ntiempo_bueno &lt;- system.time({\n  resultado_bueno &lt;- good_analysis(sample_employees)\n})\n\ncat(\"M√©todo refactorizado:\", round(tiempo_bueno[3], 4), \"segundos\\n\")\n#&gt; M√©todo refactorizado: 0 segundos\ncat(\"Filas resultado:\", nrow(resultado_bueno), \"\\n\")\n#&gt; Filas resultado: 25\n\nprint(head(resultado_bueno))\n#&gt;     department hire_year avg_salary employee_count high_performer_count\n#&gt;         &lt;char&gt;     &lt;int&gt;      &lt;num&gt;          &lt;int&gt;                &lt;int&gt;\n#&gt; 1: Engineering      2020      95376            102                   21\n#&gt; 2: Engineering      2021      92345             87                   24\n#&gt; 3: Engineering      2022      98022            104                   23\n#&gt; 4: Engineering      2023      87590            110                   17\n#&gt; 5: Engineering      2024      91134             95                   13\n#&gt; 6:     Finance      2020      95926            110                   16\n#&gt;    median_salary salary_std high_performer_rate\n#&gt;            &lt;num&gt;      &lt;num&gt;               &lt;num&gt;\n#&gt; 1:       94355.5      30045               0.206\n#&gt; 2:       86740.0      35390               0.276\n#&gt; 3:      102976.5      31567               0.221\n#&gt; 4:       86547.0      33963               0.155\n#&gt; 5:       90209.0      32451               0.137\n#&gt; 6:       97021.0      29789               0.145\n\n# Verificaci√≥n adicional: completeness\ncat(\"\\nVerificaci√≥n de completeness:\\n\")\n#&gt; \n#&gt; Verificaci√≥n de completeness:\ncat(\"Departamentos √∫nicos en original:\", uniqueN(sample_employees$department), \"\\n\")\n#&gt; Departamentos √∫nicos en original: 5\ncat(\"Departamentos √∫nicos en resultado:\", uniqueN(resultado_bueno$department), \"\\n\")\n#&gt; Departamentos √∫nicos en resultado: 5\ncat(\"A√±os √∫nicos en resultado:\", paste(sort(unique(resultado_bueno$hire_year)), collapse = \", \"), \"\\n\")\n#&gt; A√±os √∫nicos en resultado: 2020, 2021, 2022, 2023, 2024\n\nMejoras aplicadas en el refactoring:\n\n\nEliminaci√≥n total de bucles: Una sola operaci√≥n by vectorizada\n\nSin rbind repetitivo: El resultado se construye eficientemente\n\nValidaci√≥n de entrada: Verificaci√≥n de columnas requeridas\n\nOperaciones vectorizadas: mean(), sum(), .N son nativamente r√°pidas\n\nSintaxis data.table pura: Sin conversiones a/desde data.frame\n\nFiltros inteligentes: Eliminaci√≥n de grupos peque√±os\n\nC√°lculos derivados: Usando := para eficiencia\n\nDocumentaci√≥n: Funci√≥n bien documentada\n\nManejo de NAs: Par√°metro na.rm = TRUE donde corresponde\n\nOrdenamiento l√≥gico: Resultado ordenado para mejor interpretaci√≥n",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap04-buenas-practicas.html#pr√≥ximo-cap√≠tulo-integraci√≥n-con-el-ecosistema",
    "href": "cap04-buenas-practicas.html#pr√≥ximo-cap√≠tulo-integraci√≥n-con-el-ecosistema",
    "title": "10¬† Buenas Pr√°cticas y C√≥digo Idiom√°tico",
    "section": "\n10.7 Pr√≥ximo Cap√≠tulo: Integraci√≥n con el Ecosistema",
    "text": "10.7 Pr√≥ximo Cap√≠tulo: Integraci√≥n con el Ecosistema\nEn el siguiente y √∫ltimo cap√≠tulo exploraremos: - Integraci√≥n con ggplot2 para visualizaci√≥n de datos - Workflows con shiny para aplicaciones interactivas\n- Interoperabilidad con tidymodels para machine learning - Conexi√≥n con bases de datos y sistemas Big Data - dtplyr: El puente entre data.table y tidyverse\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nEl operador := es fundamental para c√≥digo eficiente en data.table\n\nLos bucles expl√≠citos destruyen todas las optimizaciones - usa vectorizaci√≥n\n\nsetkey() es crucial para datasets grandes y operaciones repetitivas\n\nLa gesti√≥n de memoria puede marcar la diferencia entre c√≥digo viable e inviable\n\nValidaci√≥n y testing previenen errores costosos en an√°lisis de datos\n\nEl estilo consistente hace el c√≥digo mantenible y colaborativo\n\nUna operaci√≥n data.table bien dise√±ada puede reemplazar cientos de l√≠neas de c√≥digo tradicional\n\n\n\nHas dominado las buenas pr√°cticas de data.table. En el pr√≥ximo cap√≠tulo veremos c√≥mo integrar todo este poder con el ecosistema R para crear soluciones completas de an√°lisis de datos.",
    "crumbs": [
      "**M√≥dulo 4**: Optimizaci√≥n y Buenas Pr√°cticas",
      "<span class='chapter-number'>10</span>¬† <span class='chapter-title'>Buenas Pr√°cticas y C√≥digo Idiom√°tico</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html",
    "href": "cap05-visualizacion.html",
    "title": "11¬† Visualizaci√≥n de Datos con data.table",
    "section": "",
    "text": "11.1 Integraci√≥n con ggplot2: Gr√°ficos Est√°ticos Profesionales",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Visualizaci√≥n de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#integraci√≥n-con-ggplot2-gr√°ficos-est√°ticos-profesionales",
    "href": "cap05-visualizacion.html#integraci√≥n-con-ggplot2-gr√°ficos-est√°ticos-profesionales",
    "title": "11¬† Visualizaci√≥n de Datos con data.table",
    "section": "",
    "text": "11.1.1 1. El Workflow Fundamental: data.table ‚Üí ggplot2\n\nLa filosof√≠a es clara: hacer toda la manipulaci√≥n pesada de datos con data.table y pasar el resultado final limpio a ggplot2.\n\n# PASO 1: Preparaci√≥n con data.table (r√°pido y eficiente)\nventas_mensuales &lt;- ventas_detalladas[,\n  .(\n    revenue_total = sum(revenue),\n    unidades_vendidas = sum(cantidad),\n    ticket_promedio = round(mean(revenue), 2),\n    num_transacciones = .N,\n    satisfaccion_media = round(mean(satisfaccion_cliente), 2)\n  ),\n  by = .(a√±o, mes)\n][, `:=`(\n  fecha_mes = as.Date(paste(a√±o, mes, \"01\", sep = \"-\")),\n  crecimiento = (revenue_total / data.table::shift(revenue_total, 1) - 1) * 100\n)]\n\n# PASO 2: Visualizaci√≥n con ggplot2 (hermoso y profesional)\np1 &lt;- ggplot(ventas_mensuales, aes(x = fecha_mes, y = revenue_total)) +\n  geom_line(color = \"#2E8B57\", size = 1.3, alpha = 0.8) +\n  geom_point(color = \"#2E8B57\", size = 3, alpha = 0.9) +\n  geom_smooth(method = \"loess\", se = TRUE, color = \"#FF6B35\", alpha = 0.3) +\n  scale_y_continuous(\n    labels = dollar_format(prefix = \"$\", suffix = \"K\", scale = 1e-3),\n    expand = expansion(mult = c(0.02, 0.1))\n  ) +\n  scale_x_date(\n    date_labels = \"%b %Y\", \n    date_breaks = \"3 months\",\n    expand = expansion(mult = c(0.02, 0.02))\n  ) +\n  labs(\n    title = \"Evoluci√≥n del Revenue Mensual\",\n    subtitle = \"Tendencia de ventas con l√≠nea de regresi√≥n suavizada\",\n    x = NULL,\n    y = \"Revenue Total\",\n    caption = \"Datos procesados con data.table | Visualizaci√≥n: ggplot2\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 16, face = \"bold\", hjust = 0),\n    plot.subtitle = element_text(color = \"gray40\", size = 12, hjust = 0),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    panel.grid.minor = element_blank(),\n    plot.caption = element_text(color = \"gray50\", size = 9)\n  )\n\nprint(p1)\n\n\n\n\n\n\n\n\n11.1.2 2. Gr√°ficos Multidimensionales Avanzados\n\n\n# An√°lisis complejo con m√∫ltiples dimensiones\nanalisis_completo &lt;- ventas_detalladas[,\n  .(\n    revenue_total = sum(revenue),\n    margen_promedio = round(mean(1 - descuento), 3),\n    satisfaccion_media = round(mean(satisfaccion_cliente), 2),\n    variacion_precios = sd(precio_final) / mean(precio_final),\n    dias_activos = uniqueN(fecha)\n  ),\n  by = .(region, producto, a√±o)\n][, `:=`(\n  revenue_per_dia = revenue_total / dias_activos,\n  categoria_revenue = cut(revenue_total, \n                         breaks = quantile(revenue_total, c(0, 0.33, 0.66, 1)),\n                         labels = c(\"Bajo\", \"Medio\", \"Alto\"),\n                         include.lowest = TRUE)\n)]\n\n# Gr√°fico de burbujas multivariable\np2 &lt;- ggplot(analisis_completo, \n             aes(x = margen_promedio, y = satisfaccion_media)) +\n  geom_point(aes(size = revenue_total, color = region, shape = factor(a√±o)), \n             alpha = 0.7, stroke = 1) +\n  geom_text(aes(label = producto), \n            vjust = -1.2, hjust = 0.5, size = 2.5, color = \"gray30\") +\n  scale_size_continuous(\n    name = \"Revenue Total\", \n    labels = dollar_format(prefix = \"$\", suffix = \"K\", scale = 1e-3),\n    range = c(3, 15),\n    guide = guide_legend(override.aes = list(alpha = 1))\n  ) +\n  scale_color_brewer(\n    name = \"Regi√≥n\", \n    type = \"qual\", \n    palette = \"Set2\"\n  ) +\n  scale_shape_manual(\n    name = \"A√±o\",\n    values = c(16, 17),\n    guide = guide_legend(override.aes = list(size = 5))\n  ) +\n  scale_x_continuous(\n    labels = percent_format(),\n    expand = expansion(mult = c(0.05, 0.05))\n  ) +\n  labs(\n    title = \"An√°lisis Multidimensional: Performance por Regi√≥n y Producto\",\n    subtitle = \"Margen vs Satisfacci√≥n vs Revenue | Tama√±o = Revenue, Color = Regi√≥n, Forma = A√±o\",\n    x = \"Margen Promedio\",\n    y = \"Satisfacci√≥n Media del Cliente\",\n    caption = \"Cada punto representa una combinaci√≥n regi√≥n-producto-a√±o\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 15, face = \"bold\"),\n    plot.subtitle = element_text(color = \"gray40\", size = 11),\n    legend.position = \"bottom\",\n    legend.box = \"horizontal\",\n    panel.grid.minor = element_blank()\n  ) +\n  guides(\n    color = guide_legend(title.position = \"top\", title.hjust = 0.5),\n    size = guide_legend(title.position = \"top\", title.hjust = 0.5),\n    shape = guide_legend(title.position = \"top\", title.hjust = 0.5)\n  )\n\nprint(p2)\n\n\n\n\n\n\n\n\n11.1.3 3. Series Temporales con M√∫ltiples M√©tricas\n\n\n# Preparar datos para series temporales m√∫ltiples\nseries_temporales &lt;- datos_temporales[,\n  .(\n    cpu_promedio = round(mean(cpu_usage), 1),\n    memory_promedio = round(mean(memory_usage), 1),\n    response_time_p95 = round(quantile(response_time, 0.95), 0),\n    error_total = sum(error_count),\n    load_promedio = round(mean(load_score), 1)\n  ),\n  by = .(fecha, hora)\n][, timestamp := as.POSIXct(paste(fecha, sprintf(\"%02d:00:00\", hora)))]\n\n# Transformar a formato largo para ggplot\nseries_largo &lt;- melt(series_temporales, \n                    id.vars = c(\"timestamp\", \"fecha\", \"hora\"),\n                    measure.vars = c(\"cpu_promedio\", \"memory_promedio\", \"load_promedio\"),\n                    variable.name = \"metrica\",\n                    value.name = \"valor\")\n\n# Mapear nombres m√°s descriptivos\nseries_largo[, metrica_clean := fcase(\n  metrica == \"cpu_promedio\", \"CPU Usage (%)\",\n  metrica == \"memory_promedio\", \"Memory Usage (%)\",\n  metrica == \"load_promedio\", \"Load Score\",\n  default = as.character(metrica)\n)]\n\n# Gr√°fico de series temporales m√∫ltiples\np3 &lt;- ggplot(series_largo[fecha &gt;= as.Date(\"2024-01-01\") & fecha &lt;= as.Date(\"2024-01-07\")], \n             aes(x = timestamp, y = valor, color = metrica_clean)) +\n  geom_line(size = 0.8, alpha = 0.8) +\n  geom_smooth(method = \"loess\", se = FALSE, size = 1.2, alpha = 0.9) +\n  scale_color_viridis_d(name = \"M√©trica\", option = \"plasma\", end = 0.8) +\n  scale_x_datetime(\n    date_labels = \"%d %b\\n%H:%M\",\n    date_breaks = \"12 hours\"\n  ) +\n  scale_y_continuous(\n    expand = expansion(mult = c(0.02, 0.1))\n  ) +\n  labs(\n    title = \"Monitoreo de Sistema - Primera Semana de Enero 2024\",\n    subtitle = \"Tendencias de CPU, Memoria y Load Score con l√≠neas de regresi√≥n suavizada\",\n    x = \"Timestamp\",\n    y = \"Valor\",\n    caption = \"Datos agregados por hora | L√≠neas suavizadas con m√©todo LOESS\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 14, face = \"bold\"),\n    plot.subtitle = element_text(color = \"gray40\", size = 11),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    legend.position = \"bottom\",\n    panel.grid.minor.x = element_blank(),\n    strip.text = element_text(size = 10, face = \"bold\")\n  ) +\n  facet_wrap(~ metrica_clean, scales = \"free_y\", ncol = 1)\n\nprint(p3)\n\n\n\n\n\n\n\n\n11.1.4 4. Heatmaps y Visualizaciones de Correlaci√≥n\n\n\n# Preparar matriz de correlaci√≥n usando data.table\ncorrelacion_por_region &lt;- ventas_detalladas[,\n  .(\n    precio_promedio = mean(precio_final),\n    revenue_promedio = mean(revenue),\n    satisfaccion_promedio = mean(satisfaccion_cliente),\n    descuento_promedio = mean(descuento),\n    cantidad_promedio = mean(cantidad)\n  ),\n  by = .(region, producto)\n]\n\n# Crear heatmap de performance por regi√≥n-producto\nheatmap_data &lt;- correlacion_por_region[, .(\n  region, producto,\n  revenue_normalizado = scale(revenue_promedio)[,1],\n  satisfaccion_normalizada = scale(satisfaccion_promedio)[,1],\n  eficiencia = (scale(revenue_promedio)[,1] + scale(satisfaccion_promedio)[,1]) / 2\n)]\n\np4 &lt;- ggplot(heatmap_data, aes(x = region, y = producto, fill = eficiencia)) +\n  geom_tile(color = \"white\", size = 0.3) +\n  geom_text(aes(label = round(eficiencia, 2)), \n            color = ifelse(heatmap_data$eficiencia &gt; 0, \"white\", \"black\"),\n            size = 3.5, fontface = \"bold\") +\n  scale_fill_gradient2(\n    name = \"√çndice de\\nEficiencia\",\n    low = \"#d73027\", mid = \"#f7f7f7\", high = \"#1a9850\",\n    midpoint = 0,\n    guide = guide_colorbar(title.position = \"top\", title.hjust = 0.5)\n  ) +\n  labs(\n    title = \"Mapa de Calor: Eficiencia por Regi√≥n y Producto\",\n    subtitle = \"√çndice combinado de Revenue y Satisfacci√≥n del Cliente (valores estandarizados)\",\n    x = \"Regi√≥n\",\n    y = \"Producto\",\n    caption = \"Verde = Alta eficiencia, Rojo = Baja eficiencia\"\n  ) +\n  theme_minimal(base_size = 11) +\n  theme(\n    plot.title = element_text(color = \"#2E8B57\", size = 14, face = \"bold\"),\n    plot.subtitle = element_text(color = \"gray40\", size = 11),\n    axis.text.x = element_text(angle = 45, hjust = 1),\n    axis.text.y = element_text(size = 10),\n    legend.position = \"right\",\n    panel.grid = element_blank()\n  )\n\nprint(p4)",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Visualizaci√≥n de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#gr√°ficos-interactivos-con-plotly",
    "href": "cap05-visualizacion.html#gr√°ficos-interactivos-con-plotly",
    "title": "11¬† Visualizaci√≥n de Datos con data.table",
    "section": "\n11.2 Gr√°ficos Interactivos con Plotly",
    "text": "11.2 Gr√°ficos Interactivos con Plotly\n\n11.2.1 1. Conversi√≥n de ggplot2 a Plotly\n\n\n# Crear gr√°fico base con ggplot2\ndatos_interactivos &lt;- ventas_detalladas[,\n  .(\n    revenue_diario = sum(revenue),\n    unidades = sum(cantidad),\n    transacciones = .N,\n    satisfaccion_avg = round(mean(satisfaccion_cliente), 2),\n    productos_unicos = uniqueN(producto)\n  ),\n  by = .(fecha, region)\n]\n\n# Gr√°fico base para conversi√≥n\ngrafico_base &lt;- ggplot(datos_interactivos[fecha &gt;= as.Date(\"2024-01-01\") & fecha &lt;= as.Date(\"2024-03-31\")], \n                       aes(x = fecha, y = revenue_diario, color = region)) +\n  geom_line(alpha = 0.8, size = 1) +\n  geom_point(aes(size = transacciones, \n                text = paste(\"Fecha:\", fecha,\n                           \"&lt;br&gt;Regi√≥n:\", region,\n                           \"&lt;br&gt;Revenue:\", scales::dollar(revenue_diario),\n                           \"&lt;br&gt;Transacciones:\", transacciones,\n                           \"&lt;br&gt;Satisfacci√≥n:\", satisfaccion_avg)),\n             alpha = 0.7) +\n  scale_color_brewer(type = \"qual\", palette = \"Set2\") +\n  scale_size_continuous(range = c(2, 8)) +\n  labs(\n    title = \"Revenue Diario por Regi√≥n (Interactivo)\",\n    x = \"Fecha\",\n    y = \"Revenue Diario\",\n    color = \"Regi√≥n\",\n    size = \"Transacciones\"\n  ) +\n  theme_minimal() %&gt;% suppressWarnings()\n\n# Convertir a plotly\nif(requireNamespace(\"plotly\", quietly = TRUE)) {\n  grafico_interactivo &lt;- plotly::ggplotly(grafico_base, tooltip = \"text\") %&gt;%\n    plotly::layout(\n      title = list(text = \"Revenue Diario por Regi√≥n&lt;br&gt;&lt;sub&gt;Hover para detalles | Click en leyenda para filtrar&lt;/sub&gt;\"),\n      hovermode = \"closest\"\n    )\n  \n  grafico_interactivo\n} else {\n  grafico_base\n  cat(\"üí° Instala 'plotly' para ver la versi√≥n interactiva: install.packages('plotly')\\n\")\n}\n\n\n11.2.2 2. Gr√°ficos 3D y Superficies\n\n\nif(requireNamespace(\"plotly\", quietly = TRUE)) {\n  # Preparar datos para superficie 3D\n  superficie_data &lt;- ventas_detalladas[a√±o == 2024,\n    .(\n      revenue_total = sum(revenue),\n      satisfaccion_media = mean(satisfaccion_cliente),\n      margen_promedio = mean(1 - descuento)\n    ),\n    by = .(mes, region)\n  ]\n  \n  # Crear matriz para la superficie\n  matriz_revenue &lt;- dcast(superficie_data, mes ~ region, value.var = \"revenue_total\", fill = 0)\n  matriz_vals &lt;- as.matrix(matriz_revenue[, -1])\n  \n  # Gr√°fico 3D\n  p3d &lt;- plotly::plot_ly(\n    z = matriz_vals,\n    x = colnames(matriz_vals),\n    y = matriz_revenue$mes,\n    type = \"surface\",\n    colorscale = \"Viridis\"\n  ) %&gt;%\n    plotly::layout(\n      title = \"Superficie 3D: Revenue por Mes y Regi√≥n\",\n      scene = list(\n        xaxis = list(title = \"Regi√≥n\"),\n        yaxis = list(title = \"Mes\"),\n        zaxis = list(title = \"Revenue\")\n      )\n    )\n  \n  p3d\n} else {\n  cat(\"üí° Instala 'plotly' para ver gr√°ficos 3D interactivos\\n\")\n}",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Visualizaci√≥n de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#tablas-interactivas-con-dt",
    "href": "cap05-visualizacion.html#tablas-interactivas-con-dt",
    "title": "11¬† Visualizaci√≥n de Datos con data.table",
    "section": "\n11.3 Tablas Interactivas con DT",
    "text": "11.3 Tablas Interactivas con DT\n\n11.3.1 1. Dashboard de Datos con DT\n\n\n# Preparar datos comprehensivos para tabla\ntabla_comprehensiva &lt;- ventas_detalladas[,\n  .(\n    Revenue_Total = round(sum(revenue), 2),\n    Unidades_Vendidas = sum(cantidad),\n    Num_Transacciones = .N,\n    Ticket_Promedio = round(mean(revenue), 2),\n    Satisfaccion_Media = round(mean(satisfaccion_cliente), 2),\n    Descuento_Promedio = round(mean(descuento) * 100, 1),\n    Precio_Promedio = round(mean(precio_final), 2),\n    Revenue_por_Transaccion = round(sum(revenue) / .N, 2)\n  ),\n  by = .(Regi√≥n = region, Producto = producto, A√±o = a√±o)\n][, `:=`(\n  Ranking_Revenue = frank(-Revenue_Total),\n  Eficiencia = round((Satisfaccion_Media * Revenue_Total) / 1000, 2)\n)][order(-Revenue_Total)]\n\n# Crear tabla interactiva avanzada\ntabla_interactiva &lt;- DT::datatable(\n  tabla_comprehensiva,\n  caption = \"Dashboard Interactivo de Ventas - An√°lisis Completo\",\n  options = list(\n    pageLength = 15,\n    scrollX = TRUE,\n    scrollY = \"400px\",\n    dom = 'Bfrtip',\n    buttons = list(\n      list(extend = 'copy', text = 'Copiar'),\n      list(extend = 'csv', text = 'Descargar CSV'),\n      list(extend = 'excel', text = 'Descargar Excel'),\n      list(extend = 'pdf', text = 'Descargar PDF')\n    ),\n    columnDefs = list(\n      list(className = 'dt-center', targets = c(3, 4, 5, 6, 7, 8, 9, 10)),\n      list(width = '100px', targets = c(0, 1, 2))\n    ),\n    initComplete = DT::JS(\n      \"function(settings, json) {\",\n      \"$(this.api().table().header()).css({'background-color': '#2E8B57', 'color': '#fff'});\",\n      \"}\"\n    )\n  ),\n  extensions = c('Buttons', 'Scroller'),\n  rownames = FALSE,\n  class = 'cell-border stripe hover'\n) %&gt;%\n  DT::formatCurrency(c(\"Revenue_Total\", \"Ticket_Promedio\", \"Precio_Promedio\", \"Revenue_por_Transaccion\"), \n                     currency = \"$\", digits = 2) %&gt;%\n  DT::formatRound(c(\"Satisfaccion_Media\", \"Eficiencia\"), digits = 2) %&gt;%\n  DT::formatPercentage(\"Descuento_Promedio\", digits = 1) %&gt;%\n  DT::formatStyle(\n    \"Eficiencia\",\n    background = DT::styleColorBar(range(tabla_comprehensiva$Eficiencia), \"#4CAF50\"),\n    backgroundSize = \"100% 90%\",\n    backgroundRepeat = \"no-repeat\",\n    backgroundPosition = \"center\"\n  ) %&gt;%\n  DT::formatStyle(\n    \"Satisfaccion_Media\",\n    backgroundColor = DT::styleInterval(\n      cuts = c(3, 4),\n      values = c(\"#ffebee\", \"#e8f5e8\", \"#c8e6c9\")\n    )\n  ) %&gt;%\n  DT::formatStyle(\n    \"Ranking_Revenue\",\n    color = DT::styleInterval(\n      cuts = c(5, 10),\n      values = c(\"#d32f2f\", \"#ff9800\", \"#4caf50\")\n    ),\n    fontWeight = \"bold\"\n  )\n\ntabla_interactiva\n\n\n11.3.2 2. Tablas con Gr√°ficos Embebidos (Sparklines)\n\n\n# Preparar datos para sparklines (tendencias mensuales)\ntendencias_mensuales &lt;- ventas_detalladas[,\n  .(revenue_mensual = sum(revenue)),\n  by = .(region, producto, a√±o, mes)\n][order(region, producto, a√±o, mes)]\n\n# Crear sparklines para cada combinaci√≥n regi√≥n-producto\nsparkline_data &lt;- tendencias_mensuales[,\n  .(\n    Revenue_Total = sum(revenue_mensual),\n    Meses_Activos = .N,\n    Revenue_Promedio = round(mean(revenue_mensual), 2),\n    Tendencia = list(revenue_mensual),\n    Max_Mes = max(revenue_mensual),\n    Min_Mes = min(revenue_mensual)\n  ),\n  by = .(Regi√≥n = region, Producto = producto)\n][order(-Revenue_Total)]\n\n# Crear funci√≥n para sparklines\ncrear_sparkline &lt;- function(values) {\n  paste0('&lt;span class=\"sparkline\"&gt;', paste(values, collapse = ','), '&lt;/span&gt;')\n}\n\n# Aplicar sparklines\nsparkline_data[, Tendencia_Visual := sapply(Tendencia, crear_sparkline)]\n\n# Tabla con sparklines\ntabla_sparklines &lt;- DT::datatable(\n  sparkline_data[, .(Regi√≥n, Producto, Revenue_Total, Revenue_Promedio, \n                    Max_Mes, Min_Mes, Tendencia_Visual)],\n  caption = \"An√°lisis de Tendencias con Sparklines\",\n  options = list(\n    pageLength = 10,\n    scrollX = TRUE,\n    columnDefs = list(\n      list(className = 'dt-center', targets = c(2, 3, 4, 5, 6))\n    ),\n    fnDrawCallback = DT::JS(\n      'function(){\n        $(\".sparkline\").sparkline(\"html\", {\n          type: \"line\",\n          width: \"100px\",\n          height: \"30px\",\n          lineColor: \"#2E8B57\",\n          fillColor: \"#e8f5e8\",\n          spotColor: \"#FF6B35\",\n          minSpotColor: \"#FF6B35\",\n          maxSpotColor: \"#FF6B35\"\n        });\n      }'\n    )\n  ),\n  escape = FALSE,\n  rownames = FALSE\n) %&gt;%\n  DT::formatCurrency(c(\"Revenue_Total\", \"Revenue_Promedio\", \"Max_Mes\", \"Min_Mes\"), \n                     currency = \"$\", digits = 0)\n\n# Note: Para que las sparklines funcionen completamente, se necesita incluir la librer√≠a jQuery Sparklines\ncat(\"üí° Para sparklines completas, incluye: &lt;script src='https://cdn.jsdelivr.net/gh/garethflowers/jquery-sparkline/jquery.sparkline.min.js'&gt;&lt;/script&gt;\\n\")\n\ntabla_sparklines",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Visualizaci√≥n de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#dashboards-integrados-combinando-todo",
    "href": "cap05-visualizacion.html#dashboards-integrados-combinando-todo",
    "title": "11¬† Visualizaci√≥n de Datos con data.table",
    "section": "\n11.4 Dashboards Integrados: Combinando Todo",
    "text": "11.4 Dashboards Integrados: Combinando Todo\n\n11.4.1 1. Dashboard Ejecutivo Completo\n\n\n# Preparar datos para dashboard ejecutivo\nresumen_ejecutivo &lt;- ventas_detalladas[,\n  .(\n    revenue_total = sum(revenue),\n    unidades_total = sum(cantidad),\n    transacciones_total = .N,\n    satisfaccion_promedio = round(mean(satisfaccion_cliente), 2)\n  )\n]\n\nkpis_por_region &lt;- ventas_detalladas[,\n  .(\n    Revenue = sum(revenue),\n    Unidades = sum(cantidad),\n    Transacciones = .N,\n    Satisfacci√≥n = round(mean(satisfaccion_cliente), 2),\n    Ticket_Promedio = round(mean(revenue), 2)\n  ),\n  by = region\n][order(-Revenue)]\n\ntendencia_mensual &lt;- ventas_detalladas[,\n  .(revenue = sum(revenue)),\n  by = .(a√±o, mes)\n][, fecha := as.Date(paste(a√±o, mes, \"01\", sep = \"-\"))]\n\ntop_productos &lt;- ventas_detalladas[,\n  .(revenue = sum(revenue), satisfaccion = round(mean(satisfaccion_cliente), 2)),\n  by = producto\n][order(-revenue)]\n\n# Layout del dashboard usando grid.arrange\nlibrary(gridExtra)\n\n# Gr√°fico 1: KPIs por regi√≥n\ng1 &lt;- ggplot(kpis_por_region, aes(x = reorder(region, Revenue), y = Revenue)) +\n  geom_col(fill = \"#2E8B57\", alpha = 0.8) +\n  geom_text(aes(label = scales::dollar(Revenue, scale = 1e-3, suffix = \"K\")), \n            hjust = -0.1, color = \"#2E8B57\", fontface = \"bold\") +\n  coord_flip() +\n  labs(title = \"Revenue por Regi√≥n\", x = NULL, y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#2E8B57\"))\n\n# Gr√°fico 2: Tendencia temporal\ng2 &lt;- ggplot(tendencia_mensual, aes(x = fecha, y = revenue)) +\n  geom_line(color = \"#2E8B57\", size = 1.2) +\n  geom_point(color = \"#2E8B57\", size = 2) +\n  scale_y_continuous(labels = scales::dollar_format(scale = 1e-3, suffix = \"K\")) +\n  labs(title = \"Tendencia Mensual\", x = NULL, y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#2E8B57\"))\n\n# Gr√°fico 3: Top productos\ng3 &lt;- ggplot(top_productos, aes(x = reorder(producto, revenue), y = revenue)) +\n  geom_col(fill = \"#FF6B35\", alpha = 0.8) +\n  coord_flip() +\n  labs(title = \"Top Productos\", x = NULL, y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#FF6B35\"))\n\n# Gr√°fico 4: Satisfacci√≥n vs Revenue\ng4 &lt;- ggplot(top_productos, aes(x = satisfaccion, y = revenue)) +\n  geom_point(size = 4, color = \"#8E44AD\", alpha = 0.7) +\n  geom_text(aes(label = producto), vjust = -0.5, size = 3) +\n  labs(title = \"Satisfacci√≥n vs Revenue\", x = \"Satisfacci√≥n\", y = \"Revenue\") +\n  theme_minimal() +\n  theme(plot.title = element_text(face = \"bold\", color = \"#8E44AD\"))\n\n# Combinar todos los gr√°ficos\ngrid.arrange(\n  g1, g2, g3, g4,\n  ncol = 2, nrow = 2,\n  top = grid::textGrob(\"DASHBOARD EJECUTIVO DE VENTAS\", \n                      gp = grid::gpar(fontsize = 20, fontface = \"bold\", col = \"#2E8B57\"))\n)\n\n\n\n\n\n\n\n# Mostrar m√©tricas clave\ncat(\"\\nüìä M√âTRICAS CLAVE DEL PER√çODO:\\n\")\n#&gt; \n#&gt; üìä M√âTRICAS CLAVE DEL PER√çODO:\ncat(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\n\")\n#&gt; ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\ncat(\"üí∞ Revenue Total:\", scales::dollar(resumen_ejecutivo$revenue_total), \"\\n\")\n#&gt; üí∞ Revenue Total: $907,171\ncat(\"üì¶ Unidades Vendidas:\", scales::comma(resumen_ejecutivo$unidades_total), \"\\n\")\n#&gt; üì¶ Unidades Vendidas: 1,534\ncat(\"üõí Total Transacciones:\", scales::comma(resumen_ejecutivo$transacciones_total), \"\\n\")\n#&gt; üõí Total Transacciones: 731\ncat(\"‚≠ê Satisfacci√≥n Promedio:\", resumen_ejecutivo$satisfaccion_promedio, \"/5\\n\")\n#&gt; ‚≠ê Satisfacci√≥n Promedio: 3.7 /5\ncat(\"üéØ Ticket Promedio:\", scales::dollar(resumen_ejecutivo$revenue_total / resumen_ejecutivo$transacciones_total), \"\\n\")\n#&gt; üéØ Ticket Promedio: $1,241.00\n\n\n11.4.2 2. Tabla de M√©tricas Interactiva Final\n\n\n# Crear tabla final con todas las m√©tricas\nmetricas_finales &lt;- ventas_detalladas[,\n  .(\n    Revenue = round(sum(revenue), 2),\n    Unidades = sum(cantidad),\n    Transacciones = .N,\n    D√≠as_Activos = uniqueN(fecha),\n    Satisfacci√≥n = round(mean(satisfaccion_cliente), 2),\n    Descuento_Avg = round(mean(descuento) * 100, 1),\n    Revenue_per_D√≠a = round(sum(revenue) / uniqueN(fecha), 2)\n  ),\n  by = .(Regi√≥n = region, Producto = producto, A√±o = a√±o)\n][, `:=`(\n  Performance_Score = round((Revenue / 1000) * Satisfacci√≥n * (1 - Descuento_Avg/100), 2),\n  Ranking = frank(-Revenue, ties.method = \"min\")\n)][order(-Performance_Score)]\n\n# Tabla final con formato avanzado\ntabla_final &lt;- DT::datatable(\n  metricas_finales,\n  caption = \"M√âTRICAS INTEGRALES DE PERFORMANCE | Dashboard Interactivo Final\",\n  options = list(\n    pageLength = 20,\n    scrollX = TRUE,\n    scrollY = \"500px\",\n    dom = 'Bfrtip',\n    buttons = list(\n      list(extend = 'copy', text = 'üìã Copiar'),\n      list(extend = 'csv', text = 'üìä CSV'),\n      list(extend = 'excel', text = 'üìà Excel'),\n      list(extend = 'print', text = 'üñ®Ô∏è Imprimir')\n    ),\n    columnDefs = list(\n      list(className = 'dt-center', targets = c(3:10)),\n      list(orderSequence = c('desc', 'asc'), targets = c(3, 9, 10))\n    ),\n    initComplete = DT::JS(\n      \"function(settings, json) {\",\n      \"$(this.api().table().header()).css({\",\n      \"'background': 'linear-gradient(90deg, #2E8B57, #3CB371)',\",\n      \"'color': '#fff',\",\n      \"'text-align': 'center',\",\n      \"'font-weight': 'bold'\",\n      \"});\",\n      \"}\"\n    )\n  ),\n  extensions = c('Buttons', 'Scroller'),\n  rownames = FALSE,\n  class = 'cell-border stripe hover compact'\n) %&gt;%\n  DT::formatCurrency(c(\"Revenue\", \"Revenue_per_D√≠a\"), currency = \"$\", digits = 0) %&gt;%\n  DT::formatRound(c(\"Satisfacci√≥n\", \"Performance_Score\"), digits = 2) %&gt;%\n  DT::formatPercentage(\"Descuento_Avg\", digits = 1) %&gt;%\n  DT::formatStyle(\n    \"Performance_Score\",\n    background = DT::styleColorBar(range(metricas_finales$Performance_Score), \"#2E8B57\"),\n    backgroundSize = \"100% 90%\",\n    backgroundRepeat = \"no-repeat\",\n    backgroundPosition = \"center\",\n    color = \"white\",\n    fontWeight = \"bold\"\n  ) %&gt;%\n  DT::formatStyle(\n    \"Ranking\",\n    backgroundColor = DT::styleInterval(\n      cuts = c(3, 7, 15),\n      values = c(\"#FFD700\", \"#C0C0C0\", \"#CD7F32\", \"#f5f5f5\")  # Oro, Plata, Bronce, Normal\n    ),\n    fontWeight = \"bold\",\n    textAlign = \"center\"\n  ) %&gt;%\n  DT::formatStyle(\n    \"Satisfacci√≥n\",\n    color = DT::styleInterval(\n      cuts = c(3.5, 4.5),\n      values = c(\"#e74c3c\", \"#f39c12\", \"#27ae60\")\n    ),\n    fontWeight = \"bold\"\n  )\n\ntabla_final",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Visualizaci√≥n de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-visualizacion.html#pr√≥ximo-cap√≠tulo-aplicaciones-del-mundo-real",
    "href": "cap05-visualizacion.html#pr√≥ximo-cap√≠tulo-aplicaciones-del-mundo-real",
    "title": "11¬† Visualizaci√≥n de Datos con data.table",
    "section": "\n11.5 Pr√≥ximo Cap√≠tulo: Aplicaciones del Mundo Real",
    "text": "11.5 Pr√≥ximo Cap√≠tulo: Aplicaciones del Mundo Real\nEn el siguiente cap√≠tulo exploraremos: - Aplicaciones Shiny para dashboards din√°micos - Integraci√≥n con tidymodels para machine learning - Conexi√≥n con bases de datos y herramientas Big Data - Casos de uso industriales reales\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\ndata.table + ggplot2 = Combinaci√≥n perfecta para an√°lisis visual profesional\n\nPlotly a√±ade interactividad sin sacrificar la est√©tica de ggplot2\n\nDT transforma tablas est√°ticas en dashboards interactivos potentes\n\nEl workflow √≥ptimo: Procesar con data.table ‚Üí Visualizar con ggplot2/plotly/DT\n\nSparklines y formato avanzado elevan las tablas a herramientas de an√°lisis\n\nLos dashboards integrados combinan m√∫ltiples visualizaciones para insights completos\n\n\n\nHas dominado la visualizaci√≥n de datos con data.table. En el pr√≥ximo cap√≠tulo veremos c√≥mo construir aplicaciones completas del mundo real.",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>11</span>¬† <span class='chapter-title'>Visualizaci√≥n de Datos con data.table</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html",
    "href": "cap05-aplicaciones.html",
    "title": "12¬† Aplicaciones del Mundo Real",
    "section": "",
    "text": "12.1 Aplicaciones Shiny Escalables con data.table",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#aplicaciones-shiny-escalables-con-data.table",
    "href": "cap05-aplicaciones.html#aplicaciones-shiny-escalables-con-data.table",
    "title": "12¬† Aplicaciones del Mundo Real",
    "section": "",
    "text": "12.1.1 1. Arquitectura de App Shiny Profesional\n\n\n# Estructura modular para apps grandes\nlibrary(shiny)\nlibrary(shinydashboard)\nlibrary(data.table)\nlibrary(DT)\nlibrary(ggplot2)\nlibrary(plotly)\n\n# === M√ìDULO: Data Processing ===\n# Todas las operaciones data.table en funciones separadas\nprocess_customer_data &lt;- function(clientes_dt, filters = list()) {\n  # Aplicar filtros din√°micamente\n  result &lt;- clientes_dt\n  \n  if(!is.null(filters$region) && filters$region != \"Todos\") {\n    result &lt;- result[region == filters$region]\n  }\n  \n  if(!is.null(filters$edad_min)) {\n    result &lt;- result[edad &gt;= filters$edad_min]\n  }\n  \n  if(!is.null(filters$fecha_desde)) {\n    # Aqu√≠ se aplicar√≠an filtros de fecha si tuvi√©ramos esos datos\n  }\n  \n  return(result)\n}\n\ncalculate_customer_metrics &lt;- function(clientes_dt) {\n  clientes_dt[,\n    .(\n      total_clientes = .N,\n      edad_promedio = round(mean(edad), 1),\n      ingresos_promedio = round(mean(ingresos), 0),\n      satisfaccion_promedio = round(mean(satisfaccion), 2),\n      churn_rate = round(mean(churn_flag) * 100, 1),\n      valor_promedio = round(mean(valor_cliente), 2),\n      engagement_promedio = round(mean(engagement_score), 2)\n    ),\n    by = .(region, categoria_ingresos)\n  ]\n}\n\n# === UI: Dashboard Layout ===\nui &lt;- dashboardPage(\n  dashboardHeader(title = \"Customer Analytics - Powered by data.table\"),\n  \n  dashboardSidebar(\n    sidebarMenu(\n      menuItem(\"Overview\", tabName = \"overview\", icon = icon(\"dashboard\")),\n      menuItem(\"Clientes\", tabName = \"clientes\", icon = icon(\"users\")),\n      menuItem(\"Segmentaci√≥n\", tabName = \"segmentacion\", icon = icon(\"chart-pie\")),\n      menuItem(\"Predicciones\", tabName = \"predicciones\", icon = icon(\"brain\")),\n      menuItem(\"Datos Raw\", tabName = \"datos\", icon = icon(\"table\"))\n    )\n  ),\n  \n  dashboardBody(\n    tags$head(\n      tags$style(HTML(\"\n        .content-wrapper, .right-side {\n          background-color: #f4f4f4;\n        }\n        .main-header .navbar {\n          background-color: #2E8B57 !important;\n        }\n      \"))\n    ),\n    \n    tabItems(\n      # Tab Overview\n      tabItem(tabName = \"overview\",\n        fluidRow(\n          valueBoxOutput(\"total_clientes\"),\n          valueBoxOutput(\"churn_rate\"),\n          valueBoxOutput(\"valor_promedio\")\n        ),\n        fluidRow(\n          box(\n            title = \"Filtros Globales\", status = \"primary\", solidHeader = TRUE,\n            width = 3,\n            selectInput(\"region_filter\", \"Regi√≥n:\",\n                       choices = c(\"Todos\", unique(datos_clientes$region)),\n                       selected = \"Todos\"),\n            sliderInput(\"edad_range\", \"Rango de Edad:\",\n                       min = 18, max = 80, value = c(18, 80)),\n            actionButton(\"aplicar_filtros\", \"Aplicar Filtros\", \n                        class = \"btn-primary\")\n          ),\n          box(\n            title = \"Revenue por Regi√≥n\", status = \"success\", solidHeader = TRUE,\n            width = 9,\n            plotlyOutput(\"revenue_plot\", height = \"400px\")\n          )\n        )\n      ),\n      \n      # Tab Clientes\n      tabItem(tabName = \"clientes\",\n        fluidRow(\n          box(\n            title = \"An√°lisis de Clientes\", status = \"primary\", solidHeader = TRUE,\n            width = 12,\n            DT::dataTableOutput(\"clientes_table\")\n          )\n        )\n      ),\n      \n      # Tab Segmentaci√≥n\n      tabItem(tabName = \"segmentacion\",\n        fluidRow(\n          box(\n            title = \"Segmentaci√≥n por Valor\", status = \"warning\", solidHeader = TRUE,\n            width = 6,\n            plotOutput(\"segmentacion_plot\")\n          ),\n          box(\n            title = \"Matriz de Retenci√≥n\", status = \"info\", solidHeader = TRUE,\n            width = 6,\n            plotOutput(\"matriz_retencion\")\n          )\n        )\n      )\n    )\n  )\n)\n\n# === SERVER: L√≥gica Reactiva ===\nserver &lt;- function(input, output, session) {\n  \n  # Datos reactivos - aqu√≠ brilla data.table\n  datos_filtrados &lt;- reactive({\n    input$aplicar_filtros  # Dependencia del bot√≥n\n    \n    isolate({\n      filtros &lt;- list(\n        region = input$region_filter,\n        edad_min = input$edad_range[1],\n        edad_max = input$edad_range[2]\n      )\n      \n      result &lt;- datos_clientes[\n        edad &gt;= filtros$edad_min & edad &lt;= filtros$edad_max\n      ]\n      \n      if(filtros$region != \"Todos\") {\n        result &lt;- result[region == filtros$region]\n      }\n      \n      return(result)\n    })\n  })\n  \n  # ValueBoxes\n  output$total_clientes &lt;- renderValueBox({\n    valueBox(\n      value = comma(nrow(datos_filtrados())),\n      subtitle = \"Total Clientes\",\n      icon = icon(\"users\"),\n      color = \"blue\"\n    )\n  })\n  \n  output$churn_rate &lt;- renderValueBox({\n    rate &lt;- round(mean(datos_filtrados()$churn_flag) * 100, 1)\n    valueBox(\n      value = paste0(rate, \"%\"),\n      subtitle = \"Tasa de Churn\",\n      icon = icon(\"exclamation-triangle\"),\n      color = if(rate &gt; 15) \"red\" else if(rate &gt; 10) \"yellow\" else \"green\"\n    )\n  })\n  \n  output$valor_promedio &lt;- renderValueBox({\n    valor &lt;- round(mean(datos_filtrados()$valor_cliente), 2)\n    valueBox(\n      value = dollar(valor),\n      subtitle = \"Valor Promedio\",\n      icon = icon(\"dollar-sign\"),\n      color = \"green\"\n    )\n  })\n  \n  # Gr√°fico principal\n  output$revenue_plot &lt;- renderPlotly({\n    # C√°lculo super r√°pido con data.table\n    plot_data &lt;- datos_filtrados()[,\n      .(\n        valor_total = sum(valor_cliente),\n        clientes = .N,\n        satisfaccion_avg = round(mean(satisfaccion), 2)\n      ),\n      by = region\n    ]\n    \n    p &lt;- ggplot(plot_data, aes(x = reorder(region, valor_total), y = valor_total)) +\n      geom_col(aes(fill = satisfaccion_avg), alpha = 0.8) +\n      geom_text(aes(label = dollar(valor_total, scale = 1e-3, suffix = \"K\")), \n               hjust = -0.1) +\n      scale_fill_viridis_c(name = \"Satisfacci√≥n\\nPromedio\") +\n      coord_flip() +\n      labs(title = \"Valor Total por Regi√≥n\", x = \"Regi√≥n\", y = \"Valor Total\") +\n      theme_minimal()\n    \n    ggplotly(p)\n  })\n  \n  # Tabla de clientes\n  output$clientes_table &lt;- DT::renderDataTable({\n    tabla_data &lt;- datos_filtrados()[,\n      .(\n        cliente_id, edad, region, \n        ingresos = dollar(ingresos),\n        valor_cliente = round(valor_cliente, 2),\n        satisfaccion,\n        engagement_score = round(engagement_score, 2),\n        riesgo_churn = ifelse(riesgo_churn == 1, \"Alto\", \"Bajo\"),\n        es_vip = ifelse(cliente_vip == 1, \"S√≠\", \"No\")\n      )\n    ]\n    \n    DT::datatable(\n      tabla_data,\n      options = list(pageLength = 25, scrollX = TRUE),\n      rownames = FALSE\n    ) %&gt;%\n      DT::formatStyle(\n        \"riesgo_churn\",\n        backgroundColor = DT::styleEqual(\"Alto\", \"#ffebee\")\n      ) %&gt;%\n      DT::formatStyle(\n        \"es_vip\",\n        backgroundColor = DT::styleEqual(\"S√≠\", \"#e8f5e8\")\n      )\n  })\n}\n\n# Lanzar la app\n# shinyApp(ui = ui, server = server)\n\n\n12.1.2 2. Optimizaci√≥n de Performance en Shiny\n\n\n# === T√âCNICAS DE OPTIMIZACI√ìN ===\n\n# 1. Pre-procesar datos pesados al inicio\nonSessionStart &lt;- function(session) {\n  # C√°lculos que no cambian frecuentemente\n  session$userData$metricas_estaticas &lt;- datos_clientes[,\n    .(\n      clientes_por_region = .N,\n      valor_total = sum(valor_cliente),\n      edad_promedio = mean(edad)\n    ),\n    by = region\n  ]\n  \n  # √çndices para b√∫squedas r√°pidas\n  setkey(session$userData$clientes_dt, cliente_id)\n  setindex(session$userData$clientes_dt, region, categoria_ingresos)\n}\n\n# 2. Usar reactive values para cache inteligente\nserver &lt;- function(input, output, session) {\n  # Cache de c√°lculos costosos\n  cache_metricas &lt;- reactiveValues()\n  \n  # Solo recalcular cuando cambien inputs relevantes\n  observe({\n    key &lt;- paste(input$region_filter, input$edad_range[1], input$edad_range[2], sep = \"_\")\n    \n    if(is.null(cache_metricas[[key]])) {\n      cache_metricas[[key]] &lt;- calculate_customer_metrics(\n        datos_clientes[\n          region %in% input$region_filter & \n          edad %between% input$edad_range\n        ]\n      )\n    }\n  })\n  \n  # 3. Renderizado condicional\n  output$tabla_grande &lt;- DT::renderDataTable({\n    # Solo renderizar si la pesta√±a est√° visible\n    req(input$tabs == \"datos_detallados\")\n    \n    # data.table operation ultrarr√°pida\n    datos_tabla &lt;- datos_filtrados()[,\n      .(cliente_id, region, valor_cliente, churn_flag)\n    ][order(-valor_cliente)]\n    \n    DT::datatable(datos_tabla, options = list(pageLength = 50))\n  })\n}\n\n# 4. M√≥dulos para escalabilidad\ncustomerMetricsUI &lt;- function(id) {\n  ns &lt;- NS(id)\n  tagList(\n    valueBoxOutput(ns(\"total_value\")),\n    plotOutput(ns(\"distribution_plot\"))\n  )\n}\n\ncustomerMetricsServer &lt;- function(id, data) {\n  moduleServer(id, function(input, output, session) {\n    output$total_value &lt;- renderValueBox({\n      # C√°lculo modular con data.table\n      total &lt;- data()[, sum(valor_cliente)]\n      valueBox(\n        value = dollar(total, scale = 1e-6, suffix = \"M\"),\n        subtitle = \"Valor Total\",\n        icon = icon(\"chart-line\"),\n        color = \"green\"\n      )\n    })\n  })\n}",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#integraci√≥n-con-tidymodels-machine-learning-robusto",
    "href": "cap05-aplicaciones.html#integraci√≥n-con-tidymodels-machine-learning-robusto",
    "title": "12¬† Aplicaciones del Mundo Real",
    "section": "\n12.2 Integraci√≥n con tidymodels: Machine Learning Robusto",
    "text": "12.2 Integraci√≥n con tidymodels: Machine Learning Robusto\n\n12.2.1 1. Workflow Completo: data.table ‚Üí tidymodels ‚Üí data.table\n\n\n# PASO 1: Feature Engineering con data.table (ultrarr√°pido)\npreparar_datos_ml &lt;- function(clientes_dt, transacciones_dt) {\n  # Calcular m√©tricas de transacciones por cliente\n  metricas_transaccionales &lt;- transacciones_dt[, monto_final := monto * (1 - descuento_aplicado)][\n    fecha_transaccion &gt;= Sys.Date() - 365,  # √öltimo a√±o\n    .(\n      transacciones_a√±o = .N,\n      monto_total_a√±o = sum(monto_final),\n      monto_promedio = round(mean(monto_final), 2),\n      categorias_compradas = uniqueN(producto_categoria),\n      canal_principal = names(sort(table(canal), decreasing = TRUE))[1],\n      frecuencia_compra_dias = as.numeric(max(fecha_transaccion) - min(fecha_transaccion)) / .N,\n      usa_descuentos = mean(descuento_aplicado &gt; 0),\n      tasa_devolucion = mean(es_devolucion)\n    ),\n    by = cliente_id\n  ]\n  \n  # Unir con datos de clientes\n  datos_completos &lt;- clientes_dt[metricas_transaccionales, on = .(cliente_id)]\n  \n  # Feature engineering adicional\n  datos_completos[, `:=`(\n    # Variables de interacci√≥n\n    ingresos_edad_ratio = ingresos / edad,\n    valor_por_producto = valor_cliente / num_productos,\n    engagement_per_month = engagement_score / pmax(antiguedad_meses, 1),\n    \n    # Variables categ√≥ricas optimizadas\n    segmento_valor = cut(valor_cliente, \n                        breaks = quantile(valor_cliente, c(0, 0.25, 0.5, 0.75, 1), na.rm = TRUE),\n                        labels = c(\"Bajo\", \"Medio-Bajo\", \"Medio-Alto\", \"Alto\"),\n                        include.lowest = TRUE),\n    \n    # Variables binarias\n    cliente_frecuente = as.numeric(transacciones_a√±o &gt; quantile(transacciones_a√±o, 0.75, na.rm = TRUE)),\n    multicanal = as.numeric(categorias_compradas &gt;= 3),\n    \n    # Target variable limpia\n    churn = factor(ifelse(churn_flag == 1, \"Si\", \"No\"), levels = c(\"No\", \"Si\"))\n  )]\n  \n  # Remover casos con NAs en variables cr√≠ticas\n  datos_limpios &lt;- datos_completos[\n    !is.na(transacciones_a√±o) & \n    !is.na(monto_total_a√±o) & \n    !is.na(churn)\n  ]\n  \n  return(datos_limpios)\n}\n\n# Ejecutar preparaci√≥n\ndatos_ml &lt;- preparar_datos_ml(datos_clientes, transacciones_detalle)\n\ncat(\"Datos preparados para ML:\\n\")\n#&gt; Datos preparados para ML:\ncat(\"- Filas:\", nrow(datos_ml), \"\\n\")\n#&gt; - Filas: 5938\ncat(\"- Columnas:\", ncol(datos_ml), \"\\n\")\n#&gt; - Columnas: 33\ncat(\"- Distribuci√≥n de churn:\\n\")\n#&gt; - Distribuci√≥n de churn:\nprint(datos_ml[, .N, by = churn])\n#&gt;     churn     N\n#&gt;    &lt;fctr&gt; &lt;int&gt;\n#&gt; 1:     Si   707\n#&gt; 2:     No  5231\n\n\n12.2.2 2. Modelado con tidymodels (Ejemplo Conceptual)\n\n\n# Ejemplo de workflow completo con tidymodels\nlibrary(tidymodels)\nlibrary(themis)  # Para balanceo de clases\n\n# PASO 2: Convertir a tibble para tidymodels\ndatos_tibble &lt;- as_tibble(datos_ml)\n\n# PASO 3: Split de datos\nset.seed(123)\ndata_split &lt;- initial_split(\n  datos_tibble, \n  prop = 0.8, \n  strata = churn\n)\n\ntrain_data &lt;- training(data_split)\ntest_data &lt;- testing(data_split)\n\n# PASO 4: Receta de preprocesamiento\nreceta_churn &lt;- recipe(churn ~ ., data = train_data) %&gt;%\n  # Remover variables no predictivas\n  step_rm(cliente_id, churn_flag) %&gt;%\n  \n  # Imputaci√≥n de NAs\n  step_impute_median(all_numeric_predictors()) %&gt;%\n  step_impute_mode(all_nominal_predictors()) %&gt;%\n  \n  # Feature engineering\n  step_log(ingresos, valor_cliente, offset = 1) %&gt;%\n  step_normalize(all_numeric_predictors()) %&gt;%\n  \n  # Variables dummy\n  step_dummy(all_nominal_predictors()) %&gt;%\n  \n  # Balanceo de clases\n  step_downsample(churn, under_ratio = 2) %&gt;%\n  \n  # Remover variables con varianza cero\n  step_zv(all_predictors()) %&gt;%\n  \n  # Correlaci√≥n alta\n  step_corr(all_numeric_predictors(), threshold = 0.9)\n\n# PASO 5: Modelos\nmodelo_rf &lt;- rand_forest(\n  trees = tune(),\n  mtry = tune(),\n  min_n = tune()\n) %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"randomForest\")\n\nmodelo_xgb &lt;- boost_tree(\n  trees = tune(),\n  tree_depth = tune(),\n  learn_rate = tune(),\n  min_n = tune()\n) %&gt;%\n  set_mode(\"classification\") %&gt;%\n  set_engine(\"xgboost\")\n\n# PASO 6: Workflows\nworkflow_rf &lt;- workflow() %&gt;%\n  add_recipe(receta_churn) %&gt;%\n  add_model(modelo_rf)\n\nworkflow_xgb &lt;- workflow() %&gt;%\n  add_recipe(receta_churn) %&gt;%\n  add_model(modelo_xgb)\n\n# PASO 7: Cross-validation y tuning\ncv_folds &lt;- vfold_cv(train_data, v = 5, strata = churn)\n\n# Tuning Random Forest\ntune_rf &lt;- workflow_rf %&gt;%\n  tune_grid(\n    resamples = cv_folds,\n    grid = 20,\n    metrics = metric_set(roc_auc, precision, recall, f_meas)\n  )\n\n# PASO 8: Mejor modelo\nbest_rf &lt;- select_best(tune_rf, metric = \"roc_auc\")\nfinal_workflow_rf &lt;- finalize_workflow(workflow_rf, best_rf)\n\n# PASO 9: Fit final y predicciones\nmodelo_final &lt;- fit(final_workflow_rf, train_data)\npredicciones &lt;- predict(modelo_final, test_data, type = \"prob\")\n\n# M√©tricas de evaluaci√≥n\nmetricas_modelo &lt;- test_data %&gt;%\n  cbind(predicciones) %&gt;%\n  mutate(pred = factor(fifelse(.pred_Si &gt;= 0.5, 1, 0), levels = c(0, 1), labels = c(\"No\", \"Si\"))) %&gt;% \n  metrics(truth = churn, pred)\n\nprint(metricas_modelo)\n\n\n12.2.3 3. Post-procesamiento y An√°lisis con data.table\n\n\n# Simular predicciones para el ejemplo (en producci√≥n vendr√≠an del modelo)\nset.seed(789)\npredicciones_simuladas &lt;- data.table(\n  cliente_id = datos_ml[sample(.N, 2000), cliente_id],\n  prob_churn = runif(2000, 0, 1),\n  pred_churn = sample(c(\"Si\", \"No\"), 2000, replace = TRUE, prob = c(0.15, 0.85)),\n  confidence_score = runif(2000, 0.6, 0.95)\n)\n\n# AN√ÅLISIS DE RESULTADOS con data.table\n# Unir predicciones con datos originales\nresultados_ml &lt;- datos_ml[predicciones_simuladas, on = .(cliente_id)]\n\n# An√°lisis de segmentos de riesgo\nanalisis_riesgo &lt;- resultados_ml[,\n  .(\n    clientes_total = .N,\n    churn_predicho = sum(pred_churn == \"Si\"),\n    prob_churn_media = round(mean(prob_churn), 3),\n    valor_en_riesgo = sum(valor_cliente[pred_churn == \"Si\"]),\n    revenue_en_riesgo = sum(monto_total_a√±o[pred_churn == \"Si\"], na.rm = TRUE),\n    ingresos_promedio = round(mean(ingresos), 0),\n    engagement_promedio = round(mean(engagement_score), 2)\n  ),\n  by = .(region, categoria_ingresos)\n][order(-valor_en_riesgo)]\n\ncat(\"=== AN√ÅLISIS DE RIESGO DE CHURN POR SEGMENTO ===\\n\")\n#&gt; === AN√ÅLISIS DE RIESGO DE CHURN POR SEGMENTO ===\nprint(analisis_riesgo)\n#&gt;     region categoria_ingresos clientes_total churn_predicho prob_churn_media\n#&gt;     &lt;char&gt;             &lt;fctr&gt;          &lt;int&gt;          &lt;int&gt;            &lt;num&gt;\n#&gt;  1: Centro               Alto            115             27            0.496\n#&gt;  2:  Norte               Alto            149             22            0.474\n#&gt;  3:   Este               Alto            149             26            0.476\n#&gt;  4:    Sur               Alto            136             15            0.472\n#&gt;  5: Centro              Medio            132             23            0.480\n#&gt; ---                                                                         \n#&gt; 11:  Oeste              Medio            123             20            0.477\n#&gt; 12: Centro               Bajo            141             19            0.477\n#&gt; 13:    Sur               Bajo            118             25            0.501\n#&gt; 14:   Este               Bajo            142             17            0.531\n#&gt; 15:  Oeste               Bajo            133             22            0.523\n#&gt;     valor_en_riesgo revenue_en_riesgo ingresos_promedio engagement_promedio\n#&gt;               &lt;num&gt;             &lt;num&gt;             &lt;num&gt;               &lt;num&gt;\n#&gt;  1:       3971.9904          4357.158            101231                7.74\n#&gt;  2:       3448.6127          3115.558            101081                7.56\n#&gt;  3:       2752.8342          2759.645            103060                7.62\n#&gt;  4:       1918.1725          1584.725             93285                7.55\n#&gt;  5:       1900.4059          2514.022             48193                7.54\n#&gt; ---                                                                        \n#&gt; 11:       1159.6149          2632.164             49278                7.63\n#&gt; 12:        912.9440          3273.967             27460                7.72\n#&gt; 13:        879.7883          3768.650             26754                7.62\n#&gt; 14:        812.1611          1624.176             27489                7.43\n#&gt; 15:        794.0182          2108.543             27076                7.72\n\n# Identificar clientes de alta prioridad para retenci√≥n\nclientes_retencion &lt;- resultados_ml[\n  pred_churn == \"Si\" & \n  prob_churn &gt; 0.7 & \n  valor_cliente &gt; quantile(resultados_ml$valor_cliente, 0.7, na.rm = TRUE),\n  .(\n    cliente_id, region, edad, ingresos, valor_cliente,\n    prob_churn = round(prob_churn, 3),\n    transacciones_a√±o, monto_total_a√±o,\n    satisfaccion, engagement_score,\n    accion_recomendada = fcase(\n      satisfaccion &lt; 3, \"Mejora_Servicio\",\n      engagement_score &lt; 5, \"Aumentar_Engagement\", \n      monto_total_a√±o &lt; 1000, \"Incentivo_Compra\",\n      default = \"Programa_Lealtad\"\n    )\n  )\n][order(-valor_cliente)]\n\ncat(\"\\n=== TOP 10 CLIENTES PARA RETENCI√ìN INMEDIATA ===\\n\")\n#&gt; \n#&gt; === TOP 10 CLIENTES PARA RETENCI√ìN INMEDIATA ===\nprint(head(clientes_retencion, 10))\n#&gt;     cliente_id region  edad ingresos valor_cliente prob_churn transacciones_a√±o\n#&gt;          &lt;int&gt; &lt;char&gt; &lt;num&gt;    &lt;num&gt;         &lt;num&gt;      &lt;num&gt;             &lt;int&gt;\n#&gt;  1:         69 Centro    49   312277      761.9559      0.899                 1\n#&gt;  2:       9176 Centro    22    70610      406.0075      0.888                 2\n#&gt;  3:       6866    Sur    49    61726      274.0634      0.967                 1\n#&gt;  4:       3461    Sur    23   138172      269.4354      0.998                 2\n#&gt;  5:       8123  Oeste    49   140832      266.1725      0.705                 1\n#&gt;  6:       3497  Norte    39   102743      240.4186      0.849                 1\n#&gt;  7:       2847   Este    41    82017      216.5249      0.890                 2\n#&gt;  8:       2896   Este    21    83534      197.9756      0.836                 2\n#&gt;  9:       4247  Oeste    35    68037      175.5355      0.709                 1\n#&gt; 10:       9463  Norte    20    46169      164.3616      0.843                 2\n#&gt;     monto_total_a√±o satisfaccion engagement_score accion_recomendada\n#&gt;               &lt;num&gt;        &lt;num&gt;            &lt;num&gt;             &lt;char&gt;\n#&gt;  1:        11.56000          3.1             10.0   Incentivo_Compra\n#&gt;  2:       292.31936          3.5             10.0   Incentivo_Compra\n#&gt;  3:        55.99000          3.1             10.0   Incentivo_Compra\n#&gt;  4:       190.29448          4.3              9.3   Incentivo_Compra\n#&gt;  5:        42.78000          1.0              8.0    Mejora_Servicio\n#&gt;  6:       103.06000          2.4              6.8    Mejora_Servicio\n#&gt;  7:       169.53063          3.1             10.0   Incentivo_Compra\n#&gt;  8:        73.40943          4.7             10.0   Incentivo_Compra\n#&gt;  9:        49.41055          2.5              4.5    Mejora_Servicio\n#&gt; 10:       148.34431          2.3             10.0    Mejora_Servicio\n\n# An√°lisis de efectividad del modelo por segmento\nif(nrow(resultados_ml[!is.na(churn_flag)]) &gt; 0) {\n  efectividad_modelo &lt;- resultados_ml[!is.na(churn_flag),\n    .(\n      precision = sum(pred_churn == \"Si\" & churn == \"Si\") / sum(pred_churn == \"Si\"),\n      recall = sum(pred_churn == \"Si\" & churn == \"Si\") / sum(churn == \"Si\"),\n      accuracy = mean(pred_churn == churn),\n      clientes_evaluados = .N\n    ),\n    by = .(region, categoria_edad)\n  ][clientes_evaluados &gt;= 10]  # Solo segmentos con suficientes datos\n  \n  cat(\"\\n=== EFECTIVIDAD DEL MODELO POR SEGMENTO ===\\n\")\n  print(head(efectividad_modelo[order(-accuracy)]))\n}\n#&gt; \n#&gt; === EFECTIVIDAD DEL MODELO POR SEGMENTO ===\n#&gt;    region categoria_edad  precision     recall  accuracy clientes_evaluados\n#&gt;    &lt;char&gt;         &lt;fctr&gt;      &lt;num&gt;      &lt;num&gt;     &lt;num&gt;              &lt;int&gt;\n#&gt; 1:  Oeste         Senior 0.20000000 0.25000000 0.8478261                 46\n#&gt; 2:   Este         Adulto 0.22222222 0.33333333 0.8225806                124\n#&gt; 3:   Este          Joven 0.13333333 0.22222222 0.8148148                108\n#&gt; 4:  Norte         Adulto 0.19047619 0.30769231 0.8000000                130\n#&gt; 5:  Oeste         Adulto 0.08333333 0.07142857 0.7837838                111\n#&gt; 6:  Norte          Joven 0.07142857 0.09090909 0.7676768                 99",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#dtplyr-el-puente-entre-data.table-y-tidyverse",
    "href": "cap05-aplicaciones.html#dtplyr-el-puente-entre-data.table-y-tidyverse",
    "title": "12¬† Aplicaciones del Mundo Real",
    "section": "\n12.3 dtplyr: El Puente Entre data.table y tidyverse",
    "text": "12.3 dtplyr: El Puente Entre data.table y tidyverse\n\n12.3.1 1. Introducci√≥n y Casos de Uso\n\n\nif(requireNamespace(\"dtplyr\", quietly = TRUE) && requireNamespace(\"dplyr\", quietly = TRUE)) {\n  library(dtplyr)\n  library(dplyr, warn.conflicts = FALSE)\n  \n  # Convertir data.table a lazy_dt\n  clientes_lazy &lt;- lazy_dt(datos_clientes)\n  \n  # Workflow con sintaxis dplyr que se traduce a data.table\n  analisis_dtplyr &lt;- clientes_lazy %&gt;%\n    filter(edad &gt;= 25, edad &lt;= 65) %&gt;%\n    mutate(\n      categoria_valor = case_when(\n        valor_cliente &gt;= quantile(valor_cliente, 0.8) ~ \"Premium\",\n        valor_cliente &gt;= quantile(valor_cliente, 0.5) ~ \"Standard\",\n        TRUE ~ \"Basic\"\n      ),\n      riesgo_total = riesgo_churn + (5 - satisfaccion) / 5\n    ) %&gt;%\n    group_by(region, categoria_valor) %&gt;%\n    summarise(\n      clientes = n(),\n      valor_promedio = round(mean(valor_cliente), 2),\n      engagement_promedio = round(mean(engagement_score), 2),\n      churn_rate = round(mean(churn_flag) * 100, 1),\n      riesgo_promedio = round(mean(riesgo_total), 2),\n      .groups = 'drop'\n    ) %&gt;%\n    arrange(desc(valor_promedio)) %&gt;%\n    as.data.table()  # Convertir de vuelta a data.table\n  \n  print(\"Resultado del an√°lisis con dtplyr:\")\n  print(head(analisis_dtplyr, 10))\n  \n  # Ver el c√≥digo data.table generado\n  cat(\"\\n=== C√ìDIGO DATA.TABLE GENERADO POR DTPLYR ===\\n\")\n  codigo_generado &lt;- clientes_lazy %&gt;%\n    filter(edad &gt;= 25, edad &lt;= 65) %&gt;%\n    group_by(region) %&gt;%\n    summarise(valor_promedio = mean(valor_cliente), .groups = 'drop') %&gt;%\n    show_query()\n  \n} else {\n  cat(\"üí° Para usar dtplyr, instala los paquetes:\\n\")\n  cat(\"install.packages(c('dtplyr', 'dplyr'))\\n\")\n}\n#&gt; üí° Para usar dtplyr, instala los paquetes:\n#&gt; install.packages(c('dtplyr', 'dplyr'))\n\n\n12.3.2 2. Comparaci√≥n de Performance: dtplyr vs dplyr puro\n\n\nif(requireNamespace(\"dtplyr\", quietly = TRUE) && requireNamespace(\"dplyr\", quietly = TRUE)) {\n  library(microbenchmark)\n  \n  # Crear dataset m√°s grande para benchmark\n  datos_benchmark &lt;- rbindlist(replicate(5, datos_clientes, simplify = FALSE))\n  \n  # Operaci√≥n compleja para comparar\n  operacion_compleja &lt;- function(data, metodo) {\n    if(metodo == \"dplyr\") {\n      # dplyr puro sobre data.frame\n      as.data.frame(data) %&gt;%\n        filter(edad &gt;= 30, satisfaccion &gt;= 3) %&gt;%\n        group_by(region, categoria_ingresos) %&gt;%\n        summarise(\n          clientes = n(),\n          valor_total = sum(valor_cliente),\n          engagement_avg = mean(engagement_score),\n          .groups = 'drop'\n        ) %&gt;%\n        arrange(desc(valor_total))\n    } else if(metodo == \"dtplyr\") {\n      # dtplyr (sintaxis dplyr + motor data.table)\n      lazy_dt(data) %&gt;%\n        filter(edad &gt;= 30, satisfaccion &gt;= 3) %&gt;%\n        group_by(region, categoria_ingresos) %&gt;%\n        summarise(\n          clientes = n(),\n          valor_total = sum(valor_cliente),\n          engagement_avg = mean(engagement_score),\n          .groups = 'drop'\n        ) %&gt;%\n        arrange(desc(valor_total)) %&gt;%\n        as.data.table()\n    } else {\n      # data.table puro\n      data[\n        edad &gt;= 30 & satisfaccion &gt;= 3,\n        .(\n          clientes = .N,\n          valor_total = sum(valor_cliente),\n          engagement_avg = mean(engagement_score)\n        ),\n        by = .(region, categoria_ingresos)\n      ][order(-valor_total)]\n    }\n  }\n  \n  # Benchmark\n  benchmark_results &lt;- microbenchmark(\n    dplyr_puro = operacion_compleja(datos_benchmark, \"dplyr\"),\n    dtplyr = operacion_compleja(datos_benchmark, \"dtplyr\"),\n    data_table = operacion_compleja(datos_benchmark, \"data.table\"),\n    times = 10\n  )\n  \n  cat(\"=== BENCHMARK DE PERFORMANCE ===\\n\")\n  print(benchmark_results)\n  \n  # Calcular speedup\n  medias &lt;- aggregate(time ~ expr, data = benchmark_results, FUN = mean)\n  medias$speedup &lt;- medias$time[medias$expr == \"dplyr_puro\"] / medias$time\n  \n  cat(\"\\n=== SPEEDUP RELATIVO (vs dplyr puro) ===\\n\")\n  print(medias[, c(\"expr\", \"speedup\")])\n  \n} else {\n  cat(\"Benchmark requiere dtplyr y dplyr instalados\\n\")\n}\n#&gt; Benchmark requiere dtplyr y dplyr instalados",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#conexi√≥n-con-bases-de-datos-y-big-data",
    "href": "cap05-aplicaciones.html#conexi√≥n-con-bases-de-datos-y-big-data",
    "title": "12¬† Aplicaciones del Mundo Real",
    "section": "\n12.4 Conexi√≥n con Bases de Datos y Big Data",
    "text": "12.4 Conexi√≥n con Bases de Datos y Big Data\n\n12.4.1 1. Lectura/Escritura Eficiente con fread/fwrite\n\n\n# === FREAD: Lectura ultrarr√°pida ===\n# Crear archivo de ejemplo grande\narchivo_test &lt;- tempfile(fileext = \".csv\")\n\n# Generar datos sint√©ticos para el ejemplo\ndatos_grandes &lt;- data.table(\n  id = 1:100000,\n  timestamp = seq(as.POSIXct(\"2024-01-01\"), by = \"min\", length.out = 100000),\n  sensor_value = round(rnorm(100000, 50, 15), 2),\n  location = sample(c(\"Factory_A\", \"Factory_B\", \"Factory_C\"), 100000, replace = TRUE),\n  quality_score = round(runif(100000, 0.8, 1.0), 3),\n  batch_id = sample(1:1000, 100000, replace = TRUE)\n)\n\n# Escribir archivo\ncat(\"Escribiendo archivo de prueba...\\n\")\n#&gt; Escribiendo archivo de prueba...\ntiempo_write &lt;- system.time({\n  fwrite(datos_grandes, archivo_test, \n         nThread = getDTthreads(),\n         showProgress = FALSE)\n})\n\n# Informaci√≥n del archivo\ninfo_archivo &lt;- file.info(archivo_test)\ncat(\"Archivo creado:\", round(info_archivo$size / 1024^2, 2), \"MB\\n\")\n#&gt; Archivo creado: 4.06 MB\ncat(\"Tiempo de escritura:\", round(tiempo_write[3], 3), \"segundos\\n\")\n#&gt; Tiempo de escritura: 0.01 segundos\n\n# Lectura con diferentes configuraciones\ncat(\"\\n=== COMPARACI√ìN DE M√âTODOS DE LECTURA ===\\n\")\n#&gt; \n#&gt; === COMPARACI√ìN DE M√âTODOS DE LECTURA ===\n\n# 1. fread b√°sico\ntiempo_fread_basico &lt;- system.time({\n  datos_fread &lt;- fread(archivo_test, showProgress = FALSE)\n})\n\n# 2. fread optimizado\ntiempo_fread_opt &lt;- system.time({\n  datos_fread_opt &lt;- fread(\n    archivo_test,\n    nThread = getDTthreads(),\n    select = c(\"id\", \"timestamp\", \"sensor_value\", \"location\"),  # Solo columnas necesarias\n    colClasses = list(character = \"location\", numeric = c(\"sensor_value\")),\n    showProgress = FALSE\n  )\n})\n\n# 3. read.csv para comparaci√≥n\ntiempo_base_r &lt;- system.time({\n  datos_base &lt;- read.csv(archivo_test, stringsAsFactors = FALSE)\n})\n\ncat(\"fread b√°sico:\", round(tiempo_fread_basico[3], 3), \"segundos\\n\")\n#&gt; fread b√°sico: 0.006 segundos\ncat(\"fread optimizado:\", round(tiempo_fread_opt[3], 3), \"segundos\\n\")\n#&gt; fread optimizado: 0.004 segundos\ncat(\"read.csv (base R):\", round(tiempo_base_r[3], 3), \"segundos\\n\")\n#&gt; read.csv (base R): 0.098 segundos\ncat(\"Speedup fread vs base R:\", round(tiempo_base_r[3] / tiempo_fread_basico[3], 1), \"x\\n\")\n#&gt; Speedup fread vs base R: 16.3 x\n\n# Verificar que los datos son id√©nticos\ncat(\"Datos id√©nticos:\", identical(datos_fread$id, datos_fread_opt$id), \"\\n\")\n#&gt; Datos id√©nticos: TRUE\n\n# Limpiar\nunlink(archivo_test)\n\n\n12.4.2 2. Integraci√≥n con Bases de Datos\n\n\n# Ejemplo de integraci√≥n con bases de datos\nlibrary(DBI)\nlibrary(RSQLite)  # o RPostgreSQL, RMySQL, etc.\n\n# === SETUP DE CONEXI√ìN ===\n# Crear base de datos SQLite para el ejemplo\ncon &lt;- dbConnect(RSQLite::SQLite(), \":memory:\")\n\n# Escribir data.table a la base de datos\ndbWriteTable(con, \"clientes\", datos_clientes)\ndbWriteTable(con, \"transacciones\", transacciones_detalle)\n\n# === WORKFLOW H√çBRIDO: SQL + data.table ===\n\n# 1. Query inicial en SQL (aprovechar √≠ndices de DB)\nquery_sql &lt;- \"\n  SELECT c.cliente_id, c.region, c.edad, c.ingresos,\n         t.monto, t.fecha_transaccion, t.producto_categoria\n  FROM clientes c\n  JOIN transacciones t ON c.cliente_id = t.cliente_id\n  WHERE c.edad &gt;= 25 AND c.edad &lt;= 65\n    AND t.fecha_transaccion &gt;= '2024-01-01'\n\"\n\n# 2. Traer datos a data.table\ndatos_query &lt;- as.data.table(dbGetQuery(con, query_sql))\n\n# 3. An√°lisis complejo con data.table (m√°s r√°pido que SQL)\nanalisis_hibrido &lt;- datos_query[,\n  .(\n    transacciones_total = .N,\n    monto_total = sum(monto),\n    monto_promedio = round(mean(monto), 2),\n    categorias_distintas = uniqueN(producto_categoria),\n    primera_compra = min(fecha_transaccion),\n    ultima_compra = max(fecha_transaccion)\n  ),\n  by = .(cliente_id, region)\n][, `:=`(\n  dias_activo = as.numeric(as.Date(ultima_compra) - as.Date(primera_compra)) + 1,\n  frecuencia_compra = transacciones_total / pmax(as.numeric(as.Date(ultima_compra) - as.Date(primera_compra)) + 1, 1)\n)][order(-monto_total)]\n\n# 4. Escribir resultados de vuelta a DB (opcional)\ndbWriteTable(con, \"analisis_clientes\", analisis_hibrido, overwrite = TRUE)\n\n# 5. Verificaci√≥n\nresumen_db &lt;- dbGetQuery(con, \"SELECT COUNT(*) as clientes_analizados FROM analisis_clientes\")\ncat(\"Clientes analizados en DB:\", resumen_db$clientes_analizados, \"\\n\")\n\n# Cerrar conexi√≥n\ndbDisconnect(con)\n\n# === MEJORES PR√ÅCTICAS ===\n# 1. Usar SQL para filtros iniciales y joins simples\n# 2. Traer datos a data.table para an√°lisis complejos\n# 3. Aprovechar √≠ndices de DB para WHERE y JOIN\n# 4. Usar data.table para agregaciones complejas y feature engineering\n# 5. Escribir resultados finales de vuelta a DB si es necesario\n\n\n12.4.3 3. Integraci√≥n con Apache Arrow/Parquet\n\n\n# Ejemplo de integraci√≥n con ecosistema Arrow\nlibrary(arrow)\n\n# === ESCRITURA A PARQUET ===\n# Parquet es ultra-eficiente para datasets grandes\narchivo_parquet &lt;- tempfile(fileext = \".parquet\")\n\n# Escribir data.table a Parquet\nwrite_parquet(datos_clientes, archivo_parquet)\n\n# === LECTURA DESDE PARQUET ===\n# Leer directo a data.table\ndatos_parquet &lt;- read_parquet(archivo_parquet, as_data_frame = TRUE)\nsetDT(datos_parquet)  # Asegurar que es data.table\n\n# === DATASETS PARTICIONADOS ===\n# Para datasets muy grandes, usar particiones\ndirectorio_particionado &lt;- file.path(tempdir(), \"partitioned_data\")\ndir.create(directorio_particionado, showWarnings = FALSE, recursive = TRUE)\n\n# Particionar por regi√≥n - m√©todo m√°s robusto\nfor(region_name in unique(datos_clientes$region)) {\n  region_data &lt;- datos_clientes[region == region_name]\n  archivo_region &lt;- file.path(directorio_particionado, paste0(\"region_\", region_name, \".parquet\"))\n  write_parquet(region_data, archivo_region)\n}\n\n# Verificar que los archivos se crearon correctamente\narchivos_parquet &lt;- list.files(directorio_particionado, pattern = \"\\\\.parquet$\", full.names = TRUE)\ncat(\"Archivos Parquet creados:\", length(archivos_parquet), \"\\n\")\n\n# Leer dataset particionado solo si hay archivos v√°lidos\nif(length(archivos_parquet) &gt; 0) {\n  dataset &lt;- open_dataset(directorio_particionado)\n} else {\n  stop(\"No se pudieron crear archivos Parquet v√°lidos\")\n}\n\n# Query con pushdown de predicados (muy eficiente)\ntryCatch({\n  resultado_arrow &lt;- dataset %&gt;%\n    filter(edad &gt;= 30, satisfaccion &gt;= 4) %&gt;%\n    group_by(region) %&gt;%\n    summarise(\n      clientes = n(),\n      valor_promedio = mean(valor_cliente),\n      ingresos_promedio = mean(ingresos)\n    ) %&gt;%\n    collect() %&gt;%  # Traer a memoria\n    as.data.table()  # Convertir a data.table\n  \n  print(resultado_arrow)\n}, error = function(e) {\n  cat(\"Error en consulta Arrow:\", conditionMessage(e), \"\\n\")\n  cat(\"Usando m√©todo alternativo con data.table directo...\\n\")\n  \n  # Fallback: usar data.table directamente\n  resultado_arrow &lt;- datos_clientes[edad &gt;= 30 & satisfaccion &gt;= 4, .(\n    clientes = .N,\n    valor_promedio = mean(valor_cliente),\n    ingresos_promedio = mean(ingresos)\n  ), by = region]\n  \n  print(resultado_arrow)\n})\n\n# === VENTAJAS DEL WORKFLOW ARROW + DATA.TABLE ===\n# 1. Parquet es extremadamente eficiente en espacio\n# 2. Pushdown de predicados reduce transferencia de datos\n# 3. Compatibilidad con otros lenguajes (Python, Spark)\n# 4. data.table para an√°lisis final en R",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#casos-de-uso-industriales-reales",
    "href": "cap05-aplicaciones.html#casos-de-uso-industriales-reales",
    "title": "12¬† Aplicaciones del Mundo Real",
    "section": "\n12.5 Casos de Uso Industriales Reales",
    "text": "12.5 Casos de Uso Industriales Reales\n\n12.5.1 1. Sistema de Monitoreo IoT en Tiempo Real\n\n\n# === AN√ÅLISIS DE SENSORES IOT ===\n# Simular an√°lisis en tiempo real de sensores\n\n# Funci√≥n para procesar batch de datos de sensores\nprocesar_batch_sensores &lt;- function(datos_sensores, ventana_horas = 1) {\n  # An√°lisis de anomal√≠as en tiempo real\n  datos_sensores[,\n    `:=`(\n      temp_anomaly = abs(temperatura - mean(temperatura)) &gt; 2 * sd(temperatura),\n      humidity_anomaly = abs(humedad - mean(humedad)) &gt; 2 * sd(humedad),\n      battery_critical = nivel_bateria &lt; 15\n    ),\n    by = .(sensor_id, fecha)\n  ]\n  \n  # Resumen por sensor y hora\n  resumen_sensores &lt;- datos_sensores[,\n    .(\n      temp_promedio = round(mean(temperatura), 2),\n      temp_min = min(temperatura),\n      temp_max = max(temperatura),\n      humedad_promedio = round(mean(humedad), 1),\n      presion_promedio = round(mean(presion), 1),\n      movimientos_detectados = sum(movimiento_detectado),\n      anomalias_temp = sum(temp_anomaly),\n      anomalias_humedad = sum(humidity_anomaly),\n      alertas_bateria = sum(battery_critical),\n      lecturas_total = .N,\n      uptime_pct = round((1 - sum(is.na(temperatura)) / .N) * 100, 1)\n    ),\n    by = .(sensor_id, fecha, hora)\n  ][, `:=`(\n    estado_sensor = fcase(\n      alertas_bateria &gt; 0, \"CR√çTICO\",\n      anomalias_temp + anomalias_humedad &gt; 5, \"ADVERTENCIA\",\n      uptime_pct &lt; 95, \"DEGRADADO\",\n      default = \"NORMAL\"\n    ),\n    score_salud = pmin(100, uptime_pct - (anomalias_temp + anomalias_humedad) * 5 - alertas_bateria * 20)\n  )]\n  \n  return(resumen_sensores)\n}\n\n# Procesar datos de sensores\nanalisis_sensores &lt;- procesar_batch_sensores(sensores_iot)\n\n# Dashboard de alertas cr√≠ticas\nalertas_criticas &lt;- analisis_sensores[\n  estado_sensor %in% c(\"CR√çTICO\", \"ADVERTENCIA\"),\n  .(\n    sensor_id, fecha, hora,\n    estado_sensor, score_salud,\n    anomalias_temp, anomalias_humedad, alertas_bateria,\n    accion_requerida = fcase(\n      alertas_bateria &gt; 0, \"Cambiar_Bater√≠a\",\n      anomalias_temp &gt; 3, \"Revisar_Sensor_Temperatura\",\n      anomalias_humedad &gt; 3, \"Revisar_Sensor_Humedad\",\n      default = \"Inspecci√≥n_General\"\n    )\n  )\n][order(fecha, hora, -score_salud)]\n\ncat(\"=== ALERTAS CR√çTICAS DEL SISTEMA IOT ===\\n\")\n#&gt; === ALERTAS CR√çTICAS DEL SISTEMA IOT ===\nprint(head(alertas_criticas, 15))\n#&gt;     sensor_id      fecha  hora estado_sensor score_salud anomalias_temp\n#&gt;        &lt;char&gt;     &lt;Date&gt; &lt;int&gt;        &lt;char&gt;       &lt;num&gt;          &lt;int&gt;\n#&gt; 1: SENSOR_091 2024-01-22    20       CR√çTICO          80              0\n#&gt; 2: SENSOR_078 2024-01-24     4       CR√çTICO          80              0\n#&gt; 3: SENSOR_030 2024-01-26    19       CR√çTICO          80              0\n#&gt; 4: SENSOR_032 2024-01-31     7       CR√çTICO          80              0\n#&gt;    anomalias_humedad alertas_bateria accion_requerida\n#&gt;                &lt;int&gt;           &lt;int&gt;           &lt;char&gt;\n#&gt; 1:                 0               1  Cambiar_Bater√≠a\n#&gt; 2:                 0               1  Cambiar_Bater√≠a\n#&gt; 3:                 0               1  Cambiar_Bater√≠a\n#&gt; 4:                 0               1  Cambiar_Bater√≠a\n\n# Estad√≠sticas de salud del sistema\nsalud_sistema &lt;- analisis_sensores[,\n  .(\n    sensores_activos = uniqueN(sensor_id),\n    sensores_criticos = uniqueN(sensor_id[estado_sensor == \"CR√çTICO\"]),\n    sensores_degradados = uniqueN(sensor_id[estado_sensor %in% c(\"ADVERTENCIA\", \"DEGRADADO\")]),\n    score_salud_promedio = round(mean(score_salud), 1),\n    anomalias_totales = sum(anomalias_temp + anomalias_humedad),\n    uptime_sistema = round(mean(uptime_pct), 1)\n  ),\n  by = .(fecha)\n]\n\ncat(\"\\n=== SALUD GENERAL DEL SISTEMA ===\\n\")\n#&gt; \n#&gt; === SALUD GENERAL DEL SISTEMA ===\nprint(head(salud_sistema))\n#&gt;         fecha sensores_activos sensores_criticos sensores_degradados\n#&gt;        &lt;Date&gt;            &lt;int&gt;             &lt;int&gt;               &lt;int&gt;\n#&gt; 1: 2023-12-31               12                 0                   0\n#&gt; 2: 2024-01-01              100                 0                   0\n#&gt; 3: 2024-01-02              100                 0                   0\n#&gt; 4: 2024-01-03              100                 0                   0\n#&gt; 5: 2024-01-04              100                 0                   0\n#&gt; 6: 2024-01-05              100                 0                   0\n#&gt;    score_salud_promedio anomalias_totales uptime_sistema\n#&gt;                   &lt;num&gt;             &lt;int&gt;          &lt;num&gt;\n#&gt; 1:                   NA                NA            100\n#&gt; 2:                  100                 0            100\n#&gt; 3:                  100                 0            100\n#&gt; 4:                  100                 0            100\n#&gt; 5:                  100                 0            100\n#&gt; 6:                  100                 0            100\n\n\n12.5.2 2. Sistema de Recomendaciones E-commerce\n\n\n# === MOTOR DE RECOMENDACIONES ===\n# Sistema basado en comportamiento de compra\n\n# Funci√≥n para calcular similaridad entre clientes\ncalcular_recomendaciones &lt;- function(transacciones_dt, cliente_target, top_n = 5) {\n  \n  # Matriz de compras por cliente-categor√≠a\n  matriz_compras &lt;- transacciones_dt[,\n    .(\n      total_comprado = sum(monto_final),\n      frecuencia = .N\n    ),\n    by = .(cliente_id, producto_categoria)\n  ]\n  \n  # Perfil del cliente target\n  perfil_target &lt;- matriz_compras[cliente_id == cliente_target]\n  \n  if(nrow(perfil_target) == 0) {\n    return(data.table(mensaje = \"Cliente no encontrado\"))\n  }\n  \n  # Encontrar clientes similares\n  clientes_similares &lt;- matriz_compras[\n    producto_categoria %in% perfil_target$producto_categoria & \n    cliente_id != cliente_target,\n    .(\n      overlap_categorias = .N,\n      valor_similar = sum(total_comprado)\n    ),\n    by = cliente_id\n  ][overlap_categorias &gt;= 2][order(-overlap_categorias, -valor_similar)]\n  \n  # Recomendaciones basadas en clientes similares\n  if(nrow(clientes_similares) &gt; 0) {\n    recomendaciones &lt;- matriz_compras[\n      cliente_id %in% head(clientes_similares$cliente_id, 20) &\n      !producto_categoria %in% perfil_target$producto_categoria,\n      .(\n        score_recomendacion = sum(total_comprado),\n        clientes_que_compran = .N,\n        frecuencia_promedio = round(mean(frecuencia), 1)\n      ),\n      by = producto_categoria\n    ][clientes_que_compran &gt;= 3][order(-score_recomendacion)][1:top_n]\n    \n    return(recomendaciones)\n  } else {\n    return(data.table(mensaje = \"No hay suficientes datos para recomendaciones\"))\n  }\n}\n\n# Funci√≥n para an√°lisis de mercado\nanalizar_tendencias_mercado &lt;- function(transacciones_dt, periodo_dias = 30) {\n  fecha_corte &lt;- max(transacciones_dt$fecha_transaccion) - periodo_dias\n  \n  tendencias &lt;- transacciones_dt[\n    fecha_transaccion &gt;= fecha_corte,\n    .(\n      ventas_recientes = sum(monto_final),\n      transacciones_recientes = .N,\n      clientes_unicos = uniqueN(cliente_id),\n      ticket_promedio = round(mean(monto_final), 2),\n      crecimiento_semanal = .N / (periodo_dias / 7)\n    ),\n    by = producto_categoria\n  ][order(-ventas_recientes)]\n  \n  # Calcular m√©tricas adicionales\n  tendencias[, `:=`(\n    penetracion_mercado = round((clientes_unicos / uniqueN(transacciones_dt$cliente_id)) * 100, 1),\n    velocidad_venta = round(transacciones_recientes / periodo_dias, 2),\n    categoria_trend = fcase(\n      crecimiento_semanal &gt; quantile(crecimiento_semanal, 0.75), \"üìà CRECIENTE\",\n      crecimiento_semanal &lt; quantile(crecimiento_semanal, 0.25), \"üìâ DECLINANTE\",\n      default = \"‚û°Ô∏è ESTABLE\"\n    )\n  )]\n  \n  return(tendencias)\n}\n\n# Ejecutar an√°lisis de recomendaciones\ncliente_ejemplo &lt;- datos_clientes[sample(.N, 1), cliente_id]\nrecomendaciones &lt;- calcular_recomendaciones(transacciones_detalle, cliente_ejemplo)\n\ncat(\"=== RECOMENDACIONES PARA CLIENTE\", cliente_ejemplo, \"===\\n\")\n#&gt; === RECOMENDACIONES PARA CLIENTE 3450 ===\nprint(recomendaciones)\n#&gt;    producto_categoria score_recomendacion clientes_que_compran\n#&gt;                &lt;char&gt;               &lt;num&gt;                &lt;int&gt;\n#&gt; 1:        Electronics            2412.048                   16\n#&gt; 2:              Books            1472.585                   10\n#&gt; 3:             Beauty            1152.812                   15\n#&gt; 4:               &lt;NA&gt;                  NA                   NA\n#&gt; 5:               &lt;NA&gt;                  NA                   NA\n#&gt;    frecuencia_promedio\n#&gt;                  &lt;num&gt;\n#&gt; 1:                 1.4\n#&gt; 2:                 1.5\n#&gt; 3:                 1.2\n#&gt; 4:                  NA\n#&gt; 5:                  NA\n\n# An√°lisis de tendencias de mercado\ntendencias_mercado &lt;- analizar_tendencias_mercado(transacciones_detalle, 60)\n\ncat(\"\\n=== TENDENCIAS DE MERCADO (√∫ltimos 60 d√≠as) ===\\n\")\n#&gt; \n#&gt; === TENDENCIAS DE MERCADO (√∫ltimos 60 d√≠as) ===\nprint(tendencias_mercado)\n#&gt;    producto_categoria ventas_recientes transacciones_recientes clientes_unicos\n#&gt;                &lt;char&gt;            &lt;num&gt;                   &lt;int&gt;           &lt;int&gt;\n#&gt; 1:             Sports         59738.74                     728             696\n#&gt; 2:              Books         57747.86                     673             658\n#&gt; 3:               Home         57641.77                     700             678\n#&gt; 4:           Clothing         55649.79                     723             699\n#&gt; 5:             Beauty         55388.89                     680             662\n#&gt; 6:        Electronics         52302.97                     689             663\n#&gt;    ticket_promedio crecimiento_semanal penetracion_mercado velocidad_venta\n#&gt;              &lt;num&gt;               &lt;num&gt;               &lt;num&gt;           &lt;num&gt;\n#&gt; 1:           82.06            84.93333                 7.0           12.13\n#&gt; 2:           85.81            78.51667                 6.6           11.22\n#&gt; 3:           82.35            81.66667                 6.8           11.67\n#&gt; 4:           76.97            84.35000                 7.0           12.05\n#&gt; 5:           81.45            79.33333                 6.7           11.33\n#&gt; 6:           75.91            80.38333                 6.7           11.48\n#&gt;    categoria_trend\n#&gt;             &lt;char&gt;\n#&gt; 1:    üìà CRECIENTE\n#&gt; 2:   üìâ DECLINANTE\n#&gt; 3:       ‚û°Ô∏è ESTABLE\n#&gt; 4:    üìà CRECIENTE\n#&gt; 5:   üìâ DECLINANTE\n#&gt; 6:       ‚û°Ô∏è ESTABLE\n\n# An√°lisis de cohorstes de clientes\nanalisis_cohortes &lt;- transacciones_detalle[,\n  .(\n    primera_compra = min(fecha_transaccion),\n    ultima_compra = max(fecha_transaccion),\n    valor_total = sum(monto_final),\n    frecuencia_compra = .N\n  ),\n  by = cliente_id\n][, `:=`(\n  cohorte_mes = format(primera_compra, \"%Y-%m\"),\n  dias_como_cliente = as.numeric(ultima_compra - primera_compra) + 1\n)][, `:=`(\n  valor_por_dia = round(valor_total / pmax(dias_como_cliente, 1), 2)\n)][,\n  .(\n    clientes_cohorte = .N,\n    valor_promedio_cohorte = round(mean(valor_total), 2),\n    dias_retencion_promedio = round(mean(dias_como_cliente), 1),\n    valor_por_dia_promedio = round(mean(valor_por_dia), 2)\n  ),\n  by = cohorte_mes\n][order(cohorte_mes)]\n\ncat(\"\\n=== AN√ÅLISIS DE COHORTES POR MES ===\\n\")\n#&gt; \n#&gt; === AN√ÅLISIS DE COHORTES POR MES ===\nprint(head(analisis_cohortes, 12))\n#&gt;     cohorte_mes clientes_cohorte valor_promedio_cohorte dias_retencion_promedio\n#&gt;          &lt;char&gt;            &lt;int&gt;                  &lt;num&gt;                   &lt;num&gt;\n#&gt;  1:     2023-01             1919                 480.73                   576.0\n#&gt;  2:     2023-02             1419                 468.32                   540.2\n#&gt;  3:     2023-03             1254                 449.64                   513.0\n#&gt;  4:     2023-04             1018                 434.10                   479.9\n#&gt;  5:     2023-05              797                 418.61                   458.0\n#&gt;  6:     2023-06              640                 400.50                   418.7\n#&gt;  7:     2023-07              573                 373.78                   393.7\n#&gt;  8:     2023-08              451                 354.58                   356.5\n#&gt;  9:     2023-09              366                 342.35                   336.0\n#&gt; 10:     2023-10              310                 326.32                   289.0\n#&gt; 11:     2023-11              218                 323.99                   274.6\n#&gt; 12:     2023-12              192                 277.01                   260.5\n#&gt;     valor_por_dia_promedio\n#&gt;                      &lt;num&gt;\n#&gt;  1:                   1.71\n#&gt;  2:                   1.81\n#&gt;  3:                   2.11\n#&gt;  4:                   2.59\n#&gt;  5:                   2.89\n#&gt;  6:                   2.14\n#&gt;  7:                   4.20\n#&gt;  8:                   3.89\n#&gt;  9:                   5.20\n#&gt; 10:                   7.84\n#&gt; 11:                   6.48\n#&gt; 12:                   5.16",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "cap05-aplicaciones.html#ejercicio-final-aplicaci√≥n-completa-de-producci√≥n",
    "href": "cap05-aplicaciones.html#ejercicio-final-aplicaci√≥n-completa-de-producci√≥n",
    "title": "12¬† Aplicaciones del Mundo Real",
    "section": "\n12.6 Ejercicio Final: Aplicaci√≥n Completa de Producci√≥n",
    "text": "12.6 Ejercicio Final: Aplicaci√≥n Completa de Producci√≥n\n\n\n\n\n\n\nüèãÔ∏è Ejercicio 10: Sistema de Analytics Empresarial\n\n\n\nDise√±a un sistema completo que integre:\n\n\nPipeline de datos con data.table\n\nDashboard Shiny interactivo\n\nModelo predictivo con tidymodels\nAlertas autom√°ticas\nReportes ejecutivos\n\nUsa los datasets de clientes, transacciones y sensores como base.\n\n\n\n\n\n\n\n\nüí° Soluci√≥n del Ejercicio 10\n\n\n\n\n\n\n# === PIPELINE DE DATOS UNIFICADO ===\ncrear_pipeline_analytics &lt;- function() {\n  \n  # 1. CONSOLIDACI√ìN DE DATOS\n  pipeline_data &lt;- list()\n  \n  # M√©tricas de clientes\n  pipeline_data$clientes_kpis &lt;- datos_clientes[,\n    .(\n      clientes_total = .N,\n      valor_total = sum(valor_cliente),\n      churn_rate = round(mean(churn_flag) * 100, 1),\n      satisfaccion_promedio = round(mean(satisfaccion), 2),\n      engagement_promedio = round(mean(engagement_score), 2)\n    ),\n    by = .(region, categoria_ingresos)\n  ]\n  \n  # M√©tricas de transacciones\n  pipeline_data$transacciones_kpis &lt;- transacciones_detalle[\n    fecha_transaccion &gt;= Sys.Date() - 90,  # √öltimos 90 d√≠as\n    .(\n      revenue_total = sum(monto_final),\n      transacciones_total = .N,\n      ticket_promedio = round(mean(monto_final), 2),\n      clientes_activos = uniqueN(cliente_id),\n      productos_vendidos = sum(1 - es_devolucion)\n    ),\n    by = .(mes = month(fecha_transaccion), producto_categoria)\n  ]\n  \n  # Estado de sensores IoT\n  pipeline_data$sensores_status &lt;- sensores_iot[\n    fecha &gt;= Sys.Date() - 7,  # √öltima semana\n    .(\n      sensores_activos = uniqueN(sensor_id),\n      alertas_criticas = sum(alerta_temperatura + alerta_bateria + alerta_humedad),\n      uptime_promedio = round(mean(1 - is.na(temperatura)) * 100, 1),\n      score_salud = round(mean(100 - alerta_temperatura * 20 - alerta_bateria * 30), 1)\n    ),\n    by = fecha\n  ]\n  \n  # 2. ALERTAS AUTOM√ÅTICAS\n  alertas &lt;- list()\n  \n  # Alerta de churn elevado\n  alertas$churn_critico &lt;- pipeline_data$clientes_kpis[\n    churn_rate &gt; 15,\n    .(region, categoria_ingresos, churn_rate, valor_total)\n  ]\n  \n  # Alerta de ca√≠da de revenue\n  alertas$revenue_bajo &lt;- pipeline_data$transacciones_kpis[,\n    .(revenue_cambio = (revenue_total / shift(revenue_total, 1) - 1) * 100),\n    by = producto_categoria\n  ][revenue_cambio &lt; -10 & !is.na(revenue_cambio)]\n  \n  # Alerta de sensores cr√≠ticos\n  alertas$sensores_criticos &lt;- pipeline_data$sensores_status[\n    score_salud &lt; 80 | alertas_criticas &gt; 10\n  ]\n  \n  # 3. DASHBOARD SUMMARY\n  dashboard_summary &lt;- list(\n    kpis_generales = list(\n      clientes_total = sum(pipeline_data$clientes_kpis$clientes_total),\n      revenue_total = sum(pipeline_data$transacciones_kpis$revenue_total),\n      churn_promedio = round(weighted.mean(pipeline_data$clientes_kpis$churn_rate, \n                                          pipeline_data$clientes_kpis$clientes_total), 1),\n      alertas_activas = length(alertas$churn_critico) + nrow(alertas$revenue_bajo) + nrow(alertas$sensores_criticos)\n    ),\n    alertas_activas = alertas,\n    datos_pipeline = pipeline_data\n  )\n  \n  return(dashboard_summary)\n}\n\n# Ejecutar pipeline\nsistema_analytics &lt;- crear_pipeline_analytics()\n\n# === REPORTE EJECUTIVO AUTOM√ÅTICO ===\ngenerar_reporte_ejecutivo &lt;- function(analytics_data) {\n  cat(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\n\")\n  cat(\"                    üìä REPORTE EJECUTIVO EMPRESARIAL                     \\n\")\n  cat(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\n\\n\")\n  \n  kpis &lt;- analytics_data$kpis_generales\n  alertas &lt;- analytics_data$alertas_activas\n  \n  # KPIs principales\n  cat(\"üìà INDICADORES CLAVE DE RENDIMIENTO:\\n\")\n  cat(\"   ‚Ä¢ Total de Clientes:\", scales::comma(kpis$clientes_total), \"\\n\")\n  cat(\"   ‚Ä¢ Revenue Total:\", scales::dollar(kpis$revenue_total), \"\\n\")\n  cat(\"   ‚Ä¢ Tasa de Churn Promedio:\", kpis$churn_promedio, \"%\\n\")\n  cat(\"   ‚Ä¢ Alertas Activas:\", kpis$alertas_activas, \"\\n\\n\")\n  \n  # Estado de alertas\n  cat(\"üö® ESTADO DE ALERTAS:\\n\")\n  cat(\"   ‚Ä¢ Regiones con Churn Cr√≠tico:\", nrow(alertas$churn_critico), \"\\n\")\n  cat(\"   ‚Ä¢ Productos con Revenue Bajo:\", nrow(alertas$revenue_bajo), \"\\n\")\n  cat(\"   ‚Ä¢ Sensores en Estado Cr√≠tico:\", nrow(alertas$sensores_criticos), \"\\n\\n\")\n  \n  # Recomendaciones autom√°ticas\n  cat(\"üí° RECOMENDACIONES AUTOM√ÅTICAS:\\n\")\n  if(nrow(alertas$churn_critico) &gt; 0) {\n    cat(\"   ‚Ä¢ ACCI√ìN INMEDIATA: Implementar programa de retenci√≥n en regiones cr√≠ticas\\n\")\n  }\n  if(nrow(alertas$revenue_bajo) &gt; 0) {\n    cat(\"   ‚Ä¢ AN√ÅLISIS REQUERIDO: Investigar ca√≠da de ventas en productos espec√≠ficos\\n\")\n  }\n  if(nrow(alertas$sensores_criticos) &gt; 0) {\n    cat(\"   ‚Ä¢ MANTENIMIENTO: Revisar sensores con bajo score de salud\\n\")\n  }\n  if(kpis$alertas_activas == 0) {\n    cat(\"   ‚Ä¢ ‚úÖ SISTEMA SALUDABLE: Todos los indicadores dentro de rangos normales\\n\")\n  }\n  \n  cat(\"\\n‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\n\")\n  cat(\"Reporte generado autom√°ticamente:\", format(Sys.time(), \"%Y-%m-%d %H:%M:%S\"), \"\\n\")\n  cat(\"‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\\n\")\n}\n\n# Generar reporte\ngenerar_reporte_ejecutivo(sistema_analytics)\n#&gt; ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n#&gt;                     üìä REPORTE EJECUTIVO EMPRESARIAL                     \n#&gt; ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n#&gt; \n#&gt; üìà INDICADORES CLAVE DE RENDIMIENTO:\n#&gt;    ‚Ä¢ Total de Clientes: 10,000 \n#&gt;    ‚Ä¢ Revenue Total: $0 \n#&gt;    ‚Ä¢ Tasa de Churn Promedio: 12.1 %\n#&gt;    ‚Ä¢ Alertas Activas: 4 \n#&gt; \n#&gt; üö® ESTADO DE ALERTAS:\n#&gt;    ‚Ä¢ Regiones con Churn Cr√≠tico: 0 \n#&gt;    ‚Ä¢ Productos con Revenue Bajo: 0 \n#&gt;    ‚Ä¢ Sensores en Estado Cr√≠tico: 0 \n#&gt; \n#&gt; üí° RECOMENDACIONES AUTOM√ÅTICAS:\n#&gt; \n#&gt; ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n#&gt; Reporte generado autom√°ticamente: 2025-08-21 01:32:29 \n#&gt; ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\n\n# === M√âTRICAS DETALLADAS ===\ncat(\"\\nüìä DETALLE DE ALERTAS CR√çTICAS:\\n\\n\")\n#&gt; \n#&gt; üìä DETALLE DE ALERTAS CR√çTICAS:\n\nif(nrow(sistema_analytics$alertas_activas$churn_critico) &gt; 0) {\n  cat(\"üî¥ CHURN CR√çTICO POR REGI√ìN:\\n\")\n  print(sistema_analytics$alertas_activas$churn_critico)\n  cat(\"\\n\")\n}\n\nif(nrow(sistema_analytics$alertas_activas$revenue_bajo) &gt; 0) {\n  cat(\"üìâ PRODUCTOS CON REVENUE BAJO:\\n\")\n  print(head(sistema_analytics$alertas_activas$revenue_bajo))\n  cat(\"\\n\")\n}\n\nif(nrow(sistema_analytics$alertas_activas$sensores_criticos) &gt; 0) {\n  cat(\"‚ö†Ô∏è SENSORES EN ESTADO CR√çTICO:\\n\")\n  print(head(sistema_analytics$alertas_activas$sensores_criticos))\n}\n\nComponentes del Sistema Completo:\n\n\nPipeline de Datos: Consolidaci√≥n autom√°tica de m√∫ltiples fuentes\n\nSistema de Alertas: Detecci√≥n autom√°tica de anomal√≠as\n\nDashboard KPIs: M√©tricas en tiempo real\n\nReporte Ejecutivo: Generaci√≥n autom√°tica de insights\n\nRecomendaciones: Acciones basadas en datos\n\nEscalabilidad: Modular y extensible\n\n\n\n\n\n\n\n\n\n\n\nüéØ Puntos Clave de Este Cap√≠tulo\n\n\n\n\n\nShiny + data.table = Aplicaciones web ultrarr√°pidas y responsivas\n\ntidymodels se integra perfectamente con data.table para ML robusto\n\ndtplyr facilita la transici√≥n desde dplyr manteniendo performance\n\nfread/fwrite son las herramientas m√°s r√°pidas de R para I/O\n\nBases de datos + data.table = Workflow h√≠brido √≥ptimo\n\nCasos reales demuestran la versatilidad industrial de data.table\n\nSistemas completos integran m√∫ltiples componentes de forma modular\n\n\n\nHas completado tu formaci√≥n integral en aplicaciones del mundo real con data.table. Ahora tienes las herramientas para construir sistemas completos de analytics empresarial de nivel industrial.",
    "crumbs": [
      "**M√≥dulo 5**: Integraci√≥n con el Ecosistema R",
      "<span class='chapter-number'>12</span>¬† <span class='chapter-title'>Aplicaciones del Mundo Real</span>"
    ]
  },
  {
    "objectID": "conclusion.html",
    "href": "conclusion.html",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "",
    "text": "Tu Transformaci√≥n: De Principiante a Experto\n¬°Felicitaciones! Has completado un viaje transformador en el mundo de data.table. Reflexionemos sobre lo que has logrado:",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#tu-transformaci√≥n-de-principiante-a-experto",
    "href": "conclusion.html#tu-transformaci√≥n-de-principiante-a-experto",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "",
    "text": "Antes de este tutorial:\n\nQuiz√°s conoc√≠as data.frame b√°sico o dplyr\n\nLas operaciones con datos grandes te tomaban minutos u horas\nEl c√≥digo de manipulaci√≥n de datos era verbose y dif√≠cil de mantener\nAhora dominas:\n\n\nFundamentos S√≥lidos\nT√©cnicas Avanzadas\nPerformance & Optimizaci√≥n\nIntegraci√≥n Ecosistema\n\n\n\n\n‚úÖ Sintaxis DT[i, j, by]: El coraz√≥n de data.table\n‚úÖ Modificaci√≥n por referencia: Poder de := sin copias de memoria\n‚úÖ S√≠mbolos especiales: .N, .SD, .I, .GRP como herramientas avanzadas\n‚úÖ Encadenamiento: Operaciones fluidas y legibles\n\n\n\n\n‚úÖ Rolling joins: Para an√°lisis temporal y series financieras\n‚úÖ Non-equi joins: Uniones basadas en rangos e inequidades\n‚úÖ Reshape avanzado: melt() y dcast() para transformaciones complejas\n‚úÖ Window functions: An√°lisis temporal sofisticado\n\n\n\n\n‚úÖ Keys e √≠ndices: Aceleraci√≥n dram√°tica en datasets grandes\n‚úÖ Threading: Aprovechar m√∫ltiples n√∫cleos autom√°ticamente\n‚úÖ Benchmarking: Medir y optimizar c√≥digo sistem√°ticamente\n‚úÖ Best practices: Do‚Äôs y Don‚Äôts para c√≥digo profesional\n\n\n\n\n‚úÖ ggplot2: Visualizaciones profesionales\n‚úÖ Shiny: Dashboards reactivos ultra-r√°pidos\n‚úÖ tidymodels: Machine learning workflows\n‚úÖ dtplyr: Lo mejor de ambos mundos",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#el-impacto-real-en-tu-trabajo",
    "href": "conclusion.html#el-impacto-real-en-tu-trabajo",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "El Impacto Real en tu Trabajo",
    "text": "El Impacto Real en tu Trabajo\nAntes vs.¬†Despu√©s: Un Ejemplo Concreto\n\n# ANTES: C√≥digo t√≠pico de R base/dplyr (simulado)\ncodigo_antes &lt;- '\n# M√∫ltiples pasos, copias de memoria, c√≥digo verbose\ndf_filtered &lt;- df[df$category %in% c(\"A\", \"B\") & df$year == 2024, ]\ndf_summary &lt;- aggregate(value ~ region + product, df_filtered, mean)\ndf_ranked &lt;- df_summary[order(-df_summary$value), ]\ndf_top10 &lt;- head(df_ranked, 10)\n'\n\n# AHORA: Tu c√≥digo data.table experto\nset.seed(123)\ndatos_demo &lt;- data.table(\n  category = sample(c(\"A\", \"B\", \"C\"), 1000, replace = TRUE),\n  year = sample(2022:2024, 1000, replace = TRUE),\n  region = sample(c(\"Norte\", \"Sur\", \"Este\", \"Oeste\"), 1000, replace = TRUE),\n  product = sample(c(\"P1\", \"P2\", \"P3\", \"P4\"), 1000, replace = TRUE),\n  value = round(rnorm(1000, 100, 20), 2)\n)\n\n# Una l√≠nea elegante y eficiente\nresultado_experto &lt;- datos_demo[\n  category %in% c(\"A\", \"B\") & year == 2024,\n  .(avg_value = mean(value)), \n  by = .(region, product)\n][order(-avg_value)][1:10]\n\nprint(resultado_experto)\n#&gt;     region product avg_value\n#&gt;     &lt;char&gt;  &lt;char&gt;     &lt;num&gt;\n#&gt;  1:    Sur      P2  113.6217\n#&gt;  2:  Oeste      P2  109.0908\n#&gt;  3:  Norte      P1  106.2233\n#&gt;  4:  Oeste      P3  103.4631\n#&gt;  5:   Este      P4  102.4247\n#&gt;  6:   Este      P1  102.0107\n#&gt;  7:  Norte      P3  101.4153\n#&gt;  8:  Norte      P2  101.2600\n#&gt;  9:    Sur      P1  101.0940\n#&gt; 10:    Sur      P3  100.8458\n\nBeneficios Cuantificables\n\n# Simulaci√≥n de mejoras t√≠picas al adoptar data.table\nmejoras &lt;- data.table(\n  Aspecto = c(\n    \"Velocidad de procesamiento\",\n    \"Uso de memoria\", \n    \"L√≠neas de c√≥digo\",\n    \"Tiempo de desarrollo\",\n    \"Mantenibilidad\"\n  ),\n  Antes = c(\"10 min\", \"2 GB\", \"50 l√≠neas\", \"2 horas\", \"Dif√≠cil\"),\n  Despues = c(\"30 seg\", \"500 MB\", \"10 l√≠neas\", \"30 min\", \"F√°cil\"),\n  Mejora = c(\"20x m√°s r√°pido\", \"75% menos memoria\", \"80% menos c√≥digo\", \n             \"4x m√°s r√°pido\", \"Significativamente mejor\")\n)\n\nkable(mejoras, caption = \"Impacto t√≠pico de adoptar data.table\")\n\n\nImpacto t√≠pico de adoptar data.table\n\n\n\n\n\n\n\nAspecto\nAntes\nDespues\nMejora\n\n\n\nVelocidad de procesamiento\n10 min\n30 seg\n20x m√°s r√°pido\n\n\nUso de memoria\n2 GB\n500 MB\n75% menos memoria\n\n\nL√≠neas de c√≥digo\n50 l√≠neas\n10 l√≠neas\n80% menos c√≥digo\n\n\nTiempo de desarrollo\n2 horas\n30 min\n4x m√°s r√°pido\n\n\nMantenibilidad\nDif√≠cil\nF√°cil\nSignificativamente mejor",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#recursos-para-continuar-aprendiendo",
    "href": "conclusion.html#recursos-para-continuar-aprendiendo",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "Recursos para Continuar Aprendiendo",
    "text": "Recursos para Continuar Aprendiendo\n1. Documentaci√≥n y Referencias Oficiales\n\n\nüìö Vi√±etas oficiales: browseVignettes(\"data.table\") en R\n\nüìñ Manual completo: CRAN data.table PDF\n\n\nüåê Wiki del proyecto: data.table Wiki\n\n\nüí° Articles collection: Community Articles\n\n2. Comunidad y Soporte\n\n\nüí¨ Stack Overflow: Tag [data.table] - comunidad muy activa\n\nüêõ GitHub Issues: Reportar bugs y pedir features\n\n\nüìß Mailing list: datatable-help@lists.r-forge.r-project.org\n\n\nüê¶ Twitter: Sigue @rdatatable para actualizaciones\n3. Recursos de Aprendizaje Avanzado\n\n\n\n\n\n\nüìö Lecturas Recomendadas\n\n\n\n\n\nAdvanced R - Para entender R a profundidad\n\nR for Data Science - Contexto del ecosistema\n\nData.table in Action - Casos de uso reales\n\nPerformance comparisons - Benchmarks detallados\n\n\n\n4. Datasets para Practicar\n\n# Datasets grandes para practicar\nlibrary(data.table)\n\n# 1. NYC Taxi Data (varios GB)\n# Descarga desde: https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n\n# 2. Flight data\ninstall.packages(\"nycflights13\")\nlibrary(nycflights13)\nflights_dt &lt;- as.data.table(flights)\n\n# 3. Datos financieros\ninstall.packages(\"quantmod\")\nlibrary(quantmod)\n# getSymbols() para datos de acciones\n\n# 4. Generar datos sint√©ticos grandes\nbig_practice_data &lt;- data.table(\n  id = 1:10000000,  # 10 millones de filas\n  group = sample(LETTERS, 10000000, replace = TRUE),\n  value = rnorm(10000000),\n  date = sample(seq(as.Date(\"2020-01-01\"), Sys.Date(), by = \"day\"), 10000000, replace = TRUE)\n)",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#desaf√≠os-de-certificaci√≥n",
    "href": "conclusion.html#desaf√≠os-de-certificaci√≥n",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "Desaf√≠os de Certificaci√≥n",
    "text": "Desaf√≠os de Certificaci√≥n\nPara consolidar tu aprendizaje, aqu√≠ tienes desaf√≠os progresivos:\nü•â Nivel Bronce: Fundamentos\n\n\n\n\n\n\nDesaf√≠o 1: Operaciones B√°sicas\n\n\n\nDado un data.table con columnas [id, category, value, date]:\n\nFiltra las filas donde value &gt; 100\n\nCalcula la suma de value por category\n\nA√±ade una columna con el ranking de value dentro de cada category\n\nOrdena por category y -value\n\n\n\n\nü•à Nivel Plata: Intermedio\n\n\n\n\n\n\nDesaf√≠o 2: Joins y Reshape\n\n\n\n\n\nUne dos data.tables usando setkey() para m√°xima eficiencia\n\nConvierte datos de formato ancho a largo usando melt()\n\n\nCalcula medias m√≥viles de 7 d√≠as para una serie temporal\n\nCrea una funci√≥n que automatice este pipeline\n\n\n\nü•á Nivel Oro: Avanzado\n\n\n\n\n\n\nDesaf√≠o 3: Optimizaci√≥n y Rolling Joins\n\n\n\n\n\nImplementa un rolling join para calcular precios de cierre m√°s recientes\n\nOptimiza una funci√≥n que toma &gt;10 segundos usando keys e √≠ndices\n\nCrea una non-equi join para categorizar observaciones por rangos\n\nBenchmarks tu soluci√≥n vs.¬†alternativas de R base/dplyr\n\n\n\nüíé Nivel Diamante: Experto\n\n\n\n\n\n\nDesaf√≠o 4: Aplicaci√≥n Completa\n\n\n\nCrea una aplicaci√≥n Shiny que: 1. Procese datasets &gt;1GB usando data.table 2. Visualice resultados con ggplot2 3. Permita interactividad en tiempo real 4. Integre un modelo predictivo simple 5. Exporte resultados en m√∫ltiples formatos",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#contribuir-al-ecosistema-data.table",
    "href": "conclusion.html#contribuir-al-ecosistema-data.table",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "Contribuir al Ecosistema data.table",
    "text": "Contribuir al Ecosistema data.table\nFormas de Contribuir\n\n\nüêõ Reportar bugs: Con ejemplos reproducibles m√≠nimos\n\nüí° Sugerir mejoras: Features que necesitas en tu trabajo\n\nüìù Documentaci√≥n: Mejorar ejemplos y explicaciones\n\nüß™ Testing: Probar versiones de desarrollo\n\nüìö Tutoriales: Crear contenido para la comunidad\nC√≥digo de Ejemplo Reproducible\n\n# Template para reportar issues\nlibrary(data.table)\n\n# Datos m√≠nimos que reproducen el problema\ndt &lt;- data.table(x = 1:3, y = c(\"a\", \"b\", \"c\"))\n\n# C√≥digo que causa el problema\n# dt[...] # Tu c√≥digo aqu√≠\n\n# Resultado esperado vs. resultado actual\n# Esperado: ...\n# Actual: ...\n\n# Informaci√≥n del sistema\nsessionInfo()",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#el-futuro-de-data.table",
    "href": "conclusion.html#el-futuro-de-data.table",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "El Futuro de data.table",
    "text": "El Futuro de data.table\nDesarrollos Recientes y Futuros\n\n\nüöÄ Performance mejorado: Optimizaciones continuas en el core C\n\nüîó Mejor integraci√≥n: Con Arrow, DuckDB, y herramientas Big Data\n\nüìä Nuevas funcionalidades: Window functions expandidas, m√°s joins especiales\n\nüåê Ecosistema creciente: M√°s paquetes construidos sobre data.table\nTendencias en Data Science donde data.table Brilla\n\n\nBig Data local: Procesamiento de TB en laptops\n\nReal-time analytics: Shiny apps ultra-responsivas\n\nFinancial modeling: Rolling joins para series temporales\n\nIoT data processing: An√°lisis de sensores en tiempo real",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#reflexi√≥n-final-tu-nueva-superheroa",
    "href": "conclusion.html#reflexi√≥n-final-tu-nueva-superheroa",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "Reflexi√≥n Final: Tu Nueva Superheroa",
    "text": "Reflexi√≥n Final: Tu Nueva Superheroa\n\n# Tu evoluci√≥n como data scientist\nevolucion &lt;- data.table(\n  Etapa = c(\"Inicio del tutorial\", \"Despu√©s del tutorial\"),\n  Herramientas = c(\"R base, dplyr b√°sico\", \"data.table experto + ecosistema\"),\n  Performance = c(\"Datasets peque√±os\", \"Big Data sin problemas\"),\n  Productividad = c(\"Horas por an√°lisis\", \"Minutos por an√°lisis\"),\n  Confianza = c(\"Principiante\", \"Experto certificado\")\n)\n\nprint(evolucion)\n#&gt;                   Etapa                    Herramientas            Performance\n#&gt;                  &lt;char&gt;                          &lt;char&gt;                 &lt;char&gt;\n#&gt; 1:  Inicio del tutorial            R base, dplyr b√°sico      Datasets peque√±os\n#&gt; 2: Despu√©s del tutorial data.table experto + ecosistema Big Data sin problemas\n#&gt;           Productividad           Confianza\n#&gt;                  &lt;char&gt;              &lt;char&gt;\n#&gt; 1:   Horas por an√°lisis        Principiante\n#&gt; 2: Minutos por an√°lisis Experto certificado\n\n# Tu nuevo toolkit mental\ncat(\"\\nüß∞ TU TOOLKIT MENTAL ACTUAL:\\n\")\n#&gt; \n#&gt; üß∞ TU TOOLKIT MENTAL ACTUAL:\ncat(\"   ‚Ä¢ DT[i, j, by] - Sintaxis universal\\n\")\n#&gt;    ‚Ä¢ DT[i, j, by] - Sintaxis universal\ncat(\"   ‚Ä¢ := para modificaciones eficientes\\n\") \n#&gt;    ‚Ä¢ := para modificaciones eficientes\ncat(\"   ‚Ä¢ setkey() para performance\\n\")\n#&gt;    ‚Ä¢ setkey() para performance\ncat(\"   ‚Ä¢ Rolling joins para temporal data\\n\")\n#&gt;    ‚Ä¢ Rolling joins para temporal data\ncat(\"   ‚Ä¢ .SD/.SDcols para operaciones complejas\\n\")\n#&gt;    ‚Ä¢ .SD/.SDcols para operaciones complejas\ncat(\"   ‚Ä¢ Integraci√≥n perfecta con ggplot2/shiny\\n\")\n#&gt;    ‚Ä¢ Integraci√≥n perfecta con ggplot2/shiny\n\n\n\n\n\n\n\n\nüéØ Tu Certificado de Maestr√≠a\n\n\n\nCERTIFICAMOS QUE:\nHas completado exitosamente el Tutorial Completo de data.table y ahora posees:\n‚úÖ Conocimiento fundamental de la sintaxis DT[i, j, by]\n‚úÖ Dominio de t√©cnicas avanzadas como rolling joins y reshape\n‚úÖ Habilidades de optimizaci√≥n para Big Data\n‚úÖ Capacidad de integraci√≥n con el ecosistema R\n‚úÖ Experiencia pr√°ctica con ejercicios del mundo real\nEst√°s oficialmente preparado/a para: - Manejar datasets de cualquier tama√±o con confianza - Escribir c√≥digo data.table eficiente y mantenible - Integrar data.table en workflows profesionales - Mentorear a otros en el uso de esta poderosa herramienta\n\n¬°Bienvenido/a al selecto grupo de expertos en data.table! üéâ",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "conclusion.html#agradecimientos",
    "href": "conclusion.html#agradecimientos",
    "title": "Conclusiones y Pr√≥ximos Pasos",
    "section": "Agradecimientos",
    "text": "Agradecimientos\nEste tutorial fue posible gracias a:\n\n\nMatt Dowle y el equipo de desarrollo de data.table\n\n\nLa comunidad R que mantiene el ecosistema vibrante\n\nLos contribuidores que reportan bugs y mejoran la documentaci√≥n\n\nT√∫, por completar este viaje de aprendizaje\n\n\n\n\n\n\n\n\nüöÄ Pr√≥ximo Paso: ¬°√ösalo en el Mundo Real!\n\n\n\nNo dejes que este conocimiento se oxide. Tu pr√≥xima misi√≥n:\n\n\nIdentifica un proyecto actual donde puedas aplicar data.table\n\n\nRefactoriza c√≥digo existente para aprovechar la velocidad de data.table\n\n\nComparte tu experiencia con colegas y la comunidad\n\nMantente actualizado con las nuevas versiones y caracter√≠sticas\n\nEl mundo de los datos te espera. ¬°Ve y conqu√≠stalo con data.table! üí™\n\n\n\n¬°Gracias por acompa√±arnos en este viaje! Tu adventure con data.table apenas comienza‚Ä¶ üåü\n\nTutorial generado el 20 de agosto de 2025 con R R version 4.4.2 (2024-10-31 ucrt) y data.table 1.17.0",
    "crumbs": [
      "Conclusiones y Pr√≥ximos Pasos"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "Referencias",
    "section": "",
    "text": "Referencias Acad√©micas y T√©cnicas\nEste tutorial se basa en la documentaci√≥n oficial de data.table, art√≠culos de la comunidad, y a√±os de experiencia pr√°ctica con la herramienta. A continuaci√≥n se presentan las referencias clave consultadas.",
    "crumbs": [
      "Referencias"
    ]
  },
  {
    "objectID": "references.html#enlaces-√∫tiles-adicionales",
    "href": "references.html#enlaces-√∫tiles-adicionales",
    "title": "Referencias",
    "section": "Enlaces √ötiles Adicionales",
    "text": "Enlaces √ötiles Adicionales\n\nDocumentaci√≥n Oficial\n\ndata.table en CRAN: https://cran.r-project.org/package=data.table\nVi√±etas del paquete: Ejecuta browseVignettes(\"data.table\") en R\nAyuda integrada: ?data.table, ?setkey, ?merge.data.table en R\n\n\n\nComunidad y Soporte\n\nStack Overflow: Preguntas etiquetadas con data.table\nGitHub del proyecto: https://github.com/Rdatatable/data.table\nReddit r/rstats: Comunidad activa de usuarios de R\n\n\n\nRecursos de Aprendizaje\n\nR for Data Science: https://r4ds.hadley.nz/\nAdvanced R: https://adv-r.hadley.nz/\nR-bloggers: https://www.r-bloggers.com/\n\n\n\nComparaciones y Benchmarks\n\nVincent Arel-Bundock: Comparaciones detalladas de performance\nH2O.ai benchmarks: https://h2oai.github.io/db-benchmark/\nThe Raft blog: Art√≠culos t√©cnicos de la comunidad data.table\n\n\n\nDatasets para Pr√°ctica\n\nNYC Open Data: https://opendata.cityofnewyork.us/\nKaggle Datasets: https://www.kaggle.com/datasets\nUCI ML Repository: https://archive.ics.uci.edu/ml/index.php\n\n\n\n\n\n\n\n\nNota sobre las Referencias\n\n\n\nEste tutorial est√° dise√±ado para ser un recurso educativo comprehensivo. Las t√©cnicas y ejemplos presentados est√°n basados en las mejores pr√°cticas de la comunidad data.table y han sido verificados contra la documentaci√≥n oficial m√°s reciente.\nPara mantenerte actualizado con los cambios en data.table, recomendamos seguir el repositorio oficial en GitHub y las notas de nuevas versiones.\n\n\n\n√öltima actualizaci√≥n el r format(Sys.Date(), \"%d de %B de %Y\") con R r R.version.string y data.table r packageVersion(\"data.table\")",
    "crumbs": [
      "Referencias"
    ]
  }
]